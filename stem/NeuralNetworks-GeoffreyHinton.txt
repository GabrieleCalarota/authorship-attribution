hello .
welcom to the coursera cours on neural network for machin learn .
befor we get into the detail of neural network learn algorithm , i want to talk a littl bit about machin learn , why we need machin learn , the kind of thing we us it for , and show you some exampl of what it can do .
so the reason we need machin learn is that the sum problem , where it's veri hard to write the program , recogn a three dimension object for exampl .
when it's from a novel viewpoint and new light addit in a clutter scene is veri hard to do .
we don't know what program to write becaus we don't know how it's done in our brain .
and even if we did know what program to write , it might be that it wa a horrend complic program .
anoth exampl is , detect a fraudul credit card transact , where there mai not be ani nice , simpl rule that will tell you it's fraudul .
you realli need to combin , a veri larg number of , not veri reliabl rule .
and also , those rule chang everi time becaus peopl chang the trick thei us for fraud .
so , we need a complic program that combin unreli rule , and that we can chang easili .
the machin learn approach , is to sai , instead of write each program by hand for each specif task , for particular task , we collect a lot of exampl , and specifi the correct output for given input .
a machin learn algorithm then take these exampl and produc a program that doe the job .
the program produc by the linear algorithm mai look veri differ from the typic handwritten program .
for exampl , it might contain million of number about how you weight differ kind of evid .
if we do it right , the program should work for new case just as well as the on it's train on .
and if the data chang , we should be abl to chang the program run veri easili by retrain it on the new data .
and now massiv amount for comput ar cheaper that pai someon to write a program for a specif task , so we can afford big complic machin learn program to produc these stark task specif system for us .
some exampl of the thing that ar best done by us a learn algorithm ar recogn pattern , so for exampl object in real scene , or the ident or express of peopl's face , or spoken word .
there's also recogn anomali .
so , an unusu sequenc of credit card transact would be an anomali .
anoth exampl of an anomali would be an unusu pattern of sensor read in a nuclear power plant .
and you wouldn't realli want to have to deal with those by do supervis learn .
where you look at the on that blow up , and see what , what caus them to blow up .
you'd realli like to recogn that someth funni is happen without have ani supervis signal .
it's just not behav in it normal wai .
and then thi predict .
so , typic , predict futur stock price or currenc exchang rate or predict which movi a person will like from know which other movi thei like .
and which movi a lot of other peopl like .
so in thi cours i'm mean as a standard exampl for explain a lot of the machin learn algorithm .
thi is done in a lot of scienc .
in genet for exampl , a lot of genet is done on fruitfli .
and the reason is thei're conveni .
thei breed fast and a lot is alreadi known about the genet of fruit fli .
the mnist databas of handwritten digit is the machin equival of fruitfli .
it's publicli avail .
we can get machin learn algorithm to learn how to recogn these handwritten digit quit quickli , so it's easi to try lot of variat .
and we know huge amount about how well differ machin learn method do on mnist .
and in particular , the differ machin learn method were implement by peopl who believ in them , so we can reli on those result .
so for all those reason , we're gonna us mnist as our standard task .
here's an exampl of some of the digit in mnist .
these ar on that were correctli recogn by neural net the first time it saw them .
but the on within the neural net wasn't veri confid .
and you could see why .
i've arrang these digit in standard scan line order .
so zero , then on , then two and so on .
if you look at a bunch of tube like the onc in the green rectangl .
you can see that if you knew thei were <num> in digit you'd probabl guess thei were two .
but it's veri hard to sai what it is that make them two .
there noth simpl that thei all have in common .
in particular if you try and overlai on on anoth you'll see it doesn't fit .
and even if you skew it a bit , it's veri hard to make them overlai on each other .
so a templat isn't go to do the job .
an in particular templat is go to be veri hard to find that will fit those two in the green box and would also fit the thing in the red box .
so that's on thing that make recogn handwritten digit a good task for machin learn .
now , i don't want you to think that's the onli thing we can do .
it's a rel simpl for our machin learn system to do now .
and to motiv the rest of the cours , i want to show you some exampl of much more difficult thing .
so we now have neural net with approach a hundr million paramet in them , that can recogn a thousand differ object class in <num> million high resolut train imag got from the web .
so , there wa a competit in <num> , and the best system got <num> percent error rate if you look at it first choic , and <num> percent error rate if you sai it got it right if it wa in it top five choic , which isn't bad for <num> , <num> differ object .
jitendra malik who's an emin neural net skeptic , and a lead comput vision research , ha said that thi competit is a good test of whether deep neural network can work well for object recognit .
and a veri deep neural network can now do consider better than the thing that won the competit .
it can get less than <num> percent error , for it first choic , and less than twenti percent error for it top five choic .
i'll describ that in much more detail in lectur five .
here's some exampl of the kind of imag you have to recogn .
these imag from the test set that he's never seen befor .
and below the exampl , i'm show you what the neural net thought the right answer wa .
where the length of the horizont bar is how confid it wa , and the correct answer is in red .
so if you look in the middl , it correctli identifi that as a snow plow .
but you can see that it other choic ar fairli sensibl .
it doe look a littl bit like a drill platform .
and if you look at it third choic , a lifeboat , it actual look veri like a lifeboat .
you can see the flag on the front of the boat and the bridg of the boat and the flag at the back , and the high surf in the background .
so it , it error tell you a lot about how it's do it and thei're veri plausibl error .
if you look on the left , it get it wrong possibl becaus the beak of the bird is miss and cuz the feather of the bird look veri like the wet fur of an otter .
but it get it in it top five , and it doe better than me .
i wouldn't know if that wa a quail or a ruf grous or a partridg .
if you look on the right , it get it complet wrong .
it a guillotin , you can why it sai that .
you can possibl see why it sai orangutan , becaus of the sort of jungl look background and someth orang in the middl .
but it fail to get the right answer .
it can , howev , deal with a wide rang of differ object .
if you look on the left , i would have said microwav as my first answer .
the label aren't veri systemat .
so actual , the correct answer there is electr rang .
and it doe get it in it top five .
in the middl , it's get a turnstil , which is a distribut object .
it doe , can't , it can do more than just recogn compact thing .
and it can also deal with pictur , as well as real scene , like the bulletproof vest .
and it make some veri cool error .
if you look at the imag on the left , that's an earphon .
it doesn't get anyth , like an earphon .
but if you look at thi fourth batch , it think it's an ant .
and for you to think that's crazi .
but then if you look at it carefulli , you can see it's a view of an ant from underneath .
the ey ar look down at you , and you can see the antenna behind it .
it's not the kind of view of an ant you'd like to have if you were a green fly .
if you look at the on on the right , it doesn't get the right answer .
but all of it answer ar , cylindr object .
anoth task that neural net ar now veri good at , is speech recognit .
or at least part of a speech recognit system .
so speech recognit system have sever stage .
first thei pre process the sound wave , to get a vector of acoust coeffici , for each ten millisecond of sound wave .
and so thei get <num> of those actor per second .
thei then take a few adjac vector of acoust coeffici , and thei need to place bet on which part of which phonem is be spoken .
so thei look at thi littl window and thei sai , in the middl of thi window , what do i think the phonem is , and which part of the phonem is it ?
and a good speech recognit system will have mani altern model for a phonem .
and each model , it might have three differ part .
so it might have mani thousand of altern fragment that it think thi might be .
and you have to place bet on all those thousand of altern .
and then onc you place those bet you have a decod stage that doe the best job it can of us plausibl bet , but piec them togeth into a sequenc of bet that correspond to the kind of thing that peopl sai .
current , deep neural network pioneer by georg dahl and abdel rahman moham of the univers of toronto ar do better than previou machin learn method for the acoust model , and thei're now begin to be us in practic system .
so , dahl and moham , develop a system , that us mani layer of , binari neuron , to , take some acoust frame , and make bet about the label .
thei were do it on a fairli small databas and then us <num> altern label .
and to get their system to work well , thei did some pre train , which will be describ in the second half of the cours .
after standard post process , thei got <num> percent error rate on a veri standard benchmark , which is kind of like the nmist for speech .
the best previou result on that benchmark for speak independ recognit wa <num> .
and a veri experienc speech research at microsoft research realiz that , that wa a big enough improv , that probabl thi would chang the wai speech recognit system were done .
and inde , it ha .
so , if you look at recent result from sever differ lead speech group , microsoft show that thi kind of deep neural network , when us as the acoust model in the speech system .
reduc the error rate from <num> percent to <num> , or altern , you could view it as reduc the amount of train data you need from <num> , <num> hour down to <num> hour to get compar perform .
ibm which ha the best system for on of the standard speech recognit task for larg recoveri speech recognit , show that even it's veri highli tune system that wa get <num> percent can be beaten by on of these deep neural network .
and googl , fairli recent , train a deep neural network on a larg amount of speech , <num> , <num> hour .
that wa still much less than thei train their mixtur model on .
but even with much less data , it did a lot better than the technolog thei had befor .
so it reduc the error rate from sixteen percent to <num> percent and the error rate is still fall .
and in the latest android , if you do voic search , it's us on of these deep neural network in order to do veri good speech recognit .
in thi video , i'm gonna tell you a littl bit about real neuron on the real brain which provid the inspir for the artifici neural network that we're gonna learn about in thi cours .
in most of the cours , we won't talk much about real neuron but i want to give you a quick overview of the begin .
there's sever differ reason to studi how network of neuron can comput thing .
the first is to understand how the brain actual work .
you might think we could do that just by experi on the brain .
but it's veri big and complic , and it di when you poke it around .
and so we need to us comput simul to help us understand what we're discov in empir studi .
the second is to understand the style of parallel comput , thi inspir by the fact that the brain can comput with a big parallel network , a world of rel slow neuron .
if you can understand that style of parallel comput we might be abl to make better parallel comput .
it's veri differ from the wai comput is done on a convent serial processor .
it should be veri good for thing that brain ar good at like vision , and it should also be bad for thing that brain ar bad at by multipli two number togeth .
a third reason , which is the relev on for thi cours , is to solv practic problem by us novel learn algorithm that were inspir by the brain .
these algorithm can be veri us even if thei're not actual how the brain work .
so in most of thi cours we won't talk much about how the brain actual work .
it's just us as a sourc of inspir to tell us the big , parallel network of neuron can comput veri complic thing .
i'm gonna talk more in thi video though about how the brain actual work .
a typic cortic neuron ha a gross physic structur that consist of a cell bodi , and an axon where it send messag to other neuron , and a denditr tree where it receiv messag from other neuron .
where an axon from on neuron contact a dendrit tree of anoth neuron , there's a structur call a synaps .
and a spike of activ travel along the axon , caus charg to be inject into the post synapt neuron at a synaps .
a neuron gener spike when it's receiv enough charg in it dendrit tree to depolar a part of the cell bodi call the axon hillock .
and when that get depolar , the neuron send a spike out along it axon .
and the spike's just a wave of depolar that travel along the axon .
synaps themselv have interest structur .
thei contain littl vesicl of transmitt chemic and when a spike arriv in the axon it caus these vesicl to migrat to the surfac and be releas into the synapt cleft .
there's sever differ kind of transmitt chemic .
there's on that implement posit weight and on that implement neg weight .
the transmitt molecul diffus across the synapt clef and bind to receptor molecul in the membran of the post synapt neuron , and by bind to these big molecul in the membran thei chang their shape , and that creat hole in the membran .
these hole ar like specif ion to flow in or out of the post synapt neuron and that chang their state of depolar .
synaps adapt , and that's what most of learn is , chang the effect of a synaps .
thei can adapt by vari the number of vesicl that get releas when a spike arriv .
or by vari the number of receptor molecul that ar sensit to the releas transmitt molecul .
synaps ar veri slow compar with comput memori .
but thei have a lot of advantag over the random access memori on a comput , thei're veri small and veri low power .
and thei can adapt .
that's the most import properti .
thei us local avail signal to chang their strength , and that's how we learn to perform complic comput .
the issu of cours is how do thei decid how to chang their strength ?
what is the , what ar the rule for how thei should adapt .
so , all on on slide thi is how the brain work .
each neuron receiv input from other neuron .
a few of the neuron receiv input from the receptor .
it's a larg number of neuron , but onli a small fraction of them .
and , the neuron commun with each other within in the cortex by send these spike of activ .
the effect in input line on a neuron is control by synapt weight , which can be posit or neg .
and these synapt weight adapt .
and by adapt these weight the whole network learn to perform differ kind of comput .
for exampl recogn object , understand languag , make plan , control the movement of your bodi .
you have about ten to the eleven neuron , each of which ha about ten to the four weight .
so you probabl ten to the fifteen or mayb onli about ten to the fourteen synapt weight .
and a huge number of these weight , quit a larg fraction of them , can affect the ongo comput in a veri small fraction of a second , in a few millisecond .
that's much better bandwidth to store knowledg than even a modern workstat ha .
on final point about the brain is that the cortex is modular , at least it learn to be modular .
differ bit of the cotex end up do differ thing .
genet , the input from the sens go to differ bit of the cortex .
and that determin a lot about what thei end up do .
if you damag the brain of an adult , local damag to the brain caus specif effect .
damag to on place might caus you to lose your abil to understand languag .
damag to anoth place might caus you to lose your abil to recogn object .
we know a lot about how function ar locat in the brain becaus when you us a part of the brain for do someth it requir energi , and so it demand more blood flow , and you can see the blood flow in a brain scanner .
that allow you to see which bit of the brain you're us for particular task .
but the remark thing about cortex is it look pretti much the same all over , and that strongli suggest that it's got a fairli flexibl univers learn algorithm in it .
that's also suggest by the fact that if you damag the brain earli on , function will reloc to other part of the brain .
so it's not genet predetermin , at least not directli , which part of the brain will perform which function .
there's convinc experi on babi ferret that show that if you cut off the input to the auditori cortex that come from the ear , and instead , rerout the visual input to auditori cortex , then the auditori cortex that wa destin to deal with sound will actual learn to deal with visual input , and creat neuron that look veri like the neuron in the visual system .
thi suggest the cortex is made of gener purpos stuff that ha the abil to turn into special purpos hardwar for particular task in respons to experi .
and that give you a nice combin of , rapid parallel comput onc you have learnt , plu flexibl , so you can put , you can learn new function , so you ar learn , to do the parallel comput .
it quiet like a fpga , where you build standard parallel hardwar , then after it built , you put in inform that tell it what particular parallel comput to do .
convent comput get their flexibl by have a store sequenti program .
but thi requir veri fast central processor to access the line in the sequenti program and perform long sequenti comput .
in thi video , i'm go to describ some rel simpl model of neuron .
i'll describ a number of differ model start with simpl linear and threshold neuron , and then , describ slightli more complic model .
these ar much simpler than real neuron , but thei're still complic enough , to allow us to make neural net , that do some veri interest kind of machin learn .
in order to understand anyth complic , we have to ideal it .
that is , we have to make simplif that allow us to get a handl on how it might work .
with atom , for exampl , we simplifi them as behav like littl solar system .
ideal remov the complic detail that ar not essenti for understand the main principl .
it allow us to appli mathemat , and to make analog to other familiar system .
and onc we understand the basic principl , it's easi to add complex , and make the model more faith to realiti .
of cours , we have to be care when we ideal someth , not to remov the thing that's give it it main properti .
it's often worth understand model that ar known to be wrong , as long as we don't forget thei're wrong .
so for exampl , a lot of work on neural network us neuron that commun real valu rather than discret spike of activ , and we know cortic neuron don't behav like that , but it's still worth understand system like that , and in practic thei can be veri us for machin learn .
the first kind of neuron i want to tell you about is the simplest , it's a linear neuron .
it's simpl .
it's computation limit in what it can do .
it mai allow us to get insight into more complic neuron .
but it mai be somewhat mislead .
so in a linear neuron , the output y .
is a function of a bi asset in your run b and the sum of all it incom connect of the activ on an input line time the weight on that line that's the synapt weight on the input line and if you plot that as curv , then if you plot on the x axi , the buyer plu the weight activ on the input line we get a straight line that goe through zero .
veri differ from linear neuron , ar binari threshold neuron that were introduc by mcculloch and pitt .
thei actual influenc von roenam when he wa think about how to design a univers comput .
in a binari threshold neuron you first comput a weight sum of the input and then you send out a spike of activ if that weight sum exce the threshold .
and pitt thought that the spike were like the truth valu of proposit .
so each neuron is combin the truth valu it get from other neuron to produc the truth valu of it own .
and that's like combin some proposit to comput the truth valu of anoth proposit .
at the time in the <num>'s logic wa the main paradigm for how the mind might work .
sinc then peopl think about how the brain comput have becom much more interest in the idea the brain is combin lot of differ sourc of unreli evid .
and so logic isn't such a good pardigm for what the brain's up to .
for a binari threshold neuron , you can think of it input output function as if the weight input is abov the threshold , it give an output of on .
otherwis , it give an output of zero .
there ar actual two equival wai to write the equat for a binari threshold neuron .
we can sai that the total input z is just the activ on the input line time the weight .
and then the output y is on if that z is abov the threshold and zero otherwis .
altern , we could sai that the total input includ a bia term .
so the total input is what come in on the input line , time the weight , plu thi bia term .
and then we could sai the output is on if that total input is abov zero and is zero otherwis .
and the equival is simpli that the threshold in first formul is equal to the neg of the bia in the second formul .
a kind of neuron that combin the properti of both linear neuron and binari threshold neuron is a rectifi linear neuron .
it first comput a linear weight sum of it input , but then it give an output that's a non linear function of thi weight sum .
so we comput z in the same wai as befor .
if z is below zero , we give an output of zero .
otherwis , we give an output that's equal to z .
so abov zero is linear , and at zero , it make a hard decis .
so the input output curv look like thi .
it's definit not linear , but abov zero it is linear .
so with a neuron like thi , we can get a lot of the nice properti of linear system , when it's abov zero .
we can also get the abil to make decis , at zero .
the neuron that we'll us a lot in thi cours , and ar probabl the commonest kind of neuron to us in artifici neuron , ar sigmoid neuron .
thei give a real valu output that is a smooth and bound function of their total input .
it's typic to us the logist function , where the total input is comput as befor , as a bia plu what come in on the input line , weight .
the output for a logist neuron is on over on plu e to the minu , the total input .
if you think about that , if the total input's big and posit .
e to the minu a big posit number is zero .
and so , the output will be on .
if the total input's big and neg , e to the minu a big neg number is a larg number , and so the output will be zero .
so the input output function look like thi .
when , the total input's zero , e to the minu zero is on , so the output's a half .
and the nice thing about a sigmoid is it ha , smooth deriv .
the deriv , chang continu .
and , so thei're nice behav , and thei make it easi to do learn as we'll see in lectur three .
final the stochast binari neuron .
thei us just the same equat as logist unit .
thei comput their total input the same wai and thei us the logist function to comput a real valu which is the probabl that thei will output a spike .
but then instead of output that probabl as a real number thei actual make a probabilist decis , and so what thei actual output is either a on or a zero .
thei're intrins random .
so thei're treat the p as the probabl of produc a on , not as a real number .
of cours , if the input is veri big and posit thei will almost alwai produc a on .
if the input's big and neg thei'll almost alwai produc a zero .
we can do a similar trick with rectifi linear unit .
we can sai that the output , there's real valu that come out of a rectifi linear unit , if it input is abov zero , is the rate of produc spike .
so that's determinist .
but onc we've figur out these rate of produc spike , the actual time at which spike ar produc is a random process .
it's a poisson process .
so the rectifi linear unit determin the rate , but intrins random in the unit determin when the spike ar actual produc .
in thi video i am go to show you an exampl of machin learn it is a veri simpl kind of neuralnet and it is gonna be learn to recogn digit .
and you gonna be abl to see how the weight evolv , as we run a veri simpl learn algorithm .
so we gonna look at the veri simpl learn algorithm for train a veri simpl network to recogn handwritten shape .
the network ha two layer of neuron .
it ha got input neuron .
whose activ repres the intens of pixel , and output neuron , whose activ repres the class class .
what we'd like is that when we show a particular shape .
the output neuron for that shape get activ .
if a pixel is activ what it doe is it vote for particular shape .
name the shape that contain that pixel .
each ink pixel can vote for sever shape .
and the vote can have differ intens , the shape that get the most vote win .
so we ar assum there is a competit between the output unit .
and that someth i haven't explain yet will explain in a later lectur .
so first , we need to decid how to displai the weight .
and it seem natur to write the weight on the connect between input unit and output unit .
but , we ar never abl to see what wa go on if we get that .
we need a displai in which we can see the valu of thousand of weight .
so the idea is for each output unit , we make a littl map .
and in that map we show the strength of connect come from each input pixel in the locat of that input pixel .
and we show the strength of connect by us black and white blob , whose area repres the magnitud .
and whose sign repres , whose color repres the sign .
so the initi weight that you see there ar just small random weight .
now what we ar gonna do is show that network some data and get it to learn weight that ar better than the random weight .
the wai we ar gonna look is when we show it an imag , we ar go to increment the weight from the activ pixel in the imag to the correct class if we just did that , the weight could get onli bigger and eventu everi class will get huge input whenev we show it to the imag .
so we need some wai of keep the weight under the control .
what we gonna do is we will also gonna decrement the weight from the activ pixel to whatev class the network guess .
so ? ? train it to the right thing , rather than ? ? current ha a tendenc to do .
if of cours it doe the right thing , then the increment we make , in the first step the learn rule will exactli cancel the decrement so noth will chang , which is what we want to .
so , these ar the initi weight .
now we ar go to show you few hundr train exampl and then look at the weight again .
so now the weight have chang , thei start to form regular pattern .
and we show it a few more hundr exampl .
and the weight have chang small , and a few more hundr exampl .
and a few more hundr exampl .
few more hundr .
and now the weight ar pretti much at their final valu .
i'll talk more in futur lectur about precis detail of the learn algorithm .
but what you can see is the weight now look like the littl templat from the shape .
if you look at the weight go into the on unit for exampl , thei don't ? ? littl templat for identifi on .
thei ar not quit templat .
if you look at the weight go into the nine unit , thei don't have ani posit weight below the half wai line .
that's becaus for tell the differ between 9s and 7s the weight below the half wai line aren't much us .
you have to tell the differ by decid whether there is a loop at the top or horizont bar at the top .
and so , those output unit ar focus on that discrimin .
on thing about thi learn algorithm is becaus the network is so simpl , it's unabl to learn a veri good wai of discrimin shape .
what it learn is equival to have a littl templat for each shape .
and then decid the winner base on which shape ha the templat that overlap most with the ink .
the problem is that the weight in which handwritten digit vari ar much too complic to be captur by simpl templat match of whole shape .
you have to model allow variat for digit .
by first extract featur and then look arrang of those featur .
so here is exampl we have seen alreadi .
if you look at those <num>'s in green box .
you can see there is no templat that will fit all those well and will fail to fit that <num> in the red box there .
so task simpli can't be solv by a simpl network like that .
the network did the best it could but it can't solv thi problem .
in thi video , i'm gonna talk about three differ type of machin learn supervis learn , reinforc learn and unsupervis learn .
broadli speak , the first half of the cours will be about supervis learn .
the second half of the cours will be mainli about unsupervis learn , and reinforc learn will not be cover in the cours , becaus we can't cover everyth .
learn can be divid into three broad group of algorithm .
in supervis learn , you're try to predict an output when given an input vector , so it's veri clear what the point of supervis learn is .
in reinforc level , you're try to select action or sequenc of action to maxim the reward you get , and the reward mai onli occur occasion .
in unsupervis learn you're try to discov a good intern represent of the input and we'll come later to what that might mean .
supervis learn itself come in two differ flavor .
in regress , the target output is a real number or a whole vector of real number , such as the price of a stock in six month time , or the temperatur at noon tomorrow .
and the aim is to get as close as you can to the correct real number .
in classif , the target output is a class label .
the simplest case is a choic between on and zero .
between posit and neg case .
but obvious , we can have multipl altern label as when we're classifi handwritten digit .
supervis learn work by initi select a model class , that is , a whole set of model that we're prepar to consid as candid .
you can think of a model class as a function that take an input vector and some paramet and give you an output y .
so a model class is simpli a wai of map .
an input to an output us some numer paramet w and then we adjust these numer paramet to make the map fit the supervis train data .
what we mean by fit is minim the discrep between the target output on each train case and the actual output produc by a machin learn system .
and an obviou measur of that discrep , if we're us real valu as output , is the squar differ between the output from our system y , and the correct output t , and we put in that on half , so it cancel the two when we differenti .
for classif you could us that measur , but there's other more sensiblb measur which we'll come to later , and these more sensibil measur typic work better as well .
in reinforc learn , the output an actual sequenc of action , and you have to decid on those action base on occasion reward .
the goal in select each action is to maxim the expect sum of the futur reward , and we typic us a discount factor so that you don't have to look too far in the futur .
we sai that reward far in the futur don't count for as much as reward that you get fairli quickli .
reinforc learn is difficult .
it's difficult becaus the reward ar typic delai , so it's hard to know exactli which action wa the wrong on in a long sequenc of action .
it's also difficult becaus a scalar award , especi on that onli occur occasion , doe not suppli much inform , on which to base the chang in paramet .
so typic , you can't learn million of paramet us reinforc learn .
wherea supervis learn and unsupervis learn , you can .
typic , in reinforc learn , you're try to learn dozen of paramet or mayb <num> , <num> paramet , but not million .
in thi cours , we can't cover everyth , and so we're not go to cover reinforc learn , even though it's an import topic .
unsupervis learn , is go to be cover in the second half of the cours .
for about <num> year , the machin learn commun basic ignor unsupervis learn except for on veri limit form call cluster .
in fact , thei us definit of machin learn that exclud it .
so thei defin machin learn , in some textbook , as map from input to output .
and mani research thought that cluster wa the onli form of unsupervis learn .
on reason for thi is that it's hard to sai what the aim of unsupervis learn is .
on major aim is to get an intern represent of the input , that is us for subsequ supervis or reinforc learn .
and the reason we might want to do that in two stage , is we don't want to us , for exampl , the payoff from reinforc learn , in order to set the paramet , for our visual system .
so you can comput the distanc to a surfac by us the dispar between the imag you get in your two ey .
but you don't want to learn to do that comput of distanc by repeatedli stub your toe and adjust the paramet in your visual system everi time you stub your toe .
that would involv stub your toe a veri larg number of time and there's much better wai to learn to fuse two imag base pure on the inform in the input .
other goal for unsupervis learn ar to provid compact , low dimension represent of the input .
so , high dimension input like imag , typic , live on or near a low dimension manifold .
or sever such manifold in the case of the handwritten digit .
what that mean is , even if you have a million pixel , there aren't realli a million degre of freedom in what can happen .
there mai onli be a few hundr degre of freedom in what can happen .
so what we want to do is move from a million pixel to a represent of those few hundr degre of freedom which will be accord to sai where we ar on a manifold .
also we need to know which manifold we're on .
a veri limit form of thi is principl command analysi which is linear .
it assum that there's on manifold , and the manifold is a plane in the high dimension space .
anoth definit of unsupervis learn , or anoth goal for unsupervis learn , is to prov , to provid an econom represent for the input in term of learn featur .
if , for exampl , we can repres the input in term of binari featur , that's typic econom cuz then it take onli on bit to sai the state of a binari featur .
altern we could us a larg number of real valu featur but insist that for each input almost all of those featur ar exactli zero .
in that case for each input we onli need to repres a few real number and that's econom .
as i mention befor , anoth definit of unsupervis learn or anoth goal of unsupervis learn is to find cluster in the input , and cluster could be view as a veri spars code , that is we have on featur per cluster and we insist that all the featur except on ar zero and that on featur ha a valu of on .
so cluster is realli just an extrem case of find spars featur .
in thi video , i'm go to talk about the reason why we want to combin mani model when we're make predict .
if we have a singl model , we have to choos some capac for it .
if we choos too littl capac , it would be abl to fit the regular in the train data .
and if we choos too much capac , it won't be abl to fit the sampl error in the particular train set we have .
by us mani model , we can actual get a better tradeoff between fit the true regular , and overfit the sampl error in the data .
at the start of the video , i'll show you that when you averag model togeth , you can expect to do better than ani singl model .
thi effect is largest when the model make veri differ predict from each other .
and at the end of thi video , i'll discuss variou wai in which we can encourag the differ model to make veri differ predict .
as we've seen befor , when we have a limit amount of train data , we tend to get overfit .
if we averag the predict of mani differ model we can typic reduc that overfit .
thi help most when the model make veri differ predict from on anoth .
for regress , the squar arrow can be decompos into a bia term and a varianc term .
and that allow us to analyz what's go on .
the bia term is big if the model ha too littl capac to fit the data .
it measur how poorli the model approxim the true function .
the varianc term is big if the model ha so much capac that it's good at model the sampl error in our particular train set .
so , it's call varianc , becaus if we go and get anoth train set of the same size from the same distribut , our model will fit differ to that train set , becaus it ha differ sampl error .
and so we'll get varianc in the wai the model fit to differ train set .
if we averag model togeth , what we're do is we're averag awai the varianc , and that allow us to us individu model that have high capac and therefor high varianc .
these high capac model typic have low bia .
so we can get the low bia without incur the high varianc by us averag to get rid of the varianc .
so now let's try and analyz how an individu model compar with an averag of model .
on ani on test case some individu predictor mai be better than the combin predictor .
the differ individu predictor will be better on differ case .
and if the individu predictor disagre a lot , the combin predictor is typic better than all of the individu predictor when we averag over test case .
so we should aim to make the individu predictor disagre , without make them be poor predictor .
the art is to have individu predictor that make veri differ error from on anoth , but ar each fairli accur .
so , now let's look at the math and what happen when we combin network .
we're go to compar two expect squar error .
the first expect squar error is the on we get if we pick on of the predictor at random and us that for make our predict .
and then what we do is we averag overal predictor , the error we'd expect to get if we follow that polici .
so y bar is the averag of what all the predictor sai , and yi is what an individu predictor sai .
so y bar is just the expect over all the individu predictor i of yi and i'm us those angl bracket to repres an expect , where the thing that come after the angl bracket tell you what it's an expect over .
we can write the same thing as on over n time the sum overal of the n of the yi .
now , if we look at the expect squar error we'd get if we chose a predictor at random , what we'd have to do is compar that predictor with the target , take the squar differ .
and then averag that over all predictor .
that's also on the left hand side there .
if i simpli add a y bar and subtract a y bar , i don't chang the valu .
and now it's go to be easier to do some manipul .
i can now multipli it that squar and insid thi expect bracket i have t minu y bar squar , y i minu y bar squar , and t minu y bar into y i minu y bar , which ha the c will disappear .
so the first term , t minu y bar squar , doesn't have an i in it anymor , and so we can forget about the expect bracket for that .
that realli is t minu y bar squar .
and that's the squar arrow you'd get if you compar the averag of the model with the target .
and our aim is to show the thing on the left hand side is bigger than that , i . e . , by us that averag , we've reduc the expect squar error .
so the extra term we have on the right hand side , is the expect of y i minu y bar squar .
and that's just the varianc of the y i .
it's the expect squar differ between y i and y bar .
and then the last tone disappear , it disappear becaus the differ of y i from y bar we expect to be uncorrel with the differ between the arrow that the averag of the network make on the target .
and so we're multipli togeth two thing that ar zero mean and uncorrel and we expect to get zero on averag .
so the result is that the expect squar error we get by pick a model at random is greater than the squar error we get by averag the model by the varianc of the output of the model .
that's how much we win by when we take an averag .
so , i want to show you that in a pictur .
so , along the horizont line , we have the possibl valu of the output , and in thi case , all of the differ model predict a valu that is too high .
the predictor that ar further than averag from t make bigger than averag squar error , like that bad gui in red , and the predictor that ar less than the averag distanc from t make smaller than averag squar arrow .
and the first effect domin , becaus we're us squar error .
so if you look at the math , let's suppos that the good gui and the bad gui were equal far from the mean .
so the averag squar error thei make is y bar minu epsilon squar plu y bar plu epsilon squar .
and when we work that out , we get the squar error that the mean of the predictor make , plu an epsilon squar .
so we win by averag predictor befor we compar them with the target .
that's not alwai true .
it depend veri much on us a squar error .
if , for exampl , you have a whole bunch of clock .
and you try and make them more accur by averag them all , that'll be a disast .
and it'll be a disast becaus the nois you expect in clock isn't gaussian nois .
what you expect is that , mani of them will be veri slightli wrong and a few of them will have stop or will be wildli wrong .
and if you averag , you make sure thei ar all significantli wrong , which is not what you want .
the same thing appli to the discret distribut as we have our class label probabl .
so suppos that we have two model , and on give the correct label of probabl of pi  , and the other give the correct label of probabl of pj .
is it better to pick on model at random , or it is it better to averag those two probabl , and predict the averag of pi  and pj .
what if i had a measur is the log probabl of get the right answer ?
then , the log of the averag of pi  and pj is go to be a better bet than the log of pi  plu the log of pj averag .
that's most easili seen in a diagram becaus of the shape of the log function .
so that black curv is the log .
on the horizont access i've drawn pi  and pj , and the gold color line , join log pi  to log pj .
you can see that if we first start with pi  and pj togeth , to get that averag valu at the blue arrow is , and then we comput the log , we get that blue dot .
wherea if we first take the log of pi  , and separ take the log of pj , and then we averag those two log , we get the mid point of that gold line , which is below the blue dot .
so to make thi averag be a big win , we want our predictor to differ by a lot .
and there's mani differ wai to make them differ .
you could just reli on a learn algorithm that doesn't work too well , and get stuck in differ local optima each time .
it's not a veri intellig thing to do , but it's worth a try .
you could us lot of differ kind of model , includ on that ar not neural network .
so , it make sens to try decis tree , gaussian process model , support vector machin .
i'm not explain ani of those in thi cours .
in andrew ng's machin on coursera , you can learn about all those thing .
well you could try mani other differ kind of model .
if you realli want to us a bunch of differ neural network model , you can make them differ by us a differ number of hidden layer or a differ number of unit per layer or differ type of unit .
like in some net you could us rectifi linear unit , and in other net you could us logist unit .
you could us differ type or strength of weight penalti .
so you might us earli stop for some net , and an l2 weight penalti for other , and an l1 weight penalti for other .
you could us differ learn algorithm .
so for exampl you could us full batch for some , and mini batch for other , if your data set is small enough to allow that .
you can also make the model differ by train the model on differ train data .
so , there's a method introduc by leo breiman call bag , where you train differ model on differ subset of the data .
and you get these subset by sampl the train set with replac .
so we sampl a train set that had exampl a , b , c , d , and e .
and we got five exampl , but we'll have some miss and some duplic .
and we train on of our model on that particular train set .
thi is done in a method call random forest that us bag with decis tree , which leo breiman wa also involv in invent .
when you train decis tree with bag and then averag them togeth , thei work much better than singl decis tree by themselv .
in fact , the connect box us random forest to convert inform about depth into inform about where your bodi part ar .
we could us bag with neural net , but it's veri expens .
if you want to train sai , twenti differ neural net thi wai , you'd have to get your twenti differ train set .
and then it would take twenti time as long as train on net .
that doesn't matter with decis tress cuz thei're so fast to train .
also , at test time , you'd have to run these twenti differ net .
again , with decis tree , that doesn't matter , cuz thei're so fast to us at test time .
anoth method for make the train data differ is to train each model on the whole train set , but to weight the case differ so , in boost , we typic we us a sequenc of fairli low capac model .
and we weight the train case for each model differ .
what we do is we up weight the case the previou model got wrong and we down weight the case of previou model got right .
so the next model in the sequenc doesn't wast it time try to model case that ar alreadi correct .
it us it resourc to try to deal with case the other model ar get wrong .
an earli us of boost , wa with neural net for mnist , and there when comput's ar actual slower .
on of the big advantag is wa that it focus to competit resourc on model the tricki case , and didn't wast a lot of time , go over easi case again and again .
in thi video , i'm go to talk about the mixtur of expert model that wa develop in the earli 1990s .
the idea of thi model is to train a number of neural net , each of which special in a differ part of the data .
that is , we assum we have a data set which come from a number of differ regim , and we train a system in which on neural net will special in each regim , and a manag neural net will look at the input data , and decid which specialist to give it to .
thi kind of system , doesn't make veri effici us of data , becaus the data is , fraction over all these differ expert .
and so with small data set , it can't be expect to do veri well .
but as data set get bigger , thi kind of system mai well come into it own , becaus it can make veri good us of extrem larg data set .
in boost , the weight on the model ar not all equal , but after we finish train , each model ha the same weight for everi test case .
we don't make the weight on the individu model depend on which particular case we're deal with .
in mixtur of expert , we do .
so the idea is that we can look at the input data for a particular case dure both train and test to help us decid which model we can reli on .
dure train thi will allow model to special on a subset of the case .
thei then will not learn on case for which thei're not pick .
so thei can ignor stuff thei're not good at model .
thi will lead to individu model that ar veri good at some thing and veri bad at other thing .
the kei idea is to make each model , or expert as we call it , focu on predict the right answer for case where it's alreadi do better than the other expert .
that will caus special .
so there's a spectrum of model from veri local model to veri global model .
nearest neighbor , for exampl , is a veri local model .
to fit it , you just store the train case .
so , that's realli simpl , and then if you have to predict y from x , you simpli find the store valu of x that's closest to the test valu of x , then you predict the valu of y that's the same as for the store valu .
the result of that is that the curv relat the input to the output consist of lot of horizont line connect by cliff .
it would clearli make more sens to smooth thing out a bit .
at the other extrem , we have fulli global model , like fit on polynomi to all the data .
thei're much harder to fit to data , and thei mai also be unstabl .
that is , small chang in the data mai caus big chang in the model you fit .
that's becaus each paramet depend on all the data .
in between these two end of the spectrum , we have multipl local model , that ar of intermedi complex .
thi is good if the data set contain sever differ regim and those differ regim have differ input output relationship .
in financi data for exampl the state of the economi ha a big effect on determin the map between input and output , and you might want to have differ model for differ state of the economi .
but you might not know in advanc how to decid what constitut differ state of the economi , you're go to have to learn that too .
so we have thi problem if we're go to us differ model for differ regim , of how do we partit the data session to these differ regim .
in order to fit differ model to differ regim we need to cluster the train data into subset , on for each of these regim .
but we don't want to cluster the data base on the similar of input vector .
all we're interest in is the similar of input output map .
so if you look at the case on the right , there's four data point that ar nice fit by the red parabola and anoth four data point that ar nice fit by the green parabola if she partit the data base on the input i put map , that is base on the idea that a parabola will fit the data nice , then you partit the data where that brown line is .
if howev you partit the data by just cluster the input , we partit where the blue line is , and then if you look to the left of that blue line , you'll be stuck with a subset of data that can't be model nice by a simpl model .
so i'm go to explain an error function that encourag model to cooper .
and then i'm go to explain an error function that encourag model to special .
and i'm go to try to give you a good intuit for why these two differ function have these veri differ effect .
so if you want to encourag cooper , what you should do is compar the averag predictor with the target and train all the predictor togeth to reduc the differ between the target and their averag .
so us angl back as for expect again , the error would be the differ between the target and the averag of all the predictor of what thei predict .
that will overfit badli .
it will make the model much more power in train each predictor separ , becaus the model will learn to fix up the error is that other model make .
so , if you're averag model dure train , and train so that the averag work nice , you have to consid case like thi .
on the right , we have the averag of all the model except for model i .
so , that's what everybodi els is sai when their vote ar averag togeth .
on the left , we have the output of model i .
now if we'd like the overal averag to be closer to the target , what do we have to do to the output of the ith model ?
we have to move it awai from the target .
that will take the overal averag toward the target .
you can see that what's happen is model i is learn to compens for the error made by all the other model .
but do we realli want to move model i in the wrong direct ?
intuit it seem better to move model i toward the target .
so here is an arrow function that encourag special , and it's not veri differ .
to encourag special , we compar the output of each model with the target separ .
we also need to us a manag to determin the weight we put on each of these model , which we can think of as the probabl of pick each model , if we have to pick on .
so now , our error is the expect over all the differ model of the squar error made by that model time the probabl of pick that model , where the manag or gate network , is determin that probabl by look at the input for thi particular case .
what will happen if you try to minim thi error is that most of the expert will end up ignor most of the target .
each expert will onli deal with the small subset of the train case and it will learn to do veri well on that small subset .
so here's a pictur of the mixtur of expert's architectur .
our cost function is the squar differ between the output of each expert in the target averag over all the expert .
but with the weight in that averag determin by the manag .
it's actual a better cost function will come to later , base on the mixtur model .
but thi wa a cost function i first thought of , and i think it's easier to explain the intuit with thi cost function .
so we have an input .
our differ expert will look at that input .
thei all make their predict base on that input .
in addit we have a manag , a manag might have multipl layer and the last layer for manag is a soft max layer , so the manag output as mani probabl as there ar expert , and us the output of the manger and output of the expert , we can then comput the valu of that error fraction .
if we look at the deriv of that other function , the output of the manag ar determin by the input xi to the soft max group in the final layer of the manag .
and then the error is determin by the output of the expert , and also the probabl output by the manag .
if we differenti that error with respect to the output of an expert , we get a signal for train that expert and that gradient that we get with respect to the output of an expert is just the probabl of pick that expert , time the differ between what that expert sai in the target .
so if the manag decid that there's a veri low probabl of pick that expert for that particular train case , the expert will get a veri small gradient , and the paramet insid that expert won't get disturb by that train case .
it'll be abl to save it paramet for model the train case where the manag give it a big probabl .
we can differenti with respect to the output of the gate network .
and actual what we're gonna do is differenti with respect to , the quantiti that goe into the soft max .
that's call the low jet , that's xi , and if we take the deriv with respect to xi , we get the probabl that , that expert wa pick time the differ between the squar arrow made by that expert and the averag overal expert when you us the weight provid by the manag of the squar arrow .
so what that mean is , if expert i make a lower squar error than the averag of the other expert , then we'll try to rais the probabl of expert i .
but if expert i make a higher squar error than the other expert , we'll try and lower hi probabl .
that's what caus special .
now there's actual a better cost function .
it's just more complic .
it depend on mixtur model , which i haven't explain in thi cours .
again , those will be well explain in andrew ing's cours .
i did explain , howev , the interpret of maximum likelihood , when you're do regress , as the idea that the network is actual make a gaussian predict .
that is the network output a particular valu , sai y1 and we think of it as make bet about what the target valu might be that ar a gaussian distribut around y1 with unit varianc .
so the red expert make a gaussian distribut of predict around by y1 and the green expert make a predict around y2 .
the manag then decid probabl for the two expert and those probabl ar us to scale down the gaussian .
those probabl have to add to on and thei ar call mix proport .
and so onc we scale down the gaussian we get to distribut that's no longer a gaussian , is the sum of the scale down red gaussian and the scale down green gaussian .
and that's the predict distribut from share expert .
what we want to do now is maxim the log probabl of the target valu under that black curv and rememb the black curv is just the sum of the red curv and the green curv .
so that lead to the follow model for the probabl re target , given a mixtur of expert .
the probabl , is on the left , and it's the sum over all the expert , of the mix proport assign to that expert by the manag or gate network time e squar the squar differ between the target and the output of that expert , scale by the normal term for a gaussian with a varianc of on .
and so our cost function is simpli go to be the neg log of that probabl on the left .
we're go to try and minim the neg log of that probabl .
in thi video , i'm go to return to the idea of full baysian learn , and explain a littl bit more about how it work .
and then in the follow video , i'm go to show how it can be made practic .
in full bayesian learn , we don't try and find a singl best set of the paramet .
instead , we try and find the full posterior distribut over all possibl set .
that is , for everi possibl set , we want a posterior probabl densiti .
and all those densiti , we want to add up to on .
it's extrem computation intens to comput thi for all , but the simplest model .
so , in the exampl earlier , we did it for a bias coin which just ha on paramet , which is how bias it is .
but in gener , for a neural net , it's imposs .
after we've comput the posterior distribut across all possibl set of the paramet , we can then make predict by let each differ set of the paramet make it own predict .
and then , averag all those predict togeth , weight by their posterior probabl .
thi is also veri computation intens .
the advantag of do thi is that if we us the full bayesian approach , we can us complic model even when we don't have much data .
so , there's a veri interest philosoph point here .
we're now us to the idea of overfit , when you fit a complic model to a small amount of data .
but that's basic just a result of not bother to get the full posterior distribut over the paramet .
so , frequentist would sai , if you don't have much data , you should us a simpl model .
and that's true .
but it's onli true if you assum that fit a model mean find the singl best set of the paramet .
if you find the full posterior distribut , that get rid of overfit .
if there's veri littl data , the full posterior distribut will typic give you veri vagu predict , becaus mani differ set of the paramet that make veri differ predict will have signific posterior probabl .
as you get more data , the posterior probabl will get more and more focus on a few set of the paramet , and the posterior predict will get much sharper .
so , here's a classic exampl of overfit .
we've got six data point and we fit a fifth order polynomi and so it should go exactli through the data , which it more or less doe .
we also featur a straight line which onli ha two degre of freedom .
and so , which model do you believ ?
the model that ha six coeffici and fit the data almost perfectli , or the model that onli ha two coeffici and doesn't fit the data all that well .
it's obviou that the complic model fit better , but you don't believ it .
it's not econom , and it also make silli predict .
so , if you look at the blue arrow , if that's the input valu and you're try to predict the output valu , the red curv will predict a valu that's lower than ani of the observ data point , which seem crazi , wherea the green line will predict a sens of the valu .
but everyth chang , if instead of fit on fifth order polynomi , we start with a reason prior of the fifth order polynomi , for exampl , the coeffici shouldn't be to big .
and then , we comput the full posterior distribut over fifth order polynomi .
and i've shown you a sampl from thi distribut in the pictur , where a thicken line mean higher probabl in the posterior .
so , you will see some of those thin curv , miss a few of the data point by quit a lot , but nevertheless , thei're quit close to most of the data point .
now , we get much vaguer , but much more sensibl predict .
so , where the blue arrow is , you'll see the differ model predict veri differ thing .
while , on averag , thei make a predict quit close to the predict made by the green line .
from a bayesian prospect , there's no reason why the amount of data you collect should influenc your prior belief and the complex of the model .
a true baysian would sai , you have prior belief about how complic thing might be and just becaus you haven't collect ani data yet , it doesn't mean you think thing ar much simpler .
so , we can approxim full baysian learn in a neural net , if the neural net ha veri few paramet .
the idea is we put a grid over the paramet space , so each paramet is onli allow a few return to valu and then we take the cross product of all those valu for all the paramet .
and now , we get a number of grid point in the paramet space .
and in each of those point , we can see how well our model predict the data , that is , if we're do supervis learn , how well a model predict the target output .
and we can sai that the posterior probabl in that grid point is the product of how well it predict the data , how like it is under the prior .
and with the whole thing normal , so that the posterior probabl is thi is still veri expens , but notic it ha some attract featur .
there's no gradient descent involv , and there's no local optimum issu .
we're not follow a path in thi space , we're just evalu a set of point in thi space .
onc we've decid on the posterior probabl to assign to each grid point , we then us them all to make predict on the test data .
that's also expens .
but when there isn't much data , it'll work much better than maximum likelihood or maximum a posteriori .
so , the wai we predict the test output , given the test input , is we sai , the probabl of the test output , given the test input , is the sum overal the grid point of the probabl that , that grid point is a good model , is the sum over all grid point of the probabl of that grid point , given the data and given our prior , time the probabl that we will get that test output , given the input and given the grid point .
in other word , we have to take into account , the fact that we might add nois to the output of the net befor produc the test answer .
so , here's a pictur of full bayesian learn .
we have a littl net here , that ha four weight and two bias .
if we allow , nine possibl valu for each of those weight and bias , there would be nine to the six grid point in the paramet space .
it's a big number but we can cope with it .
for each of those grid point , we comput the probabl of the observ output on all the train case .
we multipli by the prior for the grid point , which might depend on the valu of the weight , for exampl .
and then , we re normal to get the posterior probabl over all the grid point .
then we make predict us those grid point , but weight to each of their predict by it posterior probabl .
in thi video , i'm go to describ how to make full bayesian learn practic for neural network that have thousand , and perhap even million of weight .
the techniqu that's us is a mont carlo method , which seem veri odd the first time you hear about it .
we us a random number gener to move around the space of weight vector in a random wai , but with a bia toward go downhil in our cost function .
if we do thi right , we get a beauti properti , which is that we sampl weight vector in proport to their probabl in the posterior distribut .
and that mean by sampl a lot of weight factor , we can get a good approxim to the full bayesian method .
the number of grid point is exponenti in the number of paramet .
so we can't make a grid for more than a few paramet .
thi is enough data so that most of the paramet vector ar veri unlik .
onli a tini fraction of the group point , will make a signific contribut to the predict .
so mai be you can just focu on evalu thi tini fraction if we can find it .
an idea that make bayesian learn feasibl is that it might be good enough just to sampl weight vector accord to their posterior probabl .
so if you look at thi equat , the probabl that we assign to a test output , given the input for the test case and the train data , is the sum over all point in weight space of the poster probabl of that point in weight space given the train data , time the probabl distribut for the test valu that we predict given that point in weight space w i , and given the test input .
now instead of ad up all the term in that sum , we could just sampl term from that sum .
what we do is we sampl the weight vector in proport to that probabl .
so either we sampl them or we don't .
so thei'll get a weight of on or zero .
but the probabl of get a on .
that is , the probabl be sampl , will be their posterior probabl .
so that will give us the correct expect valu for the right hand side .
it'll have nois due to the sampl but it'll have the correct expect valu .
so here's a pictur of what happen in standard back propag .
on the right i've drawn the weight space .
which of cours is veri high dimension and unbound .
and thi is a veri bad pictur of , but it's the best i can do .
in thi white space , i've drawn some contour which ar meant to be contour of equal valu of our cost function .
and the wai back propag is normal us , is we start with some small valu of the weight , and then we follow the gradient .
we move downhil in our cost function , in the direct that increas the log likelihood , plu the log prior , sum over all train guess .
eventu , we'll either end up at a local minimum or we'll get stuck on a plateau , or we'll just move so slowli that we run out of patienc .
but the main point of thi pictur , is that we follow a path from an initi point to some final , singl point .
now if we're us a sampl method , what we could do , we start at the same place as we did befor , but each time we updat the weight .
we add a bit of gaussian nois so we're just turn around .
the weight vector will never settl down then .
it'll keep on move around .
it'll wander over the space , but alwai prefer low cost region .
that is , it'll tend to go downhil if it can .
an import question is whether we can sai anyth about how often the weight will visit each point in that space .
so the red dot ar meant to be sampl we took of the weight as we wander around the space .
and the idea is , we might save the weight after everi <num> , <num> step .
and if you look at those red dot , a few of them ar in high cost region , becaus those region ar quit big .
the deepest minimum ha the most red dot , and other minima also have red dot .
the dot aren't right at the bottom of the minima , becaus thei're noisi sampl .
if we add that gaussian nois in just the right wai , there's a wonder properti of markov chain mont carlo .
it's an amaz fact .
the weight vector , if we wander around for long enough , will be unbias sampl from the true posterior distribut overweight factor .
that is , those red dot we saw in the previou slide will be sampl from the posterior , where weight vector ar a highli probabl under the posterior , a much more like to be repres by a red dot than weight factor that is highli improb .
thi is call markov chain mont carlo , and make it feasibl to us bayesian learn with thousand of paramet .
the method i suggest of ad some gaussian nois is call the unknow method .
and it's not the most effici method .
there's more sophist method that ar more effici , and what i mean by more effici is , thei don't need to wander around the weight space for so long befor you can start take those red sampl .
full bayesian learn can actual be done with mini batch .
when we comput the gradient of the cost function on a random mini batch , we're gonna get an unbias estim but with sampl nois .
and the idea is to us that sampl nois to provid the nois that the mark up chain mont carlo method need .
it's a veri clever idea .
recent , well and hi collabor made it work nice , so thei could fairli effici get sampl from the post area distribut over weight us mini batch method .
thi should make it possibl to us full bayesian learn for much larger network where you have to train them with mini batch to have ani hope of ever finish train them .
in thi video , i'm go to describ a new wai of combin a veri larg number of neural network model without have to separ train a veri larg number of model .
thi is a method call dropout that's recent been veri success in win competit .
for each train case , we randomli omit some of the hidden unit .
so , we end up with a differ architectur for each train case .
we can think of thi as have a differ model for everi train case .
and then , the question is , how could we possibl train a model on onli on train case and how could we averag all these model togeth effici at test time ?
the answer is that we us a great deal of weight share .
i want to start by describ two differ wai of combin the output of multipl model .
in a mixtur , we combin model by averag their output probabl .
so , if model a assign probabl of <num> , <num> and <num> , to three differ answer , model b assign probabl of <num> , <num> and <num> , the combin model simpli assign the averag of those probabl .
a differ wai of combin model is to us a product of the probabl .
here , we take a geometr mean of the same probabl .
so , model a and model b again assign the same probabl as thei did befor .
but now , what we do is we multipli each pair of probabl togeth and then take the squar root .
that's the geometr mean and the geometr mean will gener add up to less than on .
so , we have to divid by the sum of the geometr mean to normal the distribut so that it add up to on again .
you'll notic that in a product , a small probabl output by on model , ha veto power over the other model .
now i want to describ an effici wai to averag a larg number of neural net that give us an altern to do the correct bayesian thing .
the altern probabl doesn't work quit as well as do the correct bayesian thing , but it's much more practic .
so , consid the neural net with on hidden layer , shown on the right .
each time we present a train exampl to it , what we're go to do is randomli emit each hidden unit with a probabl of <num> .
so , we cross out three of the hidden unit here .
and we run the exampl through the net with those hidden unit absent .
what thi mean is that we're randomli sampl from two to the h architectur , where h is the number of hidden unit , it's a huge number of architectur .
of cours , all of these architectur show weight .
that ism whenev we us a hidden unit , it's got the same weight as it's got in other architectur .
so , we can think of dropout as a form of model averag .
we sampl from these two to the h model .
most of the model , in fact , will never be sampl .
and a model of thi sampl onli get on train exampl .
that's a veri extrem form of bag .
the train set ar veri differ for the differ model , but thei're also veri small .
the share of the weight between all the model mean that each model is veri strongli regular by the other .
and thi is a much better regular than thing like l2 or l1 penalti .
those penalti pull the weight toward zero .
by share weight with other model , a model get regular by someth that's go to tend to pull the weight toward the correct valu .
the question still remain what we do with test time .
so , we could sampl mani of the architectur , mayb a hundr , and take the geometr mean of the output distribut .
but that would be a lot of work .
there's someth much simpler we can do .
we us all of the hidden unit , but we halv their outgo weight .
so , thei have the same expect effect as thei did when we were sampl .
it turn out that us all of the hidden unit with half their outgo weight , exactli comput the geometr mean that the predict that all two to the h model would have us , provid we're us a softmax output group .
if we have more than on hidden layer , we can simpli us drop out at <num> in everi layer .
at test time , we halv all the outgo weight of hidden unit , and that give us what i call the mean net .
so , we us a net that ha all of the unit but the weight ar halv .
when we have multipl hidden layer , thi is not exactli the same as averag lot of set per dropout model , but it's a good approxim and it's fast .
we could run lot of stochast model with dropout , and then averag across those stochast model .
and that would have on advantag over the mean net .
it would give us an idea of the uncertainti in the answer .
what about the input layer ?
well , we can us the same trick there , too .
we us dropout on the input , but we us a higher probabl of keep an input .
thi trick's alreadi in us in a system call denois autoencod , develop by pascal vincent , hugo larachol and yoshua bengio at the univers of montreal , and it work veri well .
so , how well doe dropout work ?
well , the record break object recognit net develop by alex krizhevski would have broken the record even without dropout .
but it broke a lot more by us dropout .
in gener , if you have a deep neural net and it's overfit dropout , it will typic reduc the number error by quit a lot .
i think ani net that requir earli stop in order to prevent it overfit would do better by us dropout .
it would , of cours , take longer to train and it might mean more hidden unit .
if you got a deep neural net and it's not overfit , you should probabl be us a bigger on and us dropout , that's assum you have enough comput power .
there's anoth wai to think about dropout , which is how i origin arriv at the idea .
and you'll see it's a bit relat to mixtur of expert , and what's go wrong when all the expert cooper , what's prevent special ?
so , if a hidden unit know which other hidden unit ar present , it can co adapt to the other hidden unit on the train data .
what that mean is , the real signal that's train a hidden unit is , try to fix up the error that's leftov when all the other hidden unit have had their sai .
that's what's be back propag to train the weight of each hidden unit .
now , that's go to caus complex co adapt between the hidden unit .
and these ar like to go wrong when there's a chang in the data .
so , a new test data , if you reli on a complex co adapt to get thing right on the train data , it's quit like to not work nearli so well on new test data .
it's like the idea that a big , complex conspiraci involv lot of peopl is almost certain to go wrong becaus there's alwai thing you didn't think of .
and if there's a larg number of peopl involv , on of them will behav in an unexpect wai .
and then , the other will be do the wrong thing .
it's much better if you want conspiraci , to have lot of littl conspiraci .
then , when unexpect thing happen , mani of the littl conspiraci will fail , but some of them will still succe .
so , by us dropout , we forc a hidden unit to work with combinatori mani other set of hidden unit .
and that make it much more like to do someth that's individu us rather than onli us becaus of the wai particular other hidden unit ar collabor with it .
but it is also go to tend to do someth that's individu us and is differ from what other hidden unit do .
it need to be someth that's margin us , given what it co worker tend to achiev .
and i think thi is what's give net with dropout , their veri good perform .
in thi video , i'm go to introduc hopfield net .
togeth with back propag , these were on of the main reason for the resurg of interest in neural network in the 1980s .
hopfield network ar beautifulli simpl devic that can be us for store memori as distribut pattern of activ .
we ar now go to learn about a differ kind of model from a feet forward neural net .
these ar sometim call energi base model becaus their properti deriv from a global energi function .
so , a hopfield net is on of the simplest kind of energi base model .
it's compos of binari threshold unit with recurr connect between them .
in gener , if you have network of non linear unit with recurr connect , thei're veri hard to analyz .
thei can behav in mani differ wai .
thei can settl to a stabl state .
thei can oscil .
thei can even be chaotic which mean that , unless you know their start state with infinit precis , you can't predict the state thei'll be in veri far into the futur .
fortun , john hopfield and variou other group , like stephen grossberg's group , realiz that if the connect ar symmetr , there's a global energi function .
each binari configur of the whole network ha an energi .
and so what i mean by binari configur is , an assign of binari valu to each neuron in the network .
so , everi neuron ha a particular binari valu in that configur .
the thing that hopfield realiz is that , if you set up the right energi function for binari threshold decis rule , is actual caus the network , to go down hill in energi , and if you keep appli that rule , it'll end up in a energi minima .
so , everyth's control by the energi function .
the global energi of a configur is the sum of a number of local contribut , and the main contribut have the form of the product of on connect weight , with the binari state of two nueron .
so , the energi function look like thi .
energi is bad , so low energi is good .
and that's what those minu sign ar do in there .
if you look at the main term here , it ha a weight which is the symmetr connect strength between two neuron .
and it ha the activ of the two connect neuron .
so , si is a binari variabl that ha valu of on or zero .
or in anoth kind of hopfield net , it ha valu of on or minu on .
in addit to that quadrat term that involv the state of two unit , there's also a bia term that onli involv the state of individu unit .
the quadrat energi function make it possibl for each unit to comput local how chang it state will chang the global energi .
so , we first need to defin the energi gap .
the energi gap for a unit i is the differ in the global energi of the whole configur depend on whether or not i is on .
so , the energi gap can be actual defin as the differ between the energi when i is off and the energi when i is on .
and that differ is what is just what is be comput by the binari threshold decis rule .
so , if you look at the equat for the energi and you differenti it with a respect to the state of the i th unit , it's a funni thing to do cuz it's a binari variabl .
but , if you differenti it , you'll see you get the binari threshold decis rule , but without the minu sign cuz that's for go down hill in energi .
so , by follow the binari threshold decis rule , a hopfield net will go downhil in it global energi .
on wai to find an energi minimum in a hopfield net is to start from a random state and then updat the unit on at a time in random order .
so , we're do a sequenti updat .
and for each unit that you pick , you comput whichev of it two state give the lowest global energi and you put it in that state independ of what state it wa previous in .
that's equival to sai you just us the binari threshold decis rule .
so , let's look at a littl exampl for the net on the right .
we'll start with a random global state .
thi wa a carefulli select random state , and that ha an energi of three , or a good of three .
it's easier to think about neg energi which ar call good .
there aren't ani bias here .
so to comput the good , you just look at all pair of unit that ar on and add in the weight between them .
and in thi configur , there's onli on pair of unit that's activ .
and that ha a weight of three , so we get a good of three .
now , let's start probe the unit .
let's pick a unit at random , like that on .
and ask , what state should that be in , given the current state of all the other unit ?
so , if we look at total input to that , it get an input of on four zero three , plu anoth zero three , so it get a total input of four .
that's below zero , so we turn it off , i . e .
it stai in the off state .
and let's probe anoth unit .
if we look at thi unit , again , it get a total input of on three on zero , so it get a total input of three , so the binari threshold decis rule will make it turn on .
let's probe on more unit .
thi unit's more interest .
it's get an input of on two on on zero three zero <i> , on , so< i> that's a total input of on .
so , it will now turn on .
previous it wa off .
and so , when it turn on , the global energi chang .
we now have a global energi of four or a good of four , and that's a local energi minimum .
if you now try probe ani of the unit , you'll see that thei don't want to chang their current state .
the next is settl to a minimum .
howev , the minimum it settl to is not the deepest energi minimum .
it's just on of two minima that thi net ha .
the deepest energi minimum is shown on the right here , and it's when the other triangl of unit that support each other is on .
that ha a good of three three on is five .
so , that's a slightli better energi minima .
if you look at that net , you can see the net compos of these two triangl in which the unit mostli support each other , although there's a bit of disagr at the bottom .
and each of those triangl mostli hate the other triangl via that connect at the top .
the triangl on the left differ from the on on the right by have a weight of two , where the other on ha a weight of three .
so , the triangl on the right will give you the deepest minimum .
so , if you ask , why did the decis need to be sequenti in the hopfield net ?
the problem is that if unit make simultan decis , thei could each think thei were us energi but actual the energi could go up .
with simultan parallel updat , we can get oscil which alwai have a period of two .
so , here's a littl network where the unit have bias of five , and a weight between them of <num> .
so when both unit ar off , the next parallel step , if we updat them both at the same time , will turn both unit on becaus thei each think thei cam improv thing by the bia term .
but , as soon as you do that , you get thi <num> , and so you've actual made thing much wors .
so then , in the next parallel step , both unit will turn off again .
if we do the updat in parallel but with random time .
in other word , we don't wait for on updat to commun the state to everybodi befor we consid anoth updat , but we do wait for random length of time between do updat of a given unit .
then , those random time will often destroi these bi phase oscil .
that mean that the idea that the updat have to be sequenti isn't quit as bad as it seem from a biolog perspect .
now , what hopfield suggest wa that we could make us of thi kind of energi base model that settl to a minimum of it's energi for store memori .
so , we had a veri influenti paper in <num> that propos that memori could be energi minima of a neural net with symmetr weight .
the binari threshold decis rule can then take partial memori , and clean them up into full memori .
so , the memori could be corrupt by part of it be wrong , or part of it could just be undecid , and we can us the net , to fill out the memori .
the idea of memori as energi minima goe back a long wai .
the first exampl i know of is in a book call principl of literari critic by i .
a .
richard , where he propos that memori ar like a larg crystal that can sit on differ face .
us energi minima to repres memori give a content eras memori , as hopfield realiz .
so , that you can access an item just by know part of it content .
i can tell you a few properti of someth that'll set the state of some of the neuron in the net .
and if you've put the other neuron in random state and now go around appli the binari threshold rule , with a bit of luck , you'll feel like that memori to be some store item that you know about .
when hopfield net were propos in <num> , that wa a veri interest properti .
<num> wa sixteen year befor googl , now that we have googl , we regard thi as perfectli obviou .
anoth properti of hopfield netsg is biolog interest , is their robust against hardwar damag .
you could remov a few of the unit in the netg and unlik the central processor of your comput , everyth will still work fine .
psychologist have a nice analog for thi kind of memori .
it's like reconstruct a dinosaur from just a few of it bone becaus you know someth about how the bone ar meant to fit togeth .
so , the weight in the network give you inform about how state of neuron fit togeth .
and now , given the state of a few neuron , i can fill out the whole state to recov a whole memori .
the storag rule for memori in the hopfield net is veri simpl .
the idea is , if we us activ of on and minu on , that we can store a binari statement by just increment the weight between ani two unit by the product of their activ .
so , it's a veri simpl rule shown on the right .
on nice thing about thi rule , is that you just go through the data onc and you're done .
so , it realli is the genuin onlin rule .
that's becaus it's not error driven .
you're not compar what you would have predict with what the right answer is , and then make small adjust .
the fact that it's not an error correct rule is both it's strength and it's weak .
it mean it can be onlin , but as we'll see later , it also mean it's not a veri effici wai to store thing .
we can also have bias , and as usual , we treat the bias as weight from a perman on unit .
if you want to us state of zero and on for unit , which is what we'll us later , the updat rule is onli slightli more complic .
in thi video , i'm go to talk about the storag capac of hopfield net .
their abil to store a lot of memori is limit by what ar call spuriou memori .
these occur when two nearbi energi minima combin to make a new minimum in the wrong place .
attempt to remov these spuriou minima eventu led to a veri interest wai of do learn in thing consider more complic than a basic hopfield net .
at the end of the video , i'll also talk about a curiou histor rediscoveri where the physicist try to increas the capac of hopfield net , rediscov the perceptron converg procedur .
off to hopfield , invent hopfield net as memori storag devic .
the field becam obsess by the storag capac of a hopfield net .
us hopfield storag rule for a total connect net , the capac is about <num> . 15n memori .
that is , if you have n binari threshold unit , the number of memori you can store is about <num> . 15n befor memori start get confus with on anoth .
so that's the number you can store and still hope to retriev them sensibl .
each memori is a random configur of the n unit , so it ha n bit of inform it .
and so , the total inform be store , in a hopfield net is about <num> . 15n squar bit .
thi doesn't make effici us of the bit that ar requir to store the weight .
in other word , if you look at how mani bit the comput is us to store the weight , it's us well over <num> . 15n squar2 bit to store the weight .
and therefor , thi kind of distribut memori and local energi minima is not make effici us of the bit in the comput .
we can analyz how mani bit we should be abl to store if we were make effici us of the bit in the comput .
those n squar weight and bias in the net .
and after store m memori , each connect weight ha an integ valu in the rang m to m .
that's becaus we increas it by on or decreas it by on each time we store a memori , assum that we us state of on and on .
now , of cours , not all valu will be equiprob , so we could compress that inform .
but ignor that , the number bit it would take us to store a connect rate in a naiv wai is log 2m on , cuz that's the number of altern connect rate and that's a log to the base two .
and so , the total number of bit of comput memori that we us is of the order of n squar log 2m on .
so , notic that , that scale logarithm with m .
wherea , if you store thing in the wai that hopfield suggest , you get thi constant <num> . <num> instead of someth thi scale is logarithm .
so , we're not so worri about the fact that the constant is a lot less than two , what we're worri about is thi logarithm scale .
that show we ought to be abl to do someth better .
if we ask , what limit the capac of a hopfield net ?
what is it that caus it to break down ?
then , it merg of energi minima .
so , each time we memor a binari configur , we hope that we'll creat a new energi minima .
so , we might have a state space for all the state of the net be depict horizont here , and the energi be depict vertic .
and , we might have on en , energi minimum for the blue pattern and anoth for the green pattern .
but , if those two patent ar nearbi , what will happen is we won't get two seper minima .
thei'll merg to creat on minimum at an intermedi locat .
and that mean , we can't distinguish those two seper memori , and inde we'll recal someth , that's a blend of them rather than the individu memori .
that's what limit the capac of a hopfield net , that kind of merg of nearbi minima .
on thing i should mention is thi pictur , is a big misrepresent .
the state of a hopfield matter realli , the corner of a hyper cube .
and , it's not veri good to show , the corner of a hyper cube , as if thei were contin on dimension horizont space .
on veri interest idea that came out of think about how to improv the crest of the hopfield net is the idea of unlearn .
thi wa first suggest by hopfield , feinstin and palmer , who suggest the follow strategi .
you left a net settl from a random initi state , and then you do unlearn .
that is whatev binari state it settl to , you appli opposit of the storag rule .
i think you can see that with the previou exampl , that red merg minimum .
if you let the net settl there and did some unlearn on that merg minimum , you'd get back the two separ minima cuz you'd pull up that red point .
so , by get rid of deep spuriou minima , we can actual increas the memori capac .
hopfield , feinstein and palmer show that thi actual work , but thei didn't have a good analysi of what wa realli go on .
franci crick , on of the discov of the structur of dna , and graham micherson , propos that unlearn might be what's go on dure rem sleep , that is rapid ey movement sleep .
so , the idea wa that dure the dai , you store lot of thing , and you'll get spuriou minima .
then at night , you put the network in a random state , you settl to a minimum , and you unlearn what you settl to .
and that actual explain a big puzzl .
thi is a puzzl that doesn't seem to puzzl most peopl that studi sleep but it ought to .
each night , you go to sleep and you dream for sever hour .
when you wake up in the morn , those dream ar all gone .
well , thei're not quit all gone .
the dream you had just befor you woke up , you can get into short term memori and you'll rememb it for a while .
and if you think about it , you might rememb it for a long time .
but , we know perfectli well that if we'd woken you up at other time in the night , you'd have been have other dream , and in the morn their just not there .
so , it look like you're simpli not store what you're dream about , and the question is , why ?
in fact , why do you bother to dream at all ?
dream is paradox and that the state of your brain look extrem like the state of your brain when you're awak , except that it's not be driven by real input .
it's be driven by a relai station just after the real input call the thalamu .
so the crick and mitchison theori at least explain , function , what the point of dream is , is to get rid of the spuriou minima .
but , there's anoth problem with unlearn , which is more mathemat problem , which is , how much unlearn should we do ?
now , given more you've seen in the school so far , a real solut to that problem will be to show that unlearn is part of the process of fit a model to data .
and , if you do maximum likelihood fit of that model , then unlearn will automat come out and fit into the model .
and what's more , you'll know exactli how much unlearn to do .
so , what we're go to try and do is deriv on learn as the right wai to minim a cost function .
where the cost function is , how well your neural net model the data that you saw dure the dai .
befor we get to that , i want to talk a littl bit about wai that physicist discov for increas the capac of the hopfield net .
as i said , thi wa a big obsess with the field .
i think it's becaus physicist realli love the idea that math thei alreadi know might explain how the brain work .
that mean , post doctor fellow in physic who can't get a job in physic might be abl to get a job in neurosci .
so , there ar a veri larg number of paper publish in physic journal about hopfield and their storag capac .
eventu , a veri smart student call , elizabeth gardner , figur out that there's actual a much better storag rule if you were concern about capac .
and that it would us the full capac of the weight .
and i think thi storag rule will be familiar to you .
instead of try to store vector in on go , what we're go to do is we're go to cycl through the train set mani time .
so , we lose our nice onlin properti that you onli have to go through the data onc .
but in return , we're go to gain , more effici storag .
what we go to do is we go to us the perceptu converg procedur to train each unit to have the correct state given the state of all the other unit in that global vector that we want to store .
so , you take your net , you put it into the memori state you want to store , and then you take each unit separ and sai , would thi unit adopt the state i want for it , given the state of all the other unit ?
if it would , you leav it incom weight alon .
if it wouldn't , you chang it incom weight in the weight specifi by converg procedur .
and notic , these would be integ chang to the weight .
you mai have to do thi sever time , and of cours , if you give it to mani memori , thi won't converg .
you onli get converg with a perceptron converg procedur if there is a set of weight that will solv the problem .
but assum there is , thi is much more effici wai to store memori in a hopfield net .
thi techniqu is also be develop in anoth field , statist .
and statistician call the techniqu pseudo likelihood .
the idea is to get on thing right given all the other thing .
and so , with high dimension data , if you want to build a model of it , the idea is you build a model that tri to get the valu on on dimens right given the valu on all the other dimens .
the main differ between the perceptron converg procedur that's normal us and pseudo likelihood is that , in the hopfield net , the weight ar symmetr .
so , we have to get two set of gradient for each weight and averag them .
but , apart from that , the wai to us the full capac of a hopfield net is to us the perceptron converg procedur and to go through the data sever time .
in thi video , i'm go to explain a veri differ wai of us hopfield's energi function .
we add some hidden unit to the network .
and what we ar try to do is make the state of those hidden unit repres an interpret of the percept input that's shown on the visibl unit .
so , the idea is that the weight on between unit repres constraint on good interpret .
and by find a low energi state , we find a good interpret of the input data .
hopfield net combin two ideal , the idea of that you can find a local energi minimum by us a network of symmetr connect binari threshold unit , and the idea that these local energi minima might correspond to memori .
there's a differ wai of us the abil to find local minima .
instead of us the net to store memori , we can us it to construct interpret of the sensori input .
so , the idea is that we have the input repres by some visibl unit .
and we can structur an interpret of that input in the set of hidden unit .
so , the interpret or explan of the input is go to be a binari configur over the hidden unit .
the energi of the whole system will repres the bad of that interpret .
so , to get good interpret accord to our current model of the world , which is in the energi function , we need to find low energi state of the hidden unit , given , the input repres by the visibl unit .
i want to give an exampl of thi to make the idea clearer , in order to give the exampl , i need to go into a littl bit of detail , about what you can infer , when you see a <num> d line in an imag .
what doe that tell you about the three dimension world ?
so , a <num> d line in an imag could have been caus by mani differ three dimension edg in the world .
if thi blue dot is your eyebal and the red line ar two line of sight come from the center of your eyebal , then the black line is a possibl <num> d edg that would lead to a two dimension line on your retina .
here's anoth <num> d edg that would lead to exactli the same thing on your retina .
and here's anoth on .
and here's anoth on .
all of these differ <num> d edg have exactli the same appear in the imag .
that's becaus we've lost the inform about how far awai the end of the line ar along that line of sight .
we know the end is somewher along the line of sight but we don't know the depth .
so , if we assum that a straight <num> d edg in the world is the caus of a straight <num> d line in the imag , then we've lost two degre of freedom of that <num> d edg , it depth at each end .
so , there is a whole famili of <num> d edg that all correspond to the same <num> d line .
you can onli see on of these <num> d edg at a time becaus thei all get in the wai of each other .
so now , we're in a posit to see a littl exampl of what you might be abl to do , if you can us the fact that you can find low energi state of a network of binari unit , to help you find interpret of sensori input .
so , here's the exampl .
you imagin we see a line draw , and we want to interpret it as a three dimension thing .
so , the data we have , let's suppos , is a bunch of <num> d line like the line shown in the pictur .
and for each possibl line , we will have set asid a neuron .
don't worri for now about the fact that , that will requir too mani neuron .
so , for everi possibl <num> d line , we have neuron .
in ani on pictur , onli a few of the possibl line will be present .
and so , we'll activ just a few of those neuron .
so , i've shown two edg in that pictur , activ two of the neuron .
and those ar neuron that repres <num> d line .
thei're the data .
now , what we're go to do is have a whole bunch of <num> d line unit , on for each possibl <num> d line or <num> d edg .
so , each of the <num> d line unit could be the project of mani differ possibl <num> d line .
we therefor need to make the <num> d line unit excit all those <num> d line , but we also need to make them all compet with on anoth , cuz you can onli see on of them at a time .
so , here's an exampl where i have a stack of <num> d line unit , the green connect ar excitr connect come from the <num> d line unit , all of them with equal weight , sai , if thi line unit is present , i'm go to try and turn on all those .
but in addit , we need competit between those so that onli on of them will turn on , and that's what the red line repres .
and we do that for each <num> d line unit .
so , i'm just show it to you for the <num> d line unit that happen to be activ at present .
and again , don't worri about the fact that thi would need far to mani unit .
now , the stori is not quit complet .
we've now wire into the neural network the inform about project that i show on the previou slide , i . e . , the neural network in those green and red connect understand that each <num> d line can cross upon to mani <num> d edg , but onli on of them should be present at a time .
but now , we know a lot about how <num> d edg connect .
for exampl , when we see two <num> d line connect in the imag , we think it's almost certain that thei correspond to edg that have the same depth at the point where the line connect .
so , let's suppos that the two <num> d edg i've join there correspond to have the same depth at the point where the two <num> d line join .
that mean thei should support each other .
it doesn't have to be like that .
you could have a veri funni viewpoint where on line end at a differ depth from the other and you just happen to be at the viewpoint from which thei coincid on your retina .
but that's veri unlik .
so , we're go to need to us the fact that we expect <num> d line that coincid in the imag to correspond to <num> d edg that agre on the depth of that point .
so , we'll put in a lot of connect like that .
but there's an even stronger fact we can us which is that in our manufactur world , we expect that quit often , <num> d edg will join in a right angl .
and so , for two particular <num> d edg that happen to agre in depth and join at a right angl , we'll put in a particularli strong connect .
and i've indic that by a thicker green line .
so , by put in lot of connect like that , we can indic how we expect <num> d edg to go togeth to form a coher <num> d object .
and now , we have a network that contain inform about how edg go togeth in the world and about how edg project to caus line in the imag .
and so , if we give that network an imag , it should be abl to come up with an interpret of the imag .
and for the imag i'm show you , there's two quit differ interpret .
it's call a necker cube , and if you look at it long enough , it will flip in depth on you .
and thi network would have two pretti much equal deep energi minima that correspond to those two interpret of the necker cube .
rememb , thi is all just a analog so you understand the idea of us low energi state as interpret of percepti data .
to actual build a proper model of what happen when the necker cube flip will be a lot more complic than thi .
so , if we decid we're go to us low energi state to repres good interpret , then we have two issu .
the first is to do with search and i'm go to deal with that in the next video .
the search question is , how do we avoid the hidden unit get trap in poor local minima of the energi function ?
the poor minima repres interpret that ar sub optim , given our current model and the weight of the network .
can we do anyth better than simpli go downhil in energi from some random start state ?
the second issu which seem even more difficult is how do we learn the weight on the connect between hidden unit and between visibl unit and hidden unit .
is the sum simpl learn algorithm for adjust all those weight so that we get sensibl percept interpret ?
and notic here we haven't got a supervisor anywher .
we're just show it input and we would like it to construct ton of activ in the hidden unit that repres sensibl interpret .
thi seem like a rather tall order .
in thi video , i'm go to explain how ad nois can help system escap from local minima .
and , i'm go to show what you have to do to the unit in hopfield net to add nois in the appropri wai .
i'm not go to introduc the idea that we confin better minima by us nois .
so , hopfield net alwai make decis that reduc the energi , or if it doesn't state of the unit , the energi stai the same .
thi make it imposs to climb out of a local minimum .
so , if you look at the landscap here .
if we get into the local minimum a , there's no wai we're go to get over the energi barrier to get to the better minimum b becaus we can't go uphil in energi .
if we add random nois , we can escap from poor minima , especi minima that is shallow , that is , on that don't have big energi barrier around them .
it turn out , rather than us a fix nois level , the most effect strategi is to start with a lot of nois which allow you to explor the space on a coars scale and find the gener good region of the space , and then to decreas the nois level .
with a lot of nois , you can cross big barrier .
as you decreas the nois level , you start concentr on the best nearbi minima .
if you slowli reduc the nois , so the system end up in a deep minimum , that's call simul anneal .
and thi ideal wa , propog by kirkpatrick at around the same time as hopfield net were propos .
so , the reason for simul anneal is becaus the temperatur , in a physic system , or in a simul system with a energi function , affect the transit probabl .
so , in a high temperatur system , the probabl of go uphil from b to a is lower than the probabl of go downhil from a to b .
but it's not much lower .
in effect , the temperatur flatten the energi landscap , and so the littl black dot ar meant to be particl .
and what we ar imagin is particl move about accord to the transit probabl that you get with an energi function and a temperatur .
and thi might be a typic distribut if you're on the system of high temperatur where it's easier to cross barrier , but it's also hard to stai in a deep minimum onc you've got that .
if you ar in the system of much lower temperatur , then your probabl of cross barrier get much smaller but your ratio get much better .
so , the ratio of the probabl of go from a to b versu the probabl of go from b to a is much better in the low temperatur system .
and so , if we run it long enough , we would expect all of the particl to end up in b .
but if we just run it for a long time at low temperatur , it will take a veri long time for particl to escap from a .
and it turn out a good compromis is to start at a high temperatur and gradual reduc the temperatur .
the wai we get nois in to hopfield net is to replac the binari threshold unit by binari stochast unit and make bias random decis .
and the amount of nois is control by someth call temperatur , which you'll see in a minut in the equat .
rais the nois level is equival to decreas all the energi gap between configur .
so , thi is our normal logist equat .
but with the energi gap scale by a temperatur .
if the temperatur is veri high , that expon will be roughli zero , so the right hand side will be on over on plu on .
and so , the probabl of the unit turn on will be about a half .
it'll be in it's on and off state , more or less equal off .
as we lower the temperatur , depend on the sign of delta e , the unit will becom either more and more firmli on and more and more firmli off .
at zero temperatur , which is what we're be us in a hopfield net , then the sign of delta e determin whether the right hand side goe to zero or goe to on .
but , with t zero , it will either be zero or on on the right hand side .
and so , the unit will behav determinist and that's a binari threshold unit .
it will alwai adopt whatev of the two state is the lowest energi .
so , the energi gap we saw on a previou slide , and it's just the differ in the energi of the whole system depend on whether unit i is off , or the unit i is on .
although simul anneal is a veri power method for improv search that get stuck in local optima , and although it wa influenti in lead terri sejnowski and i to the idea behind boltzmann machin , it's actual a big distract from understand boltzmann machin .
so , i'm not go to talk about it anymor in thi cours even though it's a veri interest idea .
and , from now on , i'm go to us binari stochast unit that have a temperatur of on .
that is , it's the standard logist function in the energi gap .
so , on concept that you need to understand in order to understand the learn procedur for both the machin , is the concept of thermal equilibrium .
and becaus we're set the temperatur to on , thi the concept of thermal equilibrium at a fix temperatur .
it's a difficult concept .
most peopl think that it mean the system is settl down and isn't chang anymor .
that's normal what equilibrium mean .
but it's not the state of the individu unit that ar settl down .
the individu unit ar still rattl around at thermal equilibrium , and less temperatur zero .
the thing that settl down is the probabl distribut over configur .
that's a difficult concept the first time you meet it , and so i'm go to give you an exampl .
the probabl distribut settl to a particular distribut call the stationari distribut .
the stationari distribut is determin by the energi function of the system .
and , in fact , in the stationari distribut , the probabl of ani configur is proport to each of the minu it energi .
a nice intuit wai to think about thermal equilibrium is to imagin a huge ensembl of ident system that all have exactli the same energi function .
so , imagin a veri larg number of stochast hopfield net all with the same weight .
now , in that huge ensembl , we can defin the probabl of configur as the fraction of the system that ar in that configur .
so , now we can understand what's happen as we approach thermal equilibrium .
we can start with ani distribut we like over all these ident system .
we could make them all , be in the same configur .
so , that's the distribut with a properti of on on on configur , and zero on everyth els .
or we could start them off , with an equal number of system in each possibl configur .
so that's a uniform distribut .
and then , we're go to keep appli our stochast updat rule .
which , in the case of a stochast hopfield net would mean , you pick a unit , and you look at it energi gap .
and you make a random decis base on that energi gap about whether to turn it on or turn it off .
then , you go and pick anoth unit , and so on .
we keep appli that stochast rule .
and after we've run system stochast in thi wai , we mai eventu reach a situat where the fraction of the system in each configur remain constant .
in fact , that's what will happen if we have symmetr connect .
that's the stationari distribut that physicist call thermal equilibrium .
ani given system keep chang it configur .
we appli the updat rule , and the state of it unit will keep flip between zero and on .
but , the fraction of system in ani particular configur doesn't chang .
and that's becaus we have mani , mani more system than we have configur .
so , here's an analog kust to help with the concept .
imagin a veri larg casino in la vega with lot of card dealer .
and , in fact , we have mani more than <num> factori card dealer .
we start with all the card pack in the standard order that thei come from the manufactur .
let's suppos that ha the ac of spade , and the king of spade , and the queen of spade .
and then , the dealer all start shuffl .
and thei do random shuffl , thei don't do fanci shuffl that bring them back to the same order again .
after a few shuffl , there's still a good chanc that the king of spade will be next to the queen of spade in ani given pack .
so , the pack have not yet forgotten where thei start .
their initi order is still influenc their current order .
if we keep shuffl , eventu the initi order will be irrelev .
the pack will have forgotten where thei start .
and , in fact , in thi exampl , there will be an equal number of pack in each of the <num> factori possibl order .
onc thi ha happen , if we carri on shuffl , there'll still be an equal number of pack in each of the <num> factori order .
that's why it's call equilibrium .
it's becaus the fraction in ani on configur doesn't chang , even though the individu system ar still chang .
the thing that's wrong with thi analog is that onc we've each equilibrium here , all configur have equal energi .
and so , thei all have the same probabl .
in gener , we're interest in reach equilibrium for system where some configur have lower energi than other .
in thi video , i'm go to explain , how a boltzmann machin model a set of binari data vector .
i'm go to start by explain , why we might want to model a set of binari data vector , and what we could do with such a model if we had it .
and then i'm gonna show how the probabl assign to binari data vector ar determin by the weight in a boltzmann machin .
stochast hopfield net with hidden unit , which we also call as boltzmann machin ar good at model binari data .
so , given a set of binari train vector , thei can us the hidden unit to fit a model per assign the probabl to everi possibl binari vector .
per sever reason , why you might like to be abl to do that .
if , for exampl you had sever distribut of binari vector , you might like to look at a new binari vector and decid which distribut it came from .
so , you might have differ kind of document , and you might repres a document by , a number of binari featur each of which sai , whether there is more than zero occurr of a particular word in that document .
for differ kind of document , you would expect differ kind of the differ word , mai be you'll see differ correl between word and so you could us a set of hidden unit to model the distribut for each document .
and then you could pick the most like document , by see .
and then you could assign a test document to the appropri class , by see which class of document is most like to have produc that binari vector .
you could also us boltzmann machin for monitor complex system to detect unusu behavior .
suppos for exampl that you have a nuclear power station , and all of the dial were binari .
so you get a whole bunch of binari number that tell you someth about the state of the power station .
what you'd like to do , is notic that it's in an unusu state .
a state that's not like state you've seen befor .
and you don't want to us supervis learn for that .
becaus realli you don't want to have ani exampl of state that caus it to blowup .
you'd rather be abl to detect that it's go into such a state without everi have seen such a state befor .
and you could do that by build a model of a normal state and notic that thi state is differ from the normal state .
if you have model of sever differ distribut .
you can complet the posterior probabl that a particular distribut produc the observ data by us bay' theorem .
so give the observ data , the probabl it came from model i , under the assumpt that it came from on of your model , is the probabl that model i would have produc that data , divid by the same quantiti for all model .
now i want to talk about two wai of produc model of data in particular binari vector .
the most natur wai to think about gener a binari vector is to first gener the state of some latent variabl , and then us the latent variabl to gener the binari vector .
so in a causal model , we us two sequenti step .
these ar the latent variabl , or hidden unit , and we first pick the state of the latent variabl from their prior distribut .
often in the causal model , these will be independ in the prior .
so their probabl of turn on , if thei were binari latent variabl , would just depend on some bia that each on of them ha .
then , onc we pick a state for those , we would us those to gener the state of the visibl unit by us weight connect in thi model .
so thi is a kind of neural network , causal , gener model .
it's us logist unit , and it us bias for the hidden unit and weight on the connect between hidden and visibl unit to assign a probabl to everi possibl visibl vector .
the probabl of gener a particular vector v , is just the sum of all the possibl hidden state of the probabl of gener those hidden state time the probabl of gener v , given that you've alreadi gener that hidden state .
so , that's a causal model , factor analysi for exampl is a causal model us continu variabl .
and , it's probabl the most natur wai to think about gener data .
in fact , some peopl when thei sai gener model mean , the causal model like thi .
but just a complet differ kind of model .
a boltzmann machin is an energi base model , and , in thi kind of model , you don't gener data causal .
it's not a causal gener model .
instead everyth is defin in term of the energi of joint configur of visibl and hidden unit .
there's two wai of relat the energi of a joint configur to it probabl .
you can simpli defin the probabl to be the probabl of a joint configur of the visibl and hidden variabl is proport to e to the neg energi of that joint configur .
or you can defin it procedur by sai we ar go to defin the probabl as the probabl find the network in that state after we've updat all the stochast binari unit for enough time so that we reach thermal equilibrium .
the good new is that those two definit agre .
the energi of a joint configur of the visibl and hidden unit ha five term in it .
so i've put the neg energi to save have to put lot of minu sign .
and so the neg energi of the joint configur vh .
that's with vector v on the visibl unit , and h on the hidden unit , ha bia term where vi is the binari state of the ith unit in vector v .
and the bk is the bia of the kth unit , in thi case , a hidden unit .
so that's the first two term .
then there's the visibl visibl interact , and to avoid count each of those interact twice , we can , just sai , we're go to count within c's , i , and j and make sure that i's alwai less than j .
that'll avoid count the interact of someth with itself , and also avoid count pair twice , and so we don't have to put a half in front .
then there's the visibl hidden interact .
my wik is a weight on a visibl hidden interact .
and then there's the hidden to hidden interact .
so the wai we us the energi to defin probabl is that the probabl of a joint configur over vnh is proport to e to the minu vh .
to make that an equal we need to normal the right hand side by all possibl configur over the visibl and hidden and that's what the divisor there is .
that's often call the partit function .
that's what physicist call it .
and notic it ha exponenti mani term .
to get the probabl of a configur of the visibl unit alon , we have to sum over all possibl configur of the hidden unit .
so p of v is the sum over all possibl hs , of each of the minu the energi you get with that h , normal by the partit function .
i want to give you an exampl of how we comput the probabl of the differ visibl vector , becaus that'll give you a good feel for what's involv .
it's all veri well to see the equat , but i find that i understand it much better when i've work through the comput .
so let's take a network with two hidden unit and two visibl unit .
and we'll ignor bias , so we just got three weight here .
to keep thing simpl , i'm not gonna connect visibl unit to each other .
so the first thing we do is write down all possibl state of the visibl unit .
i need to put them in differ color , and i'm go to write each state four time , becaus for each state of visibl unit , there's four possibl state of the hidden unit that could go with it .
so that give us sixteen possibl joint configur .
now , for each of those joint configur , we're go to comput it's neg energi minu e .
so if you look at the first line , when all of the unit ar on .
the neg energi will be two on , on is two .
and we do thi for all sixteen possibl joint configur .
we then take the neg energi and we exponenti them .
and that will give us un normal probabl .
so these ar the un normal probabl of the configur .
their probabl ar proport to thi .
if we add all those up to <num> and then we divid everyth by <num> , we get the probabl of joint configur .
there thei all ar .
now , if we want the probabl of a particular visibl configur , we have to sum over all the hidden configur that could go with it .
and so we add up the number in each block .
and now we've comput the probabl of each possibl visibl vector in a boltson's machin that ha these three weight in it .
now let's ask how we get a sampl from the model when the network's bigger than that .
obvious , in the network we just comput , we can figur out the probabl of everyth'caus it's small .
but when the network's big , we can't do these exponenti larg comput .
so , if there's more than a few hidden unit , we can't actual comput that partit function , there's too mani term in it .
but we can us markov chain mont carlo to get sampl from the model by start from a random global configur .
and then pick unit at random and date them stochast base on their energi gap .
those energi gap be determin by the state of all the other unit in the network .
if we keep do that until the markov chain reach it stationari distribut , then we have a sampl from the model .
and the probabl of that sampl is relat to it energi by the boltzmann distribut , that is , the probabl of the sampl is proport to each the of the minu energi .
what about get a sampl from the posterior distribut over hidden configur , when given a data vector ?
it turn out we're go to need that for learn .
so the number of possibl hidden configur is again exponenti .
so again , we us markov chain mont carlo .
and it's just the same as get a sampl from the model , except that we keep that we keep the visibl unit clamp to the data vector we're interest in .
so we onli updat the hidden unit .
the reason we need to get sampl from the posterior distribut , given a data vector , is we might want to know a good explan for the observ data .
and , we might want to base our action on that good explan .
but , we also need to know that for learn .
in the previou video , i show how a boltzmann machin can be us a probabilist model of a set of binari data vector .
in thi video we're final go to get around to the boltzmann machin learn algorithm .
thi is a veri simpl learn model which ha an eleg theoret justif , but it turn out in practic , it wa extrem slow and noisi , and just wasn't practic .
and for mani year , peopl thought that boltzmann machin would never be practic devic .
then we found sever differ wai of greatli speed up the learn algorithm .
and now the algorithm is much more practic , and ha , in fact , been us as part of the win entri for a million dollar machin learn competit , which i'll talk about in a later video .
the bolton machin learn algorithm is an unsupervis learn algorithm .
unlik the typic user back propag , where we have a input vector and we provid it with a desir output .
in boltzmann machin learn we just give it the input vector .
there ar q label .
what the algorithm is try to do is build a model of a set of input vector , though it might be better to think of them as output vector .
what we want to do is maxim the product of the probabl , that the boltzmann machin assign to a set of binari vector , the on in the train set .
thi is equival to maxim the sum of the log probabl that the boltzmann machin assign to the train vector .
it's also equival to maxim the probabl that we'd obtain exactli the end train case , if we ran the boltzmann machin in the follow wai .
first , we let it settl to it stationari distribut , and differ time , with no extern input .
then we sampl the visibl vector onc .
then we let it settl again , and sampl the visibl vector again .
and so on .
now the main reason why the learn could be difficult .
thi is probabl the most import reason .
if you consid a chain of unit , a chain of hidden unit here , with visibl unit attach to the two end , and if we us a train set that consist of on , zero and zero , on .
in other word , we want the two visibl unit to be in opposit state .
then the wai to achiev that is by make sure that the product of all those weight is neg .
so , for exampl , if all of the weight ar posit , turn on w1 will tend to turn on the first hidden unit .
and that will tend to turn on the second hidden unit , and so on .
and the fourth hidden unit will tend to turn on the other visibl unit .
if on of those weight is neg , then we'll get an anti correl between the two visibl unit .
what thi mean is , that if we're think about learn weight w1 , we need to know other weight .
so there's w1 .
to know how to chang that weight , we need to know w3 .
we need to have inform about w3 , becaus if w3 is neg what we want to do with w1 is the opposit of what we want to do with w1 if w3 is posit .
so given that on weight need to know about other weight in order to be abl to chang even in the right direct , it's veri surpris that there's a veri simpl learn algorithm , and that the learn algorithm onli requir local inform .
so it turn out that everyth that on weight need to know about all the other weight and about the data is contain in the differ of two correl .
anoth wai of sai that is that if you take the log probabl that the boltzmann machin assign to a visibl vector v .
and ask about the deriv of that log probabl with respect to a weight , wij .
it's the differ of the expect valu of the product of the state of i and j .
when the network settl to thermal equilibrium with v clamp on the visibl unit .
that is how often ar inj on togeth when v is clamp in visibl unit and the network is at thermal equilibrium , minu the same quantiti .
but when v is not clamp on visibl unit , so becaus the deriv of the log probabl of a visibl vector is thi simpl differ of correl we can make the chang in the weight be proport to the expect product of the activ averag over all visibl vector in the train set , that's what we call data .
minu the product of the same two activ when your not clamp anyth and the network ha reach thermal equilibrium with no extern interfer .
so thi is a veri interest learn rule .
the first term in the learn rule sai rais the weight in proport to the product of the activ the unit have when you're present data .
that's the simplest form of what's known as a hebbian learn rule .
donald hebb , a long time ago , in the 1940s or 1950s , suggest that synaps in the brain might us a rule like that .
but if you just us that rule , the synaps strength will keep get stronger .
the weight will all becom veri posit , and the whole system will blow up .
you have to somehow keep thing under control , and thi learn algorithm is keep thing under control by us that second term .
it's reduc the weight in proport to how often those two unit ar on togeth , when you're sampl from the model's distribut .
you can also think of thi as the first term is like the storag term for a hopfield net .
and the second term is like the term for get rid of spuriou minima .
and in fact thi is the correct wai to think about that .
thi rule tell you exactli how much unlearn to do .
on obviou question is why is the deriv so simpl .
well , the probabl of a global configur at thermal equilibrium , that is onc you've let it settl down , is an exponenti function of it energi .
the probabl is relat to e to the minu energi .
so when we settl to equilibrium we achiev a linear relationship between the log probabl and the energi function .
now , the energi function is linear in the weight .
so , we have a linear relationship between the weight and the log probabl .
and sinc we're try to manipul log probabl by manipul weight , that's a good thing to have .
it's a log linear model .
in fact , the relationship's veri simpl .
it's that the deriv of the energi with respect to a particular weight wij is just the product of the two activ that , that weight connect .
so what's happen here ?
is the process of settl to thermal equilibrium is propag inform about weight ?
we don't need an explicit back propag stage .
we do need two stage .
we need to settl with the data .
and we need to settl with no data .
but notic that the network behav in pretti much the same wai in those two phase .
the unit deep within the network is do the same thing , just with differ boundari condit .
with back prop the forward pass and the backward pass ar realli rather differ .
anoth question you could ask is what's that neg phase for .
i've alreadi said it's like the unlearn we do in a hopfield net to get rid of spuriou minima .
but let's look at it in more detail .
the equat for the probabl of a visibl vector , is that it's a sum overal hidden vector of e to the minu the energi of that visibl and hidden vector togeth .
normal by the same quantiti , sum overal visibl vector .
so if you look at the top term , what the first term in the learn rule is do is decreas the energi of term in that sum that ar alreadi larg and it find those term by settl to thermal equilibrium with the vector v clamp so that it can find an h that goe nice with v , that is give a nice low energi with v .
have sampl those vector h , it then chang the weight to make that energi even lower .
the second phase in the learn , the neg phase , is do the same thing , but for the partit function .
that is , the normal term on the bottom line .
it's find global configur , combin of visibl and hidden state that give low energi , and therefor , ar larg contributor to the partit function .
and have find those global configur , it tri to rais their energi so that the can contribut less .
so the first term is make the top line big , and the second term is make the bottom line small .
now in order to run thi learn rule , you need to collect those statist .
you need to collect what we call the posit statist , those ar the on when you have data clamp on the visibl unit , and also the neg statist , those ar the on when you don't have data clamp and that you're go to us for unlearn .
an ineffici wai to track these statist wa suggest by me and terri sejnowski in <num> .
and the idea is , in the posit phase you clamp a data vector on the visibl unit , you set the hidden unit to random binari state , and then you keep updat the hidden unit in the network , on unit at a time , until the network reach thermal equilibrium at a temperatur of on .
we actual did that by start at a high temperatur and reduc it , but that's not the main point here .
and then onc you reach thermal equilibrium , you sampl how often two unit ar on togeth .
so you're measur the correl of inj with that visibl vector clamp .
you then repeat that , over all the visibl vector , so that , that correl you're sampl is averag over all the data .
then in the neg phase , you don't clamp anyth .
the network is free from extern interfer .
so , you set all of the unit , both visibl and hidden , to random binari state .
and then you updat the unit , on at a time , until the network reach thermal equilibrium , at a temperatur of on .
just like you did in the posit phase .
and again , you sampl the correl of everi pair of unit inj , and you repeat that mani time .
now it's veri difficult to know how mani time you need to repeat it , but certainli in the neg phase you expect the energi landscap to have mani differ minima , but ar fairli separ and have about the same energi .
the reason you expect that is we're go to be us boltzmann machin to do thing like model a set of imag .
and you expect there to be reason imag , all of which have about the same energi .
and then veri unreason imag , which have much higher energi .
and so you expect a small fraction of the space to be these low energi state .
and a veri larg fraction of the space to be these bad high energi state .
if you have multipl mode , it's veri unclear how mani time you need to repeat thi process to be abl to sampl those mode .
in thi video , i'll go into more detail about how we can speed up the boltzmann machin learn algorithm by us clever wai of keep markov chain near the equilibrium distribut , or by us what ar call mean field method .
the materi is quit advanc and so it's not realli part of the cours .
there won't be ani quizz on it and it's not on the final test .
you can safe skip thi video .
it's includ for peopl who ar realli interest in how to get deep boltzmann machin to work well .
there ar better wai of collect the statist than the method that terri snofski and i origin came up with .
if we start from a random state , it mai take a long time to reach thermal equilibrium .
also , there's no easi test for whether you've reach thermal equilibrium , so we don't know how long we need to run for .
so , the idea is why not start from whatev state you end up in last time you saw that particular data vector ?
so , we rememb the interpret of the data vector in the hidden unit , and we start from there .
thi store state , the interpret of the data vector , is call a particl .
us particl that persist give us a warm start and it ha a big advantag .
if we were at equilibrium befor and we onli updat the weight a littl bit , it'll onli take a few updat of the unit in a particl to bring it back to equilibrium .
we can us particl for both the posit phase , where we have a clamp data vector , and for the neg phase , when noth is clamp .
so , here's the method for direct statist introduc by radford neal in <num> .
in the posit phase , you have a set of data specif particl , on or a few per train case .
and each particl ha a current valu that's the configur of the hidden unit plu which data vector it goe with .
you sequenti updat all the hidden unit a few time in each particl with the relev data vector clamp .
and then , for everi connect pair of unit , you averag the probabl of the two unit be on over all these particl .
in the neg phase , you keep a set of fantasi particl .
that is , these ar global configur .
and again , after each weight updat , you sequenti updat all the unit in each fantasi particl a few time .
now , you're updat the visibl unit as well .
and for everi connect pair of unit , your averag , sisj , over all the fantasi particl .
the learn rule is then the chang in the weight is proport to the averag you got with data , averag over all train data , and the averag you got with the fantasi particl when noth wa clamp .
thi work better than the learn rule that terri snofski and i introduc , at least for full batch learn .
howev , it's difficult to appli thi approach to mini batch .
and the reason is , that by the time we get back to the same data vectorn if we're us mini batch learn , the weight would have been updat mani time .
son the store data specif particl for that data vector won't be anywher near thermal equilibrium anymor .
the hidden unit won't be in thermal equilibrium with the visibl unit of the particl given the new weight .
and again , we don't know how long we're go to have to run for , befor we get close to equilibrium again .
so , we can overcom thi by make a strong assumpt about how we understand the world .
it's a kind of a epistemolog assumpt .
we're go to assum that when a data vector is clamp , the set of good explan , that is state of the hidden unit , that act as interpret of that data vector is uni modal .
that mean we're sai that , for a given data vector , there aren't two veri differ explan for that data vector .
we assum that for sensori input , there is on correct explan .
and if we have a good model of the data , our model will give us on energi minimum for that data point .
thi is a restrict on the kind of model we're will to learn .
we're go to us a learn algorithm that's incap of learn model in which a data vector ha mani veri differ interpret .
provid we're will to make thi assumpt , we can us a veri effici method for approach thermal equilibrium or an approxim to thermal equilibrium , with the data .
it's call a mean field approxim .
so , if we want to get the statist right , we need to updat the unit statist and sequenti .
and the updat rule is the probabl of turn on unit , i , is the logist function of the total input it receiv from the other unit in it bia .
where sj , the state of anoth unit , is a stochast binari thing .
now , instead of us that rule , we could sai , we're not go to keep binari state for unit i , we're go to keep a real valu between zero and on which we call a probabl .
and that probabl at time t on is go to be the output of the logist function .
the more you put in is the bia , and the sum of all the probabl at time t time the weight .
so , we're replac thi stochast binari thing by a real valu probabl .
and that's not quit right becaus thi stochast binari thing is insid a non linear function .
if it wa a linear function , thing would be fine .
but becaus the logist non linear , we don't get the right answer when we put probabl instead of fluctuat binari thing insid .
howev , it work pretti well .
it can go wrong by give us biphas oscil becaus now we're go to be updat everyth in parallel .
and we can normal deal with those by us what's call damp mean field where we comput that pi  of t1 .
on .
but , we don't go all the wai there .
we go to a point in between where we ar now , and where thi updat want us to go .
so , in damp mean field , we'll go to lambda time the place we ar now , plu on minu lambda time the place the updat rule tell us to go to .
and that will kill oscil .
now , we can get an effici mini batch learn procedur for both the machin , and thi is what russ salakhutdinov realiz .
in the posit phase , we can initi all probabl at <num> .
we can clamp a data vector on the visibl unit , and we can updat all the hidden unit in parallel us mean field until converg .
and for mean field , you can recogn converg is when the probabl stop chang .
and onc we converg , we record pipj for everi connect pair of unit .
in the neg phase , we do what we were do befor .
we keep a set of fantasi particl , each of which ha a valu that's a global configur .
and after each weight updat , we sequenti updat all the unit in each fantasi particl a few time .
and then , for everi connect pair of unit , we averag sisj , these stochast binari thing , over all fantasi particl .
and the differ in those averag is the learn rule .
that is , we chang the weight by an amount proport to that differ .
if we want to make the updat for the fantasi particl more parallel , we can chang the architectur of the boltzmann machin .
so , we're go to have a special architectur that allow altern parallel updat for the fantasi particl .
we have no connect within a layer , and we have no skip layer connect , but we allow ourselv lot of hidden layer .
so , the architectur look like thi .
we call it a deep boltzmann machin .
and , it's realli a gener boltzmann machin with lot of miss connect .
all those skip layer connect , if thei were present .
we wouldn't realli have layer at all , it would just be a gener boltzmann machin .
but , in thi special architectur , there's someth nice we can do .
we can updat the state for exampl the first hidden layer and the third hidden layer , given the current state of the visibl unit and the second hidden layer .
and then , we can updat the state of the visibl unit in the second hidden layer .
and then , we can go back and updat the other state , and we can go backward and forward like thi .
and so , we can updat half the state of all the unit in parallel and that'll be a correct updat .
so , on question is , if we have a deep boltzmann machin like that train by us mean field for the posit phase and updat fantasi particl by altern between even layer and odd layer for the neg phase , can we learn good model of thing like the mnist digit , or inde , a more complic thing ?
so , on wai to tell whether you've learn a good model is after learn , you remov all the input and you just gener sampl from your model .
so , you run the markov chain for a long time until it's burn in , and then you look at the sampl you get .
so , russ salakhutdinov us a eep boltzmann machin to model mnist digit us mean field for the posit phase , and altern updat of the layer of the particl for the neg phase .
and the real data look like thi .
and the data that he got from hi model look like thi .
you can see , thei're actual fairli similar .
the model is produc thing veri like the mnist digit so it's learn a pretti good model .
so here's a puzzl .
when he wa learn that , he wa us mini batch with <num> data exampl and also he wa us <num> fantasi particl , the same <num> fantasi particl for everi mini batch .
and the puzzl is , how can we estim the neg statist with onli <num> neg exampl to character the whole space ?
for all interest problem , the global configur base is go to be highli multi model .
and how do we manag to find and repres all the node with onli <num> particl ?
there's an interest answer to thi .
the learn interact with the markov chain that's be us to gather the neg statist , either on that's us to updat the fantasi particl , and it interact with it to make it have a much higher effect mix rate .
that mean , we cannot analyz the learn by think of it be an outer loop that updat the weight , and an inner loop that gather statist with a fix set of weight .
the learn is affect how effect that inner loop is .
the reason for thi is that whenev the fantasi particl outnumb the posit data , the energi surfac is rais , and thi ha an effect on the mix rate of the markov chain .
it make the fantasi rush around hyper activ , and thei move around much faster than the mix rate of the mark of chain to find better current static weight .
so , here's a pictur that show you what's go on .
if there's a mode in the energi surfac that ha more fantasi particl than data , the energi surfac will be rais until the fantasi particl escap from that mode .
so , the mode on the left ha four fantasi particl and onli two data point .
so , the effect of the learn is go to be to rais the energi there .
and that energi barrier might be much too high for a markov chain to be abl to cross , so the mix rate will be veri slow .
but , the learn will actual spill those red particl out of that energi minimum by rais the minimum .
and we get fill up and the fantasi particl will escap and go off somewher els , to some other deep minimum .
so , we can get out of minima that the markov chain would not be abl to get out of , at least , not in a reason time .
so , what's go on here is the energi surfac is realli be us for two differ purpos .
the energi surfac repres our model , but it's also be manipul by the learn algorithm to make the markov chain mix faster .
or rather , to have the effect of a faster mix markov chain .
onc the fantasi particl have fill up on hole , thei'll rush off to somewher els and deal with the next problem .
an analog for them is that their like investig journalist who rush in to investig some nasti problem .
as soon as the public ha caus that problem to be fix , instead of sai , okai , everyth is okai now .
thei rush off to find the next nasti problem .
in thi video , i will introduc restrict boltzmann machin .
these have a much simplifi architectur in which there ar no connect between hidden unit .
thi make it veri easi to get the equilibrium distribut of the hidden unit if the visibl unit ar given .
that is , onc you've clamp the datavector on the visibl unit , the equilibrium distribut of the hidden unit can be comput exactli in on step becaus thei're all independ of on anoth , given the state of the visibl unit .
the proper boltzmann machin learn algorithm is still slow for a restrict boltzmann machin .
but in <num> , i discov a veri surpris shortcut that lead to the first effici learn algorithm for boltzmann machin .
even though thi algorithm ha theoret problem , it work quit well in practic .
and it led to a reviv of interest in boltzmann machin learn .
in a restrict boltzmann machin , we restrict the connect of the network in order to make both infer and learn easier .
so , it onli ha on layer of hidden unit and there's no connect between the hidden unit .
there's also no connect between the visibl unit .
so , the architectur look like that , it's what comput scientist call a bipartit graph .
there's two piec , and within each piec , there's no connect .
the good thing about an rbm is that if you clamp a datavector in the visibl unit , you can reach thermal equilibrium in on step .
that mean with a datavector clamp , we can quickli comput the expect valu of vihj becaus we can comput the exact probabl with each j will turn on , and that is independ of all the other unit in the hidden layer .
the probabl that j will turn on is just the logist function of the input that it get from the visibl unit and quit independ of what other hidden unit ar do .
so , we can comput that probabl all in parallel and that's a tremend win .
if you want to make a good model of a set of binari vector , then the right algorithm to us for a restrict boltzmann machin is on introduc by tieleman in <num> that's base on earlier work by neal .
in the posit phase , you clamp the datavector on the visibl unit .
you then comput the exact valu of the expect vihj for all pair of invis in the hidden unit .
and you could do that cuz vi is fix , and you can comput vj exactli .
and then , for everi connect pair of unit , you averag the expect valu of vihj over all the data vector in the mini batch .
for the neg phase , you keep a set of fantasi particl that is global configur .
and then , you updat each fantasi particl a few time by us altern parallel updat .
so , after each weight updat , you updat the fantasi particl a littl bit and that should bring them back to close to equilibrium .
and then , for everi connect pair of unit , you averag vihj over all the fantasi particl , and that give you your neg statist .
thi algorithm actual work veri well , and allow rbm to build good densiti model or set of binari vector .
now , i am go to go on to our learn algorithm that is not as good at build densiti model but is much faster .
so , i'm go to start with a pictur of an ineffici learn algorithm for restrict boltzmann machin .
we're go to start by clamp a datavector on the visibl unit , and we're go to call that time t0 .
so , we're go to us time now , not to denot weight updat , but to denot step in a markov chain .
given that visibl vector , we now updat the hidden unit .
so , we choos binari state for the hidden unit and we measur the expect valu , vihj , for all pair of visibl and binari unit that ar connect .
and i'll call that vihj zero to indic that it's measur at time zero , with the hidden unit be determin by the visibl unit .
and , of cours , we can updat all the hidden unit in parallel .
we then us the hidden vector to updat all the visibl unit in parallel , and again we updat all the hidden unit in parallel .
so , the visibl vector t1 on , we'll call a reconstruct , or a on step reconstruct , and we can keep go with the altern chain that wai , updat visibl unit , and then hidden unit , each set be updat in parallel .
and after we've gone for a long time , we'll get to some state of the visibl unit , or i'll call t infin to indic it need to be a long time and the system will be at thermal equilibrium , and now , we can measur the correl of vi and hj after the chain run for a long time and i'll call that vihj infin .
and the visibl state we have after a long time , i'll call it fantasi .
so now , the learn rule is simpli , we chang wij by the learn rate time the differ between vihj at time zero and vihj at time infin .
and , of cours , the problem with thi algorithm is that we have to run thi chain for a long time befor it reach thermal equilibrium .
and if we don't run it for long enough , the learn mai go wrong .
in fact , that last statement is veri mislead .
it turn out that even if we onli run the chain for a short time , the learn still work .
so , here's the veri surpris shortcut .
you just run the chain up , down , and up again .
so , from the data , you gener a hidden state , from that .
you gener a reconstruct , and from that , you gener anoth hidden state .
and you mai have a statist onc you've done that .
so , instead of us the statist measur at equilibrium , we're us the statist measur after do on full updat of the markov chain .
the learn rule is , and the same as befor , except thi much quicker to comput , and thi is clearli is not do maximum likelihood learn becaus the term we ar us for neg statist is wrong .
but the learn , nevertheless , work quit well .
next week , we'll understand a bit more about why it work well .
but for now , we'll just see that it doe .
so , the obviou question is why doe actual cut work at all ?
and here's the reason .
if we start the chain at the data , the markov chain will wander awai from the data and toward it equilibrium distribut .
that is toward thing that is initi weight like more than the data .
we can see what direct it's wander in after onli a few step .
and if we know the initi weight aren't veri good , it's a wast of time to go all the wai to equilibrium .
we know how to chang them to stop it wander awai from the data without go all the wai to equilibrium .
all we need to do is lower the probabl of the reconstruct of confabul as a psychologist would call them , it produc after on full step , and then , rais the probabl of the data .
that will stop it wander awai from the data .
onc the data and the place it goe to after on full step have the same distribut , then the learn will stop .
so , here's a pictur of what's go on .
here's the energi surfac in the space of global configur .
here's a data point on the energi surfac , and by data point , i mean , both the visibl vector and the particular hidden vector that we got by stochast updat the hidden unit .
so , that hidden vector is a function of what the data point is .
so , start at that data point , we run the markov chain for on full step to get a new visibl vector and the hidden vector that goe with it .
so , a reconstruct of the data point plu the hidden vector that goe with that reconstruct .
we then chang the weight to pull the energi down at the data point , and pull to the energi up the reconstruct .
and the effect of that would be to make the surfac look like thi .
and you'll notic we're begin to construct an energi minimum at the data .
you'll also notic that far awai from the data , thing have stai pretti much as thei were befor .
so , thi shortcut of onli do on full step to get the reconstruct fail for place that ar far awai from the data .
we need to worri about region of the data space that the model like but which ar veri far from ani data point .
these low energi hole caus the normal term to be big , and we can't sens them if we us the shortcut .
if we us persist particl , where we rememb their state , and after each updat , we updat them a few more time , then thei would eventu find these hole .
thei'd move into the hole , and the learn would caus the hole to fill up .
a good compromis between speed and correct is to start with small weight and to us cd1 , that is contrust diverg with on full step to get the neg data .
onc the weight have grown a bit , the markov chain is mix more slowli , and now we can us cd3 .
onc the weight have grown more , we can us cd5 , or nine , or ten .
in thi video , i'm go to show a simpl exampl of a restrict boltzmann machin learn a model of imag of handwritten two .
after it's learn the model , we'll look at how good it is at reconstruct two .
and we'll look at what happen if we give it a differ kind of digit and ask it to reconstruct that .
we'll also look at the weight we get if we train a restrict boltzmann machin that's consider larger on all of the digit class .
it lend a wide varieti of featur , which between them ar veri good at reconstruct all the differ class of digit , and also ar quit a good model of those digit class .
that is , if you take a binari vector , thi imag of a hundr digit , the model will be abl to find low energi state , compat with that imag and if you give it an imag that's a long wai awai from be an imag of a hundr digit , the model will not be abl to find low energi state compat with that imag .
i'm now gonna show how a rel simpl rbm can learn to build a model of imag of the digit two .
the imag of sixteen pixel by sixteen pixel .
and it ha <num> binari hidden unit that thei're gonna learn to becom interest featur detector .
so when it's present with the data case , the first thing that it doe is us the weight and the connect from pixel to featur like thi , to activ the featur like thi .
that is for each of the binari neuron , it make the sarcast decis about whether it should deduct the state of on or zero .
it then us the binari pan for activ to reconstruct the data .
that is , for each pixel , it make a binari decis about whether it should be a on or a zero .
it then reactiv the binari featur detector us the reconstruct to activ them rather than the data .
the weight ar chang by increment the weight between an activ pixel and an activ featur detector when the network is look at data .
and that will lower the energi of the global configur of the data , and whatev hidden pattern went with it .
and it decrement the weight , between an activ pixel and an activ featur detector , when it's look at a reconstruct , and that would rais the energi of the reconstruct .
near the begin of learn when the weight ar random , the reconstruct would almost certainli have lower energi than the data .
becaus the reconstruct is what the network like to reproduc on the visibl unit , given the hidden pattern of activ .
and obvious it like to reproduc pattern that have low energi accord to it energi function .
and you can think of what learn doe as chang the weight so the data is low energi .
and the reconstruct of the data ar gener higher energi .
so let's start with some random weight for the <num> featur detector .
we'll us small random weight and each of these squar show you the weight to the pixel come from a particular featur detector .
the small random weight ar us to break symmetri .
that becaus the updat were stochast , we don't realli need that .
after see a few hundr exampl of digit , and digest the weight a few time , the weight ar begin to form pattern .
if we do it again , you can see that mani of the featur detector ar detect the pattern of a hole two .
thei're fairli global featur detector .
and those featur detector ar get stronger , and stronger , and now some of them begin to local , and thei're get more local , and even more local , and even more local , and these ar the final weight and you can see that each neuron ha becom a differ featur detector and most of the featur detector ar fairli local .
if you look at the featur detector in the red box , for exampl , it's detect the top of a two , and it's happi when the top of a two is where it white pixel ar and where there's noth where the black pixel ar .
so it's repres where the top of the two is .
onc we've learn the model , we can look at how well it reconstruct digit .
and we'll give it some test digit that it hasn't seen befor .
so we'll start by give it a test exampl of a two .
and it reconstruct is pretti faith to the test exampl .
it's slightli blurri .
the test exampl ha a hook at the top and that's been blur after the reconstruct , but it's a pretti good reconstruct .
the more interest thing we can do , is give it a test exampl from a differ digit class .
so if we give it an exampl of the three to reconstruct .
what it reconstruct actual look more like a two then like a three .
all of the featur detector is learn , ar good for repres two , but it doesn't have featur detector for thing like repres that cusp in the middl of the three .
so it end up reconstruct someth , but obei the regular of a two , better than it repres the regular of a three .
in fact , the network tri to see everyth as a two .
so here's some featur detector that were learn in the first hidden layer of a model that us <num> hidden unit to model all ten digit class .
and thi model ha been train for a long time with contrast diverg .
it ha a big varieti of featur detector .
if you look at the on in the blue box , that's obvious go to be us for detect thing like eight if you look at the on in the red box , it's not what you expect to see .
it like to see pixel on veri near the bottom there , and it realli doesn't like to see pixel on in a road that's <num> pixel abov the bottom .
what's go on here is that the data is normal and so the digit can't have a height of greater than twenti pixel .
and that mean if you know that there's a pixel on where those big posit weight ar , there can't possibl be a pixel on , where those neg weight ar .
so thi is pick up on the long rang regular that wa introduc by the wai we normal the data .
here's anoth on that's do the same thing for the fact that the data can't be wider than twenti pixel .
the featur detect in the green box is veri interest .
it's for detect where the bottom of a vertic stroke come and it will detect it in a number of differ posit and then refus to detect it in the intermedi posit .
so it's veri like on of the least signific digit in a binari number , as you increas the magnitud of a number it goe on again , and off again , and on again , and off again and it show that thi is develop quit complex wai of repres where thing ar .
in thi video , i'm go to talk about appli restrict boltzmann machin to collabor filter .
collabor filter mean try to figur out how much a user would like on product base on how much that user like other product and how much mani other user like product .
the particular case we'll look at is the netflix competit , in which a machin learn algorithm ha to predict how much a particular user will like a particular movi .
the train data for thi competit consist of <num> million rate of <num> , <num> movi by half a million user .
so it's quit a big data set .
it's not the kind of thing anybodi at the time imagin a boltzmann machin could deal with .
as we'll see , there's an import trick to be abl to get a restrict boltzmann machin to cope with the fact that nearli all the rate of nearli all the movi ar miss .
but when we us thi trick , we're abl to train model , that ar veri us in practic , and were in fact us in the win entri .
so now i'm go to explain how restrict boltzmann machin were us for collabor filter in the netflix competit .
in that competit , you're given most of the rate that half a million user gave , to <num> , <num> movi , and each movi get rate on a scale from on to five .
each user , of cours , onli rate a small fraction of the movi .
but even so , there's about a hundr million rate , so it's quit a big data set .
you have to predict the rate that the user gave to held out movi , and if you can do that well you get a big prize .
you actual win a million dollar if you're the best person at do that .
so , you can draw the rate in a big matrix like thi where we have movi across the top , and user down the side .
and so for exampl , user two gave a rate of five to movi on , and a rate of on to movi three .
user four gave a rate of four to movi on , and the question is what rate did he give to movi three .
you might decid he's quit like user two becaus he rate movi on the same wai .
so mayb like user two he hate movi three .
on the other hand , user four like movi six .
so mayb he like all the movi .
by the time you've done that much reason , you realiz you better us some statist .
let's start by try to us a languag model .
it sound bizarr , but as you'll see it's equival to a standard method .
so we can write the data as a string of tripl , much like famili tree .
each tripl ha a form , user , movi and rate .
so here's some of the data on that tabl on the previou slide and we just have to predict the third term of a tripl .
so if we built a languag model , what we would do is we'd convert each user into a vector featur for that user , that is a vector that we learn and we convert movi into a vector featur for that movi , a vector that we learn and from those two featur vector , we try and predict the rate .
now , the obviou wai to do thi is to put in a big hidden layer , and make the featur vector feed into the hidden layer and then have the hidden layer predict the rate .
we tri that , and we couldn't get that to work ani better than a veri simpl method .
which is simpli , to take the scalar product of the featur vector for the user and the featur vector for the movi .
you just multipli them togeth point wise , add it up and output that as your rate .
so it's not even a soft max , you actual output whatev real number you get form the scaler product .
now that's exactli equival to do someth els , which is normal call a matrix factor model .
if we arrang the user featur down the row and the movi featur abov the column , we can see that if we multipli , that matrix of user time featur by the matrix of featur time movi , then we'll get predict for the rate .
and it will be exactli equival to the languag model that's besid it .
so the matrix factor model is the most commonli us model for collabor filter like thi , and it work pretti well .
now let's consid an altern model , us our restrict boltzmann .
machin .
it's not obviou how you would appli a restrict boltzmann machin to thi problem .
and so we had to do some think .
in the end we decid that we would treat each user as a train case .
and so a user is realli a vector of movi rate .
and for each movi we would have a visibl unit that had five altern valu .
so visibl unit instead of be binari , ar five wai softmax .
and so the network of our restrict boltzmann machin look like thi .
each of it's visibl unit is a five wai softmax , with on visibl unit per movi .
you might start worri about there be <num> , <num> visibl unit here .
and then we had about <num> binari hidden unit .
and each hidden unit is connect to all five valu of the soft max .
it also ha a bia .
and so you can see the number of paramet we'll have is larg .
the cd learn rule for softmax , incident is exactli the same as for a binari unit and like i said we've got about a <num> in unit .
and what we're go to do is learn a model and then try and fill in on of the miss valu us the model .
now the problem with thi approach , is we don't want to have an rbm with <num> , <num> visibl unit .
onli a few of which have known valu .
that's a huge number of miss valu to begin with .
and there's a neat wai around that .
for each user we us an rbm that onli ha as mani visual unit as the movi that the user rate .
so , it's possibl that everi user will correspond to a differ rbm , with a differ subset , with visibl unit .
now , all of these rbm ar go to share the same weight .
that is , we know which move is which .
and so if two user saw the same movi and rate the same movi , the weight from that movi to the hidden unit will be the same for those two user .
so we're do an aw lot of weight share here .
and that's lucki , becaus for each user , we onli get on train case .
we make thi specif rbm for each user with the right architectur , that is , the right number of visibl unit for the movi that the user rate .
and now there's onli on train case , which is that rate vector .
but all of these half a million train case share weight to hidden unit .
so the learn work fine .
the model ar train with cd1 and then after a while with cd3 .
that is you go up and down three time befor you collect the statist for the neg phase and then we cd5 and then we cd9 and how well doe it work ?
well the rbm's work about as well as the matrix factor method but thei give veri differ error .
what that mean is that if you averag the predict of the rbm's with the predict of the matrix factor method , you get a big win , and the win group actual us multipl differ rbm model in their averag and multipl differ matrix factor model and i think probabl other model as well .
in thi video , i'm go to talk about the histori of backpropag .
i'll start with where it came from in the 70s' and 80s , ' and then i'll talk a bit about why it fail in the 90s . ' that is , why seriou machin learn research ha abandon it .
there wa a popular view of why thi happen , and we can now see that , that popular view wa larg wrong .
the real reason it wa abandon were becaus comput were too slow and data set were too small .
i'll conclud by show you a histor document .
there wa a bet made between two machin learn research in <num> .
it's interest to see what peopl back then believ and how wrong thei were .
backpropag wa invent independ sever time in the 70s' and 80s' .
it start in the late 60s' with control theori call bryson and ho who invent a linear version of backpropag .
paul werbo went to their lectur and realiz it could be made non linear .
and in hi thesi in <num> , he publish what's probabl the first proper version of backpropog .
rumelhart and william and i invent it in <num> without know about paul werbo's work .
but we tri it out , and it didn't work veri well for the first thing we tri it for , and so we abandon it .
david parker invent it in <num> , and so did yann lecun .
also in <num> , i went back and tri again the thing that rumelhart , william and i had abandon and discov it work pretti well .
in <num> , we produc a paper with a realli convinc exampl of what it could do .
it wa clear the backpropag had a lot of promis for learn multipl layer of non linear futur detector .
but it didn't realli live up to it promis .
and by the late 1990s , most of the seriou research in machin learn had given up on backpropag .
for exampl , in david mukai's textbook , there's veri littl mention of it .
it wa still wide us by psychologist for make psycholog model .
and it wa also quit wide us in practic applic , such as credit card fraud detect .
but in machin learn , peopl thought it had been supplant by support vector machin .
the popular explan of what happen to backpropag in the late 90s' wa that it couldn't make us of multipl layer and non linear featur .
thi wasn't true in convolut net , which were the except .
but in gener , peopl couldn't get feed forward neural network train with backpropag to do impress thing if thei had multipl hidden layer , except for some toi exampl .
it also did not work well in recurr network or in deep auto encod , which we'll cover in our later lectur .
and recurr network were perhap the place where it most excit , and so it wa there that it wa most disappoint that peopl couldn't make it work well .
support vector machin by contrast , work well .
thei didn't requir as much expertis to make them work , thei produc repeat result , and thei had a much better theori .
and thei had much fanci of theori .
so , that wa the popular explan of what went wrong with backpropag .
with a more histor prospect , we can see why realli fail .
the comput were thousand of time too slow , and the label data's set hundr of time too small for the regim in which backpropag would realli shine .
also , the deep network , as well as be too small , were not sensibl initi .
and so , backpropag through deep network didn't work well becaus the gradient tend to die , becaus the initi weight were typic too small .
these issu prevent backpropag from be success .
for task like vision and speech , thei would eventu be a big win .
so , we need to distinguish between differ kind of machin learn task .
there's on that ar more typic of the kind of thing peopl studi in statist , and on that ar more typic of the kind of thing peopl studi in artifici intellig .
so , at the statist end of the spectrum , you typic have low dimension data .
a statistician think of a <num> dimens as high dimension data .
at the artifici intellig end of the spectrum , thing like imag or coeffici repres speech typic have mani more than a <num> dimens .
at the statist end of the spectrum , there's usual a lot of nois in the data .
wherea , in the ai end of the spectrum , nois isn't the real problem .
for statist , there's often not that much structur in the data , and what structur there is can be captur by a fairli simpl model .
at the ai end of the spectrum , there's typic a huge amount of structur in the data .
so if you take a set of imag , it highli structur data .
but the structur is too complic to be captur by a simpl model .
so in statist , the main problem is separ true structur from nois , not think that nois is realli structur .
thi can be done by a bayesian neural net pretti well .
but for typic non bayesian neural net , it's not the kind of problem thei're good at .
and so , for problem like that , it make sens to try a support vector machin or a method call a gaussian process if you're do regress , which i'll talk about briefli later .
at the artifici intellig end of the spectrum , the main problem is to find a wai of repres all thi complic structur so that it can be learn .
the obviou thing to do is to try to hand design appropri represent .
but actual , it's easier to let back propag figur out what represent to us by give it multipl layer and us a lot of comput power to let it decid what the represent should be .
i now want to talk veri briefli about support vector machin .
i'm not go to explain how thei work , but i am go to sai what i think their limit ar .
so , there's sever wai in which you can view a support vector machin , and i'm go to give you two differ view of them .
accord to the first view , support vector machin ar just the reincarn of percept with a clever trick call the kernel trick .
so , the idea is that you take the input , you expand the raw input into a veri larg lair of non linear , but also non adapt featur .
so , that's just like perceptron where you have thi big layer of featur it doesn't learn .
and then , you onli have to learn on layer of adapt weight , the weight from the featur to the decis unit .
and support vector machin have a veri clever wai of avoid overfit when thei learn those weight .
thei look for what's call a maximum margin hyperplan in a high dimension space , and thei can do that much more effici than you might have thought possibl .
and , that's why thei work well .
the second view also view support vector machin as a clever reincarn of perceptron .
but , it ha a complet differ notion of what kind of featur thei're us .
so , accord to the second view , each input vector in the train set is us to defin on featur .
i'll spell it differ to indic it's a complet differ kind of featur from the first kind .
each of these featur give a scale of valu which involv do a global match between a test input and that particular train input .
so , roughli speak , it's how similar the test input is to a particular train case .
then , there's a clever wai of simultan find how to weight those featur , so as to make the right decis , and also dure featur select .
that is , decid which of those featur not to us .
so , although these view sound extrem differ from on anoth , thei're just two altern wai of look at the same thing , a support vector machin .
and , in both case , it's us non adapt featur and then on layer of adapt weight .
and that limit to what you can do that wai .
you can't learn multipl layer of represent with a support vector machin .
thi is a histor document from <num> .
it wa given to me by and it's a bet between larri jackel , who head the adapt system research group at bell lab , and vladamir vapnik , who is the lead propon of support vector machin .
larri jackel bet that by <num> , peopl would understand why big neural net train with backpropag work well on larg data set .
that is , thei would understand it theoret in term of condit and band .
vapnik bet that thei wouldn't , but he made a side bet .
that if he wa the on to figur it out , he would win anywai .
vapnik in turn , bet that by <num> , nobodi will be us big neural net like that train backpropag .
it turn out that thei were both wrong .
the limit to us big neural net with backpropag wa not that we didn't have a good theori and not that thei were essenti helpless , but that we didn't have big enough comput or big enough data set .
it wa a practic limit not a theoret on .
in thi lectur , i'll introduc belief net .
on of the reason i abandon back propag in the <num>'s is becaus it requir too mani label .
back then , we just didn't have data set with suffici number of label .
i wa also influenc by the fact that peopl manag to learn with veri few explicit label .
howev , i didn't want to abandon the advantag of do gradient descend learn to learn a whole bunch of weight .
so the issu wa , wa there anoth object function that we could do grade decent ?
the obviou place to look wa gener model where the object function is to model the input data rather than predict a label .
thi mesh nice with a major movement in statist and artifici intellig call the graphic model .
the idea of graphic model wa to combin discret graph structur for repres how variabl depend on on anoth .
with real valu comput that infer the probabl of on variabl , given the observ valu of other variabl .
boltzmann machin were actual a veri earli exampl of a graphic model , but thei were undirect graphic model .
in <num> , radford neal point out that us the same kind of unit as we us in boltzmann machin , we could make direct graphic model which he call sigmoid belief net .
and the issu then becam , how can we learn sigmoid belief net ?
the second problem is that for deep network , the learn time doe not scale well .
when there's multipl hidden layer , the learn wa veri slow .
you might ask why thi wa , and we now know that on of the reason wa we did not initi the weight in a sensibl wai .
yet , anoth problem is the back propag can get stuck in poor local optima .
these ar often quit good , so back propag is us .
but we can now show that for deep net , the local optima you get stuck in , if you start with small random weight ar typic far from optim .
there is the possibl of retreat to simpler model that allow convex optim .
but , i don't think thi is a good idea .
mathematician like to do that becaus thei can prove thing .
but in practic , you're just run awai from the complex of real data .
so , on wai to overcom the limit of back propag is by us unsupervis learn .
the idea is that we want to keep the effici and simplic of us a gradient method and stochast mini batch descent for adjust weight .
but , we're go to us that method for model the structur of the sensori input , not for model the relat between input and output .
so the idea is , the weight ar go to be adjust to maxim the probabl that a gener model would have gener the sensori input .
we alreadi saw that in learn boltzmann machin .
and on wai to think about it is , if you want to do comput vision , you should first learn to do comput graphic .
to first order , comput graphic work and comput vision doesn't .
the learn object for a gener model , as we saw with boltzmann machin , is to maxim the probabl of the observ data not to maxim the probabl of label given input .
then the question aris , what kind of gener model should we learn ?
we might learn an energi base model like the boltzmann machin , or we might learn a causal model made of ideal neuron , and that's what we'll look at first .
well final , we might learn some kind of hybrid of the two , and that's where we'll end up .
so , befor i go into causal belief net made of neuron , i want to give you a littl bit of background about artifici intellig and probabl .
in the <num>'s and earli <num>'s , peopl in artifici intellig were unbeliev anti probabl .
when i wa a graduat student , if you mention probabl , it wa assign that you were stupid and that you just hadn't got it .
comput were all about discret singl process , and if you'd introduc ani probabl thei would just infect everyth .
it's hard to conceiv of how much peopl ar against probabl , so here's a quot to help you .
i'll read it out .
mani ancient greek support socrat opinion that deep , inexplic thought came from the god .
todai's equivel to those god is the errat , even probabilist neuron .
it is more like that increas random of neural behavior is the problem of the epilept and the drunk , not the advantag of the brilliant .
that wa in patrick henri winston's first ai textbook , in the first edit .
and it wa the gener opinion at the time .
winston wa to becom the leader of the mit ai lab .
here's an altern view .
all of thi will lead to theori of comput which ar much less rigidli of an all or none natur than past and present formal logic .
there ar numer indic to make us believ that thi new system of formal logic will move closer to anoth disciplin which ha been littl link in the past with logic .
thi is thermodynam , primarili in the form it wa receiv from boltzmann .
that wa written by john von neumann in <num> , and wa part of the unfinish manuscript he left behind for what wa to be hi crown achiev , hi book on the comput and the brain .
i think if von neumann had live , the histori of artifici intellig might have been somewhat differ .
so , probabl eventu found their wai into ai by someth call graphic model , which ar a marriag of graph theori and probabl theori .
in the <num>'s , there wa a lot of work on expert system in ai that us bag of rule for task such as , medic diagnosi or explor for miner .
now , these were practic problem so thei had to deal with uncertainti .
thei couldn't just us toi exampl where everyth wa certain .
peopl in ai dislik probabl so much that even when thei were deal with uncertainti , thei didn't want to us probabl .
so , thei made up their own wai of deal with uncertainti that did not involv probabl .
you can actual prove that thi is a bad bet .
graphic model were introduc by pearl , heckman , lauritz and mani other who share that probabl actual work better than the ad hoc method develop by peopl do expert system .
discret graph were good for repres what variabl depend on what other variabl .
but onc you have those graph , you then need to do real valu comput that respect the rule of probabl so that you could comput the expect valu of some node in the graph , given the observ state of other node .
belief net is the name that peopl in graphic model give to a particular subset of graph which ar direct acycl graph .
and typic , thei us spars connect on .
and if those graph ar spars connect , thei have clever infer algorithm that can comput the probabl of unobserv node effici .
but , these clever of algorithm ar exponenti in the number of node that influenc each node , so thei won't work for dens connect node .
so , belief net is direct acycl graph compos of stochast variabl , and here's a pictur of on .
in gener , you might observ ani of the variabl .
i'm go to restrict myself to net in which you onli observ the leaf node .
so , we imagin is these unobserv hidden caus , and thei mai be lead , and thei eventu give rise to some observ effect .
onc we observ some variabl , there's two problem we'd like to solv .
the first is what i call the infer problem , and that's to infer the state of unobserv variabl .
of cours , we can't infer them with certainti , so what we're after is the probabl distribut of unobserv variabl .
and if unobserv variabl ar not independ of on anoth , given the observ variabl , there is probabl distribut ar like to be big cumbersom thing with an exponenti number of term in .
the second problem is the learn problem .
that is , given a train set compos of observ vector of state of all of the leaf node , how do we adjust the interact between variabl to make the network more like to gener that train data ?
so , adjust the interact would involv both decid which node is affect by which other node , and also decid on the strength of that effect .
so , let me just sai a littl bit about the relationship between graphic model and neural network .
the earli graphic model us expert to defin the graph structur and also the condit probabl .
thei would typic take a medic expert and ask him how like is thi to caus that , and then thei would make a graph in which the node had mean .
and thei typic had condit probabl tabl that describ how a set of valu for the parent of a node would determin the distribut of valu for the node .
their graph wa spars connect .
and the initi problem thei focus on wa how to do correct infer .
initi , thei weren't interest in learn becaus the knowledg came from the expert .
by contrast , for neural net , learn wa alwai a central issu and hand wire the knowledg wa regard as not cool .
although , of cours , wire in some basic properti , as in convolut net , wa a veri sensibl thing to do .
but basic , the knowledg in the net came from learn the train data , not from expert .
neural network didn't aim to have interpret or spars connect to make the infer easi .
nevertheless , there ar neural network version of belief net .
so , if we think about how to make gener model out of ideal neuron , there's basic two type of gener model you can make .
thi energi base model , where you connect binari stochast neuron us symmetr connect , and then you get a boltzmann machin .
a boltzmann machin , as we've seen , is hard to learn .
but if we restrict the connect , then it's easi to learn a restrict boltzmann machin .
howev , when we do that , we've onli learn on hidden layer .
and so , we're give up on a lot of the power of neural net with multipl hidden layer in order to make learn easi .
the other kind of model you can make is a causal model .
that is a direct acycl graph compos of binari stochast neuron .
and when you do that , you get a sigmoid belief net .
in <num> , neal introduc model like thi and compar them with boltzmann machin and show that sigmoid belief net were slightli easier to learn .
so , a sigmoid belief net is just a belief net in which all of the variabl ar binari stochast neuron .
to gener data from thi model , you take the neuron in the top layer .
you determin whether thei should be on or zero base on their bias , so you determin out stochast .
and then , given the state of the neuron in the top layer , you'd make stochast decis about what the neuron in the middl layer should be do .
and then , given their binari state , you make decis about what the visibl effect should be .
and by do that sequenc of oper , a causal sequenc from layer to layer , you would get an unbias sampl of the kind of vector of visibl valu that your neural network believ in .
so , in a causal model , unlik a boltzmann machin , it's easi to gener sampl .
in thi video , i'll talk about why it's difficult to learn sigmoid belief net .
and then in the follow two video , i'll describ two differ method we discov that allow us to do the learn .
the good new about learn in sigmoid belief net is that unlik boltzmann machin , we don't need two differ phase .
we just need what in a boltzmann machin would be the posit phase .
that's becaus sigmoid belief net ar what is call local normal model .
so we don't have to deal with a partit function or it deriv .
anoth piec of good new about sigma belief net , is that if we could get unbias sampl from the posterior distribut over the hidden unit , given the data vector , then learn would be easi .
that is , we could follow the gradient specifi by maximum likelihood learn , in a mini batch stochast kind of wai .
the problem is that it's hard to get unbias sampl , from the posterior distribut over the hidden unit .
thi is larg due to a phenomenon that judeo po call explain awai .
and i'll explain , explain awai in thi video and it's import to understand it .
now , i'm go to talk about why it's difficult to learn sigmoid belief net .
as we've seen , it's easi to gener an unbias sampl , onc you've done the learn .
that is , onc we've decid on the weight and the network , we can easili see the kind of thing the network believ in by gener sampl from thi model .
thi is done top down , on layer at a time .
it's easi , becaus it's a causal model .
howev , even if we know the weight , it's hard to infer the posterior distribut over hidden caus when we observ the visibl effect .
the reason for thi is that the number of possibl pattern of hidden caus is exponenti in the number of hidden node .
it's hard even to get a sampl from the posterior , which is what we need if we're go to do stochast gradient descent .
so given thi difficulti in sampl from the posterior .
it's hard to see how we can learn sigmoid belief net with million of paramet , which is what we'd like to do .
thi is a veri differ regim from the on normal us with graphic model .
there thei have interpret model , and thei're try to learn dozen or mayb hundr of paramet .
thei're not typic try to learn million of paramet .
now befor i go into wai in which we can try and get sampl from the posterior distribut .
i just want to tell you what the learn rule is , if we could get those sampl .
so , if we can get an unbias sampl from the posterior distribut of hidden state , given the observ data , then learn is easi .
so here's part of a sigmoid belief net , and we're go to suppos that for everi node we have a binari valu .
so , for node j , that binari valu is sj .
and that vector binari valu is a global configur for the node , which is the sampl from the posterior distribut .
in order to do maximum likelihood learn , all we have to do is maxim the law of probabl , that the infer binari state of unit , i would be gener from the infer binari state of it parent .
so the learn rule is local and simpl .
the probabl that the parent of i would turn i on , is given by a logist function that involv the binari state of the parent .
and what we need to do is make that probabl be similar to the actual observ binari valu of i and although i'm not go to deriv it here , the maximum likelihood learn rule for the weight wji is simpli to chang it in proport to the state of j time the differ between the binari state of i and the probabl that the binari state of i's parent would turn it on .
so to summar , if we have an assign of binari state to all the hidden node , then it's easi to do maximum likelihood learn in our typic stochast wai .
where we sampl from the posterior , and then we updat the weight base on that sampl .
and we averag that updat over a mini batch of sampl .
so , let's go back to the issu of why it's hard to sampl from the posterior .
the reason it's hard to get an unbias sampl from the posterior over the hidden node , given an observ data factor at the leaf node , is a phenomenon call explain awai .
so if you look at thi littl sigma b leaf net chair , it ha two hidden caus and on observ effect .
and if you look at the bias , you'll see that the observ effect of a high stress jump is veri unlik to happen unless on of those caus is true .
but if on of those caus ha happen , the twenti cancel the minu twenti , and neither hous will jump with the probabl of a half .
each of the caus is itself rather unlik but not nearli as unlik as a host spontan jump .
so if you see the hous jump , on plausibl explan is that a truck hit the hous .
a differ plausibl explan , is that it wa an earthquak .
and each of those ha a probabl of about e to the minu ten .
wherea the hous jump spontan ha a probabl of about e to the minu twenti .
howev , if you assum both hidden caus , that ha a probabl of e to the twenti , so that's extrem unlik , even if the hous did jump .
so assum there wa an earthquak , reduc the probabl that the hous jump becaus the truck hit it .
and we get an anti correl between the two hidden caus when we've observ the hous jump .
notic in the model itself , in the prior for the model , these two hidden caus ar quit independ .
so if the hous jump .
thi basic an even chunk that wa becaus of the truck or becaus of the earthquak .
the posterior actual look someth like thi .
there's four possibl pattern of hidden caus , given that the hous jump .
two of them ar extrem unlik .
name that the truck hit the hous , and there wa an earthquak .
or that neither of those thing happen .
the other two combin ar equal probabl , and you'll notic thei form an exclus all .
we have two like pattern of caus which ar just the opposit of each other .
that's explain awai .
now that we've understood explain awai , let's consid , let's go back to the issu of learn a deep sigmoid belief net .
so we're go to have multipl layer of hidden variabl .
thei're go to give rise to some data in our causal model .
and we want to learn those weight , w , between the first layer of hidden variabl in the data .
and let's see what it take to learn w .
first of all , the posterior distribut over the first layer of hidden variabl is not go to be a factori .
thei're not independ in the posterior .
and that's becaus of explain awai .
so , even if we just had that layer of hidden variabl , onc we've seen the data , thei wouldn't be independ of on anoth .
but becaus we have higher layer of hidden variabl , thei're not even independ in the prior .
thi hidden variabl in the laser bath creat prior , and that prior itself will caus correl between the hidden variabl in first layer .
to learn w , we need to learn the posteria in the first hidden layer were least in the approxim to it .
and even if you ar onli approxim it we need to know all of the weight in higher layer in order to comput that prior term .
in fact it's even wors than that .
becaus to comput that prior term , we need to integr out all the hidden variabl and higher layer .
that is we need to consid all possibl pattern of activ in these higher layer .
and combin them all to comput the prior that the higher level creat for the first hidden layer .
comput that prior is a veri complic thing .
so these three problem suggest that it's gonna be extrem difficult to learn those weight w .
and in particular , we're not gonna be abl to learn them without do a lot of work in the higher layer to comput the prior .
so now we're gonna consid some method for learn deep belief met .
the first on is the mont carlo method us by radford neal .
and that mont carlo method basic doe all the work .
that is , if we go back to the previou slide , it consid patent activ over all of the hidden variabl .
and it run a mark off chain that take a long time to settl down , given the data factor .
and onc it's settl down , to thermal equilibrium , you get a sampl from the posterior , but it's a lot of work .
so , in larg deep belief net , thi method pretti slow .
in the <num>'s peopl develop much faster method for learn deep belief net , which we call variat method .
in fact thi is where variat method came from at least the artifici intellig commun .
the variat method give up on get unbias sound post from the posterior and thei content themselv with just get approxim sampl that is sampl from some other distribut that approxim the posterior .
now as we saw befor , if we have sampl from the posterior , maximum likelihood learn is simpl .
if we have sampl from some other distribut , we could still us the maximum likelihood learn rule , but it's not clear what will happen .
on the face of it , crazi thing might happen if we're us the wrong distribut to get our sampl .
there doesn't seem to be ani guarante that thing will improv .
in fact there is a guarante that someth will improv .
it's not the log probabl that the model would gener the data .
but it is relat to that .
in fact it's a lower band on that log probabl .
and by push up the lower band , we can usual push up the log probabl .
in thi video , i'll describ the first wai we discov for get sigmoid belief net to learn effici .
it's call the wake sleep algorithm and it should not be confus with boltzmann machin .
thei have two phase , a posit and a neg phase , that could plausibl be relat to wake and sleep .
but the wake sleep algorithm is a veri differ kind of learn , mainli becaus it's for direct graphic model like sigmoid belief net , rather than for undirect graphic model like boltzmann machin .
the idea behind the wake sleep algorithm led to a whole new area of machin learn call variat learn , which didn't take off until the late 1990s , despit earli exampl like the wake sleep algorithm , and is now on of the main wai of learn complic graphic model in machin learn .
the basic idea behind these variat method sound crazi .
the idea is that sinc it's hard to comput the correct posterior distribut , we'll comput some cheap approxim to it .
and then , we'll do maximum likelihood learn anywai .
that is , we'll appli the learn rule that would be correct , if we'd got a sampl from the true posterior , and hope that it work , even though we haven't .
now , you could reason expect thi to be a disast , but actual the learn come to your rescu .
so , if you look at what's drive the weight dure the learn , when you us an approxim posterior , there ar actual two term drive the weight .
on term is drive them to get a better model of the data .
that is , to make the sigmoid belief net more like to gener the observ data in the train center .
but there's anoth term that's ad to that , that's actual drive the weight toward set of weight for which the approxim posterior it's us is a good fit to the real posterior .
it doe thi by manipul the real posterior to try to make it fit the approxim posterior .
it's becaus of thi effect , the variat learn of these model work quit nice .
back in the mid 90s , ' when we first came up with it , we thought thi wa an interest new theori of how the brain might learn .
that idea ha been taken up sinc by karl friston , who strongli believ thi is what's go on in real neural learn .
so , we're now go to look in more detail at how we can us an approxim to the posterior distribut for learn .
to summar , it's hard to learn complic model like sigmoid belief net becaus it's hard to get sampl from the true posterior distribut over hidden configur , when given a data vector .
and it's hard even to get a sampl from that posterior .
that is , it's hard to get an unbias sampl .
so , the crazi idea is that we're go to us sampl from some other distribut and hope that the learn will still work .
and as we'll see , that turn out to be true for sigmoid belief net .
so , the distribut that we're go to us is a distribut that ignor explain awai .
we're go to assum wrongli that the posterior over hidden configur factor into a product of distribut for each separ hidden unit .
in other word , we're go to assum that given the data , the unit in each hidden layer ar independ of on anoth , as thei ar in a restrict boltzmann machin .
but in a restrict boltzmann machin , thi is correct .
wherea , in a sigmoid belief net , it's wrong .
so , let's quickli look at what a factori distribut is .
in a factori distribut , the probabl of a whole vector is just the product of the probabl of it individu term .
so , suppos we have three hidden unit in the layer and thei have probabl of be wrong of <num> , <num> , and <num> .
if we want to comput the probabl of the hidden layer have the state <num> , <num> , <num> , we comput that by multipli <num> by <num> <num> , by <num> .
so , the probabl of a configur of the hidden layer is just the product of the individu probabl .
that's why it's call factori .
in gener , the distribut of binari vector of length n will have two to the n degre of freedom .
actual , it's onli two to the n minu on becaus the probabl must add to on .
a factori distribut , by contrast , onli ha n degre of freedom .
it's a much simpler beast .
so now , i'm go to describ the wake sleep algorithm that make us of the idea of us the wrong distribut .
and in thi algorithm , we have a neural net that ha two differ set of weight .
it's realli a gener model and so , the weight shown in green for gener ar the weight of the model .
those ar the weight that defin the probabl distribut over data vector .
we've got some extra weight .
the weight shown in red , for recognit weight , and these ar weight that ar us for approxim get the posterior distribut .
that is , we're go to us these weight to get a factori distribut at each hidden layer that approxim the posterior , but not veri well .
so , in thi algorithm , there's a wake phase .
in the wake phase , you put data in at the visibl layer , the bottom , and you do a forward pass through the network us the recognit weight .
and in each hidden layer , you make a stochast binari decis for each hidden unit independ , about whether it should be on or off .
so , the forward pass get us stochast binari state for all of the hidden unit .
then , onc we have those stochast binari state , we treat that as though it wa a sampl from the true posterior distribut given the data and we do maximum likelihood learn .
but what we're do maximum likelihood learn for is not the recognit weight that we just us to get the approxim sampl .
it's the gener weight that defin our model .
so , you drive the system in the forward pass with the recognit weight , but you learn the gener weight .
in the sleep phase , you do the opposit .
you drive the system with the gener weight .
that is , you start with a random vector of the top hidden layer .
you gener the binari state of those hidden unit from their prior in which thei're independ .
and then , you go down through the system , gener state for each layer at a time .
and here you're us the gener model correctli .
that's how the gener model sai you want to gener data .
and so , you can gener an unbias sampl from the model .
have us the gener weight to gener an unbias sampl , you then sai , let's see if we can recov the hidden state from the data .
well , let's see if we can recov the hidden state that layer h2 from the hidden state at layer h1 .
so , you train recognit weight , to try and recov the hidden state that actual gener the state in the layer below .
so , it's just the opposit of the weight phase .
we're now us the gener weight to drive the system and we're learn the recognit weight .
it turn out that if you start with random weight and you altern between wake phase and sleep phase it learn a pretti good model .
there ar flaw in thi algorithm .
the first flaw is a rather minor on which is , the recognit weight ar learn to invert the gener model .
but at the begin of learn , thei're learn to invert the gener model in part of the space where there isn't ani data .
becaus when you gener from the model , you're gener stuff that look veri differ from the real data , becaus the weight aren't ani good .
that's a wast , but it's not a big problem .
the seriou problem with thi algorithm is that the recognit weight not onli don't follow the gradient of the log probabl of the data , thei don't even follow the gradient of the variat bound on thi probabl .
and becaus thei're not follow the right gradient , we get incorrect mode averag , which i'll explain in the next slide .
a final problem is that we know that the true posterior over the top hidden layer is bound to be far from independ becaus of explain awai effect .
and yet , we're forc to approxim it with a distribut that assum independ .
thi independ approxim might not be so bad for intermedi hidden layer , becaus if we're lucki , the explain awai effect that come from below will be partial cancel out by prior effect that come from abov .
you'll see that in much more detail later .
despit all these problem , karl friston think thi is how the brain work .
when we initi came up with the algorithm , we thought it wa an interest new theori of the brain .
i current believ that it's got too mani problem to be how the brain work and that we'll find better algorithm .
so now let me explain mode averag , us the littl model with the earthquak and the truck that we saw befor .
suppos we run the sleep phase , and we gener data from thi model .
most of the time , those top two unit would be off becaus thei ar veri unlik to turn on under their prior , and , becaus thei ar off , the visibl unit will be firmli off , becaus it bia is <num> .
just occassion , on time in about e to the <num> , on of the two top unit will turn on and it will be equal often the left on or the right on .
when that unit turn on , there's a probabl of a half that the visibl unit will turn on .
so , if you think about the occass on which the visibl unit turn on , half those occass have the left hand hidden unit on , the other half of those occass have the right hand hidden unit on and almost none of those occass have neither or both unit on .
so now think what the learn would do for the recognit weight .
half the time we'll have a <num> on the visibl layer , the leftmost unit will be on at the top , so we'll actual learn to predict that that's on with a probabl of <num> , and the same for the right unit .
so the recognit unit will learn to produc a factori distribut over the hidden layer , of <num> , <num> and that factori distribut put a quarter of it mass on the configur <num> , <num> and anoth quarter of it mass on the configur <num> , <num> and both of those ar extrem unlik configur given that the visibl unit wa on .
it would have been better just to pick on mode , that is , it would have been better for the visibl unit just to go for truck , or just to go for earthquak .
that's the best recognit model you can have , that's the best recognit model you can have if you're forc to have a factori model .
so even though the hidden configur we're deal with ar best repres as the corner of a squar actual show it as if it's a on dimension continu valu , and the true posterior is bimod .
it's focus on <num> , <num> or <num> , <num> , that's shown in black .
the approxim window , if you us the sleep phase of the wake sleep algorithm , is the red curv , which give all four state of the hidden unit equal probabl and the best solut would be to pick on of these state , and give it all the probabl mass .
that's the best solut , becaus in variat learn we're manipul the true posterior to make it fit the approxim we're us .
normal , in learn we'll manipul an approxim to fit the true thing , but here it's backward .
in thi video , i'll talk about a differ wai of learn sigmoid belief note .
thi differ method arriv in an unexpect wai .
i stop work on sigmoid belief net and went back to boltzmann machin .
and discov that restrict boltz machin could actual be learn fairli effici .
given that a restrict boltzmann machin could effici learn a layer of nonlinear featur .
it wa tempt to take those featur , treat them as data , and appli anoth restrict boltzmann machin to model the correl between those featur .
and on can continu like thi , stack on boltzmann machin on top of the next on to learn lot of layer of nonlinear featur .
thi eventu led to a big resurg of interest in deep neural net .
the issu then aros .
onc you stack up lot of restrict boltzmann machin , each which is learn by model the pattern of futur activ produc by the previou boltzmann machin .
do you just have a set of separ restrict boltzmann machin or can thei all be combin togeth into on model ?
now , anybodi sensibl would expect that if you combin a set of restrict boltzmann machin togeth to make on model , what you'd get would be a multilay boltzmann machin .
howev , a brilliant graduat student of mine call g . y .
tai , figur out that that's not what you get .
you actual get someth that look much more like a sigmoid belief net .
thi wa a big surpris .
it wa veri surpris to me that we'd actual solv the problem of how to learn deep sigmoid belief net by give up on it and focus on learn undirect model like boltzmann machin .
us the effici learn algorithm for restrict boltzmann machin .
it's easi to train a layer of featur that receiv input directli from the pixel .
we can treat the pattern of activ of those featur detector as if thei were pixel , and learn anoth layer of featur in a second hidden layer .
we can repeat thi as mani time as we like with each new layer of featur model the correl activ in the featur in the layer below .
it can be prove that each time we add anoth layer of featur , we improv a variat lower bound on the log probabl that some combin model would gener the data .
the proof is actual complic , and it onli appli if you do everyth just right , which you don't do in practic .
but , the proof is veri reassur , becaus it suggest that someth sensibl is go on when you stack up restrict boltzmann machin like thi .
the proof is base on a neat equival between a restrict bolson machin and an infinit deep belief net .
so here's a pictur of what happen when you learn two restrict boltzmann machin , on on top of the other , and then you combin them to make on overal model , which i call a deep belief net .
so first we learn on boltzmann machin with it own weight .
onc that's been train , we take the hidden activ pattern of that boltzmann machin when it's look at data and we treat each hidden activ pattern as data for train a second boltzmann machin .
so we just copi the binari state to the second boltzmann machin , and then we learn anoth boltzmann machin .
now on interest thing about thi , is that if we start the second boltzmann machin off with w2 be the transpos of w1 , and with as mani hidden unit in h2 as there ar in v , then the second boltzmann machin will alreadi be a pretti good model of h1 , becaus it's just the first model upsid down .
and for a restrict boltzmann machin , it doesn't realli care which you call visibl and which you call hidden .
it's just a bipartit graph that's learn to model .
after we've learn those two boltzmann machin , we're go to compos them togeth to form a singl model and the singl model look like thi .
it top two layer adjust the same as the top restrict boltzmann machin .
so that's an undirect model with symmetr connect , but it bottom two layer ar a direct model like a sigmoid belief net .
so what we've done is we've taken the symmetr connect between v and h1 and we've thrown awai the upgo part of those and just kept the danger part .
to understand why we've done that is quit complic and that will be explain in video 13f .
the result combin model is clearli not a boltzmann machin , becaus it bottom layer of connect ar not symmetr .
it's a graphic model that we call a deep belief net , where the lower layer ar just like sigmoid belief net and the top two layer form a restrict boltzmann machin .
so it's a kind of hybrid model .
if we do it with three boltzmann machin stack up , we'll get a hybrid model that look like thi .
the top two layer again ar a restrict boltzmann machin and the layer below ar direct layer like in a sigmoid belief net .
to gener data from thi model the correct procedur is , first of all , you go backward and forward between h2 and h3 to reach equilibrium in that top level restrict boltamann machin .
thi involv altern gibb sampl , where you updat all of the unit in h3 in parallel , and updat all of the unit in h2 in parallel , then go back and updat all of the unit in h3 in parallel .
and you go backward and forward like that for a long time until you've got an equilibrium sampl from the top level restrict boltamann machin .
so the top level restrict bolson machin is defin the prior distribut of h2 .
onc you've done that , you simpli go onc from h2 to h1 us the gener connect w2 .
and then , whatev binari patent you get in h1 , you go onc more to get gener data , us the weight w1 .
so we're perform a top down pass from h2 , to get the state of all the other layer , just like in a sigmoid belief net .
the bottom up connect , shown in red at the lower level , ar not part of the gener model .
thei're actual go to be the transpos of the correspond weight .
so thei're the transpos of w1 and the transpos of w2 , and thei're go to be us for influenc , but thei're not part of the model .
now , befor i explain why stack up boltzmann machin is a good idea , i need to sort out what it mean to averag two factori distribut .
and it mai surpris you to know that if i averag two factori distribut , i do not get a factori distribut .
what i mean by averag here is take a mixtur of the distribut , so you first pick on of the two at random , and then you gener from whichev on you pick .
so , you don't get a factori distribut .
suppos we have an rbm with <num> hidden unit and suppos we give it a visibl vector .
and given thi visibl vector , the posterior distribut over those <num> hidden unit is factori .
and let suppos the distribut wa that the first and second unit have a probabl of <num> of turn on and the last two have a probabl of <num> of turn on .
what it mean for thi to be factori is that , for exampl , the probabl that the first two unit were both be on in a sampl from thi distribut , is exactli <num> . <num> .
now suppos we have a differ angl vector v2 , and the posterior distribut over the same <num> hidden unit is now <num> , <num> , <num> , <num> , which i chose just to make the math easi .
if we averag those two distribut , the mean probabl of each hidden unit be on , is inde , the averag of the mean for each distribut .
so the mean ar <num> , <num> , <num> , <num> , but what you get is not a factori distribut defin by those <num> probabl .
to see that , consid the binari vector <num> , <num> , <num> , <num> over the hidden unit .
in the posterior for v1 , that ha a probabl of <num> <num> , becaus it's <num> <num> <num> <num> <num> <num> .
so that's <num> . <num> .
in the posterior for v2 , thi vector is extrem unlik .
it ha a probabl of <num> in <num> , <num> .
if we averag those two probabl for that particular vector , we'll get a probabl of <num> . <num> , and that's much bigger than the probabl assign to the vector <num> , <num> , <num> , <num> by factori distribut with mean of <num> .
that probabl will be <num> <num> , which is much smaller .
so , the point of all thi , is that when you averag two factori posterior , you get a mixtur distribut that's not factori .
now , let's look at why the greedi learn work .
that is why it's a good idea to learn on restrict boltzmann machin .
and then learn a second restrict boltzmann machin that model the pattern of activ in the hidden unit of the first on .
the weight of the bottom level restrict boltzmann machin , actual defin four differ distribut .
of cours , thei defin them in a consist wai .
so the first distribut is the probabl of the visibl unit given the hidden unit .
and the second on is the probabl of the hidden unit given the visibl unit .
and those ar the two distribut we us for run our altern mark of chain that updat the visibl given the hidden and then updat the hidden given the visibl .
if we run that chain long enough , we'll get a sampl from the joint distribut of v and h .
and so the weight clearli also defin the joint distribut .
thei also defin the joint distribut more directli in term of e to the minu the energi , but for net with a larg number of unit , we can't comput that .
if you take the joint distribut , p v h , and you just ignor v , we now a distribut for h .
that's the prior distribut over h , defin by thi restrict boltzmann machin .
and similarli , if we ignor h , we have the prior distribut over v , defin by the restrict boltzmann machin .
and now , we're go to pick a rather surpris pair of distribut from those four distribut .
we're go to defin the probabl that the restrict boltzmann machin assign to a visibl vector v as the sum over all hidden vector of the probabl it assign to h time the probabl of v given h .
thi seem like a silli thing to do , becaus defin p h is just as hard as defin p v .
and nevertheless , we're go to defin p v that wai .
now , if we now leav p v h alon , but learn a better model of p h , that is , learn some new paramet that give us a better model of p h and substitut that in instead of the old model we had of p h .
we'll actual improv our model of v .
and what we mean by a better model of p h is a prior over h that fit the aggreg posterior better .
the aggreg posterior is the averag over all vector in the train set of the posterior distribut over h .
so , what we're go to do , is us our first rbm to get thi aggreg posterior and then us our second rbm to build a better model of thi aggreg posterior than the first rbm ha .
and if we start the second rbm off as the first on upsid down , it will start with the same model of the aggreg posterior as the first rbm ha .
and then , if we chang the weight we can onli make thing better .
so , that's an explan of what's happen when we stack up rbm .
onc we've learn to stack up boltzmann machin , then combin them togeth to make a deep belief net , we can then actual fine tune the whole composit model us a variat of the wake sleep algorithm .
so we first learn mani layer of featur by stack up ibm .
and then we want to fine tune both the bottom up recognit weight and the top down gener weight to get a better gener model and we can do thi by us three differ learn rout .
first , we do a stochast bottom up pass , and we adjust the top down gener weight of the lower layer to be good at reconstruct the featur activ in the layer below .
that's just as in the standard wake sleep algorithm then , in the top level rbm , we go backward and forward a few time , sampl the hidden of that rbm , and the visibl of that rbm , and the hidden of the rbm , and so on .
so that's just like the learn algorithm for rbm .
and have done a few iter of that , we do contrast diverg learn .
that is , we updat the weight of the rbm us the differ between the correl when activ first got to that rbm and the correl after a few iter in that rbm .
we take that differ and us it to updat the weight .
and then , the third stage , we take the visibl unit of that top level rbm by it lower level unit .
and start there , we do a top down stochast pass , us the direct lower connect , which ar just a sigmoid belief net .
then , have gener some data from that sigmoid belief net , we adjust the bottom up rate to be good at reconstruct the featur activ in the layer abov .
so that's just the sleep phase of the wake sleep algorithm .
the differ from the standard wake sleep algorithm is that that top level rbm act as a much better prior over the top layer , than just a layer of unit which ar assum to be independ , which is what you get with a sigmoid belief net .
also , rather than gener data by sampl from the prior , what we're actual do is look at a train case , go up to the top level rbm and just run a few iter befor we gener data .
so now we're go to look at an exampl where we first learn some rbm , stack them up , and then we do contrast wake sleep to fine tune it , and then we look to see what it's like .
is it a gener model ?
and also if we're recogn thing .
so first of all , we're go to us <num> binari hidden unit to learn to model all <num> digit class in imag of <num> by <num> pixel .
onc we've learn that rbm , without know what the label ar , so it's unsupervis learn .
we're go to take the pattern of activ in those <num> hidden unit that thei have when thei're look at data .
we're go to treat those pattern of activ as data and we're go to learn anoth rbm that also ha <num> unit , and those two ar learn without know what the label ar .
onc we've done that we'll actual tell it the label .
so the first two hidden layer ar learn without label , and then , we add a big top layer and we give it the <num> label .
and you can think that we concaten those <num> label with the <num> unit that repres featur , except that the <num> label ar realli on soft match unit .
then we train that top level rbm to model the concaten of the soft match unit for the <num> label with the <num> featur activ that were produc by the two layer below .
onc we've train the top level rbm , we can then fine tune the whole system by us contrast wake sleep .
and then we'll have a veri good gener model and that's the model that i show you in the intro video .
so if you go back , and you find the introduct video for thi cours , you'll see what happen when we run that model .
you'll see how good it is at recognit and you'll also see that it's veri good at gener .
in that introductori video , i promis you , you would eventu explain how it work , and i think you've now seen enough to know what's go on when thi model is learn .
.
in thi video i'm go to show how we can first learn a deep belief net by stack up restrict boltzmann machin .
and then we can treat that as a deep neural net that we fine tune discriminatori .
so instead of fine tune it to be better at gener , as we did in the previou video , we're go to fine tune it to be better at discrimin between class .
thi work veri well and led to a big renew of interest in neural network .
in speech recognit , it's had a major influenc and mani lead group ar now switch to us deep neural net in order to reduc the error rate , in speech recognit .
i now want to talk about fine tune these deep network to be better at discrimin .
so we first learn on layer of featur at a time , by stack up restrict boltzmann machin .
then we treat thi as pre train that find a good initi set of weight in the dpo network and we fine tune those weight us some local search procedur .
in the previou video i show you how to us contrust weight sleep to fine tune a deep network so that it wa better gener it input .
in thi video we're go to us back propag to fine tune a model to be better at discrimin .
if we do thi it overcom mani of the standard limit of back propag .
it make it much easier to learn deep net .
and it make those net generalis better .
we need to understand why back propag when we pre train the weight .
and there's realli two effect .
there's an effect on optim and there's an effect on gener .
so the pre train scale realli well if we have big network , especi if each layer ha local .
so if we're do vision , for exampl , and we had local receptor field in each layer , then there's not much interact between wide separ locat .
and so it's veri easi to learn a big layer more or less in parallel .
when we do pre train .
we don't start back propag until we've alreadi learn sensibl featur detector .
and these featur detector should be veri help for discrimin .
so the initi gradient ar much more sensibl than if we us random on .
and back propag doesn't need to do a global search .
it just need to do a local search from a sensibl start point .
in addit to be easier to optim , pre train net exhibit much less overfit .
that's becaus most of the inform in the final weight come from model the distribut of input vector .
and these input vector , if you're deal with someth like imag , gener contain a lot more inform than label .
a label typic onli contain a few bit of inform to constrain the map from input to output .
wherea an imag contain a lot of inform which will constrain ani gener model of a set of imag .
the inform in the label is onli us for the final fine tune and becaus by that stage we've alreadi decid on the featur detector , we're not squander that preciou inform design featur detector from scratch .
the fine tune onli make slight chang to the featur detector we learn in the gener pre train phase .
and those ar the chang requir to get the categori boundari in the right place .
the import thing is the back propag is not be requir to discov new featur .
and so it doesn't need nearli as much label data .
in fact , thi type of learn work well when most of the data is unlabel , becaus the gener pre train can make us of the light data .
the unlabel data is still veri us for discov good featur .
there is an obviou object to thi type of learn , which is that when we do gener pre train .
we'll be learn lot of featur that ar useless for the particular discrimin task we want the net to do .
consid , for exampl , that you might want the net to discrimin between shape or you might want the net to discrimin between differ pose of on shape .
thei need veri differ featur , and if you don't know the task in advanc .
you'll inevit learn featur that ar never us .
when comput were much smaller , that wa the seriou object .
but now that comput ar larg enough , we can afford to learn featur that ar never us .
and , we can afford it becaus among all the featur we learn , there will be some that ar much more us than their raw input .
and that more than make up for the fact that we have learn some featur that aren't help for the particular task we're interest in .
so let's appli thi to model the m list digit .
we'll now learn three hidden layer of featur entir unsupervis .
onc we've done that learn , when we gener from the model , it will gener thing that look like real digit .
and it'll gener them from all the differ class .
and it'll typic take a while befor it switch from on class to anoth .
and it will typic take a while befor it switch from on class to anoth becaus it'll tend to stai in the same ravin for a while befor it jump to anoth ravin .
but the question is , ar the featur that we've learn that wai us for do discrimin ?
so all we need to do is add a final <num> wai soft max at the top .
and fine tune it with back propag .
and see if we do better than pure discrimin train .
so here's the result on the permut invari m ness task .
and what i mean is permut invari is , if we were to appli a fix random permut to all the pixel , the same permut to everi test and train case , the result of our algorithm wouldn't chang .
that's clearli not true for someth like a convolut net .
a convolut net's been told someth about the task .
by appli thi fix permut , we destroi all simpl wai of tell the net someth about the spatial natur of the task .
so if you appli standard back propag .
it's hard to do better than <num> error .
john platt and myself have both tri quit hard appli standard back propag with variou differ architectur .
and we're both quit good at do it .
you can actual beat <num> .
by us constraint on the incom weight vector of the hidden unit .
if you us an appropri restrict on the length of an incom weight vector , you can do a bit better than <num> .
support vector machin can get <num> percent .
and thi wa on of the piec of evid that led to support vector machin , supplant back propag .
if you pretrain a network us a stack of boltzmann machin .
and then you fine tune it to be better at gener the joint densiti of digit and imag label .
then you can get down to <num> . <num> .
if you train a stack of boltzmann machin , and simpli put a <num> wai on top , and fine tune it .
you can get to <num> . <num> .
and with more fiddl around , you can get that down to about on .
so you can do a lot better than standard back propag .
and also better than support vector machin by us gener pre train follow by discrimin fine tune .
mackeri yerenzato work in yan lecann's group also show , us a slightli differ pre train method , that pre train help for model that have more data and better prion .
so thei us an addit <num> , <num> distort digit imag .
so thei had a lot more train data .
thei also us convolut multilinear network .
and yan's group is the best group , at tune those .
with back propag , thei manag to get down to . <num> .
when thei did the unsupervis layer by layer pre train , follow by back propag thei got down to . <num> .
which at the time wa a record .
so you mai rememb thi pictur from the first lectur .
thi wa on of the exampl i gave of the success neural net .
it's the same pictur .
back then , i said we could get down to <num> by pre train and then fine tune with back propag , and that the previou , and that the previou speak independ record on timint wa <num> .
which actual requir averag sever model .
lee ding at microsoft research pick up at thi result immedi and collabor on improv it .
and thi ha led to a big chang in speech recognit .
if you look at thi new stori , it will refer you to a blog where the chief research offic for microsoft is talk about the big improv in speech recognit caus by us deep neural net .
in thi video we'll look in more detail at what happen when a neural network is discriminatorili fine tune after it's first been pre train as a stack of boltzmann machin .
what we'll see is that the weight in the lower layer hardli chang at all .
but that nevertheless these tini chang make a big differ in the classif perform of the neural net , becaus thei put the decis boundari in the right place .
we also see that the effect of pre train is to make deeper network more effect than shallow on .
without pre train it's often the other wai around .
final , i give a fairli gener argument about why it make sens to start by do gener train .
and onli after thi is well under wai to consid discrimin train .
so now we're go to look at some work done in yoshua bengio's lab , examin what happen dure fine tune after a net's been gener pre train .
if you look on the left , there's the recept field in the first hidden layer of featur detector , after the gener pre train but befor the fine tune .
then on the right , there's the same recept field after the fine tune then you'll see almost noth ha chang .
nevertheless , the chang help with discrimin .
here's an exampl of how pre train reduc the test error for network with on hidden left .
the task wa discrimin between digit in a veri larg set of distort digit .
and you can see that after the back propag fine tune , the network with pre train almost alwai did better than the network without pre train .
the effect get even bigger , if you us deeper network .
so here you can see that there's basic no overlap between the two distribut .
and the deep network with pre train have got better than the shallow network , and the deep network without pre train have got wors than the shallow network .
thi is show you the classif error and the variat classif error as you chang the number of layer when you're not do pre train .
and you can see that two layer appear to be best .
and by the time you've got four layer , you're do consider wors .
by contrast , if you us pre train , four layer is better than two layer .
there's much less variat and dr is lower .
thi is a visual made with teeson of what happen to the weight dure train for both pretrain and non pretrain network and thei ar all plot in the same space but you can see thei form two distinct class in network .
on's at the top and that work without pretrain and the on at the bottom and that work with pretrain .
each point show a model in function space .
it's no us compar weight vector becaus two net might differ by have two of the hidden unit swap round .
so thei behav exactli the same wai , but the weight would look veri differ .
in order to compar them , you have to compar the function of the implement .
and a wai to do that is to have a suit of test case and look at the output the network produc on those test case .
and then concaten those output into on great long vector .
and so if two network produc veri similar output for all the test case , that concaten vector will be veri similar for the two network .
now you take those concaten output vector and you plot those in 2d us t sne .
the color show the stage of train so if you look at the network at the top , there's an initi blob in dark blue .
and then you can see that it's all move roughli the same direct .
in other word , the network after on epoch of learn ar all more similar to on anoth then thei ar to the initi network .
that's even more pronounc with the pre train network at the bottom .
so the color tell you which epoch you're in .
the trajectori at the top without pre train show that differ network end up in differ place in function space .
and thei're quit wide spread .
the trajectori of the bottom show that with pre train , you end up in a quit differ region of function space .
and the network tend to be more similar to on anoth .
but the main point is there's no overlap .
the kind of solut you find , if you pre train the network gener , ar just qualit differ from the kind of solut you find if you start with small random word .
the last thing i want to sai in thi video is to explain why pre train make sens .
so let's imagin that the wai we gener pair of an imag and a label wa by take the stuff in the real world , us that to gener an imag , for exampl by take a photograph of someth .
and then have gener the imag we attach a label to it that didn't depend on the stuff in the world .
so conting on the imag itself , the stuff in the world is relev the label thu depend on the pixel in the imag that would be the case for exampl if the label told us whether the top left pixel wa similar to the bottom right pixel .
now if we gener imag that wai , then it would make sens to try and learn a map from imag to label .
becaus the label depend directli on the imag but actual , it's more plausibl that the wai we gener imag label pair ar by there be stuff in the world that give rise to the imag .
and the reason the imag ha the name it ha is becaus of the stuff in the world , not becaus of the pixel in the imag .
so you see a cow .
you take a photograph .
and you call that a photograph of a cow , becaus you were look at a cow when you took it .
now the point is , there's a high bandwidth from the stuff in the world to the imag .
and there's a low bandwidth from the stuff in the world to the label .
for exampl if i just sai cow , you don't know whether the cow is upsid down , whether it wa brown or black and white , whether it wa aliv or dead , how big it wa , what els wa in the imag , whether it wa face you or face awai from you .
on of those thing aren't convei by the label .
if you see an imag with thousand and thousand of pixel , you typic know all of those thing .
you get much , much more inform about the caus of an imag by look at the imag then you do by look at the label of the imag .
so in that situat , where there's a high bandwidth pathwai from the world to the imag , and a low bandwidth imag from the world to the label , becaus the label typic contain veri few bit .
it make much more sens to try and recov the label by first invert the high boundari pathwai to get back to the stuff in the world that caus the imag .
and then have recov the stuff in the world that caus the imag , to decid what label it would be given .
so that's a much more plausibl model of how we assign name to thing in imag .
and that justifi have a pre train phase where you try and go from the imag to it underli caus , follow by a discrimin phase where you try and go from those underli caus to the label .
and perhap you slightli fine tune the map from the imag to the underli caus .
in thi video i'm go to describ how to us an rbm to model real valu data .
the idea is that we make the visibl unit .
instead of be binari stochast unit , the linear unit with gaussian nois .
when we do thi , we get problem with learn .
and it turn out a good solut to those problem is to then make the hidden unit be rectifi linear unit .
with linear gaussian unit for the visibl , and rectifi linear unit for the hidden , it's quit easi to learn a restrict boltzmann machin that make a good model of real valu data .
we first us restrict boltzmann machin with the imag of handwritten digit .
for those imag .
intermedi intens caus by a pixel be onli partial ink can be model quit well by probabl , that is number between on and zero that ar actual the probabl of a logist unit be on .
so we treat partial ink pixel .
as have a probabl of be ink .
thi is incorrect but it work quit well .
howev it won't work for real imag .
in a real imag the intens of a pixel is almost alwai , almost exactli the averag of it neighbor .
so it got a veri high probabl of be veri close to that averag and a veri small probabl of be a littl further awai .
and you can't achiev that with a logist unit .
mean field logist unit ar unabl to repres thing like the intens is <num> .
but veri unlik to be <num> .
or <num> .
so we need some other kind of unit .
the obviou thing to us is a linear unit with gaussian norm .
so we model pixel as gaussian variabl .
we can still us altern , get sampl , to run the markoff chain requir for the cross diverg learn .
but we need to us a much smaller learn rang , otherwis it will tend to blow up .
the equat look like thi .
the first term on the right hand side , is a kind of parabol contain function .
it stop thing blow out .
so determin that sum contribut by the ith visibl unit is parabol in shape .
it look like thi .
it's parabola with it minimum at the bia of the ith unit .
and as the ith unit depart from that valu , we add energi quadrat .
so that tri to keep the ith visibl unit close to vi .
the interact term between the visibl and the hidden unit look like thi .
and if you differenti that with respect to the i , you can see that you get a constant .
it's the sum over all j , of h j w i j divid by sigma i .
so that term with it constant gradient look like thi .
and when you add togeth , that top down contribut to the energi is linear , and the parabol contain function .
you'll get a parabol function , but with the mean shift awai from bi .
and how much it shift depend on the slope of that blue line .
so the effect of the hidden unit is just to push the mean to on side .
it's easi to write down an energi function like thi .
and it's easi to take deriv off it .
but when we try learn with it , we often get problem .
there were a lot of report in the literatur that peopl could not get these gaussian binari rbm's to work .
and it is inde extrem hard to learn tight varianc for the visibl unit .
it took us a long time to figur out why it's so hard to learn those visibl varianc .
thi pictur help .
if you consid the effect that visibl unit i ha on hidden unit j .
when visibl unit i ha a strong standard deviat sigma i , that ha the effect of exagger the bottom up weight .
that's becaus we need to measur the activ of i in unit of it standard deviat .
so when the standard deviat is small , we need to multipli the weight by a lot .
if you look at the top down effect of j on i , that's multipli by sigma i .
so when the standard deviat of a visibl unit i is veri small , the bottom up effect get exagger , on the top down effect get attenu .
the result is that we have a conflict where either we have bottom up effect that ar much too big or top down effect that ar much too small .
and the result is that the hidden unit tend to satur and be firmli on or off all the time , and thi will mess up learn .
so the solut is to have mani more hidden unit than visibl unit .
that allow small weight between the visibl and hidden unit to have big top down effect , becaus of so mani hidden unit .
but of cours , we realli need the number of hidden unit to chang as that standard deviat sigma i get smaller .
and on the next slide , we'll see how we can achiev that .
i'm go to introduc step sigmoid unit .
the idea is we make mani copi of each stacast binari hidden unit .
all the copi have the same weight , and the same bia that's learn b but in addit to that adapt bia b thei have a fix offset to the bia .
the first unit ha an offset of <num> .
the second unit ha an offset of <num> .
the third on ha an offset of minu <num> , and so on .
if you have a whole famili of sigmoid unit like that , with the bia chang by on between neighbour member of the famili , the respons code look like thi .
if the total in product is veri low , none of them ar turn on .
as it increas , the number that get turn on increas linearli .
thi mean that as the standard deviat on the previou slide get smaller , the number of copi of each hidden unit that get turn on get bigger and we achiev just the effect we want , which we get more top down effect to drive these visibl unit that have small standard deviat .
now it's quit expens to us a big popul of binari stochast unit with offset bias , becaus for each on of them , we need to put the total input through the logist function , but we can make some fast approxim which work just as well .
so the sum of the activ of a whole bunch of sigmoid unit with offset ballast , which is shown in that summat .
is approxim equal to log of on plu e to the x and that in turn is approxim equal to the maximum of nought and x .
and we can add some nois to the x if we want .
so the first term in the equat look like thi .
the second term look like that .
and you can see that the sum of all those sigmoid in the first term will be a curv like that .
and we can approxim that by a linear threshold unit that ha a valu of zero unless it's abov threshold .
in which case it valu increas linearli with it input .
contrast diverg learn work well for the sum of a bunch of stochast logist unit with offset bias .
and in that case .
you get a nois varianc that's equal to the logist function .
but the output of that sum .
altern we can us that green curv and us rectifi linear unit .
thei're much faster to comput becaus you don't need to go through the logist mani time .
and can trust diverg work just fine with those .
on nice properti of rectifi linear unit is that if thei have a bia of zero , thei exhibit scale equivari .
thi is a veri nice properti to have for imag .
what scale equivari mean is that if you take an imag x and you multipli all the pixel intens by a scalar a . , then the represent of ax in the rectifi linear unit would be just a time the represent of x .
in other word , when we scale up all the intens in the imag , we scale up the activ of all the hidden unit but all the ratio stai the same .
rectifi linear unit aren't fulli linear becaus if you add togeth two imag , the represent you get is not the sum of the represent of each unit separ .
thi properti of scale equivari is quit similar to the properti of translat equivari , convolut net off .
so if we ignor the pool for now , in a convolut on that , if we shift an imag and look at the represent , the represent of a shift imag is just a shift version of the represent of the unshift imag .
so in a convolut net without pool , translat of the input just flow through the layer of the net without realli affect anyth .
the represent of everi layer is just translat .
in thi video i'm go to talk about some advanc materi .
it's not realli appropri for a first cours on nerual network but i know that some of you ar particularli interest in the urgent of deep learn .
and the content of thi video is mathemat veri pretti so i couldn't resist put it in .
insight that stack up restrict boltzmann machin give you someth like a sigmoid belief net can actual be seen without do ani math .
just by notic , that a restrict boltzmann machin is actual the same thing as an infinit deep sigmoid belief net with share weight .
onc again , wave share lead to someth veri interest .
i'm now go to describ , a veri interest explan of why layer by layer learn work .
it depend on the fact that there is an equival between restrict bowlser machin , which ar undirect network with symmetr connect , and infinit deep direct network .
in which everi layer us the same weight matrix .
thi equival also give insight into why contrast diverg learn work .
so an rbm is realli just an infinit deep sigmoid belief net with a lot of share weight .
the markoff chain that we run when we want to sampl from an rbm can be view as exactli the same thing as a sigmoid belief net .
so here's the pictur .
we have a veri deep sigmoid belief net .
in fact , infinit deep .
we us the same weight at everi layer .
we have to have all the v layer be the same size as each other , and all the h layer be the same size as each other .
but v and h can be differ size .
the distribut gener by thi veri deep network with replic weight is exactli the equilibrium distribut that you get by altern between do p of v given h , and p of h given v , where both p of v given h and p of h given v ar defin by the same weight matrix w .
and that's exactli what you do when you take a restrict boltzmann machin , and run a markhov chain to get a sampl from the equilibrium distribut .
so a top down pass start from infinit higher up .
in thi direct note , is exactli equival to let a restrict boltzmann machin settl to equilibrium .
but that would defin the same distribut .
the sampl you get at v0 if you run thi infinit direct note , would be an equilibrium sampl of the equival rbm .
now let's look at infer in an infinit deep sigmoid belief net .
so in infer we start at v zero and then we have to infer the state of h zero .
normal thi would be a difficult thing to do becaus of explain awai .
if for exampl hidden unit k and j both had big posit weight to visibl unit i , then we would expect that when we observ that i is on , k and j becom anti correl in the posterior distribut .
that's explain a wai .
howev in thi net , k and j ar complet independ of on anoth when we do infer given v0 .
so the infer is trivial , we just multipli v0 by the transpos of w .
and put whatev we get through the logist sigmoid and then sampl .
and that give us binari state of the unit in h0 .
but the question is how could thei possibl be independ given explain awai .
the answer to that question is that the model abov h0 implement what i call a complementari prior .
it implement a prior distribut over h0 that exactli cancel out the correl in explain awai .
so for the exampl shown , the prior will implement posit correl stream k and j .
explain your wai will caus neg correl and those will exactli cancel .
so what's realli go on is that when we multipli v0 by the transpos of the weight , we're not just comput the light unit term .
we're comput the product of a light unit term and a prior term .
and that's what you need to do to get the posterior .
it normal come as a big surpris to peopl .
that when you multipli by w transpos , it's the product of the prior in the posterior of your comput .
so what's happen in thi net is that the complementari prior implement by all the stuff abov h0 , exactli count a lot explain why it make infer veri simpl .
and that's true at everi layer of thi net so we can do infer for everi layer and get an unbias sampl with each layer simpli by multipli v0 by w transpos .
then onc we comput the binari state of h0 , we multipl that by w .
put that through the logist sigmoid and sampl and that will give us a binari state for v1 and so on for all the wai up .
suggest gener from thi model is equival to run the altern mark off chain on a restrict boltzmann machin to equilibrium .
perform infer in thi model is exactli the same process in the opposit direct .
thi is a veri special kind of sigmoid belief net in which infer is as easi as gener .
so here i've shown the gener weight that defin the model , and also their transpos , that ar the wai we do infer .
and now i what want to show is how we get the bolton machin learn algorithm out of the learn algorithm for direct sigmoid belief net .
so the learn rule for sigmoid belief net sai that we should first get a sampl from the posterior , that what the sj and si ar , sampl from the posterior distribut .
and then we should chang a weight , the gener weight in proport to the product of the pre activ as j and the differ between the activ as i and the probabl of turn on i given all the binari state of the ladder sj is in .
now if we ask how do we comput pi  , someth veri interest happen .
if you look at infer in thi network on the right , we first infer a binari state for h0 .
onc we've chosen that binari state , we then infer a binari state for v1 by multipli h0 by w , put the result through the logist , and then sampl .
so if you think about how si1 wa gener ?
it wa a sampl from what we get if we put h0 through the weight matrix w and then through the logist .
and that's exactli what we'd have to , to in order to comput pio .
we'd have to take the binari activ in h0 and go downward now through the green weight , w , we will comput the probabl of turn on unit i given the binari state of it parent .
so the point is , the process that goe from h0 to v1 is ident to the process that goe from h0 to v0 .
and so si1 is an unbias sampl of pi0 .
that mean we can replac it in the learn rule .
so we end up with a learn rule that look like thi , becaus sinc we have replic weight , each of those line is the term in the learn rule that come from on of those green weight matric .
for the first green weight matrix here .
the learn rule is the presynapt state sj0 time the differ between the post synapt state si0 and the probabl that the binari state in h0 would turn on si .
which we could call pi0 but a sampl with that probabl is si1 .
and so an unbias estim of the rel , can be got by plug in si1 on that first line of the learn rule .
similarli for the second weight matrix , the learn rule is si1 into sj0 minu pj0 and an unbias estim of pj0 is sj1 .
and so that's an unbias testament of the learn rule , for thi second weight matrix .
and if you just keep go for all wave matric you get thi infinit seri .
and all the term except the veri first term and the veri last term cancel out .
and so you end up with the boltzmann machin learn rule .
which is just sj zero into si zero , minu si infin into si infin .
so let's go back and look at how we would learn an infinit deep sigmoid belief net .
we would start by make all the weight matric the same .
so we tie all the weight matric togeth .
and we learn us those ti weight .
now that's exactli equival to learn a restrict boltzmann machin .
the diagram on the right and the diagram on the left ar ident .
we can think of the symmetr arrow in the diagram on the left , as just a conveni shorthand for an infinit direct net with ti weight .
so we first learn that restrict boltzmann machin .
now we ought to learn it us maximum likelihood learn , but actual we're just go to us contrast diverg learn .
we're go to take a shortcut .
onc we've learn the first restrict boltzmann machin , what we could do is we could freez the bottom level weight .
we'll freez the gener weight that defin the model .
we'll also freez the weight we're go to us for infer to be the transpos of those gener weight .
so we freez those weight .
we keep all the other weight ti togeth .
but now we're go to allow them to be differ from the weight in the bottom layer but thei're still all ti togeth .
so learn the remain weight ti togeth is exactli equival to learn anoth restrict boltzmann machin .
name a restrict boltzmann machin with h0 as it visibl unit , v1 as it hidden unit .
and where the data is the aggreg posterior across h0 .
that is , if we want to sampl a data vector to train thi network , what we do is we put in a real data vector , v nought , we do infer through those frozen wait , and we get a binari vector at h nought , and we treat that as data for train the next restrict boltzmann machin .
and we can go up for as mani layer as we like .
and when we get fed up , we just end up with the restrict boltzmann machin at the top which is equival to sai , all the weight in the infinit direct net abov there ar still ti togeth , but the weight below have now all becom differ .
now an explan of why the infer procedur wa correct , involv the idea of a complementari prior creat by the weight in the layer abov but of cours , when we chang the weight in the layer abov , but leav the bottom layer of weight fix , the prior creat by those chang weight is no longer exactli complementari .
so now our infer procedur , us the frozen weight in the bottom layer , is no longer exactli correct .
the good new is , it's nearli alwai veri close to correct and with the incorrect infer procedur , we still get a variat bound on the low probabl of the data .
the higher layer have chang becaus thei've learn a prior for the bottom hidden layer that's closer to the aggreg posterior distribut .
and that make the model better .
so chang the hidden weight make the infer that we're do at the bottom hidden layer incorrect , but give us a better model .
and if you look at those two effect , we prove that the improv that you get in the variat bound from have a better model is alwai greater than the loss that you get from the infer be slightli incorrect .
so in thi variat bound you win when you learn the light in hire less , assum that you do it with correct maxim so now let's go back to what's happen in contrast diverg learn .
we have the infinit net on the right and we have a restrict boltzmann machin on the left .
and thei're equival .
if we were to do maximum likelihood learn for the restrict boltzmann machin , it would be maximum likelihood learn for the infinit sigmoid belief net .
but what we're go to do is we're go to cut thing off .
we're go to ignor the small derivit for the weight you get in the higher layer of the infinit sigmoid belief net .
so , we cut it off were that dot red line is .
and now if we look at the deriv , the deriv we're go to get look like thi .
thei've got two term .
the first term come from that bottom layer of net .
we've seen that befor , the router for the bottom layer of weight is just that first line here .
the second line come from the next layer of light .
that's thi line here .
we need to comput the activ in h1 , in order to comput the sj1 in that second line but we're not actual comput deriv for the third layer of weight .
and when we take those first two term , and we combin them .
we get exactli the learn rule for on step contrast diverg .
so what's go on in contrast diverg , is we're combin weight deriv for the lower layer , and ignor the weight deriv in higher layer .
the question is , why can we get awai with ignor those higher deriv ?
when the weight ar small , the markov chain mix veri fast .
if the weight ar zero , it mix in on step .
and if the markoff chain mix fast , the higher layer will be close to the equilibrium distribut , i . e .
thei will have forgotten what the input wa at the bottom layer .
and now we have a nice properti .
if the higher layer ar sampl from the equilibrium distribut , we know that the deriv of the log probabl , the data with respect to the weight , must averag out to zero .
and that's becaus the current weight in the model ar a perfect model of the equilibrium distribut .
the equilibrium distribut is gener us those weight .
and if you want to gener sampl from the equilibrium distribut , those ar the best possibl weight you could have .
so we know the root is there is zero .
as the weight get larger , we might have to run more iter of contrast diverg .
which correspond to take into account more layer of that infinit sigmoid belief net .
that will allow contras diverg to continu to be a good approxim to maximum likelihood and so if we're try to learn a densiti model , that make a lot of sens .
as the weight grow , you run cd for more and more step .
if there's a statistician around , you give him a guarante , then in the infinit limit , you'll run cd for infinit mani step .
and then you have an asymptot converg result , which is the thing that keep statistician happi .
of cours it's complet irrelev becaus you'll never reach a point like that .
there is howev an interest point here .
if our purpos in us cd is to build a stack of restrict boltzmann machin , that learn multipl layer of featur , it turn out that we don't need a good approxim to maximum likelihood .
for learn multipl layer of featur , cd1 is just fine .
in fact it's probabl better than do maximum l likelihood .
in thi video , i'm go to introduc princip compon analysi , which is a veri wide us techniqu in signal process .
the idea of princip compon analysi , is that high dimension data can often be repres us a much lower dimension code .
thi happen when the data li near a linear manifold in the high dimension space .
so the idea is , if we can find thi linear manifold , we can project the data onto the manifold , and then just repres where it is on the manifold .
and we haven't lost much , becaus in the direct orthogon to the manifold , there's not much variat in the data .
as we'll see , we can do thi oper effici us standard principl compon method , or we can do it ineffici us a neural net with on hidden layer , where both the hidden unit and the output unit ar linear .
the advantag of do it with the neural net is that we can then gener the techniqu to us deep neural net in which the code is a nonlinear function of the input .
and our reconstruct of the data from the code is also a nonlinear function of the code .
thi enabl us to deal with curv manifold in the input space .
so we repres data by where it get project on the curv manifold .
and thi is a much more power represent .
in princip compon analysi , we have n dimension data , and we want to repres it us less than n number .
and so we find m orthagon direct in which the data ha the most varianc .
and we ignor the direct in which the data doesn't vari much .
the m princip dimens form a lower dimension subspac , and we repres an n dimension data point by it project onto these m dimens in the lower dimension space .
so we've lost all inform about where the data point is locat in the remain orthogon direct .
but sinc these don't have much varianc , we haven't lost that much inform .
if we want to reconstruct the data point , from our represent in term of m number , we reduc the mean valu for all the n minu m direct that ar not repres , and then the area in our reconstruct .
would be the sum over all these unrepres direct of the squar differ between the valu of the data point count on that direct , and the mean valu on that direct .
thi is most easili seen in the pictur .
so consid <num> dimension data .
thi distribut accord to an elong gaussian like thi .
the ellips is meant to show kind of on standard deviat contour of the gaussian .
and consid a data point like that red on .
if we us princip compon analysi with a singl compon .
that compon would be the direct in the data that had the greatest varianc .
and so to repres the red point , we'd repres how far along that direct it lai .
in other word we'd repres the project of the red point onto that line , i . e .
the green point .
when we need to reconstruct the red point , what we'll do is simpli us the mean valu of all the data point , in the direct that we've ignor .
in other word you'll repres a point on that black line .
and so the lost in the reconstruct will be the squar differ between the red point and the green point .
that is , would have lost the differ between the data point and the mean valu of all the data , in the direct we're not repres , which is the direct of least varianc .
and so we obvious have minim our loss if we choos to ignor the direct of least varianc .
now , we can actual implement pca , or a version of it , us back propag , but it's not veri effici .
so what we do is we make a network in which the output of the network is the reconstruct of the data .
and we try and minim the squar error in the reconstruct .
the network ha a central bottleneck that onli ha m hidden unit .
and those ar go to correspond to the princip compon , or someth like them .
so it look like thi .
we have an input vector .
we project that onto a code vector .
and from the code vector , we construct an output vector .
and the aim is to make the output vector as similar as possibl to the input vector .
the activ of the hidden unit in the code vector from a bottleneck .
so the code vector is a compress represent of the input vector .
if the hidden unit and the output unit ar linear , then order coder like thi , we'll learn code that minim the squar reconstruct error .
and that's exactli what principl compon analysi doe .
it will get exactli the same reconstruct error as principl compon analysi doe .
but it won't necessarili have hidden unit that correspond exactli the , the principl compon .
thei will span the same space as the first n princip compon , but there mai be a rotat and skew of those ax .
so the incom weight vector of the code unit , which ar what repres the direct of the compon , mai not be orthogon .
and unlik princip compon analysi , thei will typic have equal varianc .
but the space span by the incom weight vector of those code unit will be exactli the same as the space span by the m princip compon .
so in that sens thi network will do an equival thing to princip compon .
it's just if we us to cast the great descend learn for thi network , it will typic much less suffici than the algorithm us for principl compon .
although if there's a huge amount of data , it might actual be more effici .
the main point of implement princip compon analysi us back propag in a neural net is that it allow us to gener princip compon analysi .
if we us a neural net that ha nonlinear layer befor and after the code layer , it should be possibl to repres data that li on a curv manifold rather than a linear manifold in a high dimension space .
and thi is much more gener .
so our network will look someth like thi , the b input vector , and then on or more , layer of non linear hidden unit , typic we us logist unit .
then there'll be a code layer which might be linear unit .
and then follow the code layer , there'll be on or more layer of non linear hidden unit .
and then there'll be an output vector , which we train to be as similar as possibl to the input vector .
so thi is a curiou network in which we're us a supervis learn algorithm to do unsupervis learn .
the bottom part of the network is an encod .
which take the input vector and convert it into a code us a non linear method .
the top part of the network is a decod , which take the nonlinear code and map it back to a reconstruct of the input vector .
so after we've done the learn , we have map in both direct .
in thi video , we're go to look at the issu of train deep autoencod .
peopl thought of these a long time ago , in the mid 1980s .
but thei simpli couldn't train them well enough for them to do significantli better than princip compon analysi .
there were variou paper publish about them , but no good demonstr of impress perform .
after we develop method of pre train deep network on layer at a time .
russ salakhutdinov and i appli these method to pretrain deep autoencod , and for the first time , we got much better represent out of deep autoencod than we could get from princip compon analysi .
deep autoencod alwai seem like a realli nice wai to do dimension reduct becaus it seem like thei should work much better than princip compon analysi .
thei provid flexibl map in both direct , and the map can be non linear .
their learn time should be linear or better in the number of train case .
and after thei've been learn , the encod part of the network is fairli fast becaus it's just a matrix multipli for each layer .
unfortun , it wa veri difficult to optim deep autoencod us back propag .
typic peopl try small initi weight , and then the back propag gradient di , so for deep network , thei never got off the ground .
but now we have much better wai to optim them .
we can us unsupervis layer by layer pre train , or we can simpli initi the weight sensibl , as an echo statement it work .
the first realli success deep water encod were learn by russ salakhutdinov and i in <num> .
we appli them to the n ness digit .
so we start with imag with <num> pixel .
and we then encod those via three hidden layer , into <num> real valu activ in a central code layer .
we then decod those <num> real valu activ , back to <num> reconstruct pixel .
we us a stack of restrict boltzmann machin to initi the weight us for encod , and we then took the transpos of those weight and initi the decod network with them .
so initi , the <num> pixel were reconstruct , us a weight matrix that wa just the transpos of the weight matrix us for encod them .
but after the four restrict boltzmann machin have be train and unrol to give the transpos for decod , we then appli back propag to minim the reconstruct error of the <num> pixel .
in thi case we were us a cross entropi error , becaus the pixel were repres by logist unit .
so that error wa back propag through thi whole deep net .
and we onc start back propag the error , the weight us for reconstruct the pixel becam differ from the weight us for encod the pixel .
although thei , typic stai fairli similar .
thi work veri well .
so if you look at the first row , that's on random sampl from each digit class .
if you look at the second row , that's the reconstruct of the random sampl by the deep autoencod that us <num> linear hidden unit in it central layer .
so the data ha been compress to <num> real number and then reconstruct .
if you look at the eight , you can see that the reconstruct is actual better than the eight .
it's got rid of the littl defect in the eight becaus it doesn't have the capac to encod it .
if you compar that with linear princip command analysi , you can see it's much better .
a linear map to <num> real number cannot do nearli as good a job of repres the data .
in thi video , i'm go to talk about appli deep autoencod to document retriev .
there wa a method develop some time ago call latent semant analysi , that amount to appli princip compon analysi to vector of word count extract from document .
the code produc by latent semant analysi can then be us for judg similar between document so thei can be us for document retriev .
obvious , if deep autoencod work much better than pca , we would expect to be abl to extract much better code us a deep autoencod than us latent semant analysi .
and ru lan salakhutdinov and i show that , that wa inde the case .
us a big databas of document , we show that ten compon extract with a deep autoencod ar actual worth more than <num> compon extract with a linear method , like latent semant analysi .
we also show that if you make the code veri small , have just two compon , you can us those two compon for visual document as a point in a two dimension map .
and thi , again , work much better than just extract the first two princip compon .
to find document that ar similar to a queri document , the first thing we do is convert each document into a big bag of word .
in other word , we have a vector of word count that ignor the order of the word .
thi clearli throw awai quit a lot of inform .
but it also retain a lot of inform about the topic of the document .
we ignor word like the or over which ar call stop word , becaus thei don't have much inform about the topic .
so if you look on the right , i've done the count for variou word , and thei're actual the count for the document on the left .
so , if you look at what word we have nonzero count for , thei ar vector , and count , and queri , and reduc , and bag , and a word , that tell you quit a lot about what the document is about .
now , we could compar the word count of the queri document with the word count of million of other document .
but that would involv compar quit big vector .
in fact , we us vector of size <num> .
so , that would be slow .
altern , we could us each queri vector to a much smaller vector that still contain most of the inform about the content .
so , here's how we do the reduct .
we take the deep autoencod and we compress the <num> , <num> word count down to ten real number , from which we can reconstruct the <num> , <num> word count , although we can't reconstruct them veri well .
we train the neural network to reproduc it input vector as it output vector as well as possibl .
and that forc it to put as much inform about the input into those ten number as possibl .
we can then compar document us just ten number .
that's go to be much faster .
so , there's on problem with thi , which is word count aren't quit the same as pixel or real valu .
what we do is we divid the count in a bag of word by the total number of non stop word and that convert the vector of count into a probabl vector where the number add up to on .
you can think of it as the probabl of get a particular word if you pick a word at random in the document , as long as that is not a stop word .
so , the output of the autoencod , we're us a great , big <num> , <num> wai softmax .
and our target valu ar the probabl of word when we reduc the count vector to a probabl factor .
there's on further trick we have to do .
we treat the word count as probabl when we're reconstruct them .
but when we're us them to activ the first hidden layer , we multipli all the weight by n .
and that's becaus we have n differ observ from that probabl distribut .
if we left them as probabl , the input unit would have veri small activ and wouldn't provid much input to the first hidden layer .
so , we have thi funni properti that for the first restrict boltzmann machin , the bottom up weight , ar n time bigger than the top down weight .
so , how well doe thi work ?
we train us bag of <num> , <num> word on <num> , <num> busi document from the reuter data set .
and these document had been hand label with about a <num> differ categori .
we first train a stack of restrict boltzmann machin , and then , we fine tune with back propag us a <num> , <num> wai softmax as the output .
and then , we test it on a differ set of <num> , <num> document .
and to test , you pick on document to be the queri , on of the test document , and then you rank order all the other test document by us the cosin of the angl between the ten dimension vector that the order code give you .
you repeat thi for each of the <num> , <num> possibl test document and then you plot the number of document you're go to retriev , that is how far down that rank list you're go to go , against the proport that ar in the same hand label class as the queri document .
thi is not a veri good measur of the qualiti of the retriev .
but we're go to us the same measur for compar the lsa .
and so , at least , it's a fair comparison .
so , here's the accuraci of the retriev as a function of the number of retriev document .
when you see that an autoencod wa just us a code with ten real number is do better than latent emant analysi , us <num> real number .
and , of cours , it's five time less work per document after you've got the code .
latent semant analysi with ten real number is much wors .
we can also do the same thing where we reduc to two real number , and then , instead of do retriev , we're just go to plot all the document in a map but we're go to color that two dimension point that correspond to the two number produc by pca by the class of the document .
so , we took the major class of the document .
we gave those major class differ color .
and then , we us pca on log of on plu the count .
the point of do that is that it suppress count with veri big number which tend to make pca work better .
thi is the distribut you get .
as you can see , there is some separ of the class .
the green class is in on place .
the red class is in a slightli differ place .
but the class ar veri mix up .
then , we did the same thing by us a deep autoencod to reduc the document to two number , and , again , plot the document in a two dimension space us those two number as the coordin .
and here's what we got .
it's a much better layout .
it tell you much more about the structur of the data set .
you can see the differ class , and you can see that thei're quit well separ .
we assum that the document in the middl ar on which didn't have mani word in them , and therefor , it wa hard to distinguish between the class .
a visual displai like thi could be veri us .
if , for exampl , you saw on of green dot wa the account and earn report from enron , you probabl wouldn't want to bui share in a compani that ha a green dot nearbi .
in thi video , i'm go to describ a techniqu call semant hash that provid an extrem effici wai of find document similar to a queri document .
the idea is to convert the document into a memori address .
and in that memori to organ thing so that if you go to a particular address and look at the nearbi address , you'll find document that ar veri similar .
thi is much like a supermarket where if you go to a locat where a particular product is store and look around , you'll find similar product .
peopl have known for a long time that if you could get binari descriptor of imag , you'd have a veri good wai of retriev imag quickli .
some binari descriptor ar easi to get .
for exampl , is it an indoor scene or an outdoor scene ?
is to color imag or black and white imag ?
but it's much harder to get a list of sai , <num> binari descriptor which ar more or less orthogon to on anoth , which is what we realli need .
thi is a problem that machin learn can help us with .
we're go to start by look at the equival problem for document , but then we're go to appli it to imag .
so consid , instead of get real valu code for document , get binari code , from the word cancer document .
we do thi by train a deep auto encod that ha a logist unit in it's code layer .
that by itself is not suffici becaus the logist unit will be us in their middl rang where thei have real valu in order to convei as much inform as possibl about the <num> , <num> word count .
to prevent that , we add nois to the input to the code unit dure the fine tune stage .
so , we first train it as a stack of restrict boltzmann machin .
we can unrol these boltzmann machin by us the transpos of the white matric for the decod , and then we fine tune it with back propag .
and as we're do that , we add addit gaussian nois to the input to the code unit .
in order to be resist to that nois , the code unit need to be either firmli on or firmli off .
and so the nois will encourag the learn to avoid the middl region of the logist where it convei a lot of inform , but it's veri sensit to nois in it input .
at test time , we simpli threshold the logist unit in the middl layer to get binari valu .
so , if we can train an auto encod like thi , we will be abl to convert the count for a bag of word into a small number of binari valu .
in other word , we'll have learn a set of binari featur that ar good for reconstruct the bag of word .
later on , alex krizhevski discov that we don't actual have to add gaussian nois to the input to the <num> code unit .
instead , we can just make them stochast binari unit .
so , dure the forward pass , we stochast pick a binari valu us the output of the logist .
and then , dure the backward pass , we pretend that we've transmit the real valu probabl from the logist , and that give us a smooth gradient for back propag .
onc we've got these short binari code , we could of cours do a sequenti search where for each known document , we store a code .
and then when a queri document arriv , we first extract it code , if it's not on of our known document , and then we compar the code with the code of all the store document .
the comparison can be veri fast , becaus thei can us special bit oper on a typic cpu which can compar mani bit in parallel .
but we have to go through a veri long list of document , possibl billion .
there's a much faster thing we can do , there's a much faster thing we can do .
we can treat the code as if it wa a memori address .
so , the idea is that we take a document , and we us our deep auto encod as a hash function that convert a document into a <num> bit address now , we have a memori with <num> bit address .
and in that memori , each address will have a pointer back to the document that have that address .
if sever document have the same address , we can make a littl list there .
now , if the auto ncoder is success in make similar document have similar address , we have a veri fast wai of find similar document .
we simpli take the queri document , you go to the address in memori that correspond to it binari code , and then you look at nearbi address .
in other word , you start flip bit in that address to access nearbi address .
and you could imagin a littl hum ball of nearbi address that differ by just a few bit .
what we expect to find at those nearbi address is semant similar document .
so , we've complet avoid search a big list .
we simpli comput a memori address , flip a few bit , and look up the similar document .
it's extrem effici especi if we have a veri larg databas of sai , a billion document .
we've complet avoid the serial search through a billion item .
i sometim call thi supermarket search becaus it's like what you would do in a supermarket .
suppos you went to an unfamiliar supermarket and you want to find anchovi .
you might ask the teller at the supermarket , where do you keep the can of tuna fish ?
you'd then go to that address in the supermarket and you'd look around .
hopefulli , near there is thing like can of salmon and mayb can of anchovi .
of cours , if you're unlucki , the anchovi might have been store in a complet differ place , next to the pizza top .
and that's the downsid of thi kind of search .
known as supermarket , it's essenti a <num> d surfac .
so , it's realli a <num> d string of shell , which have height and that give you <num> d , and so you onli have two dimens in which to locat thing .
and that's not suffici to put all the thing you'd like to be near on anoth , near on anoth .
you'd like , for exampl , to have the vegetarian version of thing nearbi , or the kosher version of thing nearbi , or the slightli out of date version of thing nearbi .
and in <num> d you can't do all that .
but what we have here is a <num> dimension supermarket and that's a huge more complex space where it's veri easi to have thing near an item for mani differ reason becaus of similar along mani differ dimens .
here's anoth view of what we're do in semant hach .
most of the first retriev method work by intersect store list that ar associ with cue extract from the queri .
so , googl , for exampl , will have a list of all the document that contain some particular rare word .
and when you us that rare word in your queri , thei will immedi have access to that list .
thei then have to intersect that list with other list in order to find a document that satisfi all the term in your queri .
now , comput actual have special hardwar that can intersect <num> veri long list in a singl machin instruct .
the hardwar is call the memori bu .
so , each bit in a <num> bit binari address specifi a list of half the address in memori .
for exampl , if the bit is on and it's the first bit in the address , it specifi the top half of memori .
if the bit is off , it specifi the bottom half of memori .
what the memori bu is do is intersect <num> list to find the on locat that satisfi all <num> valu in the binari code .
so , we can think of semant hash as a wai of us machin learn to map the retrial problem onto the type of list intersect comput's good at .
as long as our <num> bit correspond to meaning properti of document or imag , then we can find similar on veri fast with no search at all .
in thi video , i'm go to talk about the us of binari code for imag retriev .
for retriev document , peopl like googl have such good method alreadi , the techniqu like semant hash mai not be of much valu .
but retriev imag is much more difficult and the method that convert an imag into a fairli larg binari code of sai , <num> bit , seem to work quit well .
howev , we don't want to do a veri long sequenci search through vector of <num> bit so semant hash can be us to first creat a short list and then we can get better qualiti match by us longer binari code in a serial search .
now , we get to look at us binari code for imag retriev .
imag retriev of present is typic done by us the caption .
but why not us the imag too ?
thei obvious contain a lot more inform than the caption .
the basic problem is that pixel ar not like word .
individu pixel don't tell us much about the content of an imag .
obvious if you could recogn the object in the imag , then we'd have thing that were much more like word .
but recogn object is hard .
at least it wa when we first did thi work .
now deep neural net have got much better at it , and so that mai well be the wai to go .
so if we're not go to recogn the object , mayb what we should do is extract a vector that ha inform about the content of the imag .
and the obviou thing to extract is the real valu vector .
but the problem is that match real valu vector in the real data base is slow and it also requir a lot of storag for the real valu vector .
if we can extract a fairli short binari vector that contain a lot of inform about the imag that's much easier to store and much faster to match , even faster is to us a two stage method .
so first , we extract a short binari code of about <num> bid and that short binari code is us with semant hash to veri rapidli get us a short list of promis imag .
so we simpli take the short binari code , and flip a few bit in it to get candid imag .
the candid imag can then be match us <num> bit binari code that ar store with each known imag .
to search for much better match than can be found with a <num> bit binari code .
even a <num> bit binari code onli requir four word of memori per imag .
and even though we're then go to do a serial on these binari code .
the search can be done veri fast , becaus it onli requir a few oper to compar two , <num> binari code to find out how mani bit thei have in common .
the question is , how good is a binari code of that size at retriev imag ? .
ar thei go to find imag that we think of as be similar ?
so here's a net that train by alex krizhevski .
it's work on small color imag so thei're onli <num> pixel by <num> pixel and he take hi input the red , green , and blue channel from those imag so <num> , <num> input .
he then expand that to a larger number of hidden unit becaus we're go to go from real valu input to logist hidden unit , which probabl have less capac .
we then progress decreas the number unit in each layer until we get down to <num> bit .
thi encod ha about <num> million paramet .
it's quit big .
it take a few dai to train it on , in video gpu .
and i'll exchang it on two million imag .
there's absolut no theori to justifi the architectur we us .
we know we want a fairli deep net .
it make sens to make it get an arrow as we go up .
but thi particular architectur , where you have the number of unit each layer , is just a guess .
the interest thing is , a guess like thi alreadi work quit well .
and presum , there ar some other architectur that will work better .
the first question to ask is how well doe an order coder like thi do at reconstruct the imag ?
so , here is a face imag and it's reconstruct and you can see that from the reconstruct you can tell the kind of an imag it is .
here's anoth exampl , where it's a scene probabl at a parti , you can't realli tell what kind of scene it is from the imag but you might guess that there ar a number of peopl involv or you might not .
here's an outdoor scene .
and you can see that the reconstruct captur a lot of inform about the accuraci .
it captur the water in the sky and the hyphen of thin strip land .
so let look at the qualiti of retriev we can do within order code that give those kind of reconstruct .
we'll start with a pictur of michael jackson in the red squar and alex retriev the most similar imag and abov each imag you can see how mani bit had differ from michael jackson bodi .
and you'll notic thei're all a fairli similar number of bit .
in <num> bit , differ by onli <num> bit is extraordinarili unlik to happen by chanc if thei were random imag .
it ha to be a pretti similar imag to differ by so few bit .
on nice thing about what's retriev is , with on except , thei're all face .
if we look at the retriev you get by us euclidean distanc on the raw pixel , then some of them ar face , but most of them aren't .
so obvious the order coder ha understood someth about face that isn't in the inform about euclidean distanc .
it's clearli give much better retriev .
let's take anoth exampl , here we took the imag of a parti scene and we treat of the imag .
and you can see that about half of them have imag you would think of as fairli similar that other parti scene .
the tip of the other parti scene with someth bright in the middl , like the oigin parti scene , and you'll also notic that most of the bad match also have someth bright in the middl .
so even though we're get down to <num> bit binari code through a lot of hidden layer , it's still sensit to quit a lot about the imag structur and where the brighter patch ar .
if you look at what euclidean distanc doe , it's much wors .
euclidean distanc get on other scene with a , a group of peopl .
and then everyth els is fairli dissimilar .
you'll notic with euclidean distanc , it often get veri smooth imag .
that's becaus if you can't match the high frequenc variat in the imag , it's better to match it averag then to get other stuff with high frequenc variat out of phase .
so when you got a complic imag , includ in distanc will typic find smooth imag to match it .
and that's becaus it's minim a squar error in pixel space .
so obvious we'd like the imag retriev to be more sensit to the content of the imag that is store kind of object in the relationship in imag and less sensit to the pixel intens .
we can do that by first train a big net to recogn lot of differ kind of object in real imag and we show you how to do that in lectur five .
then we take the activ vector , in the last hidden layer of the big net , and us that as a represent of the imag .
thi should be much better than the pixel intens at captur inform about the kind of object in the imag .
so to see if thi approach is like to work , we us the net describ in lectur five , the on the imag that competit .
so far , we've onli tri it on euclidan distanc , between the activ of vector in the last hidden layer .
but obvious if it work for that , we could then that those activ vector and build an order code around those to get them down to binari code .
so let's first see if it work with the euclidean distanc .
it turn out it work realli well .
we don't know yet whether it will work with binari code .
so , in the column on the left , you see the queri imag .
and then to the right of them , you see all the thing that were retriev .
if you look at the eleph queri imag , you'll see that what get retriev is other eleph but eleph with veri differ pose .
so those imag wouldn't have a veri good overlap in pixel space , although the overlap wouldn't be that bad .
if you look at the halloween pumpkin , you'll see that all the retriev thing ar other halloween pumpkin .
and some of them , would have a pretti bad overlap pixel space .
similar with the aircraft carrier , we retriev other imag of aircraft carrier that ar veri differ .
so we anticip that if we could reduc the activ vector to short binari code .
we would have a fast and effect wai of retriev similar imag just by the content of the imag .
we'll see in lectur sixteen that we could actual combin the content of the imag with the caption of the imag , to get an even better represent .
in thi video , i'm go to talk about altern pre train method for learn deep neural net .
i introduc pre train us restrict boltzmann machin train with contrast diverg .
but after that , peopl discov there ar mani other wai to pre train layer of featur .
and inde , if you initi the weight correctli , you mai not need pre train at all provid you have enough label data .
we've seen some of the neat thing that can be done with the code produc by deep auto encod .
i now want to consid shallow auto encod that just have on hidden layer .
restrict boltzmann machin can be us with shallow auto encod , particularli if thei're train with contrast diverg becaus thei're try to make the reconstruct look like the data .
when do you us an autoencod ?
a restrict boltzmann machin ha veri strong regular becaus the hidden unit ar onli allow to have binari activ , and thi restrict their capac a lot .
if we train restrict boltzmann machin with maximum likelihood , thei're not at all like auto encod .
on wai to see that is if you had a pixel that wa pure nois , an auto encod would try to reconstruct whatev nois valu it had .
a restrict boltzmann machin train with maximum likelihood would complet ignor that pixel and model it just us the bia for that input .
so , sinc we can view a restrict boltzmann machin as a kind of a strongli regular auto encod , mayb we can replac the rbm that we us for pre train with a stack of autoencod .
it turn out that if you do that , pre train is not as effect .
at least , that's true if you us shallow auto encod that ar regular just by penal the squar weight .
so , stack these autoencod doesn't work as well as stack restrict boltzmann machin .
howev , there's a differ kind of auto encod that doe work as well , and that's the denois auto encod .
and , it's been studi extens by the group in montreal .
denois auto encod work by ad nois to each input vector by set mani of the compon to zero , but it's differ compon for differ input vector .
thi resembl dropout , but it's for the input rather than the hidden unit .
the denois auto encod is still requir to reconstruct , the input that have been set to zero .
and so , it can't just copi it input .
the danger with the shallow auto encod is that if you give it enough hidden unit , it might just copi each pixel to on hidden unit , and then reconstruct that pixel from that hidden unit .
a denois auto encod clearli can't do that so it ha to us hidden unit to catch a correl between input so that it can us the valu of some input to help it reconstruct the input that have been zero out .
if we us a stack of denois auto encod , pre train is veri effect .
there's some case in which rbm still work better , but in most case denois auto encod ar more effect .
it's also much simpler to evalu the pre train us a denois autoencod becaus we can easili comput the valu of the object function .
when we pre train a restrict boltzmann machin with contrast diverg , we can't comput the valu of the real object function we're try to minim .
so , we often just us the squar reconstruct error , which is not actual what's be minim .
in a denois auto encod , we can print out the valu of the thing we're try to minim , and that's veri help .
on disadvantag of the denois autoencod is that it lack the nice variat boundari we get with restrict boltzmann machin .
but that's onli of theoret interest becaus it onli appli if the restrict boltzmann machin is train with maximum likelihood .
yet anoth kind of auto encod is the contract auto encod , that wa also develop by the group in montreal .
the wai thi work is that we try to make the hidden activ be as insensit as possibl to the input .
of cours , the hidden unit can't just ignor the input altogeth becaus thei have to be abl to reconstruct them .
the wai we achiev thi insensit is by penal the squar gradient of each hidden unit with respect to each input .
so , we try to make each hidden unit so that it won't chang much if we chang an input valu .
contract auto encod also work veri well for pre train .
their code tend to have the properti that onli a small subset of the hidden unit ar in their sensit rang .
for differ part of the space , it's a differ subset and so thi activ set act like a spars code .
the other hidden unit ar unsatur and ar insensit .
rbm actual have a veri similar behavior .
after thei've been train , mani of the hidden unit will be satur , and the work set of the unsatur on will be differ for differ train case .
i want to finish by summar my current view of pre train .
there ar now mani differ wai to do layer by layer pre train that discov good featur .
when our data set doe not have a huge number of label , thi wai of discov featur befor you ever us the label is veri help for the subsequ discrimin fine tune .
it discov the featur without us the inform in the label , and then the inform in the label is us for fine tune the decis banquet between class .
it's especi us if we have a lot of unlabel data so that the pre train can be a veri good job of discov interest featur , us a lot of data .
for veri larg label data set howev , initi the weight that ar go to be us for supervis learn by us unsupervis pre train is not necessari , even if the net ar deep .
pre train wa the first good wai to initi the weight for deep net , but now we have lot of other wai .
howev , even if we have a lot of label , if we make the net much larger again , we'll need pretrain again .
so , an argument i often have with peopl from googl is thei sai , we've got lot and lot of label data so we don't need regular method .
our net won't over fit anywai becaus we've got so much data .
the counter argument is , that's onli becaus you're us net that ar much too small .
you should us much , much bigger net on much , much more power comput .
and then , you'll start over fit again and you'll need these regular method , like dropout and pre train .
if you ask which regim the brain is in , the brain is clearli in the regim where it got huge number of paramet compar with the amount of data it got .
and so to the brain , at least , regular method ar veri import .
in thi video , i'm go to talk about some recent work on learn a joint model of caption and featur vector that describ imag .
in the previou lectur , i talk about how we might extract semant meaning featur from imag .
but we were do that with no help from the caption .
obvious the word in a caption ought to be help in extract appropri semant categori from imag .
and similarli , the imag ought to be help in disambigu what the word in the caption mean .
so the idea is we're go to try in a great big net that get it input , stand to comput vision featur vector extract for imag and pack up word represent of caption and learn how the two input represent ar relat to each other .
at the end of the video i'll show you a movi of the final network us word to creat featur vector for imag and then show you the closest imag in it data base .
and also us imag to creat byte of word .
i'm now go to describ some work by natish rivastiva , who's on of the ta for thi cours , and roslyn salakutinov , that will appear shortli .
the goal is to build a joint densiti model of caption and of imag except that the imag repres by the featur standardli us in computer rather than by the ropic cell . thi need a lot more comput than build a joint densiti model of label and digit imag which we saw earlier in the cours .
so what thei did wa thei first train a multi layer model of imag alon .
that is it's realli a multi layer model of the featur thei extract from imag us the standard comput vision featur .
then separ , thei train a multi layer model of the word count vector from the caption .
onc thei train both of those model , thei had a new top layer , that's connect to the top layer of both of the individu model .
after that , thei us further joint train of the whole system so that each modal can improv the earlier layer of the other modal .
instead of us a deep belief net , which is what you might expect , thei us a deep bolton machin , where the symmetr connect bring in all pair of layer .
the further joint train of the whole deep boltzmann machin is then what allow each modal to chang the featur detector in the earli layer of the other modal .
that's the reason thei us a deep boltzmann machin .
thei could've also us a deep belief net , and done gener fine tune with contrast wake sleep .
but the fine tune algorithm for deep boltzmann machin mai well work better .
thi leav the question of how thei pretrain the hidden layer of a deep boltzmann machin .
becaus what we've seen so far in the cours is that if you train a stack of restrict boltzmann machin and you combin them togeth into a singl composit model what you get is a deep belief net not a deep boltzmann machin .
so i'm now go to explain how , despit what i said earlier in the cours , you can actual pre trail a stack of restrict boltzmann machin in such a wai that you can then combin them to make a deep boltzmann machin .
the trick is that the top and the bottom restrict bowser machin in the stack have to train with weight that it twice begin on direct the other .
so , the bottom boltzmann machin , that look at the visibl unit is train with the bottom up weight be twice as big as the top down weight .
apart from that , the weight ar symmetr .
so , thi is what i call scale symmetr .
but the bottom up weight ar alwai twice as big as their top down counterpart .
thi can be justifi , and i'll show you the justif in a littl while .
the next restrict boltzmann machin in the stack , is train with symmetr weight .
i've call them two w , here rather then w for reason you'll see later .
we can keep train with restrict bowsler machin like that with genuin symmetr weight .
but then the top on in the stack ha be train with the bottom up weight be half of the top down weight .
so again , these ar scale symmetr weight , but now , the top down weight ar twice as big as the bottom up weight .
that's the opposit of what we had when we train the first restrict bolton machin in the stack .
after have train these three restrict bolton machin , we can then combin them to make a composit model , and the composit model look like thi .
for the restrict bolton machin in the middl , we simpli halv it weight .
that's why thei were 2w2 to begin with .
for the on at the bottom , we've halv the up go weight but kept the down go weight the same .
and for the on at the top we've halv the down go weight and kept the up go weight the same .
now the question is why do we do thi funni busi of halv the white ?
the explan is quit complic but i'll give you a rough idea of what's go on .
if you look at the layer h1 .
we have two differ wai of infer the state of the unit in h1 , in the stack of restrict bolt and machin on the left .
we can either infer the state of h1 bottom up from v or we can infer the state of h1 top down from h2 .
when we combin these boltzmann machin togeth , what we're go to do is we're go to an averag of those two wai of infer h1 .
and to take a geometr averag , what we need to do , is halv the weight .
so we're go to us half of what the bottom up model sai .
so that's half of 2w1 .
and we're go to us half of what the top down model sai .
that's half of 2w2 .
and if you look at the deep boltzmann machin on the right , that's exactli what's be us to infer the state of h1 .
in other word , if you're given the state in h2 , and you're given the state in v , those ar the weight you'll us for infer the state of h1 .
the reason we need to halv the weight is so that we don't doubl count .
you see , in the boltzmann machin on the right .
the state of h2 alreadi depend on v .
at least it doe after we've done some settl down in the boltzmann machin .
so if we were to us the bottom up input come from the first restrict boltzmann machin in the stack .
and we us the top down input come from the second boltzmann machin in the stack , we'd be count the evid twice . 'caus we'd be infer h1 from v .
and we'd also be infer it from h2 , which , itself , depend on v .
in order not to doubl count the evid , we have to halv the weight .
that's a veri high level and perhap not total clear descript of why we have to half the weight .
if you want to know the mathemat detail , you can go and read the paper .
but that's what's go on .
and that's why we need to halv the weight .
so that the intermedi layer can be do geometr averag of the two differ model of that layer , from the two differ restrict boltzmann machin in the origin stack .
in thi video , i am go to describ how we might be abl to combin recognit of object by us the relationship between their part and recognit of object us a deep neural network .
at present in comput vision , there's broadli three approach to recogn object .
either you us a deep convolut neural net and thi current work best .
or you us a part base approach , which i think in the long run is go to work best , .
or you us the exist featur that comput vision peopl know how to extract from imag and make histogram of them and then us lot of hand engin .
thi is the approach that the convolut neural network have recent beaten .
the point of thi video is to show how we might combin a part base approach with earli stage that us convolut neraul network .
even though convolut neural network have work veri well for recogn object and imag , i think there's someth miss .
when we pool the activ of a bunch of replic featur detector , we lose the precis posit of the featur detector that wa most activ .
thi mean we don't know exactli where thing ar and that's fatal for high level part , such as the nose and the mouth .
in order to recogn whose face it is , you need to us the precis spatial relationship between high level part , like nose and mouth .
if you overlap the pool so that each featur occur in sever differ pool , you retain more inform about it posit and that make thing work a bit better , but i don't think that's the answer .
a relat problem is that convolut neural net that us translat to replic featur detector cannot extrapol their understand of geometr relationship to radic new viewpoint like differ orient or differ scale .
we could , of cours , try replic across orient and scale , but then , we get huge number of replic featur detector .
now , peopl ar veri good at extrapol .
after see a new shape onc , thei can recogn it from a veri differ viewpoint .
current , the wai we deal with that with convolut neural network is to train them on transform data .
so thi involv give them huge train set , where we tri to transform the data through differ orient , and scale , and light , and all sort of other thing so that the network can cope with those variat .
but that's a veri clumsi wai of deal with the variat .
i think a much better wai is to us a hierarchi of coordin frame and to us a group of neuron to repres the conjunct of the shape of a featur and it's pose rel to the retina .
so when these neuron ar activ , it tell you a featur of that kind is there , like a nose .
and the precis activ or rel activ of these neuron tell you the pose of the nose .
if you think about repres the pose of someth , that's realli a relationship between two coordin frame .
so it's a relationship between a coordin frame embed in the thing and the coordin frame of the camera or retina .
so , in order to repres the pose of someth , we have to emb a coordin frame within it .
onc we've done thi and we have a represent of the pose of thought of object rel to the reckon , it's easi to us the relationship between path to recogn larger object .
so we're go to us the consist of the pose of the part as a cue for recogn a larger shape .
if you look at thi pictur , we have a nose and we have a mouth and then the right spacial relationship to on anoth .
on wai of think about that is that if you ask the mouth to predict the pose of the whole face , and if you ask the nose to predict the pose of the whole face , thei'll make similar predict .
if you look on the right share , we have the same nose and the same mouth , but now thei're in the wrong spatial relationship .
and that mean that if thei separ make predict about the pose of the whole face , those predict won't agre at all .
so here's two layer in a hierarchi of part , where the larger part can be recogn by consist predict from smaller part .
let's suppos we're look for a face .
and so in the middl here the ellips with tj in it is a collect of neuron that ar go to be us for recogn the pose of the face .
and the pj next to it is a singl logist neuron that's go to be us for repres whether or not we think there's a face there .
we have a similar represent in the lab below , where we have a represent of the pose for a mouth and a represent of the pose for a nose , and we can recogn the phase by notic that those two represent make consist predict .
so we take a vector of activ that repres the pose of the mouth .
we multipli by matrix tij that repres the spatial relationship between a mouth and a face , and we get a predict , ti tij for the pose of the face .
we do the same thing with the nose .
we take a vector of neural activ that repres the pose of the nose , th .
we multipli it by the relationship between the nose and the face and we get anoth predict for the pose of the face .
if those two predict agre , there's a face there , becaus the nose and the mouth ar in the right spacial relationship and that's veri unlik without there be a face there .
what we're do here is invers comput graphic .
in comput graphic , if you knew the pose of the face , you could now comput by us the invers of tij , the pose of the mouth and similarli for the nose .
so in comput graphic you're go from pose of larger thing to pose of their part .
in comput vision , you need to go from the pose of the part to the pose of larger thing and you need to check consist when you do that .
now if we can get a neural net to repres these pose vector , as vector of neural activ , then we get a veri nice properti .
spatial relationship can then be model as linear oper .
that make it veri easi to learn hierarchi visual entiti , and it also make it veri easi to gener across viewpoint .
so , what's go to happen when we make small chang in viewpoint is the pose vector , those vector of neural activ ar all go to chang .
what's go to be invari is the weight .
it wa the weight that repres the relationship between the part from the hole , like tij on the previou slide , and those don't depend on viewpoint .
so we want to get the invari properti of a shape into the weight .
and we want to have the pose vector in the activ , becaus when we chang viewpoint , all those pose vector ar go to chang .
so , rather than try to get neural activ that ar invari to viewpoint , which is what the pool in the convolut net is try to do .
we're go to aim to get neural activ that ar equivari of viewpoint .
as the pose of the object vari the activ of the neuron vari .
that mean the percept of an object , not it label but what it look like , is go to chang as the viewpoint chang .
i'm go to finish by give you some evid that our visual system realli do impos coordin frame in order to repres shape .
thi wa point out a long time ago by a great psychologist call irvin rock .
so if you look at thi shape and i tell you it's a countri , most peopl don't know which countri it is .
thei look at it , and thei think it look a bit like australia , but it's so sort , sort of mirror imag of australia , but it's not realli a familiar countri at all .
if you tell them where the top is , that it's that wai up , thei immedi recogn that's it's africa .
if thei knew what coordin frame to impos on it , it immedi becom a familiar shape .
similarli , if i give you a shape like thi on , you can perceiv it as a squar or you can perceiv it as a diamond .
those ar two complet differ percept .
what you know about the shape is total differ depend on which wai you perceiv it .
so for exampl , if you perceiv it as a tilt squar , you're acut sensit to whether the angl ar right angl .
if you perceiv it as an upright diamond , you're not sensit to that at all .
the angl could be <num> degre off and you wouldn't notic it , but you ar sensit to someth els .
if you perceiv it as an upright diamond , you're acut sensit to whether the corner on the left and the corner of the right ar at the same height .
and you'll probabl notic now that , in thi figur , thei're veri slightli differ height .
these kind of demonstr ar evid , that in order to repres shape we impos coordin frame on them .
becaus when you're look at that squar or diamond , it's the same thing you're look at , but the percept's total differ depend on what coordin frame you impos .
in thi video , i'm go to talk about some excit recent work , which i think will go a long wai toward answer the question how do you settl those hyper paramet in a neural network ?
thi recent work us a differ kind of machin learn to help us decid what valu to us for hyper paramet .
in other word , it's us machin learn to replac the graduat student who fiddl around with all these differ set of the hyper paramet to find out what work .
it reli on a wai of model smooth function call gaussian process , which i had alwai thought of as inadequ for do thing like speech and vision and i still think thei ar inadequ for that .
but when you're in a domain where you don't have much prior knowledg and the onli thing that you can realli appeal to is that you expect similar input to have similar output , then gaussian process ar ideal .
and that's the domain we're in when we're fiddl around with vector of hyper paramet hope to find a vector of hyper paramet that work well .
so , for exampl is the number of hidden unit , the number of layer , the weight penalti , whether it's us drop out or not .
those ar all hyper paramet and differ combin of them work well togeth .
so thi is a veri hard space to explor by hand .
it's veri easi when we're explor by hand to fail to notic thing .
gaussian process ar veri good at notic trend in the data and thei provid a veri good wai of find good set of hyper paramet if you have enough comput .
on of the commonest reason that peopl give for not us neural network is that it requir a lot of skill to set the hyper paramet .
thi is actual a pretti good reason .
if you don't have much experi , it's easi to get stuck us a complet wrong valu for on of the hyper paramet , and then noth work .
you have to set thing like the number of layer , the number of unit per layer , what type of unit to us , the weight penalti , the learn rate , the momentum , and so on and so on .
if you us a learn rate that's <num> time too big or <num> time too small , your network simpli won't work .
on wai to approach thi is to do a naiv grid search .
that is , for each of these hyper paramet , you make a list of altern valu and then you try all possibl combin of valu .
you can see that thi is go to blow up .
if you have more than a few hyper paramet , you're go to end up with mani more combin than you can possibl try .
it turn out that there's someth that's consider better than do a naiv grid search .
we can just sampl random combin .
that is for each hyper paramet , we make a list of altern and then we pick on thing randomli from each list .
the reason that's better is becaus some of the hyper paramet won't have much effect and other will have a lot of effect .
and what we don't want to do is exactli repeat the set of the hyper paramet that have a lot of effect for differ set of hyper paramet that don't have much effect .
we don't learn much that wai .
in a grid search , you'll have sever point along each axi that ar ident for all the other paramet .
and so , if move along that axi of the grid search make no differ , you've replic the same experi mani time and haven't learn anyth about the other paramet .
there's someth you can do that's much better than random combin , and basic it amount to sai , let's us machin learn to simul the graduat student who is try to decid what the hyper paramet should be .
so , instead of us random combin , we look at the result we've got so far and try and predict what combin ar like to work well .
that is , we have to predict region of the hyper paramet space , in which we expect to get good result .
it's not suffici just to sai how well we expect to do .
we also have to have an idea of the uncertainti .
we might , for exampl , have a region , where we expect to do about the same as we're current do , but mayb we would do much better .
in that case , it would be worth go and explor that region .
it's even worth explor region where we expect to do wors , but we might just do a lot better .
now we're go to assum that the amount of comput involv in evalu on set of the hyper paramet is huge .
it involv train a big neura ; network on a huge data set and it might take sever dai on a big comput .
rel to that amount of work , build a model to predict how well a set of the hyper paramet will do , given all the set we've experi with so far is much less work .
and so it's go to requir much less comput to fit the predict model to the result of the experi we've seen so far than it is to run a singl experi .
so what kind of model ar we go to us for predict the result of futur experi ?
it turn out there's a kind of model i haven't talk about in the cours call gaussian process model .
basic , all these model do is assum that similar input give similar output .
thei don't have ani more sophist prior than that , but thei're veri good at us that prior in an effect wai .
so if you don't know much about what you expect hyper paramet could do , a weak prior like that is probabl the best you can do .
gaussian process ar abl to learn for each input dimens what the appropri scale is for measur similar .
so for exampl , if the number of hidden unit could be <num> or it could <num> , the question is ar those similar number or ar those veri differ number ?
should we expect the result we get with <num> to be veri similar to the result we get with <num> or should we expect them to be veri differ ?
if we don't know anyth about neural net , initi we have no idea , but we could look at the result of experi so far .
and if experi with <num> and experi with <num> tend to give veri similar answer when you take into account the other differ between the experi , then <num> is probabl similar to <num> .
and so , we set a scale for that dimens such that you need differ of much more than that to expect to get veri differ result .
now , it's import that gaussian process model do more than just predict the expect outcom of a particular experi .
that is how well the neural net that we train will do on a valid set .
in addit to predict a mean valu for how well thei expect the neural network to do , thei predict a distribut , thei predict the varianc .
thei're call gaussian process becaus their predict ar gaussian .
when thei're make a predict for new set of hyper paramet that ar close to sever consist set that we've alreadi run , so we know the answer .
the predict will tend to be fairli sharp , that is well have low varianc , but when thei ar predict for experi with hyper paramet that ar veri differ from in set the hyper paramet we'd experi it with so far , the predict made by gaussian process model will have veri high varianc .
so here's quit a good strategi for us gaussian process to decid what to try next .
so rememb , we have on kind of learn model , which is a big neural network that take a long time to rout , and we're try to figur out a good set of the hyper paramet to try next .
we have a differ kind of machin learn algorith , call a gaussian process , that's look at the result of the experi we've done so far and try to predict for some propos new set of the hyper paramet how well the neural network would do and also how unsur that predict is ?
so what we're go to do is we're go to keep track of the hyper paramet that have work best so far .
that is a singl set of all the hyper paramet that gave us the neural net with the highest perform so far .
now , when we run the next experi , our best set so far might be replac by the new experi becaus it give better perform in neural net or it might stai the same .
so sinc we're go to substitut the result of the new experi it is better than anyth we've seen so far , our best set so far can onli improv .
so here's a good strategi for what set of the hyper paramet to try next .
we pick a set of the hyper paramet , such that the expect improv in our best set is big .
we don't worri about the fact that we might do an experi that lead to a realli bad result , becaus if it get a realli bad result , we won't replac our best so far with thi new experi .
also , when learn someth .
thi is a phenomenon that manag of hedg fund know about .
i often tell the client if the fund goe up , i'll take <num> of your profit .
if the fund goe down , you lose .
now that's a crazi thing for a client to agre to , becaus that give the hedg fund manag huge incent for take huge risk , becaus he ha no signific answer .
but , for find hyper paramet that work well , it's a sensibl strategi .
so , consid these three predict , a , b , and c .
we're go to suppos that a , b , and c ar differ set of the hyper paramet that have not been tri and those green gaussian ar the predict of our gaussian process model for how well each of those set would do .
for set a , the mean is well below our current best so far and there's onli moder varianc .
for set b , the mean is closer to our best so far , but sinc there isn't much varianc , there realli isn't that much upsid .
for set c , the mean is actual lower than for set b , but becaus it's high varianc there's a big upsid .
we're go to take the area under gaussian c that's abov the red line and we're go to take the moment of that area abov the red line and that's the thing we're look for the match margin and you can see that c ha a much bigger moment than b or a .
it mai onli have the same area as b abov the line , but some of that area is much further abov the line , so we might get a veri big win if we try set c .
so that's the on our polici would tell us to pick here .
here's the worst part , b is intermedi and c is the best bet .
so how well doe thi work ?
well , if you got the resourc to run a lot of experi , it's much better than a person of find good combin of the hyper paramet .
the polici i gave you so far is a strictli sequenti polici that assum that it can see all of the experi run so far , but there's no reason why you shouldn't make it a bit more complic and run a whole bunch of experi in parallel .
us a gaussian process model to predict how well a particular set of the hyper paramet will do is sensibl , becaus it's not the kind of task we're good at .
it's not like vision speech , and it's not clear that there's a lot of complic structur to be found in the data .
it mai be that the onli real structur is that thing ar smooth and thei have some scale .
also , a person can't keep in mind the result of <num> differ experi , to see what thei predict .
if you're do all thi by hand , you might just fail to notic that all of your good result had veri small learn rate , and all of your realli bad result had veri big learn rate , becaus you're attend to lot of other thing that you're vari .
a gaussian process model would not miss a trend like that .
on final reason why gaussian process model ar a veri good wai of set hyper paramet is thei're much less like than a person to cheat .
typic when we're do research , we want to compar a new method that we thought of with some old or standard method , and there's a veri strong tendenc to work harder to find good hyperparamet for our new method than for the stupid old method .
that's why when you compar method , you should realli compar the result got by differ group , where for each method , the result ar produc by the group that believ in that method .
if we us gaussian process model to search for good set of hyper paramet , thei're go to do just as hard a search for the type of model we don't believ in as thei ar for the type of model we do believ in .
in thi final video , i wa tempt to make some predict about the futur of research on neural network .
instead , i'm go to explain to you why it would be extrem foolish to try to make ani long term predict .
i'm go to try and explain why we can't predict the long term futur by us an analog .
imagin you're drive a car at night , and you're look at the taillight of the car in front .
the number of photon that you receiv from the taillight of the car in front fall off at on over d squar , where d is the distanc to the car in front .
that's assum that the air is clear but now suppos there's fog .
over short rang , the number of photon you get from the tail light in front of you , still fall off as on over d <num> .
becaus over a short rang , the fog hardli absorb ani light .
but for larg distanc , it fall off as e to the d .
and that's becaus fog ha an exponenti effect .
fog absorb a certain fraction of the photon per unit distanc .
so for small distanc , fog look veri transpar , but for larg distanc , it look veri opaqu .
so , the car in front of us becom complet invis at a distanc at which our short rang model , the on of a discreet model , predict it will be veri visibl .
that caus peopl to drive into the back of car in fog .
it kill peopl .
the develop of technolog is also typic exponenti .
so over the short term , thing appear to chang fairli slowli .
and it's easi to predict progress .
all of us , for exampl , can probabl make quit good guess about what will be in the iphon six .
but in the longer run , our percept of the futur hit a wall , just like with fog .
so the long term futur of machin learn in neural net is realli a total mysteri .
we have no idea what's go to happen in <num> year' time .
there's just no wai to predict it from what we know now .
becaus we're go to get exponenti progress .
in the short run howev , in a period of sai three to ten year , we can predict it fairli well .
and it seem obviou to me that over the next five year or so .
big deep neural network , you ar go to do amaz thing .
i'd like to congratul all of you who stuck it out long enough to get thi far .
i hope you've enjoi the cours and good luck with the final test .
in thi video i'm go to describ variou kind of architectur for neural network .
what i mean by an architectur , is the wai in which the neuron ar connect togeth .
by far the commonest type of architectur in practic applic is a feet forward neural network where the inform come into the imput unit and flow in on direct through hidden layer until each reach the output unit .
a much more interest kind architectur is a recurr neural network in which inform can flow round in cycl .
these network can rememb inform for a long time .
thei can exhibit all sort of interest oscil but thei ar much more difficult to train in part becaus thei ar so much more complic in what thei can do .
recent , howev , peopl have made a lot of progress in train recurr neural network , and thei can now do some fairli impress thing .
the last kind of architectur that i'll describ is a symmetr connect network , on in which the weight ar the same in both direct between two unit .
the commonest type of neural network in practic applic is a feed forward neural network .
thi ha some input unit .
and in the first layer at the bottom , some output unit in the last layer at the top , and on or more layer of hidden unit .
if there's more than on layer of hidden unit , we call them deep neural network .
these network comput a seri of transform between their input and their output .
so at each layer , you get a new represent of the input in which thing that were similar in the previou layer mai have becom less similar , or thing that were dissimilar in the previou layer mai have becom more similar .
so in speech recognit , for exampl , we'd like the same thing said by differ speaker to becom more similar , and differ thing said by the same speaker to be less similar as we go up through the layer of the network .
in order to achiev thi , we need the activ of the neuron in each layer to be a non linear function of the activ in the layer below .
recurr neural network ar much more power than feed forward neural network .
thei have direct cycl in the direct , in their connect graph .
what thi mean is that if you start at a node or a neuron and you follow the arrow , you can sometim get back to the neuron you start at .
thei can have veri complic dynam , and thi can make them veri difficult to train .
there's a lot of interest at present at find effici wai of train our current , becaus thei ar so power if we can train them .
thei're also more biolog realist .
recurr neural network with multipl hidden layer ar realli just a special case of a gener recurr neural network that ha some of it hidden to hidden connect miss .
recur network ar a veri natur wai to model sequenti data .
so what we do is we have connect between hidden unit .
and the hidden unit act like a network that's veri deep in time .
so at each time step the state of the hidden unit determin the state of the hidden unit of the next time step .
on wai in which thei differ from feed forward net is that we us the same weight at everi time step .
so if you look at those red arrow where the hidden unit ar determin the next state of the hidden unit , the weight matrix depict by each red arrow is the same at each time step .
thei also get input at everi time stamp and often give output at everi time stamp , and those'll us the same weight matric too .
recurr network have the abil to rememb inform in the hidden state for a long time .
unfortun , it's quit hard to train them to us that abil .
howev , recent algorithm have been abl to do that .
so just to show you what recurr neural net can now do , i'm gonna show you a net design by ilya sutskev .
it's a special kind of recurr neural net , slightli differ from the kind in the diagram on the previou slide , and it's us to predict the next charact in a sequenc .
so ilya train it on lot and lot of string from english wikipedia .
it's see english charact and try to predict the next english charact .
he actual us <num> differ charact to allow for punctuat , and digit , and capit letter and so on .
after you train it , on wai of see how well it can do is to see whether it assign high probabl to the next charact that actual occur .
anoth wai of see what it can do is to get it to gener text .
so what you do is you give it a string of charact and get it to predict probabl for the next charact .
then you pick the next charact from that probabl distribut .
it's no us pick the most like charact .
if you do that after a while it start sai the unit state of the unit state of the unit state of the unit state .
that tell you someth about wikipedia .
but if you pick from the probabl distribut , so if it sai there's a on in <num> chanc it wa a z , you pick a z on time in <num> , then you see much more about what it's learn .
the next slide show an exampl of the text that it gener , and it's interest to notic how much is learn just by read wikipedia , and try to predict the next charact .
so rememb thi text wa gener on charact at a time .
notic that it make reason sensibl sentenc and thei compos alwai entir of real english word .
occasion , it make a non word but thei typic sensibl on .
and notic that within a sentenc , it ha some themat sentenc .
so the phrase , sever perish intellig agent is in the mediterranean region , ha problem but it's almost good english .
notic also the thing it sai at the end , such that it is the blur of appear on ani well paid type of box printer .
there's a certain sort of themat thing there about appear and print , and the syntax is pretti good .
and rememb , that's on charact at a time .
quit differ for a current net , symmetr connect network .
in these the connect between unit have the same weight in both direct .
john hopfield and other realiz that symmetr network ar much easier to analyz than recurr network .
thi is mainli becaus thei're more restrict in what thei can do , and that's becaus thei obei an energi function .
so thei come , for exampl , model cycl .
you can't get back to where you start in on of these symmetr network .
in thi video , i'm gonna talk about perceptron .
these were investig in the earli <num>'s , and initi thei look veri promis as learn devic .
but then thei fell into disfavor becaus minski and papert show thei were rather restrict in what thei could learn to do .
in statist pattern recognit , there's a statist wai to recogn pattern .
we first take the raw input , and we convert it into a set or vector featur activ .
we do thi us hand written program which ar base on common sens .
so that part of the system doe not learn .
we look at the problem we decid what the good featur should be .
we try some featur to see if thei work or don't work we try some more featur and eventu set of featur that allow us to solv the problem by us a subsequ learn stage .
what we learn is how to weight each of the featur activ , in order to get a singl scalar quantiti .
so the weight on the featur repres how much evid the featur give you , in favor or against the hypothesi that the current input is an exampl of the kind of pattern you want to recogn .
and when we add up all the weight featur , we get a sort of total evid in favor of the hypothesi that thi is the kind of pattern we want to recogn .
and if that evid is abov some threshold , we decid that the input vector is a posit exampl of the class of pattern we're try to recogn .
a perceptron is a particular exampl of a statist pattern recognit system .
so there ar actual mani differ kind of perceptron , but the standard kind , which rosenblatt call an alpha perceptron , consist of some input which ar then convert into futur activ .
thei might be convert by thing that look a bit like neuron , but that stage of the system doe not learn .
onc you've got the activ of the featur , you then learn some weight , so that you can take the featur activ time the weight and you decid whether or not it's an exampl of the class you're interest in by see whether that sum of featur activ time learn weight is greater than a threshold .
perceptron have an interest histori .
thei were popular in the earli 1960s by frank rosenblatt .
he wrote a great big book call principl of neurodynam , in which he describ mani differ kind of perceptron , and that book wa full of idea .
the most import thing in the book wa a veri power learn algorithm , or someth that appear to be a veri power learn algorithm .
a lot of grand claim were made for what perceptron could do us thi learn algorithm .
for exampl , peopl claim thei could tell the differ between pictur of tank and pictur of truck , even if the tank and truck were sort of partial obscur in a forest .
now some of those claim turn out to be fals .
in the case of the tank and the truck , it turn out the pictur of the tank were taken on a sunni dai , and the pictur of the truck were taken on a cloudi dai .
all the perceptron wa do wa measur the total intens of all the pixel .
that's someth we human ar fairli insensit to .
we notic the thing in the pictur .
but a perceptron can easili learn to add up the total intens .
that's the kind of thing that give an algorithm a bad name .
in <num> , minski and papert publish a book call perceptron that analyz what perceptron could do and show their limit .
mani peopl thought those limit appli to all neural network model .
and the gener feel within artifici intellig wa that minski and papert had shown that neural network model were nonsens or that thei couldn't learn difficult thing .
minski and papert themselv knew that thei hadn't shown that .
thei'd just shown that perceptron of the kind for which the power learn algorithm appli could not do a lot of thing , or rather thei couldn't do them by learn .
thei could do them if you sort of hand wire the answer in the input , but not by learn .
but that result got wildli overgener , and when i start work on neural network model in the 1970s , peopl in artifici intellig kept tell me that minski and papert have prove that these model were no good .
actual , the perceptron converg procedur , which we'll see in a minut , is still wide us todai for task that have veri big featur vector .
so , googl , for exampl , us it to predict thing from veri big vector of featur .
so , the decis unit in a perceptron is a binari threshold neuron .
we've seen thi befor and just to re , refresh you on those .
thei comput a weight sum of input thei get from other neuron .
thei add on a bia to get their total input .
and then thei give an output of on if that sum exce zero , and thei give an output of zero otherwis .
we don't want to have to have a separ learn rule for learn bias , and it turn out we can treat bias just like weight .
if we take everi input vector and we stick a on on the front of it , and we treat the bia as like the weight on that first featur that alwai ha a valu of on .
so the bia is just the neg of the threshold .
and us thi trick , we don't need a separ learn rule for the bia .
it's exactli equival to learn a weight on thi extra input line .
so here's the veri power learn procedur for perceptron , and it's a learn procedur that's guarante to work , which is a nice properti to have .
of cours you have to look at the small print later , about why that guarante isn't quit as good as you think it is .
so we first had thi extra compon with a valu of on to everi input vector .
now we can forget about the bias .
and then we keep pick train case , us ani polici we like , as long as we ensur that everi train case get pick without wait too long .
i'm not gonna defin precis what i mean by that .
if you're a mathematician , you could think about what might be a good definit .
now , have pick a train case , you look to see if the output's correct .
if it is correct , you don't chang the weight .
if the output unit output a zero when it should've output a on , in other word , it said it's not an instanc of the pattern we're try to recogn , when it realli is , then all we do is we add the input vector to the weight vector of the perceptron .
convers , if the output unit , output a on , when is should have output a zero , we subract the input vector , from the weight vector of the and what's surpris is that , that simpl learn procedur is guarante to find you a set of weight that will get a right answer for everi train case .
the proviso is that it can onli do it if it is such a set of weight and for mani interest problem there is no such set of weight .
whether or not a set of weight exist depend veri much on what featur you us .
so it turn out for mani problem the difficult bit is decid what featur to us .
if you're us the appropri featur learn then mai becom easi .
if you're not us the right featur learn becom imposs and all the work is decid the featur .
in thi figur , we're go to get a geometr understand of what happen when a perceptron learn .
to do thi , we have to think in term of a weight space .
it's a high dimension space in which each point correspond to a particular set for all the weight .
in thi phase , we can repres the train case as plane and learn consist of try to get the weight vector on the right side of all the train plane .
for non mathematician , thi mai be tougher than previou materi .
you mai have to spend quit a long time studi the next two part .
in particular , if you're not us to think about hyperplan and high dimension space , you're go to have to learn that .
to deal with hyperplan in a <num> dimension space , for exampl , what you do is you visual a <num> dimension space and you sai , fourteen to yourself veri loudli .
everybodi doe it .
but rememb , that when you go from <num> dimension space to a <num> dimension space , your creat as much extra complex as when you go from a 2d space to a 3d space .
<num> dimension space is veri big and veri complic .
so , we ar go to start off by think about weight space .
thi is the space that ha on dimens for each weight in the perceptron .
a point in the space repres a particular set of all the weight .
assum we've elimin the threshold , we can repres everi train case as a hyperplan through the origin in weight space .
so , point in the space correspond to weight vector and train case correspond to plane .
and , for a particular train case , the weight must lie on on side of that hyperplan , in order to get the answer correct for that train case .
so , let's look at a pictur of it so we can understand what's go on .
here's a pictur of white space .
the train case , we're go to think of on train case for now , it defin a plane , which in thi 2d pictur is just the black line .
the plane goe through the origin and it's perpendicular to the input vector for that train case , which here is shown as a blue vector .
we're go to consid a train case in which the correct answer is on .
and for that kind of train case , the weight vector need to be on the correct side of the hyperplan in order to get the answer right .
it need to be on the same side of the hyperplan as the direct in which the train vector point .
for ani weight vector like the green on , that's on that side of the hyperplan , the angl with the input vector will be less than <num> degre .
so , the scaler product of the input vector with a weight vector will be posit .
and sinc we alreadi got rid of the threshold , that mean the perceptron will give an output of what ?
it'll sai ye , and so we'll get the right answer .
convers , if we have a weight vector like the red on , that's on the wrong side of the plane , the angl with the input vector will be more than <num> degre , so the scalar product of the weight vector and the input vector will be neg , and we'll get a scalar product that is less than zero so the perceptron will sai , no or zero , and in thi case , we'll get the wrong answer .
so , to summar , on on side of the plane , all the weight vector will get the right answer .
and on the other side of the plane , all the possibl weight vector will get the wrong answer .
now , let's look at a differ train case , in which the correct answer ar zero .
so here , we have the weight space again .
we've chosen a differ input vector , of thi input factor , the right answer is zero .
so again , the input case correspond to a plane shown by the black line .
and in thi case , ani weight vector will make an angl of less than <num> degre with the input factor , will give us a posit scalar product , perceptron to sai ye or on , and it will get the answer wrong convers .
and the input vector on the other side of the plain , will have an angl of greater than <num> degre .
and thei will correctli give the answer of zero .
so , as befor , the plane goe through the origin , it's perpendicular to the input vector , and on on side of the plane , all the weight vector ar bad , and on the other side , thei're all good .
now , let's put those two train case togeth in on pictur weight space .
our pictur of weight space is get a littl bit crowd .
i've move the input vector over so we don't have all the vector in quit the same place .
and now , you can see that there's a code of possibl weight vector .
and ani weight vector insid that cone , will get the right answer for both train case .
of cours , there doesn't have to be ani cone like that .
it could be there ar no weight vector that get the right answer for all of the train case .
but if there ar ani , thei'll lie in a cone .
so , what the learn algorithm need to do is consid the train case on at a time and move the weight vector around in such a wai that it eventu li in thi cone .
on thing to notic is that if you get a good weight factor , that is someth that work for all the train case , it'll lie on the cone .
ad if you had anoth on , it'll lie on the cone .
and so , if you take the averag of those two weight vector , that will also lie on the cone .
that mean the problem is convex .
the averag of two solut is itself a solut .
and in gener in machin learn if you can get a convex learn problem , that make life easi .
in thi video , we're go to , look at a proof that the perceptron learn procedur will eventu get the weight into the cone of feasibl solut .
i don't want you to get the wrong idea about the cours from thi video .
in gener , it's gonna be about engin , not about proof of thing .
there'll be veri few proof in the cours .
but we get to understand quit a lot more about perceptron when we try and prove that thei will eventu get the right answer .
so we go to us our geometr understand of what's happen in weight space as subset from learn , to get a proof that the perceptron will eventu find a weight vector if it get the right answer for all of the train case , if ani such vector exist .
and our proof is gonna assum that there is a vector that get the right answer for all train case .
we'll call that a feasibl vector .
an exampl of a feasibl vector is shown by the green dot in the diagram .
so we start with the wait vector that's get some of the train case wrong , and in the diagram we've shown a train case that is get wrong .
and what we want to show .
thi is the idea for the proof .
is that , everi time he get a train case wrong , it will updat the current weight vector .
in a wai that make it closer to everi feasibl weight factor .
so we can repres the squar distanc of the current weight factor from a feasibl weight factor , as the sum of a squar distanc along the line of the input factor that defin the train case , and anoth squar differ orthogon to that line .
the orthogon squar distanc won't chang , and the squar distanc along the line of the input factor will get smaller .
so our hope claim is that , everi time the perceptor make a mistak .
our current weight factor is go to get closer to all feasibl weight factor .
now thi is almost right , but there's an unfortun problem .
if you look at the feasibl weight vector in gold , it's just on the right side of the plane that defin on of the train case .
and the current weight factor is just on the wrong side , and the input vector is quit big .
so when we add the input factor to the count weight factor , we actual get further awai from that gold feasibl weight factor .
so our hope claim doesn't work , but we can fix it up so that it doe .
so what we're gonna do is we're gonna defin a gener feasibl weight factor .
that's a weight factor that not onli get everi train case right , but it get it right by at least a certain margin .
where the margin is as big as the input factor for that train case .
so we take the cone of feasibl solut , and insid that we have anoth cone of gener feasibl solut .
which get everyth right by at least the size of the input vector .
and now , our proof will work .
now we can make the claim , that everi time the perceptron make a mistak .
the squar distanc to all of the gener feasibl weight vector would be decreas by at least the squar length of the input vector , which is the updat we make .
so given that , we can get an inform sketch of a proof of converg .
i'm not gonna try and make thi formal .
i'm more interest in the engin than the mathemat .
if your mathematician i'm sure you can make it formal yourself .
so , everi time the preceptor make a mistak , the current weight vector move and it decreas it squar distanc from everi fea , gener feasibl weight vector , by at least the squar length of the current input vector .
and so the squar distanc to all the gener feasibl weight vector decreas by at least that squar length and assum that none of the input vector ar infinitesim small .
that mean that after a finit number of mistak the weight vector must lie in the feasibl region if thi region exist .
notic it doesn't have to lie in the gener feasibl region , but it ha to get into the feasibl region to make , to stop it make mistak .
and that's it .
that's our inform sketch of a proof that the perceptron converg procedur work .
but notic , it all depend on the assumpt that there is a gener feasibl weight vector .
and if there is no such vector , the whole proof fall apart .
in thi video , we're gonna look at the limit of perceptron .
these limit stem from the kind of featur you us .
if you us the right featur , you could do almost anyth .
if you us the wrong featur , thei're extrem limit in what the learn part purpos that font can do .
and that's what caus perceptron to guard favor , and it emphas that the difficult bit of learn is to learn the right featur .
there's still a lot you can do with learn , even if you do not learn featur .
for exampl , if you want to sai whether a sentenc is a plausibl english sentenc , you could hand defin a huge number of featur , and then learn how to write them in order to decid whether particular sentenc is like a good english sentenc .
but , in the long run you need to learn featur .
so the reason that neural network research came to a halt in the late 1960s and earli 1970s is that perceptron were shown to be veri limit , and we're now gonna understand what those limit ar .
if you'd like to choos the featur by hand , and if you us enough featur , you can make the perceptron do almost anyth .
suppos for exampl we have binari input vector .
and we creat a separ featur unit that get activ by exactli on of those binari input vector .
we'll need exponenti mani featur unit .
but now we can make ani possibl discrimin on binari input vector .
so for binari input vector there's no limit if you're will to make enough featur unit .
but of cours , that's not a veri good strategi for solv a practic problem becaus you need an aw lot of featur unit and it won't gener .
you can't look at a subset of all possibl case and have ani hope of get the remain case right becaus those remain case requir new featur unit and you don't know what weight to put on those featur unit .
onc you've decid the hand code featur .
that is onc thei've been determin , there ar veri strong limit on what a perceptron can learn to do .
so here's a classic exampl .
what we're interest in is what can you learn to do with the binari threshold decis unit that is by chang it weight .
and we're go to show that there's veri simpl thing that it can learn to do .
so the simplest exampl is consid a problem in which there's two posit case and two neg case .
and the featur , just singl bit featur , that have valu either on or zero .
so the two posit case consist of both featur be on .
in which case the right answer's on .
or both featur be off .
in which case the right answer's on .
and the two neg case ar when on featur's on and the other on's off .
in which case the right answer is zero .
so all we're ask the binari threshold unit to do is decid whether the two featur have the same valu .
and thei can't even learn to do that .
we can prove that algebra .
those four input output pair that i show you give rise to four inequ , and it's imposs to satisfi them .
so the first posit case , when the two featur valu ar on the output should be on .
that give us the inequ that on time w1 plu on time w2 is gonna be greater than the threshold .
so we give an output a on .
then the second posit case give us the inequ that zero time w1 plu zero time w2 , must also be greater than the threshold .
and the neg case give us the inequalit that on time w1 plu zero time w2 , must be less than the threshold , and similarli zero time w1 plu on time w2 , must be less than the threshold .
now if you take those first two inequ and you add them up , you get the w1 plu w2 must be greater than twice the threshold .
and if you take the second two inequ and you add them up , you get w1 plu w2 must be less than twice the threshold .
so there's clearli no wai to satisfi all four inequ .
or to put it anoth wai , if you look at the binari decis unit where we're go to put the threshold as a neg weight on an input line that alwai ha valu of on .
if you take that binari threshold unit shown at the bottom right , there's no wai to set the threshold in the two weight , so it get all four case right .
we can also see thi geometr .
so we're go to imagin a data space now , in which the axi correspond to compon of an input vector .
so in thi space each point correspond to a data point .
and , a weight vector is go to find a plane in thi space .
so it's just the opposit of what we're do with weight space .
in weight space we made each point be a weight vector , and we us a plane , to defin an input case .
of cours that plane wa defin by an input vector .
now what we're go to do is we're go to make each point be an input vector and we're go to us a wait vector to defin a plane in the data space .
the plane defin by the weight vector is go to be perpendicular to the weight vector and it's go to miss the origin by a distanc equal to the threshold .
so here's a pictur .
you see the four data case there , and for the two data case in red , we need to give an output of zero .
and with the two data case in green , we need to put an output of on .
that me , mean we need the green case to be on the side of the weight plane where the output is on and we need the red case to be on the side where the output is zero , and we obvious cannot arrang the weight plane so that's true .
we call a set of case like that , where there's no hyperplan that will separ the case where we want the answer to be on , from the case where we want the answer to be zero .
we call that a set of train case that's not linearli separ .
and even more devast exampl for perceptron becaus it's much more gener is when we try and discrimin simpl pattern that have to retain the ident when you translat them with wrap around .
i'll give you an exampl of what that mean in a minut .
but the idea is that we want to recogn a pattern and we want to recogn it even when it's translat .
so suppos we just us pixel as the featur .
the question is can a binari threshold unit discrimin between two differ pattern .
we'll call on posit exampl and the other's neg exampl if thei've got the same number of pixel in them .
and the answer is no it can't discrimin two pattern out of the same number of pixel if that discrimin ha to work when the pattern ar translat and if the pattern can wrap around when translat .
so , if you look at these exampl of pattern a , in a on dimension imag .
pattern a ha four pixel that ar on .
those four black pixel .
it's like a littl bar code .
and it's the same pattern when we translat it a bit to the right .
and we're go to allow ourselv to translat the pattern so it goe off the right hand end , and come back on the left hand end .
so the third exampl is the same pattern that's been translat with some wrap around .
and pattern b , it also ha four pattern , but four pixel , but in a differ arrang .
and in the third exampl of pattern b , it's been translat with wrap around .
so that's still an exampl of pattern b .
and for two set of pattern like that , a binari threshold unit cannot learn to discrimin them .
and here's the proof .
what we're go to do is we're go to consid that for the posit exampl we have pattern a in all possibl translat .
now sinc pattern a ha four on pixel , that mean if we look at ani pixel on the retina , there'll be four differ posit in which we can put pattern a that will activ that pixel .
so each pixel will be activ by four differ translat of pattern a .
that mean that the total input receiv by the decis unit , over all those variou translat of pattern a , would be four time the sum of all the weight in the perceptron , becaus each pixel will activ the decis unit four differ time .
and so sum over all those pattern will get four time the sum of the weight .
now consid pattern b .
we're go to make the neg case be pattern b , in all possibl translat .
and again , each pixel will be activ by four differ translat of pattern b .
so the total input of the decis unit receiv and , over all those differ translat of pattern b , will again be four time the sum of all the weight .
but the perceptron , in order to discrimin correctli , ha to have weight so that everi singl case of pattern a provid more input to the decis unit than everi singl case of pattern b .
and that's clearli imposs if when you sum of all these case , all those differ version of pattern a and all of those differ version of pattern b , provid exactli the same amount of input to the decis unit .
so we've prove that a perceptron cannot recogn pattern under translat if we allow wrap around .
that's a particular case of minski and papert's group invari theorem .
and that result is devast for perceptron , it wa histor devast .
becaus the whole point of pattern recognit is to recogn pattern that undergo transform and see that thei're still the same pattern , despit the transform .
like for exampl , translat .
and when minski and papert show that a perceptron couldn't do that if the transform form a group , that is the learn part of a perceptron couldn't learn to do that , it becam clear that the claim that have been made for what perceptron could learn were somewhat exagger , and that to get them to do anyth interest , you had to choos just the right featur to make it fairli easi for the last stage to learn the classif .
so the translat within our prime form a group and , minski and papert prove a gener theorem for transform that form a group , ar make it imposs , for a perceptron .
for the learn part of a perceptron to do the recognit .
the perceptron architectur can still do the recognit , but you have to organ the featur so thei do the difficult part .
so we have to have multipl featur unit that recogn inform sub pattern that tell you someth about what class it is , and we have to have separ featur unit for each posit of those inform sub pattern , if we're try to recogn under translat .
so the tricki part of pattern recognit ha to be solv by the hand code featur detector , not the learn procedur .
the temporari conclus from thi is that perceptron ar no good and therefor neural network ar no good .
the longer term conclus is that neural network ar onli gonna be realli power if we can learn the featur detector .
it's not enough just to learn weight sum featur detector , we have to learn the featur detector themselv .
and the second gener of neural network , which we'll come to in the next lectur , wa all about how you learn the featur detector .
but it took twenti year befor peopl figur out how to do that .
so , network without hidden unit ar veri limit in what thei can learn to model .
if we add more layer of linear unit , it doesn't help becaus everyth is linear .
we can make them much more power by put in hand code hidden unit but thei're not realli hidden unit becaus we hand code them .
we told them what to do .
it's not enough just to have fix output non linear .
what we need is multipl layer of adapt non linear hidden unit .
and the problem is how can we train such net .
we need a wai to adapt all the weight not just the last layer like in a perceptron , and that's hard .
in particular , lean the weight go in to the hidden unit , that's equival to learn featur .
and that's the hard thing to do .
becaus nobodi is tell us directli , what the hidden unit should be do , when thei should be activ and , when thei should not be activ .
and the , real problem is , how do we figur out how to learn these weight go into hidden unit so that the hidden unit turn into the kind of featur detector we need for solv a problem , when nobodi is tell us what the featur detector should be .
thi video introduc the learn algorithm for a linear neuron .
thi is quit like the learn algorithm for a perceptron , but it achiev someth differ .
in a perceptron , what's happen is the weight , so alwai get closer to a good set of weight .
in a linear neuron , the output ar alwai get closer to the target output .
the percept converg procedur work by ensur that when we chang the weight , we get closer to a good set of weight .
that type of guarante cannot be extend to more complex network .
becaus in more complex network when you averag two good set of weight , you might get a bad set of weight .
so for multilay neural network , we don't us the perceptron learn procedur .
and to prove that when thei're learn someth is improv , we don't us the same kind of proof at all .
thei should never have been call multilay perceptron .
it's partli my fault and i'm sorri .
for multilay net we're gonna need a differ wai to show that the learn procedur make progress .
instead of show that the weight get closer to a good set of weight , we're gonna show that the actual output valu get closer to the target output valu .
thi can be true even for non convex problem in which averag the weight of two good solut doe not give you a good solut .
it's not true for perceptu learn .
in perceptu learn , the output as a whole can get further awai from the target output even though the weight ar get closer to good set of weight .
the simplest exampl of learn in which you're make the output get closer to the target output is learn in a linear neuron with a squar error measur .
linear neuron , which ar also call linear filter in electr engin , have a real valu output that's simpli the weight sum of their output .
so the output y , which is the neuron's estim of the target valu , is the sum over all the input i of a weight vector time an input vector .
so we can write it in summat form or we can write it in vector notat .
the aim of the learn is to minim the error sum over all train case .
we need a measur of that error and to keep life simpl , we us the squar differ between the target output and the actual output .
so on question is why don't we just solv it analyt .
it's straightforward to write down a set of equat with on equat per train case , and to solv for the best set of weight .
that's the standard engin approach , and so why don't we us it ?
the first answer , and the scientif answer , is we'd like to understand what real neuron might be do , and thei're probabl not solv a set of equat symbol .
an engin answer is that we want a method that we can then gener to multilay , nonlinear network .
the analyt solut reli on it be linear and have a squar error measur .
an iter method , which we're gonna see next , is usual less effici , but much easier to gener to more complex system .
so i'm now gonna go through a toi exampl that illustr an iter method for find the weight of a linear neuron .
suppos that everi dai , you get lunch at a cafeteria .
and your diet consist entir of fish , chip , and ketchup .
each dai , you order sever portion of each , but on differ dai , it's differ number of portion .
the cashier onli show you the total price of the meal , but after a few dai , you ought to be abl to figur out what the price is for each portion of each kind of thing .
in the iter approach , you start with random guess for the price of portion .
and then you adjust these guess so that you get a better fit to the price that the cashier tell you .
those ar the observ price of whole meal .
so each meal , you get a price and that give you a linear constraint on the price of the individu portion .
it look like thi , the price of the whole meal is the number of portion of fish , x fish , time the cost of a portion of fish , w fish .
and the same for chip and ketchup .
so the price of the portion ar like the weight of a linear neuron .
and we can think of the whole weight vector as be the price of a portion of fish , the price of a portion of chip , and the price of a portion of ketchup .
we're go to start with guess for these price and then we're go to adjust the guess slightli , so that we agre better with what the cashier sai .
so let's suppos that the true weight that the cashier us to figur out the price , ar <num> for a portion of fish , <num> for portion of chip and a <num> for a portion of ketchup .
for the meal shown here , that will lead to a price of <num> .
so that's go to be our target valu .
that suppos that we start with guess , but each portion cost <num> .
so for the meal with two portion of fish , five of chip , and three of ketchup , we're go to initi think that the price should be <num> .
that give us a residu error of <num> .
the residu error is the differ between what the cashier sai and what we think the price should be with our current weight .
we're then gonna us the delta rule for revis our price of portion .
we make the chang in a weight , delta wi be equal to a learn rate , epsilon time the number of portion of the i th thing , time the residu error .
the differ between the target and our estim .
so if we make the learn rate be on over <num> , so the math stai simpl , then the learn rate time the residu error for thi particular exampl is ten .
and so , our chang in the weight for fish will be two time ten .
we'll increas that weight by twenti .
our chang in the weight for chip will be five time ten .
and our chang in the weight for ketchup will be three time ten .
that'll give us new weight of <num> , <num> , and <num> .
and notic , the weight for chip actual got wors .
there's no guarante with thi kind of learn that the individu weight will keep get better .
what's get better is the differ between what the cashier sai and our estim .
so now , we're go to deriv the delta rule .
we start by defin the arrow measur , which is simpli our squar residu sum over all train case .
that is the squar differ between the target and what the neural net predict .
or the linear neuron predict .
squar , in some liber train case .
and we put a on half in front , which will cancel the two , when we differenti .
we now differenti that error measur with respect to on of the weight , wi .
to do that differenti we need to us the chain rule .
the chain rule sai that how the error chang as we chang a weight , will be how the output chang as we chang the weight , time how the error chang as we chang the output .
the chain rule is easi to rememb , you just cancel those two dy but you can onli do that when there's no mathematician look .
the reason the first on , dy by dw is written with a curli d is becaus it's a partial deriv .
that is , there's mani differ weight you can chang to chang the output .
and here , we're just consid the chang to weight i .
so , dy by dwi , is actual equal to xi , and that's becaus y is just wi time xi , and de by dy , is just t minu y , becaus when we differenti that t minu y squar , and us the half to cancel the two we just get t minu y .
so our learn rule is now , we chang the weight by an amount that's equal to the learn rate epsilon time the deriv of the error with respect to a weight , to e by dwi .
and with a minu sign in front cuz we want the error to go down .
and that minu sign cancel the minu sign in the line abov and we get that .
the chang in a weight is the sum of all train case of the learn rate time the input valu time the differ between the target and actual output .
now we can ask how doe thi learn procedur , thi delta rule , behav ?
doe thi , for exampl , eventu get the right answer ?
there mai be no perfect answer .
it mai be that we give the linear neuron a bunch of train case with desir answer .
and there's no set of weight that'll give the desir answer .
there's still some set of weight that get the best approxim on all those train case , minim that error measur .
some that ar all train case .
and if we make the learn rate small enough and we learn for long enough , we can get as close as we like to that best answer .
anoth question is , how quickli do we get toward the best answer .
and even for a linear system .
the learn can be quit slow in thi kind of intric learn .
if two input dimens ar highli correl , it veri hard to tell how much of the sum of the weight on both input dimens should be attribut to each input dimens .
so if for exampl , you alwai get the same number of portion of ketchup and chip is , we can't decid how much of the price is due to the ketchup and how much is us to the chip .
and if thei're almost alwai the same , it can take a long time for the learn to correctli attribut the price to the ketchup and the chip .
there's an interest relationship between the delta rule and the learn rule for perceptron .
so , if you , you us the onlin version of the delta rule , but we chang the weight after each train case , it's quit similar to the perceptron learn rule .
in perceptron learn , we increment or decrement the weight vector by the input vector , but we onli chang the input vector when we make an error .
in the onlin version of the delta rule , we increment or decrement the weight vector by the imperfector .
but we scale that by both the residu error and the learn rate .
and on annoi thing about thi is we have to choos a learn rate .
if we choos a learn rate that's too big , the system will be unstabl .
in thi video we're go to look at the error surfac for a linear neuron .
by understand the shape of thi error surfac , we can understand a lot about what happen as a linear neuron is learn .
we can get a nice geometr understand of what's happen when we learn the weight of a linear neuron .
by consid a space that's veri like the weight space that we us to understand perceptron , but it ha on extra dimens .
so we imagin a space in which all the horizont dimens correspond to the weight .
and there's on vertic dimens that correspond to the error .
so in thi space , point on the horizont plane , correspond to differ set of the weight .
and the height correspond to the error that your make with that set of weight , sum over all train case .
for a linear neuron , the error you make for each set of weight defin error surfac .
and thi error surfac is a quadrat bowl .
that is , if you take a vertic cross section , it's alwai a parabola .
and if you take a horizont cross section , it's alwai an ellips .
thi is onli true for linear system with a squar error .
as soon as we go to a multilay nonlinear neuron net , thi error surfac will get more complic .
as long as the weight aren't too big , the error surfac will still be smooth , but it mai have mani local minimum .
us thi error surfac we can get a pictur of what's happen as we do gradient descent learn us the delta rule .
so what the delta rule doe is it comput the deriv of the error with respect to the weight .
and if you chang the weight in proport to that deriv , that's equival to do steepest descent on the error surfac .
to put it anoth wai , if we look at the error surfac from abov , we get ellipt contour line .
and the delta rule is gonna take it at right angl to those ellipt contour line , as shown in the pictur .
that's what happen with what's call batch learn , where we get the grai in , sum overal train case .
but we could also do onlin learn , where after each train case , we chang the weight in proport to the gradient for that singl train case .
that's much more like what we do in perceptron .
and , as you can see , the chang in the weight move us toward on of these constraint plane .
so in the pictur on the right , there ar two train case .
to get the first train case correct , we must lie on on of those blue line .
and to get the second train case correct , the two weight must lie on the other blue line .
so if we start at on of those red point , and we comput the gradient on the first train case , the delta rule will move us perpendicularli toward that line .
if we then consid the other train case , we'll move perpendicularli toward the other line .
and if we altern between the two train case , we'll zigzag backward and forward , move toward the solut point which is where those two line intersect .
that's the set of weight that is correct for both train case .
us thi pictur of the error surfac , we can also understand the condit it will make learn veri slow .
if that ellips is veri elong , which is gonna happen if the line that correspond to train case is almost parallel , then when we look at the gradient , it's go to have a nasti properti .
if you look at the red arrow in the pictur , the gradient is big in the direct in which we don't want to move veri far , and it's small in the direct in which we want to move a long wai .
so the gradient will quickli take us across the bottom of that ravin .
correspond to the narrow axi of the ellips .
and will take a long time to take us along the ravin , correspond to the long xs of the ellips .
it's just the opposit of what we want .
we'd like to get a great into a small across the ravin , and big along the ravin but that's not what we get .
and so , simpl steepest descent , in which you chang each weight in proport to a learn rate time the error deriv , is gonna have great difficulti , with veri elong surfac like the on shown in the pictur .
to extend the learn rule for a linear neuron to a learn rule we can us for multilay net of nonlinear neuron , we need two step .
first , we need to extend the learn rule to a singl nonlinear neuron .
and we're go to us logist neuron , although mani other kind of nonlinear neuron could be us instead .
we're now go to gener the learn rule for a linear neuron to a logist neuron , which is a non linear neuron .
so , a logist neuron , comput it logic , z , which is it total input , it , it bia plu the sum over all it input line of the valu of , on an input line xi time the weight on that line , wi .
it then give an output y that's a smooth nonlinear function of that logit .
as shown in the graph here , that function is approxim zero when z is big and neg , approxim on when z is big and posit , and in bet , in between , it chang smoothli and nonlinearli .
the fact that it chang continu give it nice deriv , which make learn easi .
so to get the deriv of a logist neuron with respect to the weight , which is what we need for learn , we first need to comput the deriv of the logit itself , that is the total input with respect to our weight , that's veri simpl .
the logit is just a bia plu the sum of all the input line of the failur on the input line time the weight .
so , when we differenti with respect to wi , we just get xi .
so , the deriv of the logit with respect to wi is xi , and similarli , the deriv of the logit with respect to xi is wi .
the deriv of the output with respect to the logic is also simpl if you express it term of the output .
so , the output is on on e z .
and dy by dz is just y into on y .
that's not obviou .
for those of you who like to see the math , i've put it on the next slide .
the math is tediou but perfectli straightforward so you can go through it by yourself .
now , we've got the deriv , the output with respect to the logic and the deriv , the logit with respect to the weight , we can start to figur out the deriv , the output with respect to the weight .
we just us the chain rule again .
so , dy by dw is dz by dw time dy by dz .
and dz by dw , as we just saw , is xi , dy by dz is y into on minu y .
and so , we now have the learn row for a logist neuron .
we've got dy by dw , and all we need to do is us the chain rule onc more , and multipli it by de by dy .
and we get someth that look veri like the delta rule .
so , the wai the arrow chang is we chang the weight , de by dwi , is just the sum of all the row of train case and of the valu on input line xin time the residu , the differ between the target and the output , on the actual output of the neuron .
but it's got thi extra term in it , which come from the slope of the logist function , which is yn into on yn .
so , a slight modif of the delta rule give us the gradiant decent learn rule for train a logist unit .
now that we have the preliminari out the wai , we can get back to the central issu , which is how to learn multipl layer of featur .
so in thi video , i'm final go to describ the back propag algorithm which wa the main advanc in the 1980s that led to an explos of interest in neural network .
befor i describ back propag , i'm go to describ anoth veri obviou algorithm that doe not work nearli as well , but is someth that mani peopl think of .
now that we know how to learn the weight of the logist unit , we're go to return to the central issu , which is how to learn the weight of hidden unit .
if you have neural network without hidden unit , thei ar veri limit in the map thei can model .
if you add a layer of hand code featur as in a perceptron , you make the net much more power but the difficult bit for a new task is design the featur .
the learn won't solv the hard problem ; you have to solv it by hand .
what we'd like is a wai of find good featur without requir insight into the task or repeat trial and error , where we guess some featur and see how well thei work .
in effect , what we need to do is autom the loop of design featur for a task and see how well thei work .
we'd like the comput to do that loop , instead of have a person in that loop .
so the thing that occur to everybodi who know about evolut is to learn by perturb the weight .
you randomli perturb on weight .
so that's meant to be like a mutat , and you see if it improv perform .
and if it improv perform of the net , you save that chang in the weight .
you can think of thi as a form of reinforc learn .
your action consist of make a small chang .
and then you check whether that pai off , and if it doe , you decid to perform that action .
the problem is it's veri ineffici .
just to decid whether to chang on weight , we need to do multipl forward pass on a repres set of train case .
we have to see if chang that weight improv thing , and you can't judg that by on train case alon .
rel to thi method of randomli chang weight , and see if it help , back propag is much more effici .
it's actual more effici by a factor of the number of weight in the network , which could be million .
an addit problem with randomli chang weight and see if it help is that toward the end of learn , ani larg chang in weight will nearli alwai make thing wors , becaus the weight have to have the right rel valu to work properli .
so toward the end of learn not onli do you have to do a lot of work to decid whether each of these chang help but the chang themselv have to be veri small .
there ar slightli better wai of us perturb in order to learn .
on thing we might try is to perturb all the weight in parallel and then correl the perform gain with the weight chang .
that actual doesn't realli help at all .
the problem is that we need to do lot and lot of trial with differ random perturb of all the weight , in order to see the effect of chang on weight , through the nois creat by chang all the other weight .
so it doesn't help to do it all in parallel .
someth that doe help , is to randomli perturb the activ of the hidden unit , instead of perturb the weight .
onc you've decid that perturb the activ of a hidden unit on a particular train case is go to make thing better .
you can then comput how to chang the weight .
sinc there's mani fewer activ than weight , there's less thing that you're randomli explor .
and thi make the algorithm more effici .
but it's still much less effici than backpropag .
backpropag still win by a factor of the number of neuron .
so the idea behind back propag is that we don't know what the hidden unit ought to be do .
thei're call hidden unit becaus nobodi's tell us what their state ought to be .
but we can comput how fast the error chang as we chang a hidden activ on a particular train case .
so instead of us activ of the hidden unit as our desir state , we us the error deriv with respect to our activ .
sinc each hidden unit can affect mani differ output unit , it can have mani differ effect on the overal error if we have mani output unit .
these affect have to be combin .
and we can do that effici .
so that allow us to comput error deriv for all of the hidden unit effici at the same time .
onc we've got those error deriv for the hidden unit , that is , we know how fast the error chang as we chang the hidden activ on that particular train case , it's easi to convert those error deriv for the activ into error deriv for the weight come into a hidden unit .
so here's a sketch of how backpropag work , for a singl train case .
first we have to defin the error , and here we'll us the error be the squar differ between the target valu of the output unit j and the actual valu that the net produc for the output unit j .
and we're gonna imagin there ar sever output unit in thi case .
we differenti that , and we get a familiar express for how the error chang as you chang the activ of an output unit j .
and i'll us a notat here where the index on a unit will tell you which layer it's in .
so the output layer ha a typic index of j , and the layer in front of that , the hidden layer below it in the diagram , will have a typic index of i .
and i won't bother to sai which layer we're in becaus the index will tell you .
so onc we've got the aeroderiv with respect to the output of on of these output unit , we then want to us all those aeroderiv in the output layer to comput the same quantiti in the hidden layer that come befor the output layer .
so back propag , the core of back propag is take error deriv in on layer and from them comput the error deriv in the layer that come befor that .
so we want to comput de by dy , i .
now obvious , when we chang the output of unit i , it'll chang the activ of all three of those output unit , and so we have to sum up all those effect .
so we're go to have an algorithm that take error deriv we've alreadi comput for the top layer here .
and combin them us the same weight as we us in the forward pass to get error deriv in the layer below .
so , thi slide is go to explain the backpropag algorithm .
and you realli need to understand thi slide .
and the first time you see it , you mai have to studi it for a long time .
thi is how you backpropag the error deriv with respect to the output of a unit .
so we'll consid an output unit j on a hidden unit i .
the output of the hidden unit i will be yi .
the output of the output unit j will be yj .
and the total input receiv by the output unit j will be zj .
the first thing we need to do is convert the error deriv with respect to y j , into an error deriv with respect to z j .
to do that we us the chain rule .
so we sai de by dzj , equal dyj by dzj , time de by dyj .
and af , as we've seen befor , when we were look at logist unit , that's just yj into on minu yj time the error deriv with respect to the output of unit j .
so now we've got the error deriv with respect to the total input receiv by unit j .
now we can comput the error deriv with respect to the output of unit i .
it's go to be the sum over all of the three outgo connect of unit i , of thi quantiti , dzj by dyi time de by dzj .
so the first term there is how the total input to unit j chang as we chang the output of unit i .
and then we have to multipli that by how the error root of chang as we chang the total input to unit j which we comput on the line abov .
and as we saw befor when studi the logist unit dzj by dyi is just the weight on the connect wij .
so what we get is that the error deriv .
we respect to the output of unit i is the sum over all the outgo connect to the layer abov of the weight wij on that connect time a quantiti we would have alreadi comput which is de by dzj for the layer abov .
and so you can see the comput look veri like what we do on the forward pass , but we're go in the other direct .
what we do for each unit in that hidden layer that contain i , is we comput the sum of a quantiti in the layer abov the weight on the connect .
onc we've got to e by dzj , which we comput on the first line here , it's veri easi to get the error deriv for all the weight come into unit j .
to e by dwij is simpli d , e , by dzj , which we comput alreadi , time how zj chang .
as we chang the weight on the connect .
and that's simpli the activ of the unit in the layer below yi .
so the rule for chang the weight is just you multipli , thi quantiti you've comput at a unit , to e by dzj , by the activ come in from the layer below .
and that give you the error of deriv with respect to weight .
so on thi slide we have seen how we can stop with de by dyj and back propag to get de by dyi we'll come backward through on layer and comput the same quantiti the deriv of the error with respect to the output in the previou layer .
so we can clearli do that for as mani layer as we like .
and after we've done that for all these layer , we can comput how the error chang as you chang the weight on the connect .
that's the backpropag algorithm .
it's an algorithm for take on train case , and comput , effici , for everi weight in the network , how the error will chang as , on that particular train case , as you chang the weight .
figur out how to get the error deriv for all of the weight in a multilay network is the kei to be abl to learn effici neural network .
but there ar a number of other issu that have to be address befor we actual get a learn procedur that's fulli specifi .
for exampl , we need to decid how often to updat the weight .
and we need to decid how to prevent the network from over fit veri badli if we us a larg network .
the back propag algorithm is an effici wai to comput the deriv with respect to each weight of the error for a singl train case .
but that's not a learn algorithm .
you have to specifi a number of other thing to get a proper learn procedur .
we need to make lot of other decis .
some of these decis ar about how we're go to optim , that is how we're go to us the other deriv on the individu case , to discov good set of weight .
those will be describ in detail in lectur six .
anoth set of issu is how do we ensur that the weight that we've learn will gener well , that is how do we make sure thei work on case that we didn't see dure train and lectur seven will be devot to that issu .
what i'm go to do now is give you a veri brief overview of these two set of issu .
so , optim issu ar about how you us the weight deriv .
the first question is how often should you updat the weight ?
we could try out date the weight after each train case .
so , you comput the error deriv on a train case us back propag and then , you make a small chang to the weight .
obvious , thi is go to zigzag around cuz on each train case , you'll get differ error deriv .
but on averag , if we make the weight chang small enough , it'll go in the right direct .
what seem more sensibl is to us full batch train , where you do a full sweep through all of the train data , you add togeth all of the error deriv you get on the individu case , and then you take a small step in that direct .
a problem with thi is that we start off with a bad set of weight , and we might have a veri big train set .
and we don't want to do all that work of go through the whole train set in order to fix up some weight that we know ar pretti bad .
realli , we onli need to look at a few train case befor we get a reason idea of what direct we want to move the weight in .
and we don't need to look at a larg number of train case until we get toward the end of learn .
so , that give us mini batch learn , where we take a small random sampl of the train case and we go in that direct .
we'll do a littl bit of zigzag , not nearli as much zigzag as if we did onlin where we us on train case at a time .
and mini batch learn is what peopl typic do when thei're train big neural network on big data set .
then there's the issu of how much we updat the weight .
how big a chang we make .
so , we could just by hand try and pick some fix learn rate and then learn the weight by chang each weight by the deriv that we've comput time that learn rate .
it seem more sensibl to actual adapt the learn rate .
we could get the comput to adapt it by , if we're oscil around , if the error keep go up and down , then we'll reduc the learn rate .
but if we're make steadi progress , we might increas the learn rate .
we might even have a separ learn rate for each connect in the network , so that some weight learn rapidli and other weight learn more slowli , or we might go even further and sai , we don't realli want to go in the direct of steepest decent at all .
if you look at the figur on the right , when we had a veri elong ellips , the direct of steepest decent is almost at right angl to the direct to the minimum that we want to find .
and thi is typic particularli toward the end of learn of most learn problem .
so , there ar much better direct to go in than the direct of steepest decent .
the problem is , it's quit hard to figur out what thei ar .
the second set of issu is to do with how well the network gener the case it didn't see dure train .
and the problem here is that the train data contain inform about the regular in the map from input to output , but it also contain two type of nois .
the first type of nois is that the target valu mai be unreli .
and from neural network , that's usual onli a minor worri .
the second type of nois is that the sampl error .
if we take ani particular train set , especi if it's a small on , there will be accid irregular that ar caus by the particular case that we chose .
so , for exampl , if you show someon some polygon , if you're a bad teacher , you might choos to show them a squar and a rectangl .
those ar both polygon , but there's no wai for someon to realiz from that , that polygon might have three side or seven side .
there's no wai for them to understand that the angl don't have to be right angl .
if you're a slightli better teacher , you might show them a triangl and a hexagon .
but again , from that , thei can't tell whether polygon ar alwai convex , and thei can't tell whether the angl in polygon ar alwai multipl of <num> degre .
and , howev carefulli , you choos exampl .
for ani finit set of exampl , there'll be accident regular .
now , when we fit a model , there's no wai it can tell the differ between an accid regular that's just there becaus of the particular sampl we chose and a real regular that's , that we'll gener properli to new case .
so , what the model will do is it will fit both kind of regular .
and if you've got a big power model , it'll be veri good at fit the sampl error , band that will be a real disast .
that will caus it to gener realli badli .
thi is best understood by look at a littl exampl .
so here , we've got six data point shown in black , and we can fit a straight line to them , but the model ha two degre of freedom and it's fit the six y valu , given the six x valu , or we can fit a polynomi that ha six degre of freedom .
ad by hand , i've drawn in red , my idea of a polynomi with six degre of freedom fit thi data .
and you'll see the polynomi goe through the data point exactli and so it's a much better fit to the data .
but which model do you trust ?
the complic model certainli fit the data much better .
but it's not econom .
for a model to be convinc , what you want it to do is be a simpl model that explain a lot of data surprisingli well .
and the polynomi doesn't do that .
it explain these six data point , but it's got six degre of freedom .
so , wherev these data point were , it won't be abl to explain them .
we're not surpris that the model as complic can fit that data veri well and it doesn't convinc us that thi is a good model .
so , if you look at the arrow , which output valu do you predict for thi input valu ?
well , you'd have to have a lot of faith in the polynomi model in order to predict a valu that's outsid the rang of valu in all of the train data you've seen so far .
and i think almost everybodi would prefer to predict the blue circl that's on the green line rather than the on on the red line .
howev , if we had ten time as much data , and all of these data point lai veri close to the red line , then we would certainli prefer the red line .
there's a number of wai to reduc over fit that have been develop for neural network and for mani other model , and i'm go to give just a brief survei of them here .
there's weight decai where you try and keep the weight of the network small , or try and keep mani of the weight at zero .
and the idea of thi is that it will make the model simpler .
it's weight share , where again , you make the model simpler , by insist that mani of the weight have the exactli same valu as each other .
you don't know what the valu is and you're go to learn it .
but it ha to be exactli the same for mani of the weight .
we'll see that in the next lectur , how weight share is us .
there's earli stop , where you make yourself a fake test set .
and as you're train the net , you peek at what's happen on thi fake test set .
and onc the perform on the fake test set start get wors , you stop train .
thi model averag where you train not so differ neural on that , and you averag them togeth in the hope that , that will reduc the error you're make , those bayesian fit of your own ey , which is just a fanci form of model averag , is drop out but you try and make your model more robust by randomli emit hidden unit when you're train it .
and thi gener pretrain which ar somewhat more complic and i'll describ toward the end of the cours .
the next few video ar about us the back propag algorithm to learn a featur represent of the mean of the word .
i'm gonna start with a veri simpl case from the 1980s , when comput were veri slow .
it's a small case , but it illustr the idea about how you can take some relat inform , and us the back propag algorithm to turn relat inform into featur vector that captur the mean of word .
thi diagram show a simpl famili tree , in which , for exampl , christoph and penelop marri , and have children arthur and victoria .
what we'd like is to train a neural network to understand the inform in thi famili tree .
we've also given it anoth famili tree of italian peopl which ha pretti much the same structur as the english tree .
and perhap when it tri to learn both set of fact , the neural net is go to be abl to take advantag of that analog .
the inform in these famili tree can be express as a set of proposit .
if we make up name for the relationship depict by the tree .
so we're gonna us the relationship son daughter , nephew niec , father mother , uncl aunt , brother sister and husband wife .
and us those relationship we can write down a set of tripl such as , colleen ha father jame , colleen ha mother victoria and jame ha wife victoria .
and in the nice simpl famili depict in the diagram , the third proposit follow from the previou two .
similarli , the third proposit in the next set follow from the previou two .
so the relat learn task , that is , the task of learn the inform in those famili tree , can be view as figur out the regular in a larg set of tripl that express the inform in those tree .
now the obviou wai to express irregular is as symbol rule .
for exampl , x ha mother y , and y ha husband z , impli x ha father z .
we could search for such rule , but thi would involv a search through quit a larg space , a combinatori larg space , of discret possibl .
a veri differ wai to try and captur the same inform is to us a neural network that search through a continu space of real valu weight to try and captur the inform .
and the wai it's go to do that is we're go to sai it's captur the inform if it can predict the third termin tripl from the first two term .
so at the bottom of thi diagram here , we're go to put in a person and a relationship and the inform is go to flow forward through thi neural network .
and what we ar go to try to get out of the neural network after it's learn is the person who's relat to the first person by that relationship .
the architectur of thi net wa design by hand , that is i decid how mani layer it should have .
and i also decid where to put bottl neck to forc it to learn interest represent .
so what we do is we encod the inform in a neutral wai , becaus there ar <num> possibl peopl .
so the block at the bottom of the diagram that sai , local encod of person on , ha <num> neuron , and exactli on of those will be turn on for each train case .
similarli there ar twelv relationship .
and exactli on of the relationship unit will be turn on .
and then for a relationship that ha a uniqu answer , we would like on of the <num> peopl at the top , on of the <num> output peopl to turn on to repres the answer .
by us a represent in which exactli on of the neuron is on , we don't accident give the network ani similar between peopl .
all pair of peopl ar equal dissimilar .
so , we're not cheat by give the network inform about who's like who .
the peopl , as far as the network is concern , ar uninterpret symbol .
but now in the next layer of the network , we've taken the local encod of person on , and we've connect it to a small set of neuron , actual six neuron for thi .
and becaus there ar <num> peopl , it can't possibl dedic on neuron to each person .
it ha to re repres the peopl as pattern of activ over those six neuron .
and what we're hope is that when it learn these proposit , the wai in which thing encod a person , in that distribut panel activ .
will reveal structur the task , or structur the domain .
so what we're go to do is we're go to train it up on <num> of these proposit .
and we go through the <num> proposit mani time .
slowli chang the weight as we go , us back propag .
and after train we're gonna look at the six unit in that layer that sai distribut encod of person on to see what thei ar do .
so here ar those six unit as the big grai block .
and i laid out the <num> peopl , with the twelv english peopl in a row along the top , and the twelv italian peopl in a row underneath .
so each of these block you'll see , ha <num> blob in it .
and the blob tell you the incom weight for on of the hidden unit in that layer .
so go back to the previou slide .
if you look at that layer that sai distribut and code of person on .
there ar six neuron there .
and we're look at the incom weight of each of those six neuron .
if you look at the big grai rectangl on the top right , you'll see an interest structur to the weight .
the weight along the top that come from english peopl ar all posit .
and the weight along the bottom ar all neg .
that mean thi unit tell you whether the input person is english or italian .
we never gave it that inform explicitli .
but obvious , it's us inform to have in thi veri simpl world .
becaus in the famili tree that we're learn about , if the input person is english , the output person is alwai english .
and so just know that someon's english alreadi allow you to predict on bit of inform about the output .
which is accord to sai it halv the number of possibl .
if you look at the grai blob immedi below that , the second on down on the right , you'll see that it ha four big posit weight at the begin .
those correspond to christoph and andrew with our italian equival .
then it ha some smaller weight .
then it ha two big neg weight , that correspond to collin , or hi italian equival .
then there's four more big posit weight , correspond to penelop or christina , or their italian equival .
and right at the end , there's two big neg weight , correspond to charlott , or her italian equival .
by now you've probabl realiz that , that neuron repres what gener somebodi is .
it ha big posit weight to the oldest gener , big neg weight to the youngest gener , and intermedi weight which ar roughli zero to the intermedi gener .
so that's realli a three valu featur , and it's tell you the gener of the person .
final , if you look at the bottom grai rectangl on the left hand side , you'll see that ha a differ structur , and if we look at the top row and we look at the neg weight in the top row of that unit .
it ha a neg weight to andrew , jame , charl , christin and jennif and now if you look at the english famili tree you'll see andrew , jame , charl , christin , and jennif ar all in the right hand branch of the famili tree .
so that unit ha learn to repres which branch of the famili tree someon is in .
again , that's a veri us featur to have for predict the output person , becaus if you know it's a close famili relationship , you expect the output to be in the same branch of the famili tree as the input .
so the network in the bottleneck have learn to repres featur of peopl that ar us for predict the answer .
and notic , we didn't tell it anyth about what featur to us .
we never mention thing like nation or brunch or famili tree or gener .
it figur out that those ar good featur for express the regular in thi domain .
of cours , those featur ar onli us if the other bottleneck , the on for relationship , and the on near the top of the network befor the output person , us similar represent .
and the central layer is abl to sai how the featur of the input person and the featur of the relationship predict the featur of the output person .
so for exampl if the input person is a gener three , and the relationship requir the output person to be on gener up , then the output person is a gener two .
but notic to captur that rule , you have to extract appropri featur at the first hidden layer , and the last hidden layer of the network .
and you have to make the unit in the middl , relat those featur correctli .
anoth wai to see that the network work , is to train it on all but a few of the tripl .
and see if it can complet those tripl correctli .
so doe it gener ?
so there's <num> tripl , and i train it on <num> of them and test it on the remain four , i did that sever time and it got either two or three of those right .
that's not so bad for a <num> wai choic , so it's true it make mistak , but it didn't have much train data , there's not enough tripl in thi domain to realli nail down the regular veri well .
and it doe much better than chanc .
if you train it on a much bigger data set , it can gener from a much smaller fraction of the data .
so if you have thousand and thousand of relationship you onli need to show a small percentag befor it can start guess the other on correctli .
that research wa done in the 1980s , and wa a wai of show that back propag could learn interest featur .
and it wa a toi exampl .
now we have much bigger comput , and we have databas of million of relat fact .
mani of which of the form a , r , b , a ha relationship r to b , we could imagin train a net to discov featur vector represent of a and r , that allow it to predict the featur vector represent of b .
if we did that , it would be a veri good wai of clean a databas .
it wouldn't necessarili be abl to make perfect predict .
but it could find thing in the databas that it thought were highli implaus .
so if the databas contain inform , like , for exampl , bach wa born in <num> .
it could probabl realiz that wa wrong , 'cuz bach's a much older kind of person , and everyth els he's relat to is much older than <num> .
instead of actual us the first two term to predict the third term , we could us the whole set of term , three of them in thi case , but possibl more , and predict the probabl that the fact is correct .
to train a net to do that , we'd need exampl of a whole bunch of correct fact , and we'd ask it to give a high output .
we'd also need a good sourc of incorrect fact , and we'd ask it to give a low output when we're told it wa someth that wa fals .
we're now go to talk a littl bit about an issu that's of interest accord to scientist , but mai not be of much interest to engin .
so if you're an engin you can just ignor thi video .
in comput scienc , there's been a debat go on for mayb a <num> year about the relationship between featur vector represent of concept and represent of concept by their relat to other concept .
and the learn algorithm we've just seen for famili tree ha a lot to sai about that debat .
we're now go to make a brief divers into cognit scienc .
there's been a long debat between two rival theori of what it mean to have a concept .
the featur sai a concept is a big set of semant featur .
thi is good for explain similar between concept .
and it's conveni for thing like machin learn .
becaus we like to deal with vector of activ .
the structuralist theori sai that the mean of a concept li in it relationship to other concept .
so conceptu knowledg is best express not as a big vector , but as a relat graph .
in the earli 1970s , marvin minski us the limit of perceptron as evid against featur actor in favor of relat graph represent .
my belief is that both side in thi debat ar wrong becaus both side believ that the two theori ar rival and thei're not rival at all .
a neural net can us vector of semant featur to implement a relat graph .
in the neural network that learn famili tree , we can think of explicit infer as i give you person on and i give you a relationship then you tell me person two .
and to arriv at that conclus , the neural net doesn't follow a whole bunch of rule of infer .
it just pass inform forward through the net .
as far as the neural net is concern , the answer is intuit obviou .
now if you look at the detail of what's happen , there's lot of probabilist featur that ar influenc each other .
we call these microfeatur to sort of emphas thei're not like explicit consciou featur .
in a real brain , there might be million of them and million of interact , and as a result of all these interact , we can make on step of explicit infer .
and that's what we believ is involv in just see the answer to someth .
there ar no interven consciou step , but nevertheless there's a lot of comput go on in the interact of neuron .
so we mai us explicit rule for consciou deliber reason , but a lot of our common sens reason , particularli analog reason , work by just see the answer , with no consciou interven step .
and even when we do consciou reason , we have to have some wai of just see which rule appli , in order to avoid an infinit regress .
so , mani peopl , when thei think about implement a relat graph in a neural net , just assum that you should make a neuron correspond to a node in the relat graph and a connect between , two neuron correspond to a binari relationship .
but thi method doesn't work .
for a start , the relationship come in differ flavor .
thei're ar differ kind of relationship .
like mother of , or aunt of and , a connect in a neural net onli ha a strength .
it doesn't come in differ type .
also we need to do we turn around your relationship like'a' is between'b' and'c' .
we still don't know for sure the right wai to implement relat knowledg in a neural net .
but it seem veri probabl that mani neuron ar us for repres each of the concept we know , and each of those neuron is probabl involv in deal with mani differ concept .
thi is call a distribut represent .
it's a mani to mani map between concept and neuron .
in thi video , we're go to look at the soft max output function .
thi is a wai of forc the output of a neural network to sum to on so thei can repres a probabl distribut across discreet mutual exclus altern .
befor we get back to the issu of how we learn featur vector to repres word , we're gonna have on more digress , thi time it's a technic divers .
so far i talk about us a squar area measur for train a neural net and for linear neuron it's a sensibl thing to do .
but the squar error measur ha some drawback .
if for exampl the design acuiti ar on , so you have a target of on , and the actual output of a neuron is on billionth , then there's almost no gradient to allow a logist unit to chang .
it's wai out on a plateau where the slope is almost exactli horizant .
and so , it will take a veri , veri long time to chang it weight , even though it's make almost as big an error as it's possibl to make .
also , if we're try to assign probabl to mutual exclus class label , we know that the output should sum to on .
ani answer in which we sai , the probabl thi is a is three quarter and the probabl that it's a b is also three quarter is just a crazi answer .
and we ought to tell the network that inform , we shouldn't depriv it of the knowledg that these ar mutual exclus answer .
so the question is , is there a differ cost function that will work better ?
is there a wai of tell it that these ar mutual exclus and then us a , an appropri cost function ?
the answer , of cours is , that there is .
what we need to do is forc the output of the neural net to repres a probabl distribut across discret altern , if that's what we plan to us them for .
the wai we do thi is by us someth call a soft max .
it's a kind of soft continu version of the maximum function .
so the wai the unit in a soft max group work is that thei each receiv some total input thei've accumul from the layer below .
that's zi for the i th unit , and that's call the logit .
and then thei give an output yi that doesn't just depend on their own zi .
it depend on the zs accumul by their rival as well .
so we sai that the output of the i th neuron is e to the zi divid by the sum of that same quantiti for all the differ neuron in the softmax group .
and becaus the bottom line of that equat is the sum of the top line over all possibl , we know that when you add over all possibl you'll get on .
that is , the sum of all the yi's must come to on .
what's more , the yi's have to lie between zero and on .
so we forc the yi to repres a probabl distribut over mutual exclus altern just by us that soft max equat .
the soft max equat ha a nice simpl deriv .
if you ask about how the yi chang as you chang the zi , that obvious depend on , all the other zs .
but then the yi itself depend on all the other zs .
and it turn out , that you get a nice simpl form , just like you do for the majest unit , where the deriv of the output with respect to the input , for an individu neuron in a softmax group , is just yi time on minu yi .
it's not total trivial to deriv that .
if you tri differenti the equat abov , you must rememb that thing turn up in that normal term on the bottom row .
it's veri easi to forget those term and get the wrong answer .
now the question is , if we're us a soft max group for the output , what's the right cost function ?
and the answer , as usual , is that the most appropri cost function is the neg log probabl of the correct answer .
that is , we want to maxim the log probabl of get the answer right .
so if on of the target valu is a on and the remain on ar zero , then we simpli sum of all possibl answer .
we put zero in front of all the wrong answer .
and we put on in front of the right answer and that get us the neg log probabl of the correct answer , as you can see in the equat .
that's call the cross entropi cost function .
it ha a nice properti that it ha a veri big gradient when the target valu is on and the output is almost zero .
you can see that by consid a coupl of case .
so valu of on in a million is much better than a valu of on in a billion , even though it differ by less than a millionth .
so when you make the output valu , you increas by less than on millionth .
the valu of c improv by a lot .
that mean it's a veri , veri steep gradient for c .
on wai of see why a valu of on in a million is much better than a valu of on in a billion , if the correct answer is on is that if you believ the on in a million , you'd be will to bet but odd of on in a million , then you'd lose on million .
if you thought the answer wa on in a on billion you'd , you'd lose on billion make the same bet .
so we get a nice properti that .
that cost function , c ha a veri steep deriv when the answer is veri wrong and that exactli bounc the fact that the wai which the advert chang is to chang the import , the y or the z is veri flat when the onc is veri wrong .
and when you multipli the two togeth to get the deriv of cross entropi with respect to the logic go into i put unit i .
you us the chain rule so that deriv is how fast the cost function chang as you chang the output of the unit time how fast the output of the unit chang as you chang zi .
and notic we need to add up across all the js , becaus when you chang the i , the output of all the differ unit chang .
the result is just the actual output minu the target output .
and you can see that when the actual target output ar veri differ , that ha a slope of on or on .
and the slope is never bigger than on or on .
but the slope never get small until the two thing ar pretti much the same .
in other word , you're get pretti much the right answer .
in thi video , we're go to look at a practic us for featur vector that repres word .
the us in speech recognit system , where have a good idea of what somebodi might sai next is veri help in recogn the sound thei make .
we're now go to see an import practic us for featur factor that describ word .
when we're try to do speech recognit , it's imposs to identifi phonem perfectli in noisi speech .
the acoust input just isn't good enough .
it's often ambigu .
there mai be sever differ word that fit the acoust signal equal well .
we don't notic thi a lot of the time , becaus we're so good at us the mean of the utter to hear the right word .
so if i read the next comment on the slide , i would sai we do thi unconsci when we recogn beach .
and you would hear , we do thi unconsci when we recogn speech .
you can actual hear the slight differ between recogn beach and recogn speech .
but if you're expect recogn speech , particularli if there's nois around you wouldn't hear recogn beach .
okai .
so we're veri good at do thi .
we do it all the time when we do it unconsci .
that mean that speech recogn have to know which word ar like to come next and which ar not .
fortun .
word can be predict quit well without have a full understand of what's be said .
so there's a standard method for predict the probabl of the variou word that might come next , it's call the trigram method .
you take a huge amount of text and you count the frequenc of all tripl of word .
then you us these frequenc to make bet on the rel probabl of the next word given the previou two word .
so if we've heard the word a and b .
we can look at the count that we have in our huge bodi of text .
for the sequenc abc , and the sequenc abd , we can sai that the rel probabl that the third word will be c versu the third word will be d , is given by the ratio of the two count .
abc and abd .
until veri recent , thi wa the state of the art method for get the probabl of the next word to help out the speech recogn .
we can't us much bigger context than two previou word , becaus there ar just too mani possibl to store , and if we did us bigger context , the count would be mostli zero .
even for two word context there's mani context that you will never have heard .
for exampl , if i sai dinosaur pizza , that's probabl a string of two word that you've never heard befor .
for case like that , we have to back off to individu word .
so , after dinosaur pizza , you predict the next word by just see what's like to come after the word pizza , becaus you've never heard dinosaur pizza befor .
what you mustn't do is to sai that probabl's a zero just becaus you haven't seen an exampl .
that's clearli not true .
now the trigram model fail to us a lot of obviou inform that will help you predict the next word .
suppos for exampl , you have seen the sentenc the cat got squash in the yard on fridai .
that should help you predict the word in the sentenc , the dog got flatten in the yard on mondai .
in particular , the trigram model doesn't understand the similar between word like cat and dog , or squash and flatten , or garden and yard , or fridai and mondai .
so it can't us past experi with on of those word to help it with the other on .
to overcom thi limit , what we need to do is convert the word into a vector of semant and syntact featur .
and us the featur of previou word to predict the featur of the next word .
us a featur represent , allow us to us much bigger context , that contain mani more word .
for exampl , ten previou word .
yoshua bengio pioneer thi approach for languag model , and hi initi network for do thi look rather familiar .
it is actual veri similar to the famili tree network .
it's just appli to a real problem , and is much bigger .
so at the bottom you can think of us as put in the index of a word , and you could think of that as a set of neuron of which just on is on .
and then the weight from that on neuron will determin the pattern of activ in the next hidden layer .
and so the weight from the activ neuron in the bottom layer will give you the pattern of activ in the layer that ha the distribut represent of the word .
that is it's featur vector .
but thi is just equival to sai you do tabl look up .
you have a store featur vector reach word , and with learn , you modifi that featur vector .
which is exactli equival to modifi the weight come from a singl activ input unit .
after get distribut represent of a few previou word , i've onli shown two here but you would typic us , sai , five .
you can then , us those distribut represent , via hidden layer , to predict , via huge softmax , what the probabl ar for all the variou word that might come next .
when extra refin that make it work better is to us skip lag connect that go straight from the input word to the output word .
becaus the individu input word ar , ar individu quit inform about what the output word might be .
bengio's model wa actual slightli wors than trigram's at predict the next word , but it wa in the same ballpark , and if you combin it with trigram's it improv thing .
sinc then these languag model that us featur vector for word have been improv consider , and thei're now consider better than trigram model .
on problem with have a big softmax output layer , is that you might have to deal with <num> , <num> differ output work .
becaus typic in these languag model , the plural of a word is a differ word from the singular .
and the variou differ tens of a verb ar differ word from other tens .
so each unit in the last hidden layer of the net , might have to have a hundr thousand outgo weight .
and that mean we can onli afford to have a few unit there befor we start over fit .
that's not necessarili true .
we might have a huge number of train case .
so some organ like googl might have so much train tech that it can afford to have a veri big softmax layer .
we could try and make the last hidden less small , so we don't need too mani weight .
but then we have the problem that we have to get the <num> , <num> probabl of the variou word that might come next fairli accur right .
it's not just the big probabl we need .
a veri larg number of word will have small probabl .
and the small probabl ar often relev .
it might be that the speech recogn ha to decid whether it's two differ rare word , and then it's veri relev which of those is more common in the context , even though both of them ar pretti unlik .
the question is , is there a better wai to deal with such a larg number of output ?
and we'll see sever differ wai of do that in the next video .
in thi , video we're go look at variou wai to avoid have to us <num> , <num> differ output unit in the softmax , if we want to get probabl for a <num> , <num> differ word .
at the end of the video , i'll show an exampl of the word , or the word represent that ar learn by a particular method .
to see what these represent look like , what we do is we emb them in a two dimension space .
and then , we can see which word have extrem similar represent .
that give us a feel for what the neural network ha been abl to learn , just in try to predict the next word or perhap , the middl word of a string of word .
so , on wai to avoid have a <num> , <num> output unit , is to go through the word on at a time .
so , the input consist of a context of previou word , and we plug in a candid word .
then the output of the network is a score for how good that combin is .
how well doe that candid word fit into that context ?
of cours , that mean we have to run thi net mani , mani time but most of the work can be share so the input that come into that final hidden layer from the context , stai the same for all differ candid word and so we onli need to run a small part of the network for each candid word .
we try all the candid word on at a time .
and i don't want to so , on wai have so , on wai to avoid have a <num> , <num> differ output unit , is to us a serial architectur .
we put in the context word as befor but now , we also put in a candid for the next word in the same wai as the context word .
then , we go forward through the net and what we output , is a score for how good that candid word is , in that context .
of cours , we have to run forward through thi net , mani , mani time .
but most of the work onli need to be done onc .
so , the input from the context to that big , big hidden layer ar the same for everi differ candid word .
the onli bit we need to run for each candid word is the input come from the candid word and the final output to the score .
and , of cours , that doesn't have mani weight in it .
so , we try all the candid word on at a time .
and by put in the word as a candid at the bottom , we're abl to us the learn featur vector that , for that kind of word , that we learn when it wa a context word .
so , we can have the same represent of the candid word when it's in the context , and when it's a candid for the next word .
so , we can have the same represent of the word when it's part of the context , and when it's a candid for the next word that we're try to predict .
learn in the serial architectur work in the follow wai .
we first comput the score for each possibl candid word and then we put all those score , which we comput sequenti into a big softmax to get word probabl .
now , the differ between the word probabl and their target probabl which is normal on for the correct word and zero for everyth els , give us the cross entropi error deriv and we us those deriv to chang the wai , in such a wai that we rais the score for the correct candid and we lower the score for all of these high score rival .
we can save a lot of time in thi architectur if instead of consid all possibl candid word , we onli consid a small set .
perhap , candid word suggest by some other predictor .
for exampl , we could us the neural net to revis the probabl of the word that the trigram model think ar like .
a differ wai to avoid a great big softmax is to structur the word into a tree .
so , we arrang all of the word in a binari tree , with the word as it leav , we then us the context of previou word to gener a predict vector v .
we compar that predict vector with a vector that we learn for each node of the tree .
the wai we do the comparison is by take a scale of product of the , the predict vector and the vector that we've learn for the node of the tree .
and then , we appli , appli the logist function .
and then , we appli the logist function to that scale of product , and that will give us the probabl of take the right branch in the tree and on minu that , give us the probabl of take the left branch in the tree .
so , the tree look like thi and if that sigma is the logist function , you can see at the top of tree that we take the logist of the predict vector , time the vector that we learn ui of the top node , and that tell us the probabl take the right branch and convers we take the left branch with on minu that probabl and so on , all the wai down the tree to the word we want .
so , when we're learn , we us our contact to get a predict vector .
and in thi work , we us quit a simpl neural network , that simpli take the store , learn represent of each word , and us the featur vector for each word to provid evid for the great predict vector .
we us quit the simpl , we us quit a simpl neuron at work , for thi work , where we take the featur vector for each word and those featur vector directli contribut evid in favor of a predict vector .
we simpli add up the evid contribut by those featur vector and that give us the predict vector .
that predict vector then get compar with the vector that have been learn for all the node in the tree on the path to the correct next word .
so , that would be node i , j , and m in thi tree .
that red path show you the path to the word that actual occur next and those ar the onli node we need to consid dure learn .
what we know is that , we'd like the probabl of predict that word to be as high as possibl .
and so we'd like the probabl of take that path to be as high as possibl .
so , we'd like the product of the probabl on the individu element of that path to be as high as possibl .
and that mean we'd like the sum of their log probabl to be high .
so , we benefit from a nice decomposit here .
that when we try and maxim the probabl of pick the correct target word , we're realli try to maxim the sum of the log probabl of take all the branch on the path that lead to that target word .
so , dure learn , we onli need to consid the node on that correct path .
and that's a huge win , that's exponenti fewer node when consid all of the node .
so , it's log to the base two of n instead of n .
for each of those node , we know the correct branch , cuz we know what the next word is .
we know the current probabl of take that branch , by compar the predict vector with the learn vector of the node .
as so , we can get deriv for learn both the predict vector v and learn vector of that node , u .
thi make train hundr of time faster .
unfortun , it's still slow at test time .
at test time , you need to know the probabl of mani word to help speech recogn .
and so , you can't just consid on path .
there's a much simpler wai to learn featur vector for word .
thi is what by collobert and weston .
and what thei did wa learn featur vector for word and then show that the featur vector thei learn were veri good for a whole bunch of differ natur languag process task .
thei're not try to predict the next word , thei're just try to get good featur vector for word , and so , thei us both the past context and the futur context .
so , thei look at a window of eleven word , five in the past and five in the futur .
and in the middl of that window , thei put either the correct word , the on that actual occur in the text , or a random word .
and then thei train a neural net to produc an output that's high if it's a correct word and low if it's a random word .
the neural net work the same wai as befor .
we map the individu word to featur vector , these word code , and then we us the featur vector in the neural net , possibl with more layer in the neural net to try and predict whether thi is the right or wrong word for that context .
so , what thei're realli do is judg whether the middl word is an appropri word for the five word context on either side of it .
thei train thi up on about <num> million exampl from wikipedia .
and thei show that the vector thei get ar good for a varieti of differ natur languag process task .
on wai of get a sens of the vector that thei learn for word , is to displai the vector in a two dimension map .
all we want to do is lai out the word vector in such a wai that veri similar vector ar veri close to on anoth .
so , then you'll discov what word the neural network think have similar mean .
we're go to us a multi scale method call t sne .
you can look up t sne on googl and discov how it work if you want .
and t sne is abl , in addit to put veri similar word close to each other , it's also abl to put similar cluster close to each other .
so , it give you structur at mani differ scale .
what we see , is that the learn featur vector captur lot of subtl semant distinct .
and thei do thi just by look at string of word from wikipedia .
nobodi tell them anyth other than the fact that these eleven word occur in the string .
there's no extra supervis .
what's remark is that , that contextu inform , the fact that these word occur togeth , tell you an aw lot about what the word mean .
in fact , some peopl think that's the main wai we learn the mean of word .
so , here's and exampl .
if i give you a sentenc with a word you've never heard befor like , she scram him with a fry pan .
from that on sentenc , you alreadi have a pretti good idea what scram mean .
it's conceiv that she wa try to impress him with her cook skill and so scram mean impress or someth like that but probabl it mean someth like wallop .
so , here's part of a two dimension map in which we laid out the two and a half thousand commonest word and you'll see thi part of the map is all about game .
not onli that , it's got similar kind of word togeth .
so , match and game and race ar togeth .
it's got player and team and club togeth .
it's got the thing you win at game togeth , like cup , and bowl , and medal and prize .
it's got differ kind of game togeth .
it's done a veri good job of take these word to do with game and find out which on ar veri similar in mean .
and becaus it's us veri similar featur vector for those , it can in ani natur languag process task , sai , that if on word wa a good word for that context , the other word's probabl also a pretti good word for that context .
here's anoth part of the map .
thi part of the map is entir about place .
at the top , it ha us state .
under that it ha some citi .
mainli on in north america .
and under that other citi , then it ha some countri .
so , if you look at the citi thi on is clearli cambridg .
and underneath cambridg , there's someth els that's veri similar to cambridg .
here , we see that it's put toronto with detroit and ontario and boston .
toronto's in english speak canada .
and it's put quebec , which is in french speak canada , with berlin and pari .
if we look at the bottom , we can see that it think iraq is pretti similar to vietnam .
here's anoth exampl .
if you look here , these ar adverb .
and it's understood that like and probabl and possibl and perhap , all mean veri similar thing .
it's also understood that entir , complet , fulli , and greatli have veri similar mean .
and it's understood variou other kind of similar .
for exampl , which and that , or whom and what , or how and whether and why .
in thi video , i'm go to describ some of the thing that make it difficult to recogn object in real scene .
we're incred good at thi , and so it's veri hard for us to realiz how difficult it is to take a bunch of number that describ the intens of pixel and go from there to the label of an object .
there's all sort of difficulti .
we have to segment the object out .
we have to deal with variat in light , in viewpoint .
we have to deal with the fact that the definit of object ar quit complic .
it's also possibl that to get from an imag to an object requir huge amount of knowledg , even for the lower level process that involv segment and deal with viewpoint and light .
if that's the case , it's gonna be veri hard for ani hand engin program to be abl to do a good job of those thing .
there ar mani reason why it's hard to recogn object and imag .
first of all , it's hard to segment out an object from the other thing in an imag .
in the real world , we move around , and so we have motion cue .
we also have two ey , so we have stereo cue .
you don't get those in static imag .
so it's veri hard to tell which piec go togeth as part of the same object .
also , part of an object can be hidden behind other object , and so , you often don't see the whole of an object .
you're so good at do vision that you don't often notic thi .
anoth thing that make it veri hard to recogn object is that the intens of a pixel is determin as much by the light as it is by the natur of the object .
so , for exampl , a black surfac in bright light will give you much more intens pixel than a white surfac in veri gloomi light .
rememb , to recogn an object you've got to convert a bunch of number , that is the intens of the pixel , into a class label .
and , these intens ar vari for all sort of reason that have noth to do with the natur of the object .
or noth to do with the ident of the object .
object can also deform in a varieti of wai .
so for rel simpl thing like handwritten digit there's a wide varieti of differ shape that have the same name .
a two for exampl could be veri ital with just a cusp instead of a loop or it could be a veri loopi two with a , a big loop and veri round .
it's also the case that for mani type of object , the class is defin more by what the object's for , than by it visual appear .
so consid chair .
there's a huge varieti of thing we call chair , from armchair to modern chair made with steel frame and wood back to basic anyth you can sit on .
on other thing that make it hard to recogn object , is that we have differ viewpoint .
so , there's a wide varieti of viewpoint from which we can recogn a 3d object .
now , chang in viewpoint caus chang in the imag that standard machin learn method cannot cope with .
the problem is that inform hop about between the input dimens .
so , typic envis the input dimens correspond to pixel , and , if an object move in the world and you don't move your ey to follow it , the inform about the object will occur on differ pixel .
that's not the kind of thing we normal have to deal with in machin learn .
just to stress that point , suppos we had a medic databas in which on of the input is the ag of a patient and anoth input is the weight of the patient .
and we start do machin learn , and then we realiz that some coder ha actual chang which input i mention is code which properti .
so for on of the coder thei've put weight where thei should have put ag , and thei put ag where thei should have put weight .
obvious , we wouldn't just carri on do our learn .
we'd try and do someth to fix that .
that's go to make everyth go wrong .
i call that phenomenon dimens hop .
when inform jump from on input dimens to anoth .
and that's what viewpoint doe and it's someth we need to fix .
and prefer we'd like to fix it in a systemat wai .
in thi video i'm go to talk about the issu of viewpoint invari .
each time we look at an object in the seen , we typic have a differ view point .
so the object share up on differ pixel .
thi make okai recognit veri unlik most machin learn task and i'm go to talk about variou wai of try to do with that issu .
and number of differ wai have been suggest for cope with view point variat .
we're so good at it that we don't realli appreci how difficult it is .
it's on of the main difficulti in make comput perceiv , and there still aren't gener accept solut , either in engin or in psycholog .
the first approach is to us redund invari featur .
the second approach is to put a box round the object so that you can normal the pixel .
the third approach is to us replic featur , and pool them .
thi is call convolut neural net .
i'll go to that in great detail .
and the first approach we shall talk about at the end of the lectur is to us a hierarchi of part and to explicitli repres the place of the part rel to the camera or retina .
so , the invari featur approach sai you should extract a larg and redund set of featur .
and thei should be featur that ar invari under the transform like translat and rotat scale .
so here's an exampl of an invari featur .
it's a pair of roughli parallel line , with a red dot between them .
that's actual be suggest as the featur the babi her gull us for know what to peck for food .
if you paint that featur on a piec of wood , thei'll peck at the appropri place on the piec of wood .
with enough invari featur , there's onli on wai to assembl them into an object or an imag .
you don't actual need to repres the relationship between featur directli becaus those relationship ar captur by other featur .
thi ha been point out for string of letter by psychologist call wayn it's been point out in vision by shimon ullman .
and , it's a sort of acut point that all we need is a big bag of featur , becaus with overlap and redund featur .
on featur will tell you how two other featur ar relat .
unfortun , if you're do recognit , you're go to get a whole bunch of featur that ar compos of part of differ object .
and thei'll be veri mislead for recognit .
so you'd like to avoid form featur from part of differ object .
a second approach is what i call judici normal .
so if you look at that upsid down capit letter r on the right , i put a box around it .
not veri well , in fact .
and i've label a top and a front for that box .
and rel to that box , the r ha for exampl a vertic stroke at the back , and it ha a loop face forward at the top .
so if we describ featur of the r rel to that box , thei're go to be invari .
thi is assum it's a rigid shape .
put a box around a rigid shape solv the dimens hop problem .
it get rid of the effect of chang in viewpoint .
if we choos the box correctli , the same part of an object would alwai occur on the same normal pixel .
it doesn't have to be a rectangular box .
we can provid invari to not onli translat and rotat scale but also thing like sheer and stretch .
unfortun , choos the box is difficult .
it's difficult becaus we might have segment error .
we might have occlus so you can't just shrink a box around thing .
we might have unusu orient .
that exampl of the upsid down r make it clear that we have to us our knowledg of what the shape is to help us decid what the box is .
if , for exampl , we had a charact that wa like a lowercas d , but with an extra stroke come out of the loop of the d .
we would see that as an upright on of those charact .
so it's a chicken and egg problem .
in order to get the box right , we need to recogn the shape .
in order to recogn the shape , we need to get the box right .
an asid here for psychologist .
mani psychologist think we do mental rotat to deal with shape that aren't orient right .
thi is complet nonsens .
that capit letter r you recogn perfectli well befor you do ani mental rotat .
inde , you need to recogn that it's an r and it's upsid down , in order to know how to rotat it .
you us mental rotat for deal with judgment like handed .
that is , is it a correct r or mirror imag r ?
you can't tell that without do mental rotat .
the mental rotat is not us for deal with the fact that it's upsid down when we want to recogn it .
the brute forc normal approach work like thi .
you us well segment , upright imag that you can judici put a box around when you train the recogn , and then at test time , when you have to deal with clutter imag , you try all possibl box in a whole rang of posit and scale .
thi approach is wide us in comput vision .
particularli for detect upright thing like face or hous number in unseg imag .
it's much more effici if thei recogn thei can cope with some variat in the posit and scale so that we can us a cours grid when try on possibl box .
in thi video , i'm go to talk about convolusion neural network for hundr and digit recognit .
thi wa on of the big success stori of neuron network in the 1980s .
the deep convolut net develop by yann lacun and hi collabor did a realli good job of recogn handwrit and were actual us in practic .
thei're on of the few exampl from that period of deep neural net that it wa possibl to train on comput that exist then , and that perform realli well .
convolut neural network ar base on the idea of replic featur .
so , becaus object move around and show up on differ pixel , if we have a featur detector that's us in on place in the imag , it's like that the same featur detector will be us somewher els .
so , the idea is to build mani differ copi of the same featur detector in all the differ posit .
if you look on the right i've shown you three featur detector , which ar replica of each other .
each of them ha weight to nine pixel .
and those weight ar ident between the three differ featur detector .
so the red arrow ha the same weight on it for all three featur detector .
and when we learn we keep those red arrow all have the same weight as each other and we keep the green arrow have all the same weight as each other .
even though the red and green arrow will have differ weight .
we could also try replic across scale and orient but that's much more difficult and expens and probabl not a good idea .
replic across posit greatli reduc the number of free paramet that you have to learn .
so those <num> pixel that you see in those three replic detector onli have nine differ weight .
now we don't just want to us on featur type .
so we're go to have mani map .
each map will have replica of the same featur , featur that ar constrain to be ident in differ place .
and then differ map will learn to detect differ featur .
thi allow each patch of the imag to be repres by featur of mani differ type .
replic featur fit in nice with back propag that is it's easi to learn us back propag .
in fact it easi to modifi the back propag algorithm incorpor ani linear constraint between the weight .
so what we do is we comput the gradient as usual .
but then we modifi the gradient , so that if the weight satisfi the linear constraint befor the weight updat , thei'll also satisfi the linear constraint after the weight updat .
so , the simplest exampl is we want two weight to be equal .
we want w1 to equal w2 .
that would be true if we start off with w1 equal to w2 .
and then we make sure that the chang in w1 is alwai equal to the chang in w2 .
the wai we do that is we comput the gradient of the arrow with respect to w1 .
and the gradient with respect to w2 .
and then we us the sum or averag of those two gradient for both w1 and w2 .
by us weight constraint like that , we can forc back propag to learn replic featur detector .
there's quit a lot of confus in the literatur about what replic featur detector ar actual achiev .
mani peopl claim thei're achiev translat invari .
and that's not true .
well at least it's not true in the activ of the neuron .
so if you look at the activ , what replic featur achiev is equivari not invari .
an exampl should make that clear .
here's an imag , and the black dot ar the activ neuron .
here's a translat imag .
and notic the black dot have also translat .
so the imag chang and the represent also chang by just as much as the imag .
that's equivari not invari .
there is someth invari , and that's the knowledg .
so if you learn replic featur detector , if you know how to detect a featur in on place , you'll know how to detect that same featur in anoth place .
and it's import to note that we're achiev equivari in the activ and invari in the weight .
if you want to achiev some invari in the activ , what you need to do is pool the act replic featur detector .
so you can get a small amount of translat in varianc at each level of a deep net , by averag full neighbor replic detector .
on advantag of thi is that it reduc the number of input for the next layer .
so that we can have more differ map , allow us to learn more differ kind of featur in the next layer .
it actual work slightli better to take the maximum of four neighbor featur detector , rather than an averag , but there is a problem .
and the problem is that after sever level of do thi kind of pool , we've lost precis inform about where thing ar .
that's okai if we just want to recogn that it's a face .
the fact that we've got a few ey , and a nose , and a mouth float about in vagu the same posit is veri good evid that it's a face .
but if you want to recogn whose face it is , you need to us the precis spatial relationship between the ey and between the nose and the mouth .
and that's been lost by these convolut neural net .
i'll come back to that issu later on .
so the first impress exampl of a convolut on your own end wa done by yann lecun and hi collabor who develop a realli good recogn for a hundr digit .
in it had mani hidden layer .
in each layer , it had mani map of replic unit .
and it had pool between layer .
so you pool adjac replic unit befor you send them to the next layer .
but i also us a wide net that could cope with sever charact at onc .
and that would work even if the charact overlap .
so you didn't have to segment out individu charact befor you fed them to their net .
and someth which , peopl often forget , is that thei us a clever wai of train a complet system .
thei weren't just train a recogn of individu charact .
thei were train a complet system , so that you put in pixel at on end and you get out whole zip code at the other end .
and in train that system thei us a method that would now be call maximum margin .
but when thei did it , it wa wai befor maximum margin had been invent .
the net thei us wa at on point respons read about for ten percent of the check in north america .
so it wa of great practic valu .
there were some veri nice demo on that , on yann's workpaget .
you should realli go look at them .
look at all of them .
becaus thei show you just how .
well it cope with variat in size , orient , posit , overlap of digit , and all sort of background nois that would , would kill most method .
the architectur of lenet <num> look like thi .
there's an input , which is pixel .
and then there's a whole sequenc of featur map follow by sub sampl .
so in the c1 featur map , the six differ map , each which is <num> by <num> .
of those map contain small featur that just look at i think three by three pixel .
and their weight ar constrain togeth .
so per map there's onli about nine paramet .
that make learn much more effici .
it mean you need much less data .
then after the featur map , there's what thei call sub sampl which is now call pool .
and so , you pool togeth the output of a bunch of neighbor replic featur in c1 .
and that give you a smaller map , which will then provid the input to the next layer , which is discov more complic replic featur .
as you go up thi hierarchi , you get featur that ar much more complic , but ar more invari to posit .
here's the error that lenet5 made .
and thi show you the data that it's deal with is quit tricki .
there's <num> , <num> test case , and these ar the <num> error that it make .
so it's do better than <num> correct .
nevertheless , most of the error it make ar the thing that peopl find quit easi to recogn .
so there's some wai to go still .
nobodi know the human error rate on thi data .
but it's probabl twenti to <num> error .
of cours the might be digit that lenet5 got right and you would get wrong .
so you have to be care in estim the error rate .
you can't just look at these <num> and ask which on you'll get right and which on you'll get wrong .
you have to worri about all those other on that lynett five might've got right and you might've got wrong .
i'm now want to go to a veri gener point , about how to inject prior knowledg in machin learn , and it appli particularli to neural network .
we can put in prior knowledg as it is done in the net five , by the design of the network .
we can have local connect .
we can have weight constraint .
or we can choos neuro activit that ar particularli appropri for the task we're do .
thi is much less intrus than try to hand engin the futur .
but it still prejudic the network toward a particular wai of solv the problem that we had in mind .
we have an idea about how to do object recognit by gradual make bigger and bigger featur .
and by replic these featur across space .
and we forc the network to do it that wai .
there is an altern wai to put in prior knowledg that give the network a much freer hand .
what we can do is us our prior knowledg to get a whole lot more train data .
on of the first exampl of thi wa work by hofmann and tresp on try to model what happen in a steel mill .
thei want to know the relationship between what come out of the steel mill and variou input variabl , and thei actual had an , big old fortran simul that would allow them to simul the steel mill .
of cours , the simul wasn't realiti .
it wa make all sort of approxim .
so thei had real data , and also a simul .
and what thei did wa run the simul in order to creat some synthet data .
we then ad that to the real data , and show that thei could do better than just us the real data alon .
if i rememb right , their great , big fortran simul wa onli worth a few dozen extra real exampl , but nevertheless , thei made the point .
of cours , if you gener a lot of synthet data , it mai make learn take much longer .
so in term of the speed of learn , it's much more effici to put in knowledg by us thing like connect and weight constraint , as wa done in lynett five .
but as comput get faster , thi other wai of put in knowledg , by gener synthet exampl , begin to look better and better .
in particular , it allow optim to discov clever wai of us the multilay network that we didn't think of .
if fact , we might never fulli understand how it doe it .
if we just want good solut to a problem , that might be fine .
so us the idea of synthet data , there's a brute forc approach to handwritten digit recognit .
lenet5 us knowledg about invari to design the connect and the weight share and the pool .
and that achiev about <num> error .
ad a lot more trick , includ synthet data , wa abl to get that down to about <num> error .
a group in switzerland , led by went to town with inject knowledg by put in synthet data .
thei put a lot of work into creat veri instruct synthet data .
so for everi real train case , thei transform it to make mani more train exampl .
thei then train a larg net with mani unit per layer , mani layer on a graphic processor unit .
the graphic processor unit gave them a factor of thirteen comput .
and becaus of all the synthet data thei put in , it didn't overfit .
if thei just us a larg net with a gpu .
it would have been a disast that over fit terribl that thei would have done on the train data but terribl on the test data .
so thei were realli combin three trick .
put your effort in to gener lot of synthet data then train a larg net on a gpu .
thei manag to achiev <num> error like that .
so here's the <num> error that thei got .
the top print digit is the right answer .
and the bottom two digit ar their top two answer .
what you'll notic is that thei nearli alwai get the right answer in their top two .
there's onli five case where thei don't .
with some more work by build sever differ model like thi and then us a consensu to decid what the digit wa , thei manag to get down to about <num> error .
and that must be around about the human error rate .
on question thi work rais is how do you tell if a model make <num> error is realli better than a model that make <num> error .
is that significantli differ ?
rather surprisingli , it turn out it depend on which error thei make .
the number then provid you enough inform .
you have to know which on thei get wrong and which on thei get right .
so thi statist test call the mcnemar test that us the particular error and is far more sensit than just us the number .
let me give you an exampl .
if you look at thi two by two tape .
it show you , in the top left hand corner , how mani exampl model on got wrong and model two also got wrong .
that's <num> .
and in the bottom right , it show you how mani exampl model on got right and model two also got right .
and in the magnema test , you can just ignor those number in black .
all you're interest in is on where model on got it right and model two get it wrong , or model two got it right and model on get it wrong .
and if you look at that , there's an eleven to on ratio , and it turn out that's pretti signific .
model two is definit better than model on .
that didn't happen by accid , almost certainli .
by contrast if you look at thi tabl , again .
model on is make <num> hour , model two is make <num> hour , but now model on is win fifteen time when model two lose and model <num>'s win <num> time when model on lose .
that differ is not veri signific so we wouldn't be confid that model two is better than model on .
it wa alwai a question for specul whether the kind of net develop for recogn handwritten digit could actual be scale up to what vision peopl call a real task .
that is , recogn object in high resolut color imag when the scene is clutter .
so that you have to do thing like segment , you have to deal with 3d viewpoint , you have to deal with <num> foot list .
mani differ object surround , you're not quit sure which is the intend on , and so on .
sinc the start of thi cours , we've got some interest new result on that .
so in my first lectur , i describ the network develop by alex krizhevski and show that it wa good at object recognit .
but at that point it hadn't been benchmark against the best comput vision system , now it ha .
peopl work on emenis for mani year , gradual improv their abil of these network to recogn handwritten digit .
mani comput vision research thought thi wa a wast of time if you want to be abl to recogn real object in color imag , becaus thei thought the lesson learn from emnis would not gener to that domain .
that wa a fairli reason thing to think .
here's a number of reason why it's a much more difficult task .
first of all , there's mani , mani more differ kind of object .
even if we onli recogn a thousand class , that's still a factor of a hundr .
secondli there is mani more pixel even if we us tran sampl imag that ar onli <num> by <num> with color pixel that's still <num> or <num> time of mani pixel anoth factor is that in real scene you have to deal with the fact you've got a two dimension imag of a three dimension realiti so a lot of inform is be lost .
and real scene have clutter of a kind that doesn't occur in handwrit .
in handwrit you can have overlap letter and that requir segment but you don't have thing like occlus of larg part of object by opaqu other object .
you don't have mani differ kind of object in the same scene .
and you don't have a littl light variat that you get in real scene .
so the question is will the same kind of convolut neural network that prove to be so good on recogn hand written digit work for real color imag in the domain of real color imag we probabl do need to wire in some prior knowledg .
becaus , if we try and do it in the sera san wai with no knowledg wire in , put in all the knowledg by gener extra train exampl .
the comput problem is still too larg for current comput .
so there wa a recent competit .
and it wa on a data base call imagenet .
imagenet actual ha mani more than a machin imag but a subset of <num> millimet wa chosen and the classif task wa to correctli label those imag .
now the imag were hand label with a thousand differ class but thi wasn't veri reliabl .
there could be an imag that ha two of those thousand differ object in it and onli on of them is label .
so , to make the task feasibl the comput vision system is allow to make five bet .
and it's set to get it right if on of those bet correspond to the label that a person ha given the imag .
there's also a local task .
the reason for the local task is that mani comput vision system us a bag of featur approach .
for the whole imag or for sai , a quadrant of the imag thei know what the featur ar , but thei don't know where thei ar .
thi allow them to recogn object but without know exactli where thei ar .
that's veri unlik how peopl behav except peopl with a curiou kind of brain damag call balanc syndrom where thei can recogn object and not be sure where thei ar .
so for the local task you have to place a box around an object onc you've recogn it and to get it right your box must have at least a <num> overlap with the correct box .
on thi task , peopl tri some of the best exist comput vision method .
so , lead group from oxford and the french nation research lab inria and xerox's european research center and variou other univers tri thi task and discov it's veri hard .
the comput vision system typic us complic multi stage system .
the earli stage of these system ar typic hand tune by optim a few paramet us some of the data .
and , the top stage of these system is alwai a learn algorithm .
but thei don't learn all the wai through .
in the wai that a deep neural net doe when it train to do back propag .
thei don't have end to end learn , where the paramet us in the earli featur detector ar be influenc by how us thei ar for make final decis about class .
so here ar some exampl from the test set to show you what the data is like .
you alreadi sow some exampl in the first lectur , but here's some more .
so you can see that it's fairli obviou what the object is in that imag , but a lot of it's miss .
it doesn't have ear , it doesn't have leg .
the predict ar the un normal probabl of alex krizhevski's deep neural network .
and you can see it's confid that , that is a cheetah and if it's not a cheetah , it think it almost sudden a leopard .
it also understand there's other possibl , like a snow leopard , it's the wrong color for a snow leopard , or an egyptian cat .
here's an exampl the other wai around , here there's mani object in the imag and the object of interest is onli a veri small fraction of the pixel .
the network correctli sai bullet train .
but it also ha other bet , like subwai train or electr locomot , which ar present bet .
if you look at the imag , there's lot of other thing that could be label , like the roof which occupi a much larger fraction of the imag than the train or the pillar that's support the roof or the pedestrian .
or the larg apart block in the background .
in these kind of imag you realli have to be abl cope with the fact that there's lot of altern target .
last imag show a differ kind of exampl where there is no background clutter .
the object is quit well isol , probabl a pictur from a catalog or someth .
and the network doesn't get it right for it first bet , but it doe get it in it top five bet .
but here the network isn't confid about anyth .
these ar the rel probabl , and the network correctli realiz it doesn't realli know .
and if you look at the other possibl , thei're all perfectli plausibl .
if you screw your ey up so you can't see the imag too well , you can see how it might think it wa a fry pan or a stethoscop .
so how did the system do on thi data ?
here's the error rate for the comput vision system .
on thing you'll notic is that the best system ar all veri similar .
so the univers of tokyo manag to get <num> , and here what i'm do is just report the best system from each group .
oxford univers , which ha a veri good comput vision group , gener recogn to be possibl the best group in europ , again got in the <num> percent and the french nation research lab in the xerox park center , which ar , again , a veri good comput vision group , got <num> .
so you'll guess from thi that it is go to be hard to be <num> , and if you do beat <num> you're compar with the veri best comput vision system .
so alex krizhevski's neural net got sixteen percent error .
it's a huge gap .
normal , in these competit you don't see big gap like that .
so alex krizhevski's network work like thi .
it's a veri deep convolut neural net of the type pioneer by yann le cun wa first us for digit recognit and then yann later appli it to recogn real object .
and we're us all the lesson that we learn by yann's group from group and variou other group , develop these deep neural net for do real vision .
it ha seven hidden layer , which is deeper than usual and that's not count some of the max pool layer .
the earli layer ar convolut .
we could probabl get awai with us just local recept field , without ty ani weight , if we had a much bigger comput .
but by make them convolutionari , you cut down the paramet a lot , so you cut down the amount of train data you need a lot which cut down the amount of comput time a lot .
the last two load were global connect and that's where most of the paramet ar .
i think there's about sixteen million paramet between each pair of those layer .
what the last two layer ar do is look for combin of local featur that were extract by the earli layer .
and obvious thi commonli tourili mani combin to look for .
and that's why you need a lot of paramet there .
the activ function were rectifi linear unit in everi hidden layer .
these train much faster than logist unit and thei're more express .
most of the peopl serious appli deep in your own network to real imag to the object recognit of i switch direct fi linear unit .
we also us competit normal , within a layer to suppress the activ of a unit , if other unit that ar look nearbi local ar veri activ .
thi help a lot with variat in intens .
so , you might have an edg detector , which get somewhat activ due to some fairli faint edg .
and that's pretti much irrelev , if there is much more intens thing around .
there's other trick that we us to significantli improv the gener of thi net .
first of all , we us the trick of enhanc the data by us transform .
so here's a skit for down sampl the imag in the competit to <num> by <num> .
but instead of us those whole imag alex krizhevski took random <num> by <num> patch from those imag .
which gave him huge more imag to train on .
and help him deal with translat and varianc .
even though thei're convolut net that's still a help .
he also us left right reflect of the imag , which again doubl the amount of data .
he didn't us up dime reflect .
becaus , graviti's veri import .
left right reflect don't realli chang what thing look like much unless thei're thing like write .
at test time , he doesn't just us on patch .
he us a number of differ patch , the four corner , the middl , that give him five , and then the left right reflect of all those , that give him ten .
he run all ten through the network and then combin their opinion .
in the top layer , where most of the paramet ar , he us a new regular techniqu , call drop out , which is veri effect .
and stop the network over fit .
that's worth sever percent in hi result .
i'll describ drop pouch at some length in the later lectur .
but for now , the basic idea of drop out is that each time you present a train exampl , you omit half the hidden unit from a layer .
thi mean that the other hidden unit in that layer , the survivor , can't reli on the their com rate be present .
thei can't learn to fix up the error left over by the other hidden unit in that layer , cuz the other hidden unit might not be there no matter be fix up an error that doesn't exist .
so thei have to becom more individualist .
thei have to individu do us thing but thei still have to do us thing that ar differ from what the other survivor do .
so drop out is stop too much cooper between the hidden unit .
and a lot of cooper is veri good for fit the train data .
but if the test distribut is significantli differ , then all that cooper caus over fit .
alex couldn't have done thi work without signific hardwar , but the hardwar onli cost a few thousand dollar now .
alex is a veri good programm , and he us a veri effici implement of convolut and neural net on two invidia gtx <num> graphic processor .
each of these ha over <num> fast littl core , which ar veri good at do arithmet and not much good at anyth els .
the gp us ar veri good at do matrix , matrix multipli .
so if you stack togeth the vector of activ of a hidden layer , over mani train case , that give you a matrix .
and now you multipli that by matrix of weight to figur out the activ in the next hidden layer for all those train case .
and if both those matric ar big , the gpu's give you a huge advantag .
thei give you about a factor of <num> .
thei also have veri high bandwidth to memori , and that's need for neural net .
caus in neural net you keep want to know anoth weight so that you can multipli it by an activ .
and there's million of these weight , so you can't keep them all in the cach .
us all that hard brac , he could train hi final network , in a week .
and you could also combin result from ten , ten differ patch of testtim veri quickli .
so test time you can run it at just about the frame rate .
in the futur we ar go to be abl to spread thi kind of network over a larg number of call .
as call becom cheaper , peopl at googl ar alreadi experi with that .
and if we can commun the stake fast enough we ar go to be abl to do much bigger network on mani more call .
googl ha alreadi simul network with <num> billion connect and i think that it's onli go to get bigger .
as the core get cheaper and the data set get bigger , these big deep neural net ar gonna improv much faster than the old fashion comput vision system , becaus thei don't involv much hand engin , and thei can make veri good us of huge data set and huge amount of comput .
so the fact that we've alreadi open up a big gap i think mean there's no look back .
i think from now on all the best object recognit system , at least of static imag , will us big deep neural net .
there ar other applic domain where we've learn the same lesson so vladimir nee .
us a net with local field but without convolut to extract road from aerial imag .
these ar clutter aerial imag of urban scene .
again he us multipl layer of rectifi linear unit .
and he take a rel larg imag patch , and predict for the central 16x16 pixel whether each of those pixel is a piec of road or not a piec of road .
the nice thing about thi task is that there's a lot of label train data avail .
that's becaus map tell you where the centr line of road ar and road ar roughli fix width .
so from the vector in the map that tell you where the centr line of the road is you can estim which pixel ar probabl road .
nevertheless , the task is veri hard .
there's the normal kind of vision problem so road ar occlud by build becaus a plane isn't look straight down when it take the photograph .
thei're occlud by tree .
thei're also occlud by car that ar sit on the road .
the shadow effect from build , the major light chang depend on whether it's a sunni dai or a cloudi dai for exampl and there's minor view point chang .
so the plane is basic look downward , but in ani larg photo it can't be look straight downward at everi pixel .
the worst problem in thi data ar the incorrect label .
you get incorrect label becaus the map aren't perfectli regist .
for most purpos , you don't need a map to be regist better than a few meter .
the pixel ar about on meter squar in thi data .
and so if the registr of the map is off by three meter , you're go to get at least three of the label wrong for pixel , across everi road .
anoth , sever problem , is that the peopl make map have to make arbitrari decis about what count as a road and what count as a lanewai .
so , in mai of the map , you look at someth , and you've no idea whether that's gonna be consid to be a road or a lane wai .
and so you simpli don't know what label it's gonna get from the map .
big neural net train on big imag patch , us million of exampl , ar , i think , the onli real hope for do a good job at thi task .
it's veri hard to find out what peopl can do .
so , here is what the data look like .
thi is a part of toronto .
if you know toronto , you can tell that by the angl of the road .
and , abov the imag of the part of toronto , i put two patch extract from that imag .
and if you look at those patch , you can see it's not trivial to tell which the road pixel ar .
on the right , is the output of system .
green is correctli identifi pixel of road , and red mean thing that hi system thought might be road , but actual aren't .
actual that thing is a park lot but you can see why he might have thought it wa a road .
in thi video , we're go to look at stochast gradient descent learn for a neural network , particularli the mini batch version , which is probabl the most wide us learn algorithm for larg neural network .
we've seen thi befor , but let's start with a remind about what the error surfac look like for a linear neuron .
the error surfac mean a surfac that li in a space where the horizont ax correspond to the weight of the neural net .
and the vertic axi correspond to the error it make .
for a linear neuron with a squar error , that surfac alwai form a quadrat bowl .
the vertic cross section ar parabola , and the horizont cross section ar ellips .
for multilay non linear net the error surfac is much more complic , but as long as the weight aren't to big it's a smooth error surfac , and local it's well approxim by a fraction of a quadrat bowl .
it might not be the bottom of the bowl but there's a piec of quadrat bowl that will fit the local error surfac veri well .
if we look at the convers speed when we do full batch learn , when the error surfac is a quadrat bubbl , the obviou thing to do is go downhil , thi will reduc the error .
but the problem is , that the direct of steepest descent doe not point to the place we want to go to .
as you can see in the ellips , the direct of steepest descent is almost at rectangl to the direct we want to go in .
you've got a gradient that's veri big across the ellips , which is the direct which we onli want to travel a small distanc , and the gradient's veri small along the ellips , and that's the direct which we want to travel a larg distanc .
it's precis the wrong wai around .
now you might think that studi linear system like thi , is not a good idea if you want to optim big non linear net .
but even for these non linear multi line net , thi kind of a problem aris .
it's a veri similar problem that aris even though the error surfac aren't global quadrat bowl .
local thei have all these same kind of properti .
that is thei tend to be veri curv in some direct , and veri uncurv in other direct .
so the wai the learn goe wrong if you us a big learn rate is that you slash to and fro in the direct in which the area surfac is veri curv .
so we'll sai call that slash across a ravin .
and with the line rate too big you'll actual diverg .
what we want to achiev , is that we go quickli along the ravin in direct that have small , but veri consist gradient .
and we move slowli in direct with these big , but veri inconsist gradient .
that is if you go in that direct for a short distanc , the gradient will revers sign .
befor we go into how we achiev that , i need to talk a littl bit about stochast gradient descent , and the motiv for us it .
if you have a data set that's highli redund , then if you comput the gradient for a weight on the first half of the data set , you'll get almost exactli the same answer as you get if you comput the gradient on the second half .
so it's a complet wast of time to comput the gradient on the whole data set .
you'd be much better off comput the gradient on a subset of the data , then updat the weight and on the remain data , comput the gradient for the updat weight .
we can take that to extrem and sai we're go to comput the gradient on a singl train case , we're go to updat the weight and then we're go to comput the gradient on the next train case us those new weight .
that's call onlin learn .
in gener , we don't want to go quit that far .
it's usual better to us small mini batch , typic ten or a <num> or even <num> exampl .
on advantag of a small mini batch , is that less comput is us for actual updat the weight , cuz you do that less often , compar with onlin .
anoth advantag is that when you comput the gradient , you can comput the gradient for a whole bunch of case in parallel .
most comput ar veri good at do matrix , matrix multipli , and that will allow you to consid a whole bunch of train case and appli the weight to a whole bunch of train case at the same time to figur out the activ go into the next layer for all of those train case .
that give you a matrix , matrix multipli , and it's veri effici , especi on a graphic processor unit .
on point about us mini batch is you wouldn't want to have a mini batch in which the answer is alwai the same and then on the next mini batch have a differ answer that's alwai the same .
that would caus the weight to slosh unnecessarili .
the ideal , if you have sai ten class , would be to have a mini batch with sai ten exampl or <num> exampl , that ha exactli the same number from each class in the mini batch .
on wai to approxim that is simpli to take all your data and just put it in random order and grab random mini batch .
but you must avoid have mini batch that ar veri uncharacterist of the whole set of data becaus the mini batch ar all of on class .
so basic there's two type of learn algorithm for neural net .
there's full gradient algorithm , where you comput the gradient from all of the train case .
and onc you've done that , there's a lot of clever wai to speed up learn .
there's thing like nonlinear version of a method call conjug gradient .
the optim commun ha been studi the gener problem of how you optim smooth nonlinear function for mani year .
now multi layer neural network ar pretti untyp of the kind of problem thei studi .
so appli the method thei develop mai need a lot of modif to make them work for these multi layer neural network .
but when you have highli redund and larg train set , it's nearli alwai better to us mini batch learn .
the mini batch mai need to be quit big , but that's not so bad becaus big mini batch ar more computation effici .
i'm now go to describ a basic mini batch grade descent linear algorithm .
thi is what most peopl would us when thei start train a big neural net on a big redund data set .
tyou start by guess an initi learn rate , and you look to see if the network learn satisfactorili or if the error keep get wors , oscil wildli .
if that happen , you reduc the learn rate .
you also look to see if the error is fall too slowli .
you expect that the error might fluctuat a bit if you measur it on a valid set , becaus the great electron mini batch is just a rough estim of the over all gradient .
so you don't want to reduc the learn rate everi time the error aris .
but what you're hope is that the error will fall fairli consist .
and if it is fall fairli consist and veri slowli , you can probabl increas the learn rate .
onc you've got that work , you can then write a simpl program to autom that wai of adjust the learn rate .
on thing that nearli alwai help is , toward the end of learn with mini batch .
it help to turn down the learn rate .
that's becaus you're go to get fluctuat in the weight caus by the fluctuat in the gradient that come from the mini batch .
and you'd like a final set of weight .
as a good compromis .
so , when you turn down the learn rate , you're smooth awai those fluctuat , and get a final set of weight that's good for mani mini batch .
so a good time to turn down the learn rate is when the error stop decreas consist .
and a good criterion for sai the error stop decreas is to us the error on a separ valid set .
that is , it's a bunch of exampl that you ar not us for train and also thei're not go to be us for your final test .
in thi video , we ar go to look at a number of issu that aris when us stochast gradient descent with mini patch .
there is a larg number of trick that make thing work much better .
these ar the kind of black out neural network .
and i'm go to go over some of the main trick in thi video .
the first issu i want to talk about , is initi the wai it's in your own network .
if two hidden unit have exactli the same weight , the same bios , with incom and i current , then thei can never becom differ from on anoth .
becaus thei would alwai get exactli the same gradient .
so , to allow them to learn diffrent featur detector , you need to start them off differ from on anoth .
we do thi by us small random weight to initi the weight .
that break the symmetri .
those small random weight umm shouldn't all necessarili be the same size as each other .
so if you've got a hidden unit that ha a veri big fan in if you us quit big weight it'll tend to satur it so you can afford to us much smaller weight for a hidden unit that ha a big fan in .
if you have a hidden unit with a veri small fan , then you want to us bigger weight .
and sinc the weight ar random , it scale with the squar root of the number of the weight .
and so a good principl is to make the size of the initi weight be proport to the squar root of the fan .
we can also scale the learn rate for the weight the same wai .
on thing that ha a surprisingli big affect on the speed with which a neural network will learn , is shift the input .
that is ad a constant to each of the compon of the input .
it seem surpris that , that could make much differ .
but when you're us steepest decent , shift an input valu by ad a constant can make a veri big differ .
it usual help to shift each compon of the input , so that averag over all of the train data , it ha a valu of zero .
that is , make sure it's mean is zero .
so suppos we have a littl neuron like like , just a linear neuron with two weight .
and suppos we have some train case .
the first train case is where the input ar <num> and a <num> , you should give an output of two .
and the second on sai when there ar a <num> and <num> you should output a zero .
and i'm us color here to indic which train case i'm talk about if you look at the error surfac you get for those two train case , it look like thi .
the green line is the line along which the weight will satisfi the first train case , and the red line is the line along which the weight will satisfi the second train case .
and what we notic is that thei're almost parallel , and so when you combin them , you get a veri elong ellips .
on wai to think about what's go on here is that , becaus we're us a squar error measur , we get a parabol trough along the red line .
the red line is the bottom of thi parabol trough that tell us the squar error we'll be get on the red case .
and there's anoth parabol trough with the green line along it bottom .
and it turn out , although thi mai surpris your spatial intuit .
if you add togeth two parabol trough , you get a quadrat bowl .
and elong quadrat bowl , in thi case .
so that's where that error surfac came from .
now , look what happen , if we subtract a hundr from each of those two inbook compon .
we get a complet differ area surfac .
it's , in thi case , it's a circl , it's ideal .
the green line is the line along which the weight add to two .
we're go to take the first weight , and multipli it by on .
we're go to take the second weight and multipli it by on .
and we need to get two .
so the weight better add to two .
the red line is the line along which the two weight ar equal .
becaus we're go to take the first weight , and multipli it by on .
and we're go to take the second weight , and multipli it by on .
so if the weight ar equal , we'll be abl to get that zero that we need .
so the error surfac in thi case is a nice circl where gradient descent is realli easi , and all we did wa subtract <num> from everi input .
if you're think about what happen not with the input but with the hidden unit .
it make sens to have hidden unit that ar hyperbol tangent that go between on and on .
the hyperbol tangent is simpli twice the logist on .
and the reason that make sens is becaus then the activ of the hidden unit ar roughli mean zero and that should make the learn faster in the next level .
of cours , that's onli true if the input to the hyperbol tangent ar distribut sensibl around zero .
but in that respect , a hyperbol tangent is better than a logist .
howev there is other respect in which a logist is better .
for exampl , logist give you a rug to sweep thing under .
it give an output of zero , and if you make the input even smaller than it wa , the output is still zero .
so fluctuat in big nativ input ar ignor by the logist .
for the hyperbol tangent you have to go out to the end of it plateau befor it can ignor anyth .
anoth thing that make a big differ is scale the input .
when we us the steepest descent , scale the input valu is a veri simpl thing to do .
we transform them so that each compon of the input ha unit varianc over the whole train set .
so it ha a typic valu of on or on .
so , again if we take thi simpl net with two rate and we look at the error surfac when the first compon is veri small and the second compon is much bigger .
we get an error surfac in which we get an ellips that ha got a veri high curvatur , when the input compon big becaus small chang in the weight make a big differ in the output .
and veri low curvatur in the direct in which the input compon is small becaus small chang to the weight hardli make ani differ to the error .
the color here is indic which axi we're us , not which train exampl we're us , as it did in the previou slide .
if we simpli chang the varianc of the input , just re scale them .
make the first compon ten time as big and the second compon ten time as small , we now get a nice circular error surfac .
shift and scale the input is a veri simpl thing to do , but someth that's a bit more complic .
that actual work even better caus it's guarante to give you a circl , a circular error surfac .
at least it is for linear neuron .
what we do is we try and decorrel the compon of the input vector .
in other word , if you take two compon and look at how thei're correl with on anoth over the whole train set .
like , if you rememb the earli exampl how the number of portion of chip .
and the number of portion of ketchup might be highli correl .
we want to try and get rid of those correl .
that will make learn much easier .
there's actual mani wai to de correl thing .
for those of you who know about principl compon analysi .
a veri sensibl thing to do is appli principl compon analysi .
remov the compon that have the smallest eigenvalu which alreadi achiev some dimension reduct .
and then scale the remain compon by divid them by the squar root of their eigenvalu .
for a linear system , that will give you a circular error surfac .
if you don't know about principl compon , we'll cover it later in the cours .
onc you got a circular error surfac , the gradient point straight toward the minimum , so learn is realli easi .
now , let's talk about a few of the common problem that peopl encount .
on thing that can happen is if you start with a learn rate that's much too big , you drive the hidden unit either to be firmli on , or firmli off .
that is the incom weight ar veri big in posit or veri big in neg .
and their state no longer depend on the input and of cours that mean that error root is come from output won't affect them , becaus thei ar on the plateau where the deriv is basic zero .
and so learn will stop .
becaus peopl ar expect to see local minimum , when learn stop thei sai , oh , i'm at a local minimum and the error's terribl .
so there ar these realli bad local minimum , usual that's not true .
usual it's becaus you got stuck out on the end of a plateau .
a second problem that occur , is , if you ar classifi thing and you're us either a squar error or a cross entropi error .
the best guess strategi is normal to make the output unit equal to the proport of the time that it should be on .
the network will fairli quickli find that strategi and so the error will fall quickli , but particularli if the network ha mani layer it mai take a long time befor it improv much on that .
becaus to improv over the guess statedgi it ha to get sensibl inform from the input through all the hidden layer to the output and that could take a long time to learn if you start with small weight .
so again , you learn quickli and then the error stop decreas , and it look like a local minimum but actual it's anoth platter .
i mention earlier that toward the end of learn , you should turn down the learn rate .
you should also be care about turn down the learn rate too soon .
when you turn down the learn rate you reduc the random fluctuat in the area do to the differ grade on differ mini batch .
but of cours you also reduc the rate of learn .
so if you look at the red curv you see that when we turn the learn rate down we got a great win .
the error fell but after that we get slower learn .
and if we do that too soon we're gonna loos rel to the green curv .
so don't turn down the learn rate too soon , not too much .
i'm now gonna talk about four main wai to speed up mini batch learn a lot .
the previou thing i talk about were kind of a bag of trick for make thing work better .
and these ar four method all explicitli design to make the learn go much faster .
i'm now gonna talk about a mathic moment .
in thi method we don't us the gradient to chang the posit of the white .
that is , if you think of the white as a ball on the error surfac , standard gradient descent us the gradient to chang the posit of that ball .
you simpli multipli the gradient by a learn rate and chang the posit of the ball by that vector .
in the momentum method , we us the gradient to acceler thi ball .
that is the gradient chang it's veloc .
and then the veloc is what chang the posit of the ball .
the reason that's differ is becaus the bull can have momentum .
that is , it rememb previou gradient in it philosophi .
a second method for speed up when you're batch learn is to us a separ adapt learn rate for each paramet .
and then to slowli adjust that learn rate base on empir measur .
and the obviou empir measur is ar we keep make progress by chang the weight in the same direct ?
or doe the gradient keep oscil around so that the sign of the grade keep chang .
if the sign of the grade keep chang , what we're go to do is reduc the learn rate and if it keep stai the same , we're go to increas the learn rate .
a third method is what i now call rm prop and what we do in thi method is we divid by a run averag of the magnitud of the recent gradient flat weight .
so that if the gradient ar big you divid by a larg number and if the gradient is small and you divid then divid by small number .
that will deal veri nice with a wide rang of differ gradient .
it's actual a mini batch version of just us the sign of the gradient which is a method call r prompt , that wa design for full batch learn .
the final wai of speed up learn , which is what optim peopl would natur recommend , is to us full batch learn .
and to us a fanci method that take curvatur inform into account .
to adapt that method to work for neural net .
and then mayb to try and adapt it some more , so it work with mini batch .
i am not go to talk about that in thi lectur .
in thi video we're go to look at the momentum method for improv the learn speed when do grade descent into neural network .
the momentum method can be appli to full batch learn , but it also work for mini batch learn .
it's veri wide us .
and probabl the commonest recip for learn big neural net is to us stochast grade and descent with mini batch combin with momentum .
i'm go to start with the intuit behind the momentum method .
so , we think of a ball on the area surfac , where the locat of the ball in the horizont plane repres the current weight vector .
the ball start off stationari and so initi it will follow the direct of steepest descent .
it will follow the gradient .
but as soon as it's got some veloc it'll no longer go in the same direct as the gradient .
it momentum will make it keep go in the previou direct .
obvious we want eventu to get to a low point on the surfac , so we want to lose energi .
so we need to introduc a bit of viscos .
that is , we make it veloc die off gentli on each updat .
what the momentum method doe , is it damp oscil in direct of high curvatur .
so if you look at the red start point , and then look at the green point we get to after two step , thei have gradient that ar pretti much equal and opposit .
as a result , the gradient across the ravin ha cancel out .
but the gradient along the ravin ha not cancel out .
along the ravin , we're go to keep build up speed , and so , after the momentum method ha settl down , it'll tend to go along the bottom of the ravin , accumul veloc as it goe , and if you're lucki , that'll make you go a whole lot faster , than if you just judg steepest descent .
the equat of the momentum method ar fairli simpl .
we sai that the veloc vector at time t , is just the veloc vector at time t minu on , time here is the updat of the weight .
so it's the veloc vector that we got after mini batch t minu on , attenu a bit .
so we multipli by some number like point . <num> .
which is realli viscos , or it's relat to viscos .
but unfortun , i call it momentum .
so we now call alpha momentum .
and then we add in the effect of the current gradient , which is to make us go downhil by some learn rate time the gradient that we have at time t and that'll be our new veloc at time t we then make our weight chang at time t equal to veloc .
that veloc can actual be express in term of previou weight chang as it's shown on the slide share .
then i will leav it to you to follow the math .
the behavior of the momentum method is veri intuit .
on an air surfac that's just a plane , the ball will reach some termin veloc of which the gain veloc that come from the gradient is balanc by the multipl attenu of veloc due to the momentum term , which is realli viscos .
if that momentum term is close to on , then it'll be go down much faster than a simpl gradient descent method would .
so the termin veloc , the veloc you get at time infin is the gradient time the learn weight , multipli by thi factor of on over on minu alpha .
so if alpha is <num> . <num> , you'll go <num> time as fast as you would with the learn rate alon .
you have to be care in set momentum .
at the veri begin of learn , if you make the initi random weight quit big , there mai be veri larg gradient .
you have a bunch of weight that's complet no good for the task you're do .
and it mai be veri obviou how to chang these weight to make thing a lot better .
you don't want a big momentum .
becaus you're go to quickli chang them to make thing better .
and then you're go to start on the hard problem of find out how to get just the right rel valu of differ weight .
so you have sensibl featur detector .
so it pai at the begin of learn to have a small momentum .
it is probabl better to have <num> than zero , becaus <num> will averag out some slosh and obviou ravin .
onc the larg gradient have disappear , and you've reach the sort of normal phase of learn , where you're stuck in a ravin .
and you need to go along the bottom of thi ravin without slosh to and fro sidewai .
you can smoothli rais the momentum to it final valu .
or you could rais it in on step , but that might start an oscil .
you might think that , why didn't we just us a bigger learn rate .
but what you'll discov is that , us a small learn rate and a big momentum allow you to get awai with an overal learn rate that's much bigger than you could have had if you us learn rate alon with no momentum .
if you us a big learn rate by itself , you'll get big diverg oscil across the ravin .
veri recent ilya sutskev ha discov that there's a better type of momentum .
the standard momentum method work by first comput the gradient at the current locat .
it combin that with it store memori of previou gradient , which is in the veloc of the ball .
and then it take a big jump in the direct of the current gradient combin with previou gradient .
so that's it accumul gradient direct .
ilya sutskev ha found that it work better in mani case to us a form of momentum suggest by nesterov who wa try to optim convex function , where we first make a big jump in the direct of the previou accumul gradient , and then we measur the gradient where we end up and make a correct .
it's veri , veri similar , and you need a pictur to realli understand the differ .
on wai of think about what's go on is in the standard momentum method , you add in the current gradient and then you gambl on thi big jump .
in the nesterov method , you us your previous accumul gradient , you make the big jump and then you correct yourself at the place you've got to .
so here's the pictur , when we first make the jump and then make a correct .
here is a stamp in the direct of the accumul gradient .
so thi depend on the gradient that we've accumul on , in our previou iter .
we take that step .
we then make it the gradient , and go downhil in the direct of the gradient .
like that .
we then combin that littl correct stat with the big jump we made to get our new accumul gradient .
we then take that accumul gradient , we attenu it by some number , like nine .
or <num> .
multipli it by that number , and we now take our next big jump in the direct of that accumul gradient , like that .
then again , at the place where we end up , we measur the gradient and we go downhil .
that correct ani error you made , and we our new accumul gradient .
now if you compar that with the standard momentum method , the standard momentum method start with a accumul gradient , like that initi brand vector , but then it measur the gradient where it is , so it measur the gradient at it current locat , and it add that to the brown vector , so that it make a jump like thi big blue vector .
that is just the brown vector plu the current gradient .
it turn out , if you're go to gambl , it's much better to gambl and then make a correct , than to make a correct and then gambl .
in thi video , we're go to look at a method that wa develop in the late <num>'s by robbi jacob and then improv by a number of other peopl .
the idea is that each connect in the neural net should have it own adapt learn rate , which we set empir by observ what happen to the weight on that connect when we updat it .
so that if the weight keep revers it gradient , we turn down the learn weight .
and if the gradient stai consist , we turn up the learn weight .
so , let's start by think why have separ adapt learn weight on each connect is a good idea .
the problem is , thei're in a deep multilay net .
the learn weight can vari wide between differ weight , especi between weight in differ layer .
so , if for exampl , we start with small weight , the gradienc start from much smaller in the initi layer than in the later layer .
anoth factor that caus on differ learn rate for differ weight is the fan in of the unit .
the fan in determin the size of the overshoot effect that you get when you simultan chang mani of the differ incom weight to fix up the same error .
it mayb that the unit didn't get enough input , when you chang all these weight at the same time to fix up the error , it now get too much input .
obvious , that effect is go to be bigger if there's a bigger fan in .
so , the net in the diagram on the right ha the same fain in for both layer more or less the same fain in for both layer , but that's veri differ in some net .
so , the idea is that we're go to us a global learn weight which we set by hand , and then we're go to multipli it by a local gain that is determin empir for each weight .
a simpl wai to determin what those local gain should be is to start with a local gain of on for everi weight .
so that , initi we're go to chang the weight , wij , by the learn rate time the gain of on , gij time the error deriv for that weight .
then , what we're go to do is we're go to adapt gij .
we're go to increas gij if the gradient for the weight doe not chang side .
and we're go to us small addit increas , and multipl decreas .
so , if the gradient for the weight at time t ha the same sign as the gradient for the weight at time t minu on , with t refer to weight updat , then when you take that product , it'll be posit .
cuz you alreadi get two neg gradient or two posit gradient , and then what we're go to go is increas gij by small addit amount .
if the gradient have opposit sign , we're go to decreas gij .
and becaus we want to damp down gij quickli if it's alreadi big , we're go to decreas it multipl .
that ensur that big gain will decai veri rapidli if oscil start .
it's interest to ask what would happen if the grade wa total random .
so , on each updat of the weight , pick a random gradient .
then , you'll get an equal number of increas and decreas cuz it will equal often be the same sign as the previou gradient or the opposit sign .
and so , you'll get a bunch of addit <num> . <num> increas , and multipl <num> . <num> decreas , and thei have an equilibrium point which is when the gain is on .
if the gain's bigger than on , the multipli by <num> . <num> will reduc it by more than ad <num> . <num> .
if the gain's smaller than on , ad <num> . <num> will increas it more than multipli by <num> . <num> decreas it .
so , with random gradient , we'll hover around on .
and if the gradient is consist in the same direct we can get much bigger than on .
if the gradient is consist in opposit direct , which mean we're oscil across a ravin , we can get much smaller than on .
there's a number of trick for make the adapt learn rate work better .
it's import to limit the size of the gain .
a reason rang is <num> to ten .
or <num> to <num> .
you don't want the gain to get huge becaus then you can easili get into an instabl and thei won't die down fast enough , and you'll destroi all the weight .
the adapt learn rate wa design for full batch learn .
you can also appli it with mini batch but thei had better be pretti big mini batch .
that'll ensur that the sign , chang sign of gradienc aren't due to the sampl error of mini batch , thei ar realli due to the other side of the ravin .
there's noth to prevent you combin adapt learn rate with momentum .
so , jacob suggest that , instead of us the agreement in sign between the current gradient and the previou gradient , you us the agreement in sign between the current gradient and the veloc for that weight , so the accumul gradient .
and , if you do that , you get a nice combin of the advantag of momentum , and the advantag of adapt learn rate .
so , adapt learn rate onli deal with axi of line defect .
wherea , momentum doesn't care about the align of the axi .
momentum can deal with these diagon ellips and go in that diagon direct quickli which adapt learn rate can't do .
in thi video , i'm first go to introduc a method call rprop , that is us for full batch learn .
it's like robbi jacob method , but not quit the same .
i'm then go to show how to extend rprop so that it work for mini batch .
thi give you the advantag of rprop and it also give you the advantag of mini batch learn , which is essenti for larg , redund data set .
the method that we end up with call rm pro is current my favorit method as a sort of basic method for learn the weight in a larg neural network with a larg redund data set .
i'm now go to describ rprop which is an interest wai of try to deal with the fact that gradient vari wide in their magnitud .
some gradient can be tini and other can be huge .
and that make it hard to choos a singl global learn rate .
if we're do full batch learn , we can cope with thi big variat in gradient , by just us the sign of the gradient .
that make all of the weight updat be the same size .
for issu like escap from plateau with veri small gradient thi is a great techniqu caus even with tini gradient we'll take quit big step .
we couldn't achiev that by just turn up the learn rate becaus then the step we took for weight that had big gradient would be much to big .
rprop combin the idea of just us the sign of the gradient with the idea of make the step size .
depend on which weight it is .
so to decid how much to chang your weight , you don't look at the magnitud of the gradient , you just look at the sign of the gradient .
but , you do look at the step size you decid around for that weight .
and , that step size adopt over time , again without look at the magnitud of the gradient .
so we increas the step size for a weight multipl .
for exampl by factor <num> .
if the sign of the last two gradient agre .
thi is like in robbi jacob' adapt weight method except that we did , gonna do a multipl increas here .
if the sign of the last two gradient disagre , we decreas the step size multipl , and in thi case , we'll make that more power than the increas , so that we can die down faster than we grow .
we need to limit the step size .
mike shuster's advic wa to limit them between <num> and a millionth .
i think it depend a lot on what problem you're deal with .
if for exampl you have a problem with some tini input , you might need veri big weight on those input for them to have an effect .
i suspect that if you're not deal with that kind of problem , have an upper limit on the weight chang that's much less than <num> would be a good idea .
so on question is , why doesn't rprop work with mini batch .
peopl have tri it , and find it hard to get it to work .
you can get it to work with veri big mini batch , where you us much more conserv chang to the step size .
but it's difficult .
so the reason it doesn't work is it violat the central idea behind stochast gradient descent , which is , that when we have a small loan rate , the gradient get effect averag over success mini batch .
so consid a weight that get a gradient of . <num> on nine mini batch , and then a gradient of . <num> on the tenth mini batch .
what we'd like is those gradient will roughli averag out so the weight will stai where it is .
rprop won't give us that .
rprop would increment the weight nine time by whatev it current step size is , and decrement it onli onc .
and that would make the weight get much bigger .
we're assum here that the step size adapt much slower than the time scale of these mini batch .
so the question is , can we combin the robust that you get from rprop by just us the sign of the gradient .
the effici that you get from mani batch .
and thi averag of gradient over mini batch is what allow mini batch to combin gradient in the right wai .
that lead to a method which i'm call rmsprop .
and you can consid to be a mini batch version of rprop .
rprop is equival to us the gradient , but also divid by the magnitud of the gradient .
and the reason it ha problem with mini batch is that we divid the gradient by a differ magnitud for each mini batch .
so the idea is that we're go to forc the number we divid by to be pretti much the same for nearbi mini batch .
we do that by keep a move averag of the squar gradient for each weight .
so mean squar wt mean thi move averag for weight w at time t , where time is an indic of weight updat .
time increment by on each time we updat the weight the number i put in of <num> and <num> for comput move averag ar just exampl , but their reason sensibl exampl .
so the mean squar is the previou mean squar time <num> , plu the valu of the squar gradient for that weight at time t , time <num> .
we then take that mean squar .
we take it squar root , which is why it ha the name rm .
and then we divid the gradient by that rm , and make an updat proport to that .
that make the learn work much better .
notic that we're not adapt the learn rate separ for each connect here .
thi is a simpler method where we simpli , for each connect , keep a run averag of the rout mean squar gradient and divid by that .
there's mani further develop on could make for rmsprop .
you could combin the standard moment .
my experi so far suggest that doesn't help as much as momentum normal doe , and that need more investig .
you could combin our rmsprop with nesterov momentum where you first make the jump and then make a correct .
and ilya sutskev ha tri that recent and got good result .
he's discov that it work best if the rm of the recent gradient is us to divid the correct term we make rather than the larg jump you make in the direct of the accumul correct .
obvious you could combin rmsprop with adapt learn rate on each connect which would make it much more like rprop .
that just need a lot more investig .
i just don't know at present how help that will be .
and then there is a bunch of other method relat to rmsprop that have a lot in common with it .
yann lecun's group ha an interest paper call no more peski learn rate that came out thi year .
and some of the term in that look like rmsprop , but it ha mani other term .
i suspect , at present , that most of the advantag that come from thi complic method recommend by yann lecun's group come from the fact that it's similar to rmsprop .
but i don't realli know that .
so , a summari of the learn method for neural network , goe like thi .
if you've got a small data set , sai <num> , <num> case or less , or a big data set without much redund , you should consid us a full batch method .
thi full batch method adapt from the optim literatur like non linear conjug gradient or lbfg , or levenbergmarkhart , marquardt .
and on advantag of us those method is thei typic come with a packag .
and when you report the result in your paper you just have to sai , i us thi packag and here's what it did .
you don't have to justifi all sort of littl decis .
altern you could us the adapt learn rate i describ in anoth video or rprop , which ar both essenti full batch method but thei ar method that were develop for neural network .
if you have a big redund data set it's essenti to us mini batch .
it's a huge wast not to do that .
the first thing to try is just standard gradient descent with momentum .
you're go to have to choos a global learn rate , and you might want to write a littl loop to adapt that global learn rate base on whether the gradient ha chang side .
but to begin with , don't go for anyth as fanci as adapt individu learn rate for individu weight .
the next thing to try is rm prop .
that's veri simpl to implement if you do it without momentum , and in my experi so far , that seem to work as well as gradient descent with momentum , would be better .
you can also consid all sort of wai of improv rmsprop by ad momentum or adapt step size for each weight , but that's still basic unchart territori .
final , you could find out whatev yann lecun's latest receipt is and try that .
he's probabl the person who's tri the most differ wai of get stochast gradient descent to work well , and so it's worth keep up with whatev he's do .
on question you might ask is why is there no simpl recip .
we have been mess around with neural net , includ deep neural net , for more than <num> year now , and you would think that we would come up with an agre wai of do the learn .
there's realli two reason i think why there isn't a simpl recip .
first , neural net differ a lot .
veri deep network , especi on that have narrow bottleneck in them , which i'll come to in later lectur , ar veri hard thing to optim and thei need method that can be veri sensit to veri small gradient .
recur net ar anoth special case , thei're typic veri hard to optim , if you want them to notic thing that happen a long time in the past and chang the weight base on these thing that happen a long time ago .
then there's wide shallow network , which ar quit differ in flavor and ar us a lot in practic .
thei often can be optim with method that ar not veri accur .
becaus we stop the optim earli befor it start overfit .
so for these differ kind of network , there's veri differ method that ar probabl appropri .
the other consider is that task differ a lot .
some task requir veri accur weight .
some task don't requir weight to be veri accur at all .
also there's some task that have weird properti , like if your input ar word rare word mai onli occur on on case in a hundr thousand .
that's a veri , veri differ flavor from what happen if your input ar pixel .
so to summar we realli don't have nice clear cut advic for how to train a neural net .
we have a bunch of rule of sum , it's not entir satisfactori , but just think how much better in your all natur work onc we've got thi sort out , and thei alreadi work pretti well .
in thi video , i am go to give an overview of variou type of model that have been us for sequenc .
i'll start with the simplest kind of model , which is ultra aggress model , that just try and predict the next term or the sequenc from previou term .
i'll talk about more elabor variant of them us hidden unit .
and then i'll talk about , more interest kind of model , that have hidden state , and hidden dynam .
these includ linear dynam system and hidden markov model .
most of these ar quit complic kind of model , and i don't expect you to understand all the detail of them .
the main point of mention them is to be abl to show how recurr your own network ar relat to model of that kind .
when we're us machin learn to model sequenc , we often want to turn on sequenc into anoth sequenc .
for exampl , we might want to turn english word into french word or we might want to take a sequenc of sand pressur and turn it into a sequenc of word ident which is what's happen in speech recognit .
sometim we don't have a separ target sequenc , and in that case we can get a teach signal by try to predict the next term in the input sequenc .
so the target output sequenc is simpli the input sequenc with an advanc of on time step .
thi seem much more natur , than try to predict on pixel in an imag from all the other pixel or on patch of an imag from the rest of the imag .
on reason it probabl seem more natur is that for tempor sequenc , there is a natur order to do the predict in .
wherea for imag it's not clear what you should predict from what .
but in fact a similar approach work veri well for imag .
when we predict the next term in a sequenc , it blur the distinct , between supervis and unsupervis learn , that i made at begin of the cours .
so we us method that were design for supervis learn to predict the next term .
but we don't requir separ teach signal .
so in that sens , it's unsupervis .
i'm now go to give a quick review of some of the , other model of sequenc , befor we get on to us recurr neural net to model sequenc .
so a nice simpl model for sequenc that doesn't have ani memori is an auto regress model .
what that doe is take some previou term in the sequenc and try and predict the next term basic as a weight averag of previou term .
the previou term might be individu valu or thei might be whole vector .
and a linear auto regress model would just take a weight averag of those to predict the next term .
we can make that consider more complic by ad hidden unit .
so in a feedforward neural net , we might take some previou input term , put them through some hidden unit , and predict the next term .
memori list model ar onli on subclass of model that can be us for sequenc .
we can think about wai of gener sequenc , and on veri natur wai to gener a sequenc is to have a model that ha some hidden state which ha it own intern dynam .
so , the hidden state evolv accord to it intern dynam , and the hidden state also produc observ , and we get to see those observ .
that's a much more interest kind of model .
it can store inform in it hidden state for a long time .
unlik the memoryless model , there's no simpl band , to how far we have to look back befor we can be sure it's not affect thing .
if the dynam of the hidden state is noisi and the wai it gener output from it hidden state is noisi , then by observ the output of a gener model like thi , you can never know for sure what it's hidden state wa .
the best you can do is to infer probabl distribut over the space of all possibl hidden state vector .
you can know that it's probabl in some part of the space and not anoth part of the space , but you can't pin it down exactli .
so with a gener model like thi , if you get to observ what it produc , and you now try to infer what the hidden state wa , in gener that's veri hard , but there's two type of hidden state model for which the comput is tractabl .
that is , there's a fairli straightforward comput that allow you to infer the probabl distribut over the hidden state vector that might have caus the data .
of cours when we do thi and appli it to real data .
we're assum that the real data is gener by our model .
so that's typic what we do when we're model thing .
we assum the data wa gener by the model and then we infer what state the model must have been in , in order to gener that data .
the next three slide ar mainli intend for peopl who alreadi know about the two type of hidden state model i'm go to describ .
the point of the slide is so that i make it clear how recurr neural network differ from those standard model .
if you can't follow the detail of the two standard model , don't worri too much .
that's not the main point .
so on standard model is a linear dynam system .
it's veri wide us in engin .
thi is a gener model that ha real valu hidden state .
the hidden state ha linear dynam , shown by those red arrow on the right .
and the dynam ha gaussian nois , so that the hidden state evolv probabilist .
there mai also be drive input , shown at the bottom there , which directli influenc the hidden state .
so the input , influenc the hidden state directli , the hidden state determin the output to predict the next output of a system like thi , we need to be abl to infer it hidden state .
and these kind of system ar us , for exampl , for track missil .
in fact , on of the earliest us of gaussian distribut wa for try to track planet from noisi observ .
gaussian actual figur out that , if you assum gaussian nois , you could do a good job of that .
on nice properti that a gaussian ha is that if you linearli transform a gaseon you get anoth gaussian .
becaus all the nois in a linear dynam system is gaseon .
it turn out that the distribut over the hidden state given the observ so far , that is given the output so far , is also a gaussian .
it's a full covari gaussian , and it's quit complic to comput what it is .
but it can be comput effici .
and there's a techniqu call kalman filter .
thi is an effici recurs wai of updat your represent of the hidden state given a new observ .
so , to summar , given observ of the output of the system , we can't be sure what hidden state it wa in , but we can , estim a gaussian distribut over the possibl hidden state it might have been in .
alwai assum , of cours , that our model is a correct model of the realiti we're observ .
a differ kind of hidden state model that us discret distribut rather than gaussian distribut , is a hidden markov model .
and becaus it's base on discret mathemat , comput scientist love these on .
in a hidden markov model , the hidden state consist of a on of n .
choic .
so there a number of thing call state .
and the system is alwai in exactli on of those state .
the transit between state ar probabilist .
thei're control by a transit matrix which is simpli a bunch of probabl that sai , if you're in state on at time on , what's the probabl of you go to state three at time two ?
the output model is also stochast .
so , the state that the system is in doesn't complet determin what output it produc .
there's some variat in the output that each state can produc .
becaus of that , we can't be sure which state produc a given output .
in a sens , the state ar hidden behind thi probabilist veil , and that's why thei're call hidden .
histor the reason hidden unit in a neural network ar call hidden , is becaus i like thi term .
it sound mysteri , so i stole it from neural network .
it is easi to repres the probabl distribut across n state with n number .
so , the nice thing about a hidden markov model , is we can repres the probabl distribut across it discreet state .
so , even though we don't know what it , what state it's in for sure , we can easili repres the probabl distribut .
and to predict the next output from a hidden markov model , we need to infer what hidden state it's probabl in .
and so we need to get our hand on that probabl distribut .
it turn out there's an easi method base on dynam program that allow us to take the observ we've made and from those comput the probabl distribut across the hidden state .
onc we have that distribut , there is a nice eleg learn algorithm hidden markov model , and that's what made them so appropri for speech .
and in the 1970s , thei took over speech recognit .
there's a fundament limit of hmm .
it's easiest to understand thi limit , if we consid what happen when a hidden markov model gener data .
at each time step when it's gener , it select on of it hidden state .
so if it's got n hidden state , the tempor inform store in the hidden state is at most logn n bit .
so that's all it know about what it's done so far .
so now let's consid how much inform a hidden markov model can convei to the second half of an utter it produc from the first half .
so imagin it's alreadi produc the first half of an utter .
and now it's go to have to produc the second half .
and rememb , it memori of what it said for the first half is in which of the n state it's in .
so it memori onli ha log n bit of inform in it .
to produc the second half that's compat with the first half , we must make the syntax fit .
so for exampl , the number intend must agre .
it also need to make the semant fit .
it can't have the second half of the sentenc be about someth total differ from the first half .
also the inton need to fit so it would look veri silli if the , inton contour complet chang halfwai through the sentenc .
there's a lot of other thing that also have to fit .
the accent of the speaker , the rate thei're speak at , how loudli thei're speak .
and the vocal tract characterist of the speaker .
all of those thing must fit between the second half of the sentenc and the first half .
and so if you want a hidden markov model to actual gener a sentenc , the hidden state ha to be abl to convei all that inform from the first half to the second half .
now the problem is that all of those aspect could easili come to a hundr bit of inform .
so the first half of the sentenc need to convei a hundr bit of inform to the second half and that mean that the hidden markov model need two to the hundr state and that's just too mani .
so that bring us to recurr your own network .
thei have a much more effici wai of rememb inform .
thei're veri power becaus thei combin two properti that have distribut hidden state .
that mean , sever differ unit can be activ at onc .
so thei can rememb sever differ thing at onc .
thei don't just have on activ unit .
thei're also nonlinear .
you see , a linear dynam system ha a whole hidden state vector .
so it's got more than on valu at a time , but those valu ar constrain to act in a linear wai so as to make infer easi , and in a recurr neural network we allow the dynam to be much more complic .
with enough neuron and enough time , a recur neuron network can comput anyth that can be comput by your comput .
it's a veri power devic .
so linear dynam system and hidden mark off model ar both stochast model .
that is the dynam and the product of observ from the underli state both involv intrins nois .
and the question is do model need to be like that .
well on thing to notic is that the posterior probabl distribut over hidden state in either a limit anom system or hidden markoff model is a determinist function of the data that you've seen so far .
that is the infer algorithm for these system end up with a probabl distribut , and that probabl distribut is just a bunch of number , and those number ar a determinist version of the data so far .
in a recurr neural network , you get a bunch of number that ar a determinist function of the data so far .
and it might be a good idea to think of those number that constitut the hidden state of a recurr neural network .
thei're veri like the probabl distribut for these simpl stocast model .
so what kind of behavior can recur at your own network exhibit ?
well , thei can oscil .
that's obvious good for thing like motion control , where when you're walk , for exampl , you want to know regular oscil , which is your stride .
thei can settl to point attractor .
that might be good for retriev memori .
and later on in the cours we'll look at hopfield net where thei us the settl to point attractor to store memori .
so the idea is you have a sort of rough idea of what you're try to retriev .
you then let the system settl down to a stabl point and those stabl point correspond to the thing you know about .
and so by settl to that stabl point you retriev a memori .
thei can also behav chaotic if you set the weight in the appropri regim .
often , chaotic behavior is bad for inform process , becaus in inform process , you want to be abl to behav reliabl .
you want to achiev someth .
there ar some circumst where it's a good idea .
if you're up against a much smarter adversari , you probabl can't outwit them , so it might be a good idea just to behav randomli .
and on wai to get the appear of random is to behav chaotic .
on nice thing about r and n's , which , a long time ago , i thought wa gonna make them veri power , is that an r and n could learn to implement lot of littl program , us differ subset of it hidden state .
and each of these littl program could captur a nugget of knowledg .
and all of these thing could run in parallel , and interact with each other in complic wai .
unfortun the comput power of recurr neural network make them veri hard to train .
for mani year , we couldn't exploit the comput power of recurr neural network .
it wa some heroic effort .
for exampl , toni robinson manag to make quit a good speech recogn us recurr net .
he had to do a lot of work implement them on a parallel comput built out of transput .
in thi video , i'm go to talk about the back propag through time algorithm .
it's the standard wai to train or recurr your own network .
the algorithm is realli quit simpl onc you have seen the equival between a recurr neural network and a feed forward neural network that ha on layer for each time step .
i'll also talk about wai of provid input , and desir output , to recurr neural network .
so the diagram show a simpl recurr net with three interconnect neuron .
we're go to assum there's a time delai of on in us each of those connect and that the network run in discret time , so the clock that ha integ tick .
the kei to understand how to train a recurr network is to see that a recurr network is realli just the same as a feed forward network , where you've expand the recurr network in time .
so the recurr network start off in some initi state .
shown at the bottom there , time zero .
and then us the wai some of these connect to get a new state , shown at time on .
you then us the same weight again to get anoth new state , and it us the same weight again to get anoth new state and so on .
so it's realli just a lead feed forward network , where the weight is a constraint to be the same at everi layer .
now backprop is good at learn when there ar weight constraint .
we saw thi for convolut net and just to remind you , we can actual incorpor ani linear constraint quit easili in backprop .
so we comput the gradient as usual , as if the weight were not constrain .
and then we modifi the gradient , so that we maintain the constraint .
so if we want w1 to equal w2 , we start off with an equal and then we need to make sure that the chang w1 is equal to the chang w2 .
and we do that by simpli take the deriv of the area with respect to w1 , the deriv with respect to w2 , and ad or averag them , and then appli the same quantiti for updat both w1 and w2 .
so if the weight start off satisfi the constraint thei'll continu to satisfi the constraint .
the backpropag through time algorithm is just the name for what happen when you think of a recurr net as a lead feet forward net with share weight , and you train it with backpropag .
so , we can think of that algorithm in the time domain .
the forward pass build up a stack of activ at each time slice .
and the backward pass peel activ off that stack and comput error deriv each time step backward .
that's why it's call back propag through time .
after the backward pass we can add togeth the deriv at all the differ time step for each particular weight .
and then chang all the copi of that weight by the same amount which is proport to the sum or averag of all those deriv .
there is an irrit extra issu .
if we don't specifi the initi state of the all the unit , for exampl , if some of them ar hidden or output unit , then we have to start them off in some particular state .
we could just fix those initi state to have some default valu like <num> , but that might make the system work not quit as well as it would otherwis work if it had some more sensibl initi valu .
so we can actual learn the initi state .
we treat them like paramet rather than activ and we learn them the same wai as learn the weight .
we start off with an initi random guess for the initi state .
that is the initi state of all the unit that aren't input unit and then at the end of each train sequenc we back propag through time all the wai back to the initi state .
and that give us the gradient of the error function with respect to the initi state .
we then just , adjust the initi state by follow , that gradient .
we go downhil in the gradient , and that give us new initi state that ar slightli differ .
there's mani wai in which we can provid the input to a recurr neural net .
we could , for exampl , specifi the initi state of all the unit .
that's the most natur thing to do when we think of a recurr net , like a feed forward net with constrain weight .
we could specifi the initi state of just a subset of the unit or we can specifi the state at everi time stamp of the subset of the unit and that's probabl the most natur wai to input sequenti data .
similarli , there's mani wai we can specifi target for a recurr network .
when we think of it as feed forward network with constrain weight , the natur thing to do is to specifi the desir final state for all of the unit .
if we're try to train it to settl to some attractor , we might want to specifi the desir state not just for the final time step but for sever time step .
that will caus it to actual settl down there , rather than pass through some state and go off somewher els .
so by specifi sever state of the end , we can forc it to learn attractor and it's quit easi as we back propag to add in deriv that we get from each time stamp .
so the back propeg start at the top , with the deriv for the final time stamp .
and then as we go back through the line befor the top we add in the deriv for that man , and so on .
so it's realli veri littl extra effort to have deriv at mani differ layer .
or we could specifi the design activ of a subset of unit which we might think of as output unit .
and that's a veri natur wai to train a recurr neural network that is meant to be provid a continu output .
in thi video , i'm go to describ how a recurr neural network solv a toi problem .
it's a problem that's chosen to demonstr what it is you can do with recurr neural network that you cannot do conveni with feet forward neural network .
the problem is ad up two binari number .
off to the recurr neural network , ha learn to solv the problem .
it's interest to look at it hidden state , and see how thei relat to the hidden state in a finit state automaton that's solv the same problem .
so consid the problem of ad up two binari number .
we could train a feed forward neural network to do that .
and the diagram on the right show a network that get some input and produc some output .
but there's problem with us a feed forward neural network .
we have to decid in advanc what the maximum number of digit is both for both of the input number and for the output number .
and more importantli , the process that we appli to the differ bit of the input number , doesn't gener .
that is , when we learn how to add up the last two digit and deal with the carri , that knowledg in some weight .
and as we go to a differ part of a long binari number , the knowledg will have to be in differ weight .
so we won't get automat gener .
as a result , although you can train a neuron feedfoward neural network , and it will eventu learn to do binari addit on fix length number , it's not an eleg wai to solv the problem .
thi is a pictur of the algorithm for binari addit .
the state shown here ar like the state in a hidden markov model , except thei're not realli hidden .
the system is in on state at a time .
when it enter a state it perform an action .
so it either print a on or print a zero and when it's in a state it get some input , which is the two number in the next column .
and that input caus it to go into a new state .
so if you look on the top right , it's in the carri station and it's just print a on .
if it see a on , on , it goe back in to the same stage and print anoth on .
if howev it see a on , zero or zero , on , it goe into the carri state but print a zero .
if it see a zero , zero , it goe into the no carri state , and print a on .
and so on .
so a recur neuro net for binari edit need to have two input unit and on output unit .
it's given two input digit at each time stamp .
and it also ha to produc an output at each time step .
and the output is the output for the column that it took in two time step ago .
the reason we need a delai of two time step , is that it take on time step to updat the hidden unit base on the input , and anoth time step to produc the output from the hidden state .
so the net look like thi .
i onli gave it three hidden unit .
that's suffici to do the job .
it would learn faster with more hidden unit , but it can do it with three .
the three hidden unit ar fulli interconnect and thei have connect in both direct that don't necessarili have the same weight .
in fact in gener thei don't have the same weight .
the connect between hidden unit allow the pattern of on time step to insens the pattern of the next time step .
the input unit have feed forward connect to the hidden unit and that's how it see the two digit in a column .
and similarli , the hidden unit have feed forward connect to the output unit and that's how it produc it output .
it's interest to look at what the recur neural network learn .
it learn four distinct pattern of activ in it three hidden unit .
and these pattern correspond to the node in the finit state automaton for binari addit .
we must confus the unit in a neural network , with the node in a final state automaton .
the node in the finit state automaton correspond to the activ vector of the recurr neural network .
the automaton is restrict to be exactli on state at each time .
and similarli , the hidden unit ar restrict to have exactli on activ vector at each time in the recurr neural network .
so a recurr neural network can emul a finit state automaton but it's exponenti more power in it represent .
with ani hidden neuron , it ha 2n to the n possibl binari activ vector .
of cours it onli ha n squar weight so it can't necessarili make full us of all that represent power .
but if the bottleneck is in the represent a recurr neural network can do much better than a finit state automaton .
thi is import when the input stream ha two separ thing go on at onc .
a finit state automaton need to squar it number of state in order to deal with the fact that there's two thing go on at onc .
a recurr neural network onli need to doubl it number of hidden unit .
by doubl the number of unit , it doe of cours squar the number of binari vector state that it ha .
in thi video , i'm go to talk about the explod and vanish gradient problem , which is what make it difficult to train recurr neural network .
for mani year , research in url network thought thei would never be abl to train these network to model depend over long time period .
but at the end of thi video , i can describ four differ wai in which that can now be done .
to understand why it's so difficult to train recurr neural network , we have to understand a veri import differ between the forward and backward pass in a recurr neural net .
in the forward pass , we us squash function , like the logist , to prevent the activ vector from explod .
so , if you look at the pictur on the right , each neuron is us a logist unit shown by that blue curv and it can't output ani valu greater than on or less than zero , so that stop explos .
the backward pass , howev , is complet linear .
most peopl find thi veri surpris .
if you doubl the error deriv is it the final layer of thi net , all the error deriv will doubl when you back propag .
so , if you look at the red dot that i put on the blue curv , we'll suppos those ar the activ level of the neuron on the forward pass .
and so , when you back propag , you're us the gradient of the blue curv at those red dot .
so the red line ar meant to throw the tangent to the blue curv at the red dot .
and , onc you finish the forward pass , the slope of that tangent is fix .
you now back propag and the back propag is like go forward though a linear system in which the slope of the non linear ha been fix .
of cours , each time you back propag , the slope will be differ becaus thei were determin by the forward pass .
but dure the back propag , it's a linear system and so it suffer from a problem of linear system , which is when you iter , thei tend to either explod or die .
so when we backpropag through mani layer if the weight ar small the gradient will shrink and becom exponenti small .
and that mean that when you backpropag through time gradient that ar mani step earlier than the target arriv will be tini .
similarli , if the weight ar big , the gradient will explod .
and that mean when you back propag through time , the gradient will get huge and wipe out all your knowledg .
in a feed forward neural net , unless it's veri deep , these problem aren't nearli as bad becaus we typic onli have a few hidden layer .
but as soon as we have a recurr neural network train on a long sequenc , for exampl <num> time step , then if the gradient ar grow as we back propag , we'll get whatev that growth rate is to the power of <num> and if thei're dy , we'll get whatev that decai is to the power of <num> and , so , thei'll either explod or vanish .
we might be abl to initi the weight veri carefulli to avoid thi and more recent work , show that inde care initi of the weight doe make thing work much better .
but even with good initi weight , it's hard to detect the depend of the current output or an input from mani time step ago .
so it's hard to make the output depend on thing that happen a long time ago .
rnn's have difficulti deal with long rang depend .
here's an exampl of explod and dy gradient for a system that's try to learn attractor .
so suppos we try and train a recurr neural network , so that whatev state we start in , it end up in on of these two attractor state .
so we're go a learn blue basin of attract and a pink basin of attract .
and if we start anywher within the blue basin of attract , we will end up at the same point .
what that mean is that , small differ in our initi state make no differ to where we end up .
so the deriv of the final state with respect to chang in the initi state , is zero .
that's vanish gradient .
when we back propag through the dynam of thi system we will discov there's no gradienc from where you start , and the same with the pink basin of attract .
if howev , we start veri close to the boundari between the two attractor .
then , a tini differ in where we start , that's the other side of the watersh , make the huge differ to where we end up , that's the explos gradient problem .
and so whenev your try to us a recurr neural network to learn attractor like thi , you're bound to get vanish or explod gradient .
it turn out , there's at least four effect wai to learn a recurr neural network .
the first is a method call long short term memori and i'll talk about that more in thi lectur .
the idea is we actual chang the architectur of the neural network to make it good at rememb thing .
the second method is to us a much better optim that can deal with veri small gradient .
i'll talk about that in the next lectur .
the real problem in optim is to detect small gradient that have an even smaller curvatur .
heissan free optim , tailor to your own app is good at do that .
the third method realli kind of evad the problem .
what we do is we carefulli initi the input to hidden weight and we veri carefulli initi the hidden to hidden weight , and also feedback weight from the output to the hidden unit .
and the idea of thi care initi is to make sure that the hidden state ha a huge reservoir of weakli coupl oscil .
so if you hit it with an input sequenc , it will reverber for a long time and those reverber ar rememb what happen in the input sequenc you then try and coupl those reverber to the output you want and so the onli thing that learn in an echo state network is the connect between the hidden unit and the output .
and if the output unit ar linear , that's veri easi to train .
so thi hasn't realli learn the recurr .
it's us a fix random recurr bit , but a carefulli chosen on and then just learn the hidden tripod connect .
and the final method is to us momentum , but to us momentum with the kind of initi that wa be us for echo state network and that make them work even better .
so it wa veri clever to find out how to initi these recurr network so thei'll have interest dynam , but thei work even better if you now modifi that dynam slightli in that direct that will help with the task at hand .
in thi video , i am go to describ an approach to train recurr neural network that's call long short term memori .
you can consid the dynam state of a neural network to be a short term memori .
and the idea is , you want to make that short term memori last for a long time .
thi is done by creat special modul that ar design to allow inform to be gate in , and then inform to be gate out when need .
and in the intermedi period , the gate is close , so the stuff that arriv in the intermedi period doesn't interfer with the rememb state .
long short term memori ha been veri success for task like recogn handwrit , where it's won a number of competit .
in <num> , hochreit schmidhub publish a paper in neural comput that solv the problem of get a recur neural network to rememb thing for a long time .
there recurr net could rememb thing for hundr of time step .
thei did thi by design a memori cell that us logist and linear unit with multipl interact .
so inform get into the memori cell whenev a logist write gate is turn on .
the rest of the recurr network determin the state of that write gate , and when the rest of the recurr network want inform to be store , it turn the write gate on , and whatev the current input from the rest of the net to the memori cell is , get store in the memori cell .
the inform stai in the memori cell so long as it keep gate is on .
so again , the rest of the system is determin the state of a logist keep gate , and if it keep it on , then the inform will stai there .
and final , the inform get read from the memori cell so that it then goe off to the rest of the recurr neural network and influenc futur state and it's read by turn on a read gate , which again is a logist unit control by the rest of the neural network .
the memori cell actual store an analog valu , so we can think of it as a linear neuron that ha an analog valu and keep write that valu to itself at each time step by a weight of on , so the inform just stai there .
the weight of on is determin by a keep gate so the rest of the system determin the state of that logist keep gate and if it put it into a state of on or close to on the inform just cycl around and that valu of <num> . <num> will stai there .
as soon as the rest of the system want to get rid of that valu , all it ha to do is set the keep gate to have a valu of zero and the inform will disappear .
to store the inform in the memori cell , the rest of the system ha to turn on the write gate .
and then whatev input is be provid to the memori cell from the rest of the system will get written into the memori cell .
similarli , to read the inform from the memori cell , the rest of the system turn on the logist read gate and then , the valu in the memori cell come out and affect the rest of the recur neural network .
the point of us logist unit is that we can back propag through them becaus thei have nice deriv , and that mean we can learn to us thi kind of circuit over mani time step .
so i'm go to show you now a pictur of what backpropag through a memori cell look like .
first we're go to do a forward pass .
so at the initi time , let's suppos that the keep gate wa set to zero , so we wipe out whatev inform wa in the memori cell befor , and the write gate is set to on .
so the valu of <num> that is come from the rest of the recurr neural network get written into the memori cell .
and we're not go to read it at thi time , so the read gate is set to zero .
we then set the keep gate to on , or rather the rest of the , neural network ha to set the keep gate to on , and that mean that the valu is written back into the memori cell .
it's store .
at the next time step , we're go to set the right gate to zero and the read gate to zero , so the inform isn't influenc by what's go on in the rest of the net , and it doesn't influenc what's go on in the rest of the net .
it's insul .
again , at the next time step , the keep gate is set to on , so the inform is store for on more time step .
and then , we're go to t set the right gate to zero , so no inform is written in , but we're now go to retriev the inform by set the reed gate to on .
the valu of <num> then come out of the memori cell and goe off to influenc the rest of the network .
and if we don't need it anymor then the keep gate can be set to zero and the inform will be remov .
now , if you look at the <num> that come out when we do the retriev and you look at the path back to the <num> that came in , along that path is these littl triangular symbol and next to each triangular symbol is a on .
that mean that the effect weight on that connect is a on .
so as we go back along that path whatev error deriv we have for the <num> when it's retriev get backpropag to <num> when it's store .
so if you'd rather retriev a bigger valu to make the right thing happen now you can send the inform back and tell it , it should have store a bigger valu .
and notic that as long as the relev gate have valu of on , there's no attenu in thi backpropag signal .
it's got just the properti we want .
of cours if thei're logist gate there will be some slight attenu , but it can be veri small and so inform can travel back through hundr of time step .
now , let's look at a task that a recurr neural network with long short term memori is veri good at .
it's a veri natur task for recurr neural network .
it's read cursiv handwrit .
the input is just a sequenc of the x and y coordin of the tip of the pen , plu some inform about whether the pen is on the paper or not .
the output is go to be a sequenc of recogn charact .
grave schmidhub in <num> , show that recurr neural network with long short term memori ar extrem good at thi task .
so far as i know , thei're current the best system there ar and i believ canada post is start to us them for read handwrit .
grave schmidhub who , in <num> , didn't us pen coordin as input .
thei us a sequenc of small imag .
and that mean thei can deal with optic input where the time of the pen isn't known .
thei can look at imag after thei've been written and read them .
so i'm now gonna show you a demonstr of alex grave's system work on pen coordin .
and in the movi that follow you're go to see four stream of inform .
the top row show the charact as thei're recogn .
the system never revis it output .
so if it ha to make a difficult decis , it delai it for a littl bit , so that it can see a littl distanc into the futur to help it resolv ambigu .
the second row show the state in a subset of the memori cell , and you should notic how thei get reset when it recogn a charact .
the third row show the actual write and all the net see is the x and y coordin of the tip of the pen .
just two number plu some inform about whether the pen is up or down .
final , the fourth row show someth much more complic .
it show the gradient backpropag all the wai to the xy locat .
so what you get to see is , for the most activ charact , if you backpropag from that charact and ask what would make that most activ charact more activ , you get to see which bit of the input ar affect the probabl that it's that charact .
so that let's you see how the decis , ar depend on thing that happen in the past .
so here's the movi .
in thi video , i'm go to give a brief overview of the hessian free optim that can be us to train recurr neural network veri effect .
thi is a veri complic optim and i don't expect you to get all the detail of it from thi video .
i just want you to have a gener feel for how it work .
and then in the next video , we will see how well it doe on an interest problem .
when we're train the weight of a neural network , we ar try to get as far down the error surfac as possibl .
so on question is if we choos a given direct to go in , how much reduct in the arrow can we achiev by go just the right distanc in that direct ?
how much doe the arrow decreas befor it start rise again ?
and here we'll assum that the curvatur is constant .
i will assum it realli is a quadrat error surfac .
we can assum that the magnitud of the gradient decreas as we move down the gradient .
that amount to assum that the error surfac is concav upward like a bowl .
the maximum reduct that we can get in the error by go in a particular direct depend on the ratio of the gradient to the curvatur .
so we want to move in direct that have a good ratio .
even if the gradient is quit small , we want the curvatur to be even smaller .
so here's an exampl of a direct we could move in where the vertic axi correspond to the error , the horizont axi correspond to the weight in the direct we're move in , and the blue arrow correspond to the reduct we get if we start at that red point .
here's a surfac that ha a gentler gradient but becaus it's got a better ratio as the gradient to the curvatur , we get a bigger reduct in the error by the time we get to the minimum .
the question is , how can we find direct like that second on ?
direct in which even though the gradient mai be small , the curvatur is even smaller .
so let's start with newton's method .
newton's method address the basic problem at it deepest descent , which is that the gradient isn't the direct that you want to go in .
if the error surfac ha circular cross section and is quadrant , the gradient is a good direct to go .
it will point straight at the minimum .
so the idea of newton's method is to appli a linear transform that turn ellips into circl .
if that we appli that transform to the gradient vector , it will be as if we were go downhil in a circular error surfac .
to do thi , we need to multipli the gradient de by dw by the invers of the curvatur matrix .
so h is the curvatur matrix , sometim call the hessian .
it the function of the weight we have and we need to take it invers and multipli the gradient by that , then we need to go some distanc in that direct .
if it's a truli quadrat surfac and we choos epsilon correctli , which is quit easi to do , we'll arriv at the minimum of the surfac in a singl step .
of cours , that singl step involv someth complic , which wa invert that hessian matrix .
the problem with thi is that even if we onli have a million weight in our neural network , the curvatur matrix , the hessian , will have a trillion term , is complet infeas to invert it .
so curvatur matric look like thi .
for each weight , wi or wj , thei tell you how the gradient in on direct chang as you chang in anoth direct .
in other word , as i chang weight i , how doe the gradient of the error with respect to weight j chang ?
that's what a typic off diagon term tell you .
the term on the diagon tell you how the gradient of the arrow chang in the direct of a weight as you chang that weight .
so the off diagon term in a curvatur matrix correspond to twist in the error surfac .
a twist mean , when you travel in on direct , the gradient in anoth direct chang .
if we have a nice circular , all those off diagon term ar zero .
as we travel in on direct , the gradient in other direct doesn't chang .
so , what's go wrong with steepest descent , when you have an ellipt error surfac , is that , as we travel in on direct , the gradient in anoth direct chang .
and so if i updat on of the weight , at the same time as i'm updat all the other weight , all those other updat will caus a chang in the gradient for the first weight .
and that mean , when i updat it , i mai actual make thing wors .
the gradient mai have actual revers sine due to all the chang in the other weight .
and so .
as we get more and more weight , we need to be more and more cautiou about chang each on of them , becaus the simultan chang in all the other weight can chang the gradient of our rang .
the curvatur matrix determin the size of those interact .
so we have to deal with the curvatur .
we can't just ignor it .
and we'd like to deal with it without actual invert a huge matrix , becaus the matrix ha too mani term in a big neural net .
on thing we can do is to just look at the lead diagon of the curvatur matrix and make our step size depend on that lead diagon .
that help a bit .
it will get us to make differ step size for differ weight , but the diagon turn onli a tini fraction of the interact , so we're ignor most of the turn in the curvatur matrix when we do that .
in fact , we're ignor nearli all of them .
anoth thing we could do is , turn approxim the coverag of matrix with the matrix of much lower rank that captur the main aspect of the coverag matrix .
that wa done in hessian free method and lbfg , and mani other method that try and do an approxim second order method for minim the error .
in the hessian free method , we make an approxim to the curvatur matrix and then we assum that the approxim is correct .
so we assum we know what the curvatur is and that the error surfac realli is quadrat .
and then , start from wherev we ar now , we minim the error us an effici techniqu call conjug gradient .
onc we've done that , onc we got close to a minimum on thi approxim to the curvatur , we then make anoth approxim to the curvatur matrix and we us conjug gradient to minim again .
it's also import in recurr neural network to add a penalti for chang ani of the hidden activ too much .
that will prevent us for exampl , from chang a weight earli on that caus huge effect later on in the sequenc .
we don't want to get effect that ar too big , and if we look at the chang in the hidden activ we can prevent that by penal those chang .
if we put a quadrat penalti on those chang , we can combin that with the rest of the hessian free method .
the last thing i need to explain is conjug gradient and i'm just go to explain it briefli .
conjug gradient is a veri clever method that , instead of try to go straight to the minimum like in newton's method , tri to minim in on direct at a time .
so it start off by take the direct of steepest descend and goe to the minimum in that direct .
that might involv re evalu the gradient , re evalu the error a few time to find the minimum in that direct .
onc it done that , it now find anoth direct and goe to the minimum in that second direct .
the clever thing about the techniqu is , it choos it second direct in such a wai that it doesn't mess up the minim it alreadi did in the first direct .
that's call a conjug direct .
conjug mean that as you go in the new direct , you don't chang the gradient in the previou direct .
it's a funni idea .
it's like the idea of a twist in an error surfac .
a twist mean when you go in on direct , you chang the gradient in anoth direct .
and a conjug direct is on you can go in that in a sens , doesn't have a twist .
you go in that direct and the gradient in the first direct doesn't chang .
so here is a pictur of an ellips and the red line is the major axi of the ellips .
we start off by do on step of steepest descent all the wai to the minimum in that direct .
and if you think about it a bit , you can see that the minimum won't actual lie on the red line .
on the red line , the gradient will be zero , at right angl for that red line , cuz it's the bottom of the ravin .
but the direct we're go in , isn't actual at right angl to that point .
we can make a littl bit more progress by make a small step at right angl to the red line and then a small step along the red line .
sinc the red line slope down toward the middl of the elips , that's go to make some progress for us .
so when we minim in the first direct , we'll go slightli across the bottom of the ellips .
and when we reach that point that's a minimum , there's an interest properti of all the point that lie on the green line .
on that green line , the gradient in the direct of that black arrow is zero .
so we can go anywher along that green line and we won't destroi the fact that we ar at a minimum in the direct of the black arrow .
if we can keep do that from mani direct in a high dimension error surfac , we'll eventu be at a minimum in mani differ direct .
and if we ar at a minimum in as mani differ direct as there ar dimens in the space , we'll be at the global minimum .
so , we take thi first step of steepest descent , we then figur out , and i'm not go to explain how we do that .
we figur out the direct of that green line , and then , we do a search along the green line to find how far we should go in order to minim the error along the green line .
and we take our second step , like thi .
and now , in thi <num> dimension space , we'll be at the minimum .
becaus , we're at the minimum in the direct of the first step and we're now at a minimum in the direct of the second step , while still be at a minimum in the direct of the first step and so that must be the global minimum .
what conjug gradient achiev is that it get to the global minimum of an n dimension quadrat surfac in onli n step .
it's veri effici .
it doe that becaus it manag to get the gradient to be zero in n differ direct .
thei're not orthogon direct , but thei ar independ of on anoth and so that's effici to be at the global minimum .
more importantli , in mani less than n step on a typic quadrat surfac , it will have reduc the area veri close to the minimum valu , and that's why we us it .
we're not go to do the full n step , that would be as expens as invert the whole matrix .
we're go to do mani less than n step , and we're go to get quit close to the minimum .
you can appli conjug gradient directli to a non quadrat error surfac , like the error surfac for a multilay non linear neural net and it usual work quit well .
it's essenti a batch method , but you can appli it to larg mini batch .
and when you do that , you do mani step of conjug gradient on the same larg mini batch and then you move on to the next larg mini batch .
that's call non linear conjug gradient .
the hessian free optim us conjug gradient for minim on a genuin quadrat surfac and that's what conjug gradient is best at .
it work much better for that than for a non linear surfac .
thi genuin quadrat surfac that hf is us it for is the quadrat approxim to the true surfac that wa made by the hessian free method .
so it make that approxim , it us conjug gradient to get close to a minimum , for the first approxim .
and then it make a new approxim to the curvatur , and doe it again .
we're now go to appli hessian free optim , to the task of model charact string from wikipedia .
so , the idea is , you read a lot of wikipedia and then try to predict the next charact .
befor we get to see what the model learn , i want to describ why we need multipl connect and how we can implement those multipl connect effici in a recurr neural network .
i need to start by explain why we chose to model charact string rather than string of word , which is what you normal do when you're try to model languag .
the web is compos of charact string .
ani learn method that's power enough to understand what's go on in the world by read the web , ought to find it trivial to learn which string make word .
as we'll see , thi turn out to be true .
so we're go to be veri ambiti here .
we want someth that will read wikipedia and understand the world .
if we have to pre process the text in wikipedia into word it's go to be a big hassl .
there's all sort of problem .
the first problem is morphem .
the smallest unit of mean , accord to linguist , ar morphem .
so we're go to have to break up a word into these morphem if we want to deal with it sensibl .
the problem is , it's not quit clear what morphin ar .
there's thing that ar a bit like morphem , but that a linguist wouldn't call a morphem .
so in english , if you take ani word that start with the letter sn , it ha a veri high chanc of mean someth to do with the lip or nose , particularli the upper lip or nose .
so word like snarl , and sneez , and snot , and snog , and snort .
there's too mani of these word for it just to be coincid .
mani peopl sai ye but what about snow ?
that's got noth to do with the appl lip or nose .
but , ask yourself someth , why is snow such a good word for cocain ?
then there's word that come in sever piec .
so normal , we'd want to treat new york as on lexic item .
but if we're talk about the new york minster roof , then we might want to treat new and york as two separ lexic item .
and then there's languag like finnish .
finnish is an agglutin languag , so it put togeth lot of morphem to make great big word .
so here's an exampl of a word in finnish that take about five word in english to sai the same thing .
i have no idea what thi word mean .
but despit my lack of understand , it make the point .
so here's an obviou kind of recur net we might us to try and model charact strength .
it ha a hidden state and in thi case , we're go to us <num> hidden unit .
and , the hidden state dynam is that the hidden state at time t provid input to determin the hidden state at time t <num> .
and the charact also provid some input .
so we add togeth the effect of the current charact with the previou hidden state to get the new hidden state .
and then when we arriv at a new hidden state , we try and predict the next charact .
so , we have a singl softmax over the <num> charact , and we get the hidden state to try and assign high probabl to the correct next charact , and low probabl to the other .
and we train the whole system by backpropag from that softmax , the low probabl of get the correct charact .
we backpropag that through the hidden to output connect back through the hidden to charact connect , and then back through the hidden to hidden connect , and so on and all the wai back'til the begin of the string .
it's a lot easier to predict <num> charact than <num> , <num> word .
so it's easier to us a softmax at the output , we don't have the problem of a great , big softmax .
now , to explain why we didn't us that kind of recurr net , but instead us a differ kind of net that work quit a lot better .
you could arrang all possibl charact string into a tree with a branch ratio of <num> , in our case .
and what i'm show here , is a tini littl subtre , of that great big tree .
in fact , thi littl subtre will occur mani time , but with differ thing that ar repres by that dot , dot , dot befor the fix .
so thi repres that we had a whole bunch of charact , then we had f and then i and then x .
and now if we get an i , we're go to go to the left .
if we get an e , we're gonna go to the right , and so on .
so each time we get a charact , we move on step down in thi tree to a new note .
there's exponenti mani node in the tree of all charact string of length n .
so thi is go to be a veri big tree .
we couldn't possibl store it all .
if we could store it all , what we'd like to do is put a probabl on each of those arrow .
and that will be the probabl of produc that letter , given the context of the node .
in an rnn , we try and deal with the fact that the full tree is enorm by us a hidden state vector to repres each of these node .
so now , what the next charact ha to do is take the hidden state vector that's repres the whole string of charact follow by fix and oper on the hidden state vector to produc the appropri new hidden state vector if the next charact wa an i .
so when you see an i , you want to turn the hidden state vector into a new hidden state vector .
a nice thing about implement these node in thi charact tree by us the hidden state of recurr neural network , is that we can share a lot of structur .
for exampl , by the time we arriv at that node , that sai f , i , x , we mai have decid that it's probabl a verb .
and if it's a verb , then i is quit like becaus of the end i , n , g .
and that knowledg that i is quit like with a verb , can be share with lot of other node that don't have f i x in .
so we can get i to oper on the part of the state that repres that it's a verb , and that can be share between all the verb .
notic that , it's realli the conjunct of the current state we're at and the charact that determin where we want to go .
we don't want i , to give us a state that's expect to get an n next if it wasn't a verb .
so , we don't want to sai that i tend to make you expect an n next .
we realli want to sai , if you alreadi think it's a verb , then when you see an , i , you should expect an n next .
it's the conjunct of the fact that we think it's a verb , and that we saw an i , that get us into thi state label f , i , x , i , that's expect to see an n .
so we're go to try and captur that by us multipl connect .
instead of us the charact input to their current net to give extra addit input to the hidden unit , we're go to us those charact to swap in a whole hidden to hidden weight matrix .
the charact is go to determin the transit matrix .
now , if we did that in the naiv wai , we'd have each of the <num> charact to find a 1500x1500 matrix and that would be a lot of paramet .
if we have that mani paramet , then that's like to overfit , unless we run it on huge amount of text , for which we might not have time .
so the question is , can we achiev thi kind of multipl interact , where the charact determin the hidden to hidden weight matrix us mani fewer paramet , by make us of the fact that charact have thing in common .
for exampl , all of the digit ar all quit similar to each other in the wai in which thei make the hidden state evolv .
so , we want to have a differ transit matrix for each of those <num> charact , but we want those <num> charact specif weight matric to share paramet , and that's a reason thing to do cuz we know that charact eight to nine should have veri similar transit matric .
so here's how we're go o do it .
we're go to have thing call factor , and thei're go to be denot by thi littl triangl with an f abov it .
what that factor mean is that group a and group b interact multipl to provid input to group c .
so , what each factor doe is it first comput a weight sum for each of it two input group .
so , we take the vector state of group a , which i just call a , and we multipli that by the weight sum connect come into the factor .
in other word , we take the scale of product of the vector a and the weight vector u , and that give us a number at the left hand vertex of that triangl .
similarli , we take the vector stage of group b and we multipli it by the weight factor w , and we get anoth number off the bottom vertex of the triangl .
we now multipli those two number togeth and that give us a number or scalar .
and we us that scalar to scale the outgo weight v in order to provid input for group c .
so the input to group c is just the product of the two number that come into the two vertic of the triangl , time the outgo weight factor v .
we can write that as an equat .
the input that factor f provid to group c , so it vector input to group c , is a scalar input to f from group b , that's got by multipli the state of group b by the weight w , f time a scalar input to f from group a , that's got by multipli that state of group a by the weight u .
we then take the product of those two scalar and multipl the weight vector vf by that , and that's the input that the factor give to group c .
then , of cours , we're go to have a whole bunch of those factor .
there's anoth wai we can think about these factor that give more insight into what's go on .
each of the factor actual defin a veri simpl kind of transit matrix .
it's a transit matrix that ha rank on .
so , the equat we had on the previou slide treat a factor as comput two scalar product , multipli them togeth , and then us that as a weight on the outgo vector v .
we can rearrang that equat .
so that we get on scalar product , and then we rearrang the last bit so that now , we take the outer product of the weight vector u and the weight vector v , and that give us a matrix .
and the scalar product that would be comput by multipli b by w is just a coeffici on that matrix .
so we get a scalar coeffici , we multipli a rank on matrix by that scalar coeffici to give us that scalar matrix .
and then , we multipli the current hidden state a by thi matrix to determin the input the factor f give to the next hidden state .
if we sum that up over all the factor , the total input to group c is just a sum over all factor of a scaler time a rank on matrix , and that sum is a great big matrix , that's the transit matrix , and it get multipli by the current hidden state to produc the new hidden state .
so , we can see that we synthes the transit matrix , actual , these rank on matric provid by each factor .
and what the current charact in group b ha done is , is it's determin the weight on each of these rank on matric .
so , bw time w determin the scalar weight , the scalar coeffici to put on each of the matric , actual which we ar go to compos thi great big charact specif right matrix .
so here's a pictur of the whole system , we have a number of factor , in fact we'll have about <num> factor .
and the charact input is differ in that onli on of those is activ so there will onli be on relev weight at a time .
and that weight from the current charact k , which call w , kf , is the gain that's us on the rank on matrix got by take the outer product of u and v .
so the charact determin again w , kf , you multipli the rank on matrix uv by that gain , you add togeth the scale matric for all the differ factor and that's your transit matrix .
in thi video , we're go to see what happen when the hessian free optim is us to optim the current neural network contain multipl connect and the network is train to predict the next charact in wikipedia .
the network is train on million of charact and it work remark well .
it learn a lot about english and it becom veri good at complet sentenc in interest wai .
ilya sutskev us five million string of <num> charact each taken from english wikipedia .
for each string , he start predict after eleventh charact .
so the recurr network start off in a default state .
it read eleven charact , chang it hidden state each time .
and then it readi to start predict .
and it get train by back propag the error it make in predict .
he us the hessian free optim , and it took about a month on a veri fast gpu board to get a realli good model .
hi current best recurr neural network for charact predict is probabl the best singl model there is for predict charact .
you can do better than thi model by combin mani differ model , us a neural network to decid which on to us , but for a singl model , it is as good as it get .
it work in a veri differ wai , from the best other model .
so ilya's model can balanc quot and bracket over long distanc .
ani model that reli on match a specif previou context can't do that so , for exampl , if it ha a bracket , and it want to close it <num> charact later , in order to do that properli a model that reli on match previou context , would have to match all <num> interven charact .
and it's veri unlik that it ha that whole string store .
onc the model's learn , you can see what it know by gener string from the model .
of cours you have to be veri care not to over interpret what it sai .
the wai we gener string is we start in the default to hidden state .
we then give it a burn sequenc .
so we feed it charact and let it updat it hidden state after each charact .
and then we let it stop predict .
we look at the probabl distribut it predict for the next charact .
we pick a charact randomli from that distribut .
so if it predict , the probabl q is on in a thousand , we pick a q on time in a thousand .
we then tell the net that whatev charact we pick wa the charact that actual occur , and ask it to predict the next charact .
in other word , we're tell it whatev he guess is correct .
we let it continu to make charact until we've got as mani as we want , and then we look at the string it produc to see what it know .
so here's an exampl of a string produc by ilya's network after some burn in .
thi wa select from a much longer passag of text .
but it's a continu passag , which show you that it work pretti well .
you'll notic that it ha weird semant associ .
so , opu paul at rome .
no person would never sai that .
but we understand that opu and paul and rome ar all highli interconnect .
you'll notic it doesn't realli have ani long rang themat structur .
it pretti much chang topic after each full stop .
on amaz thing is that is produc veri few non word .
what that mean is that , even though it's predict probabl of charact , as soon as you've got enough charact so there's onli on wai to complet it as an english word , it will predict the next charact almost perfectli .
if that wasn't the case , it would produc non word .
even when it doe produc a non word , like the word in red , it's a veri good non word .
i'm not absolut certain , or i wasn't when i first saw it , that ephemer wasn't an english word .
you'll also notic it's produc a close bracket without an open on .
so it doesn't alwai balanc bracket .
it just doe it quit frequent .
you'll also notic at the end , that it produc an open quot and then a close quot much later .
that's consist behavior on it part .
it realli did produc that close quot , becaus it had an open quot earlier on .
if you look at thi text you can see there's a lot of good local syntax .
so , littl string of three or four word look perfectli reason .
there's also lot of semant knowledg .
so on thing we can do is we can test the model by give it carefulli design string to see what it know .
so i tri give it a non word .
the word thrung t h r u n g e is not an english word .
but most english speaker , when thei see that word , would expect it to be a verb becaus of it's form .
so i gave it open context in which that might be aver , to see what charact wa most like to come next .
so , if you give it sheila thrung and ask for the next charact , the most frequent on is an s , which suggest that it know that sheila is singular , just from read wikipedia .
if you give it peopl thrung the most frequent next charact is a space , not an s , which suggest that it know that peopl is plural .
i then tri give it a list of name .
so i us capit for the name with a comma in between .
and i put a capit t for thrung so it look like a name , to see what it would do with that .
so it actual complet it as a name .
and if you look at the name it made , it's not a bad name .
it indic that it know an aw lot about name in mani languag .
you can also give it the mean of life is , and the see what come next .
if it produc <num> , that wouldn't be veri interest cuz i'm fairli sure that will be somewher in wikipedia .
it produc random thing .
but in it's first ten tri , it produc the mean of life is liter recognit .
which is syntact and semant sensibl .
we then train the model some more and present it with a mean of life is again .
we took the first ten thing it produc and i'm go to show you the most interest on .
the complet it produc for the mean of life is , suggest that by read wikipedia it realli is begin to understand someth about the mean of life .
that's probabl just wild over interpret , though .
so here's it complet .
so , what doe the model know after it's read all these charact in wikipedia ?
well , it certainli know about word .
it produc almost alwai , english word .
it will produc string of initi , typic in capit .
it can produc number and date and thing like that .
but it doesn't produc non word veri often .
it produc them extrem rare .
and when it doe produc them , thei're typic veri plausibl non word .
it also know a lot about proper name , like frangelini del rei .
it know about date and number , and the context in which thei occur .
it's good at balanc quot and bracket , and in fact it can actual count bracket .
if you give it no open bracket , it's veri unlik to produc a close bracket .
if you give it on open bracket , it's quit like to produc a close bracket in the next twenti charact or so .
if you give it two open bracket , it'll produc a close bracket veri quickli .
give it three doesn't seem to make it ani faster .
it clearli know a lot about syntax becaus it's abl to produc these littl string of english word that ar sensibl .
but it's veri hard to pin down exactli what form thi knowledg ha .
it's not like trigram model which have just learn littl sequenc of word .
or rather thei have a tabl that contain littl sequenc of word .
it's actual synthes string of word .
and it's synthes them with sensibl syntax .
it's veri hard to sai though what form that syntact knowledg had .
it's not a bunch of rule like a linguist ha .
it's much more like what's in the linguist head when he speak a languag .
it know a lot of weak semant associ .
so , for exampl , it onli ever produc the word wittgenstein onc .
and it produc that soon after produc the word plato .
so it know that plato and wittgenstein ar associ .
well , that's a pretti good assumpt .
it clearli know that cabbag is associ with veget .
it doesn't know much about the precis wai in which these thing ar associ .
peopl ar like that too if you get them to respond veri fast .
so i'm go to ask you a question , and i want you to shout out the answer .
so you're sit there watch thi video .
and thi experi will work , by far , the best , if you actual shout out the answer out loud .
and you have to shout it out realli fast .
you get reward for respond veri quickli .
it doesn't matter what you sai .
you just have to respond fast .
so the question is , what do cow drink .
most peopl , when given that question , shout out milk .
now , most cow don't drink milk most of the time .
we sai milk cuz it's associ with both drink and with cow .
but it's not logic to sai milk .
recent , thoma mikolov and hi collabor have been train larg recurr neural network to predict the next word in larg data set .
thei us the same techniqu as the feet forward neural net .
that first convert a word to a real valu featur vector .
and then us those featur vector as input to the rest of the network .
and thei do better than the feed forward neural net .
thei also do better than the best other model .
and when you averag them with the best other model , thei do better still .
so that's the best languag model there ar current .
on interest properti of the rnn is that thei requir less train data than the other method to reach a given level of perform .
more importantli , as the data set get bigger , the rnn improv faster than the other method .
so method like trigram , for exampl , do get better with bigger data set but it's a veri slow process .
you need to doubl the size of the data set to get a small improv .
with rnn , thei can make much better us of the data .
thi mean it's go to be veri hard to beat them as data set get bigger .
i think it mai be the same stori as for object recognit with larg , deep neural net .
but onc the neural net get ahead , thei can make better us of faster comput and bigger data set .
and so , it's go to be veri hard for other method to catch up .
in thi video i'm go to describ eco state network .
these us a clever trick to make it much easier to learn a recurr neural network .
thei initi the connect in the recurr neural network in such a wai that it ha a big reservoir of coupl oscil .
so if you provid input to it , it convert that input into the state of these oscil , and then you can predict the output you want , from the state of these oscil .
and the onli thing you have learn , is how to coupl the output to the oscil .
thi entir get rid of the problem .
of learn hidden to hidden connect or even input to hidden connect .
howev , to get these network to be good at complic task , you need a veri big hidden state .
as we'll see at the end of the video , there's no reason not to us the initi that wa carefulli design for echo state network , and then to us back propag through time with momentum to train the network to be even better at the task that thei're do .
on interest and quit recent idea about train recurr neural network , is to not train the hidden to hidden connect at all , but to just fix them randomli , and hope that you can learn sequenc by just train the wai thei affect the output .
thi ha strong similar with old idea about percept .
so a veri simpl wai to train a feedforward neural network , is to make the earli layer of featur detector just be random .
you put in sensibl size random weight and then all you learn is the last layer so that you're learn a linear model from the activ of the hidden unit in the last layer to the output .
and of cours it's much faster to learn a linear model .
thi reli on the idea that a big , random expans of the input vector , can often make it easi for a linear model to fit the data , when it couldn't fit the data well , just look at the raw input .
through the littl neural network here , those red weight will be fix at random .
thei would expand the input vector and then us that expand represent , we try and fit a linear model .
thi actual ha some quit strong similar with support vector machin .
which ar realli just a realli effici wai of do thi .
so those same idea , mani year later , were recycl for recurr neural network .
the idea is to make the input to hidden connect .
and the hidden to hidden connect have random valu that ar carefulli chosen .
and just learn the final layer of hidden to output connect .
the learn is then veri simpl if you us linear output unit .
and it can be done extrem fast .
thi approach is onli ever go to work if you set the random connect veri carefulli , so that the recur neural network doesn't die out with no activ and doesn't explod .
so , the wai thei set the random connect in a echo state network is thei set the hidden to hidden weight so that the length of the activ vector stai about the same after each durat .
for those of you us to linear system and matric , you're set it so the spectral radiu is on .
that is the biggest eigenvalu of the matrix of hidden to hidden weight is on .
or it would be on if it wa a linear system .
and you want to achiev the same properti in a non linear system .
if you set those weight to be about the right magnitud , then an input can echo around in the recurr state for a long time .
it's also import to us spars connect .
so instead of have lot of medium size weight , we have a few quit larg weight .
and nearli all the weight ar zero in the hidden to hidden connect .
what thi doe is it make a lot of loos coupl oscil .
so inform can hang around in on part of the net without be propag to other part of the net too quickli .
it's also import to choos the scale of the input to hidden connect veri carefulli .
those connect need to drive the state of the loos coupl oscil but , thei mustn't wipe out inform that those oscil contain about the recent histori .
fortun the learn is veri fast in echo state network so we can afford to experi with the scale of the import connect .
you could think of it as a littl learn loop that's just learn the scale of those connect and it's do it by sort of feedback that involv the experiment .
it also help to learn the level of spars that's need in the hidden to hidden connect , and again becaus the learn is so fast , you can afford to experi with that .
that's import becaus it's often necessari to do those experi to get the system to work well .
so i'm now go to show you a simpl exampl taken from the web of an eco state network .
it ha an input sequenc which is a real valu that vari with time , and specifi the frequenc of a sine wave for the output of the eco state network .
so you'd like thi thing to gener sine wave , and the input is gonna specifi the frequenc .
the target output sequenc is go to be the same wave with the frequenc specifi by the output .
and it's go to be learn simpli by put a linear model that take the state of the hidden unit and from those tri to predict the correct scalar output valu .
so here's a pictur taken from scholarpedia of an echo state network do thi program , the input signal is the desir frequenc of the sine wave .
the output signal after it's learn , or the teacher signal , when it's learn , is a sine wave with the frequenc specifi by the input .
and the stuff in the middl is a big dynam reservoir , so that the input come from the input signal driver those loos coupl oscil , and caus complic dynam that goe on for a long time .
and those output weight ar learn to map that complic dynam to the particular dynam you want for the output .
all the other pictur ar show you the actual dynam of individu unit insid the dynam reservoir .
on thing to notic is that there ar also connect from the output back to the reservoir .
those aren't alwai need , but thei help to tell the reservoir what have ha been produc so far .
so here's an exampl of what thei system actual produc after it's learn , and you can see that at the begin it's produc a sign wave , in phase .
at the end , it's produc a sign wave of the right frequenc , but the phase is wrong .
and that's becaus we weren't tell what phase the sign wave should be in .
so it's satisfi the requir of produc an appropri frequenc .
there some veri good aspect of echo state network .
thei can be train veri fast becaus thei just fit in a linear model .
thei also demonstr how import it is to initi the hidden to hidden weight sensibl .
and thei can do quit impress model of on dimension time saver .
that's where thei excel .
thei can look at a time seri for awhil , and then predict it veri well a long time into the futur .
what thei're not so good at is model high dimension data , like frame of acoust coeffici , or frame of video .
in order to model data like that , thei need mani more hidden unit than a recurr neural network where you train the hidden to hidden connect .
recent , ilya sutskev tri someth which is fairli obviou which is to initi a recurr neural network us all the trick develop by the peopl do echo state network .
onc you've done that , you know you could learn quit well just by learn the hidden driver connect .
but then , presum , you could learn even better if you also learn to make the hidden to hidden weight better .
so ilya tri us the echo state network initi but then train with back propag through time .
in thi video , i'm go to talk about improv gener by reduc the overfit that occur when a network ha too much capac for the amount of data it's given dure train .
i'll describ variou wai of control the capac of a network .
and i'll also describ how we determin how to set the metric paramet when we us a method for control capac .
i'll then go on to give an exampl where we control capac by stop the learn earli .
just to remind you , the reason we get over fit is becaus as well as have inform about the true regular in the map from the input or output , ani finit set of train data also contain sampl error .
there's accident regular in the train set , just becaus of the particular train case that were chosen .
so when we fit the model , it can't tell which of the regular ar real , and would also exist if we sampl the train set again , and which ar caus by the sampl error .
so the model fit both kind of regular .
and if the model's too flexibl , it'll fit the sampl error realli well , and then it'll gener badli .
so we need a wai to prevent thi over fit .
the first method i'll describ is by far the best .
and it's simpli to get more data .
there's no point come up with fanci scheme to prevent over fit if you can get yourself more data .
data ha exactli the right characterist to prevent over fit .
the more of it you have the better .
assum your comput's fast enough to us it .
a second method is to try and judici limit the capac of the model so that it's got enough capac to fit the true regular but not enough capac to fit the spuriou regular caus by the sampl error .
thi of cours is veri difficult to do .
and i'll describ in the rest of thi lectur , variou approach to try to regul the capac appropri .
in the next lectur , i'll talk about averag togeth mani differ model .
if we averag model that have differ form and make differ mistak , the averag will do better than the individu model .
we could make the model differ just by train them on differ subset of the train data .
thi is a techniqu call bag .
there's also other wai to mess with the train data to make the model as differ as possibl .
and the fourth approach , which is the basian approach , is to us a singl neural network architectur , but to find mani differ set of weight that do a good job of predict the output .
and then on test data , you averag the predict made by all those differ weight vector .
so , there's mani wai to control the capac of a model .
the most obviou is via the architectur .
you limit the number of hidden layer , and the number of unit per layer .
and thi control the number of connect in the network , i . e .
the number of paramet .
a second method which is often veri conveni is to start with small weight and then stop the learn befor it ha time to overfit .
again on the assumpt that it find the true regular befor it find the spuriou regular that have just to do with the particular train set we have .
i'll describ that method at the end of thi video .
a veri common wai to control the capac of a neural network is to give it a number of hidden lair or unit per lair is a littl to larg , but then to penal the weight us penalti or constraint us squar valu of the weight or absolut valu of the weight .
and final , we can control the capac of a model by ad nois to the weight , or by ad nois to the activ .
typic , we us a combin of sever of these differ capac control method .
now for most of these method , there's meta paramet that you have to set .
like the number of hidden unit , or the number of layer , or the size of the weight penalti .
an obviou wai to transit those meta paramet is to try lot of differ valu of on of the meta paramet like , for exampl , the number of hidden unit , and see which give the best perform on the test set .
but there's someth deepli wrong with that .
it give a fals impress of how well the method will work if you give it anoth test set .
so the set that work best for on particular test set ar unlik to work as well on a new test set that's drawn from the same distribut becaus thei've been tune to that particular test set .
and that mean you get a fals impress of how well you would do on a new test set .
let me give you an extrem exampl of that .
suppos the test set realli is random , quit a lot of financi data seem to be like that .
so the answer just don't depend on the input or can't be predict from the input .
if you choos the model that doe best on your test set , that will obvious do better than chanc becaus you select it to do better than chanc .
but if you take that model and try it on new data that's also random , you can't expect it to do better than chanc .
so by select a model , you got a fals impress of how well a model will do on new data and the question is , is there a wai around that ?
so here's a better wai to choos the meta paramet .
you start by divid the total data set into three subset .
you have the train data , which is what you're go to us to train your model .
you hold back some valid data , which isn't go to be us for train .
but is go to be us for decid how to set the meta paramet .
in other word , you're go to look at how well the model doe on the valid data to decid what's an appropri number of hidden unit or an appropri size of weight penalti .
but then onc you've done that , and train your model with what look like the best number of hidden unit and the best weight penalti , you're then go to see how well it doe on the final set of data that you've held back which is the test data .
and you must onli us that onc .
and that'll give you an unbias estim of how well the network work .
and in gener that estim will be a littl wors than on the valid data .
nowadai in competit , the peopl organ the competit have learn to hold back that true test data and get peopl to send in predict so thei can see whether thei realli can predict on true test data , or whether thei're just over fit to the valid data by select meta paramet that do particularli well on the valid data but won't gener to new test set .
on wai we can get a better estim of our weight penalti or number of hidden unit or anyth els we're try to fix us the valid data , is to rotat the valid set .
so , we hold back a final test set to get our final unbias estim .
but then we divid the other data into n equal size subset and we train on all but on of those n , and us the nth as a valid set .
then we can rotat and a hold back a differ subset as a valid set , and so we can get mani differ estim of what the best weight penalti is , or the best number of hidden unit is .
thi is call n fold cross valid .
it's import to rememb , the n differ estim we get ar not independ of on anoth .
if for exampl , we were realli unlucki and all the exampl of on class fell into on of those subset , we'd expect to gener veri badli .
and we'd expect to gener veri badli , whether that subset wa the valid subset or whether it wa in the train data .
so now i'm go to describ on particularli easi to us method for print over fit .
it's good when you have a big model on a small comput and you don't have the time to train a model mani differ time with differ number of hidden unit or differ size weight penalti .
what you do is you start with small weight , and as the model train , thei grow .
and you watch the perform on the valid set .
and as soon as it start to get wors , you stop train .
now , the perform civil on the set mai fluctuat particularli if you're error rate rather than a squar error or presentori error .
and so it hard to decid when to stop and so what you typic do is keep go until you're sure thing ar get wors and then go back to the point at which thing were best .
the reason thi control the capac of the model , is becaus model with small weight gener don't have as much capac , and the weight haven't had time to grow big .
it's interest to ask why small weight lower the capac .
so consid a model with some input unit , some hidden unit , and some output unit .
when the weight's veri small , if the hidden unit's a logist unit , their total input will be close to zero , and thei'll be in the middl of their linear rang .
that is , thei'll behav veri like linear unit .
what that mean is , when the weight ar small , the whole network is the same as a linear network that map the input straight to the output .
so , if you multipli that weight matrix w1 by that weight matrix w2 , you'll get a weight matrix that you can us to connect the input to the output and provid the weight ar small , a net with a layer of logist hidden unit will behav pretti much the same as that linear note .
provid we also divid the weight in the linear note by four , which take into account the fact that when there's hidden unit there , in that linear region , and thei have a slope of a quarter .
so it's got no more capac than the linear net , so even though in that network i'm show you there's three six six two weight , it's realli got no more capac than a network with three two weight .
that's the wai it grow .
we start us the non linear region of the sequenc .
and then we start make us of all those paramet .
so if the network ha six weight at the begin of learn and ha <num> weight at the end of learn , then we could think of the capac as chang smoothli from six perimet to <num> perimet as the weight get bigger .
and what's happen in earli stop is we're stop the learn when it ha the right number of paramet to do as well as possibl on the valid data .
that is when it's optim the trade off between fit the true regular in the data and fit the spuriou regular that ar just there becaus of the particular train exampl we chose .
in thi video , i'll talk about how we can control compac by limit the size of the weight .
the standard wai to do thi is to introduc a penalti that prevent the weight from get too larg .
with the implicit assumpt that a network with small weight is somehow simpler than a network with larg weight .
there ar sever differ penalti term we can us .
and it's also possibl to constrain the weight , so that the incom weight vector to each of the hidden unit is not allow to be longer than a certain length .
the standard weight can limit the size of the weight , is to us an l2 weight penalti , which mean that we penal the squar valu of the weight .
thi is sometim call weight decai in the neural network literatur , becaus the deriv of that penalti act like a forc pull the weight toward zero .
thi weight penalti keep the weight small , unless thei have big urg deriv to counteract it .
so if you look at what the penalti term look like , as the weight move awai from zero , you get thi parabol cost .
if you look at the equat , the cost that you're optim is the normal error that you're try to reduc , plu a term which is the sum of the squar of the weight , with a coeffici in front , lambda .
and we divid by two so that when we differenti the two is cancel .
that coeffici in front of the sum squar weight is sometim call the weight cost .
that determin how strong the penalti is .
if you differenti , you can see the deriv of thi cost is just the deriv of the error plu someth that's to do with the size of the weight and the valu of lambda .
that deriv will be zero when the magnitud of the weight is on over lambda time the magnitud of the deriv .
so the onli wai you can have big weight , when you're at a minimum of the cost function , is if thei also have big error deriv .
and thi make the weight much easier to interpret .
you don't have a whole lot of weight that ar larg but aren't do anyth .
the effect of an l2 penalti on the weight is to prevent the network from us weight that it doesn't need .
thi often improv gener a lot , becaus it can us those weight that it doesn't realli need to fit the sampl error .
it also make a smoother model in which the output chang more slowli as the input chang .
so if the network ha two veri similar input , when you put in an l2 weight penalti , it prefer to put half the weight on each of those two similar input rather than all of the weight on on , as shown on the right here .
if the two input ar veri similar , those two network will produc veri similar output .
but the on with the half weight will have much less extrem chang in it output when you chang the input .
there ar other kind of weight penalti .
for exampl , an l1 penalti , where the cost function is just thi v shape .
so here what we're do is we're penal the absolut valu of the weight .
thi ha the nice effect that it drive mani of the weight to be exactli zero and that help a lot in interpret .
if there's onli a few non zero weight left , it's much easier to understand what's go on .
we can also us weight penalti that ar more extrem than l1 where the gradient of the cost function actual get smaller when the weight get realli big .
thi allow the network to keep larg weight without them be pull toward zero .
it's just the small weight that'll get pull toward zero .
so we then even more like that get it with a few larg weight .
instead of put penalti on the weight , we could actual us weight constraint .
what i mean by that is instead of penal the squar valu of each weight separ , we put a constraint on the maximum squar length of the incom weight vector of each hidden unit or output unit .
when we updat the weight , if the length of that incom vector get longer than allow by the constraint , we simpli scale the vector down by divid all the weight by the same amount until it length fit the allow length .
us weight constraint like thi , ha a number of advantag over weight penalti , and i found these work necessari better .
it's much easier to select the sensibl valu for the squar length of the incom weight factor than it is to select the weight penalti .
that's becaus , logist unit .
have , a natur scale to them so we know what a weight of on mean .
us weight constraint also prevent hidden unit get stuck near zero with all their weight be tini and not do anyth us .
becaus when all their weight ar tini , there's no constraint on the weight .
so there's noth prevent them grow .
weight constraint also prevent the weight from explod .
on of the subtl thing that weight constraint do is that when a unit hit it constraint , the effect penalti on all of it weight is determin by the big gradient .
so if some of the incom weight have veri big gradient , thei'll be try to push the length of the incom weight factor up .
and that will push down on all the other weight .
so in effect , if you think of it like a penalti , the penalti scale itself so as to be appropri for the big weight and to suppress the small weight .
thi is much more effect than a fix penalti of push irrelev weight toward zero .
for those of you who know about la grang multipli , the penalti of in just the la grang multipli requir to keep the constraint satisfi .
in thi video , i'll talk about anoth wai of restrict the capac of a neural network .
we can do that by ad nois , either to the weight or to the activ .
i'll start by show , that if we add nois to the input in a simpl linear network , that's try to minim the squar error , that's exactli equival to impos an l2 penalti on the weight of the network .
i'll then describ us of noisi weight in more complic network and i'll finish by describ a recent discoveri that extrem nois in the activ can also be a veri good regular .
so let's look at what happen if we add gaussian nois to the input to a simpl neural network .
the varianc of the nois get amplifi by the squar weight on the connect go into the next hidden layer .
if we have a veri simpl net , with just a linear output unit that's directli connect to the input , the amplifi nois then get ad to the output .
so if you look at the diagram , we put in an input xi with addit gaussian nois that's sampl from a gaussian with zero mean and variant sigma i . .
that addit nois ha it's variant multipli by the squar weight .
it then goe through the linear output unit j .
and so what come out of j is the yj that would have come out befor plu gaussian nois but ha zero mean and ha varianc wi sigma i . .
thi addit varianc make an addit contribut to the squar error .
you can think of it like pythagora theorem , that the squar error is go to be the sum of the squar error caus by yj , and thi addit nois , becaus the nois is independ of yj .
so when we minim the total squar error , we'll minim the squar error that will come out if it wa a nois free system .
and in addit , we'll be minim that second term .
that is , we'd be minim the expect squar valu of that second term and the expect squar valu is just wi <num> , sigma i <num> , so that correspond to an i<num> penalti on wi with a penalti strength of sigma i <num> .
for those of you who like math , i'm gonna deriv that on thi slide .
if you don't like math , you can just skip thi slide .
the output , y noisi , when we add nois to all of the input , is just what the output would have been with nois free system .
the sum of all the input at wixi , plu wi time the nois that we ad to each input .
and those nois ar sampl from a gaussian with zero mean of varianc sigma i . . so so if we comput the expect squar differ between y nois e and the target valu t , that's the quantiti that's shown on the left hand side of the equat .
and i'm us an e follow by squar bracket to mean an expect .
that's not the arrow , that's an expect .
and what we're comput the expect of is the thing in the squar bracket .
so in thi case , we're comput the expect of the squar arrow that we'll get with the noisi system .
so if we substitut the equat abov for y noisi , we need the expect of y .
plu the sum of all the i , wi , epsilon i so when we complet the squar , the first time we get is yt and that's not in the side of expect bracket becaus it doesn't involv ani nois .
the second term is the cross product of the two term abov and the third term is the squar of the last term .
now that equat simplifi a lot .
in fact , it simplifi down to the normal squar error .
plu the expect of wi <num> , epsilon i <num> , sum over all i .
the reason it simplifi is becaus epsilon i is independ of epsilon j .
so if you look at the last term , when we multipli at that squar , all of the cross term have an expect valu of zero .
becaus we're multipli togeth two independ thing that ar zero mean .
if you look at the middl chart , that also ha an expect of zero , becaus each of the epsilon i's is independ of the residu error .
so we can rewrit the expect of the sum over all i of wi epsilon squar , as simpli the sum over all i with w i squar , sigma i squar , becaus the expect of up to i squar is just sigma i squar , becaus that's how we gener epsilon i .
and so we see that the expect squar error we get is just the squar error we get in the nois free system .
plu thi addit term .
and that look just like an l2 penalti on the wi .
with the sigma i be the strength of the penalti .
in more complex net , we can restrict the capac by ad gaussian nois to the weight .
thi isn't exactli equal to an l2 penalti .
but it seem actual to work better , especi in recur network .
so alex grave recent took hi recurr net that recogn handwrit and tri it with nois ad to the weight .
and it actual work better .
we can also us nois in the activ as a regular so suppos we us back propag to train a multi lanur match with logist hidden unit .
what's gonna happen if we make the unit binari and stochast on the forward pass but then we do the backward pass as if we'd done the normal determinist forward pass us the real valu ?
so we're go to treat a logist unit , in the forward pass , as if it's a stacast binari neuron .
that is , we comput the output of the logist p , and then we treat that p as the probabl of output a on .
and in the forward pass , you make a random decis whether to output a on or a zero us that probabl .
but in the backward path , you us the real valu of p for back propag deriv through the hidden unit .
thi isn't exactli correct , but it's close to be a correct thing to do for the stochast system if all of the unit make small contribut to each unit in the layer abov .
when we do thi the perform on the train set is wors and train is consider slower .
it mai be sever time slower .
but it doe significantli better on the test set .
thi is current an unpublish result .
in thi video , i'm gonna describ the bayesian approach to fit model , us a simpl coin toss exampl .
if you're alreadi know about the bayesian approach , you can skip thi video .
the main idea behind the bayesian approach is instead of look for the most like set of the paramet of the model , we should consid all possibl set of the paramet and try to figur out for each of those possibl set , how probabl it is , given the data we observ .
the bayesian framework assum that we alwai have a prior distribut for everyth .
that is , for ani event that you might care to mention , i have to have some prior probabl that , that event might happen .
the problem might be veri vagu .
so what's happen is , our data give us a likelihood term .
we combin it with our prior and then we get a posterior .
the likelihood term favor set of our paramet that make the data more like .
it can disagre with the prior .
and in the limit , if we get enough data , howev unlik the prior is , the data can overwhelm it .
and in the end , with enough data , the truth will out .
that is , even if your prior's wrong , you'll end up with the right hypothesi .
but that mai take an aw lot of data if you thought that thing were veri unlik under your prior .
so let's start with a coin toss exampl .
suppos you don't know anyth about coin except that thei can be toss and when you toss a coin you get either a head or a tail .
and we're also go to assum you know that each time you do that it's an independ decis .
so our model of a coin is go to have on paramet p .
thi paramet p determin the probabl that the coin will produc a head .
what happen now if we see <num> toss and there ar <num> head .
what is a good valu for p .
well obvious you're tempt to sai . <num> .
but what's the justif for that ? .
the frequentest answer , which is also call maximum likelihood , is to pick the valu of p that make the observ most probabl .
and that valu of p is . <num> .
it's not obviou that's true , let's deriv that .
so the probabl of a particular sequenc that contain <num> head and <num> tail could be written out by write down p everi time you toss a head .
and <num> p everi time you toss a tail .
and then if we collect all the p's togeth , and all the <num> p's togeth , we get p <num> , and <num> p <num> .
if we now ask , how doe the probabl of observ that data depend on p , we can differenti with respect to p , and we get the express shown here , and if we then set that deriv to zero .
we discov that the probabl of the data is maxim by set p to be . <num> .
so that's maximum likelihood .
but there's some problem with us maximum likelihood to decid on the paramet of a model .
suppos for exampl , we onli toss the coin onc and we got on head .
it doesn't realli make sens to sai we think the probabl of the coin come down head in futur is on .
that would mean we'd be will to bet that infinit odd that it can't come down tail .
and that seem ridicul .
it's sort of intuit obviou that a much better answer is not . <num> .
but how can we justifi that .
more importantli , we can ask , is it reason to give a singl answer .
we don't know much .
we don't have much data , and so we're unsur about what the valu of p is .
so what we realli ought to do is refus to give a singl answer and instead give a whole probabl distribut across possibl answer .
an answer like <num> is fairli like .
an answer like on is mayb still pretti unlik if we have some prior belief that coin come down head half the time .
so , now i'm go to go through an exampl where we start with some prior distribut over paramet valu , and we'll pick a prior distribut that's easi to work with .
not on that necessarili fit what we realli believ about common .
and then we'll show how that prior distribut get modifi by data if we adopt the bayesian approach .
so , we're gonna start with a prior distribut that sai all the differ valu of p ar equal like .
we believ that coin come bias to variou extent .
and ani amount of bia is equal like .
so that some coin come down head half the time .
other coin come down head all the time .
and those two kind of coin ar equal like .
we now observ a coin come down head .
so what we do now , is for each possibl valu of p , we take it prior probabl and we multipli by the probabl that we would have observ ahead , given that , that valu of p is the correct on .
so , for exampl , if we take the valu of p on which sai coin come down head everi time then the probabl of observ a head would be on .
there would be no altern .
and if we take the valu of p to be zero the probabl of observ a head would be zero .
and if we take it to b . <num> , the probabl of observ have b is . <num> .
so we take that red line , that's our prior , and we multipli each point on that by the probabl of observ a head accord to that hypothesi .
and now we get the slope like , that's a unnorm posterior .
it's unnorm becaus the area under that line doesn't add up to on .
and of cours for a probabl distribut , the probabl of all the altern event have to add to on .
so the last thing we do is re normal it .
we scale everyth up so the area under the curv is on .
and now if we start with the uniform pri distribut of the p we end up with thi triangular posterior distribut of the p have observ on head .
now let's do it again .
and thi time let's suppos we get a tail .
so , the prior distribut that we start with now is the post serial distribut we had after observ our on head .
and now , the green line show the probabl that we will get a tail accord to each of those hypothes that correspond to a valu of p .
so , for exampl , if p is on , the probabl we would observ at time is zero .
so we have to multipli our prior by our likelihood term .
and now we get a curv like that .
then we have to re normal to make the area be on .
and that's now a posterior distribut , after have observ on head and on tail .
i notic it's a pretti sensibl distribut .
after observ on of each , we know that p can't be either zero or on , and it also seem veri sensibl that the most like thing is now in the middl .
if we do thi again anoth <num> time , and keep appli the same strategi of multipli the posterior we had after the last task , by the likelihood of observ that event , given the variou differ set of the paramet p .
and let's suppos we get <num> head and <num> tail in all .
then we'll end up with a curv that look like thi .
it'll have it mean at <num> . .
becaus we start with the uniform prior .
and it'll be fairli sharpli peak by <num> . .
but it'll allow other valu like <num> .
is a perfectli reason valu under thi curv .
not quit as lengthi as <num> . , but veri reason .
wherea a valu of <num> .
is extrem unlik under thi curv .
so we can summar all that with base therm .
determin the middl of thi equat is the joint probabl of a set of paramet w , and some data d .
and for supervis learn , the data is gonna consist of the target valu .
so we assum we ar given input and the data valu consist of the target valu that ar associ with those iinput .
that what we observ .
that joint probabl can be re written as the product of an individu probabl and a condit probabl .
so on the right , we're written it as p of w time p of d given w , and on the left , i've written it as p of d time p of w given d .
now we can divid both side by p of d .
and thi give us base there , i mean it's usual form .
base theorem sai that the posterior probabl of a particular valu of w , given the data d , is just the prior probabl of that particular valu of w time the probabl given that particular valu of w , that you would have observ the data you observ .
and that ha to be normal by p of d .
the probabl of the data which is simpli the integr over all possibl valu of w , of p of w , p of d , given w .
the bottom line need to be the sum of the top line a row of possibl valu w in order for thi to be a probabl distribut that add to on .
becaus that p of d ha integr over all possibl valu of w , it's not affect by pick a particular valu of w on the left hand side .
so when we're look for the best valu of w , for exampl , we can ignor p of d .
it doesn't depend on w .
the other two term on the right hand side , howev , do depend on w .
in thi video , i'm go to talk about the bayesian interpret of weight penalti .
in the full bayesian approach , we try to comput the posterior probabl of everi possibl set of the paramet of a model .
but there's a much reduc form of the bayesian approach , where we simpli sai , i'm go to look for the singl set of paramet that is the best compromis between fit my prior belief about what the paramet should be like , and fit the data i've observ .
thi is call maximum alpha posteriori learn and it give us a nice explan of what's realli go on , when we us weight decai to control the capac of a model .
i'm now go to talk a bit about what's realli go on , when we minim the squar error dure supervis maximum likelihood learn .
find the weight vector that minim the squar residu , that is the differ between the target valu and the valu predict by the net , is equival to find a weight vector that maxim the log probabl densiti of the correct answer .
in order to see thi equival , we have to assum that the correct answer is produc by ad gaussian nois to the output of the neural net .
so the idea is , we make a predict by first run the neural net on the input to get the output .
and then ad some gaussain nois .
and then we ask , what's the probabl that when we do that , we get the correct answer ?
so the model's output is the center of a gaussian and what we're interest in is have the target valu of high probabl under that gaussian becaus the probabl produc the valu t , given that the network give an output of y is just the probabl densiti of t under a gaussian center at y .
so the math look like thi let's suppos that the output of the neural net on train case c is yc and thi output is produc by appli the weight w to the input c .
the probabl that we'll get the correct target valu when we add gaussian nois to that output yc is given by a gaussian center on yc .
so we're interest in the probabl densiti of the target valu , under a gaussian center at the output of the neural net .
and on the right here , we have that gaussian distribut , with mean yc .
we also have to assum some varianc , and that varianc will be import later .
if we now take log and put in a minu sign , we see that the neg log probabl densiti of the target valu tc given that the network output yc , is a constant that come from the normal term of the gaussian plu the log of that exponenti with the minu sign in which is just tc2 yc <num> divid by twice the varianc of the gaussian .
so what you see is that , if our cost function is the neg log probabl of get the right answer , that turn into minim a squar distanc .
it's help to know that whenev you see a squar error be minim , you can make a probabilist interpret of what's go on , and in that probabilist interpret , you'll be maxim the log probabl under a gausian .
so the proper bayesian approach , is to find the full posterior distribut over all possibl weight vector .
if there's more than a hand of weight , that's hopelessli difficult when you have a non linear net .
bayesian have a lot of wai of approxim thi distribut , often us mont carlo method .
but for the time be , let's try and do someth simpler .
let's just try to find the most probabl weight vector .
so the singl set of the weight that's most probabl given the prior knowledg we have and given the data .
so what we're go to try and do is find an optim valu of w by start with some random weight vector , and then adjust it in the direct that improv the probabl of that weight factor given the data .
it will onli be a local optimum .
now , it's go to be easier to work in the log domain than in the probabl domain .
so if we want to minim a cost , we better us neg log prop .
just an asid about why we maxim sum of log probabl , or minim sum of neg log prob , what we realli want to do is maxim the probabl of the data , which is maxim the product of the probabl of produc all the target valu that we observ on all the differ train case .
if we assum that the output error on differ case ar independ , we can write that down as the product over all the train case , of the probabl of produc the target valu , tc , given the weight .
that is the product of the probabl of produc tc , given the output that we're go to get from out network , if we give it input c and it ha weight w .
the log function monoton , and so it can't chang where the maxima ar .
so instead of maxim a product of probabl , we can maxim the sum of log probabl , and that typic work much better on a comput .
it's much more stabl .
so we maxim the log probabl of the data given the weight , which is simpli maxim the sum over all train case of the log probabl of the output for that train case , given the input and given the weight .
in maximum a posteriori learn , we're try to find the set of weight that optim the trade off between fit our prior and fit the data .
so that's base theorem .
if we take neg log to get a cost , we get that the neg log of the probabl of the weight given the data , is the neg log of the prior term , and the neg log of the data term , and an extra term .
so , that last extra term , is an integr overal possibl weight vector .
and so that doesn't affect w .
so we can ignor it when we're optim w .
the term that depend on the data is the neg log probabl is given w , and that's our normal error term .
and then term that onli depend on w is the neg log probabl of w under it prior .
maxim the log probabl of a weight is relat to minim a squar distanc , in just the same wai as maxim the log probabl of produc correct target valu is relat to minim the squar distanc .
so minim the squar weight is equival to maxim the log probabl of the weight under a zero mean gaussian prior .
so here's a gaussian .
it's got a mean zero , and we want to maxim the probabl of the weight , or the log probabl of the weight .
and to do that , we obvious want w to be close to the mean zero .
the equat for the gaussian is just like thi , where the mean is zero so we don't have to put it in .
and the log probabl of w is then the squar weight scale by twice the varianc , plu a constant that come from the normal term of the gaussian .
and isn't affect when we chang w .
so final we can get to the base interpret of weight decai or weight penalti .
we're try to minim the neg log probabl of the weight given in the data and that involv minim a term that depend on by the turn the weight name how will we shift the target and determin that depend onli on the weight .
is deriv from the log probabl of the data given the weight , which if we assum gaussian nois is ad to the output of the model to make the predict , then that log probabl is the squar distanc between the output of the net on the target valu scale by twice the varianc of that gaussian nois .
similarli , if we assum we have a gaussian prior for the weight , the log probabl of a weight under the prior is the squar valu of that weight scale by twice the varianc of the gaussian prior .
so now let's take that equat and multipli through by two sigma squar d .
so , we got a new cost function .
and the first term , when we multipli through turn into simpli the sum of all train case of the squar differ between the output of the net and the target .
that's the squar error that we typic minim in the neural net .
the second term now becom , the ratio of two varianc time the sum of the squar of the weight .
and so what you see is , the ratio of those two varianc is exactli the weight penalti .
so we initi thought of weight penalti as just a number you make up to try and make thing work better .
where you fix the valu of the weight penalti by us a valid set .
but now we see that if we make thi gaussian interpret where we have a gaussian prior and we have a gaussian model of the relat of the output of the net to the target , then the weight penalti is determin by the varianc of those gaussian .
it's just the ratio of those varianc .
it's not an arbitrari thing at all within thi framework .
in thi video , i'm go to describ a method develop by david mackai in the 1990s for determin the weight penalti to us in a neural network without us a valid set .
it's base on the idea that we can interpret weight penalti as do map estim so that the magnitud of the weight penalti is relat to the tight of the prior distribut over the weight .
mackai show we can empir fit both the weight penalti and the assum nois in the output of the neural net to get a method for fit weight penalti that doe not requir a valid set and therefor , allow us to have differ weight penalti for differ subset as the connect in a neural network , someth that will be veri expens to do us valid set .
mackai went on to win competit us thi kind of method .
i'm now go to describ a simpl and practic method develop by david mackai for make us of the fact that we can interpret weight penalti as the ratio of two varianc .
after we've learn a model to minim squar error we can find the best valu for the output varianc and the best valu is found by simpli us the varianc of the residu error .
we can also estim the varianc in the gaussian prior of the weight .
we have to start with some guess about what thi varianc should be .
then , we do some learn , and then we us a veri dirti trick call empir bay .
we set the varianc of our prior to be the varianc of the weight of the model learn becaus that's the varianc that will make those weight most like .
thi realli violat a lot of the presupposit of the bayesian approach .
we're us the data to decid what our prior belief ar .
so , onc we've learn the weight , we fit a zero mean gaussian to the on dimension distribut of the learn weight .
and then , we take the varianc of that gaussian , and we us that for our prior .
now , on nice thing about that is , is the differ subset of weight .
like in differ layer , for exampl , we could learn differ varianc for the differ layer .
we don't need a valid set so we can us all of the non test data for train .
and becaus we don't need valid set to determin the weight penalti in differ layer , we can actual have mani differ weight penalti .
thi will be veri hard to do with valid set .
so , here's mackai's method .
you start by guess the nois varianc and the weight prior varianc .
actual , all you have to realli do is guess their ratio .
then , you do some gradient descent learn , try to improv the weight .
then , you reset the nois varianc to be the varianc of the residu error and you reset the weight prior varianc to be the distribut of the actual learn weight .
and then , you go back around thi loop again .
so , thi actual work quit well in practic .
and mackai won sever competit thi wai .
