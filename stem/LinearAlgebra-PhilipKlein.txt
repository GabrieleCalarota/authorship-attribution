you have a super power .
you alreadi realiz that be abl to code , give you the abil to creat thing with just your mind and your finger .
i see program as a wai of learn mathemat , write program and run them on data is a learn modal .
your abil to creat vector and matric , will enabl you to build stuff with them and do fun thing .
through code , we escap two pitfal of the tradit linear algebra cours .
some linear algebra cours , ar a bit too abstract for mani of us .
thi make the concept hard to grasp and keep us at a remov from the applic .
some of the linear algebra cours ar too tediou , thei requir a lot of hand calcul , possibl with the aid of a calcul .
some hand calcul is us , to help acquaint you with the oper .
but it should not be consid the onli wai of learn a procedur , my hope is that by code comput method in linear algebra , you'll better learn both the method .
and the wai thei appli to real problem and real data .
the exampl problem i us in thi cours have a comput scienc flavor to them .
that's becaus , i'm a comput scientist and i expect mani of you have some background in comput scienc .
i develop thi cours becaus i felt too mani student of comput scienc were go off and learn linear algebra and come back .
and sai well that's nice , but what doe it have to do with what i'm interest in .
by draw on your abil to program , i hope to give you an introduct to linear algebra that plai to your strength , give you the power to build thing that ar fun and interest .
that make linear algebra come aliv for you .
that put in your hand the tool to us linear algebra in the problem and applic that ar interest to you .
program is the power to creat and creation ha a two wai relationship with understand .
my twofold hope then is , that the creat you do in meet the challeng of thi cours will help you to reach greater understand of the materi .
and two , that , that greater understand will give you the abil to creat even more .
in addit , i want to highlight three specif concept from program that ar relev to thi cours .
data abstract , procedur abstract , and what i would call procedur sophist .
first , data abstract .
in the languag of object orient program , you can have sever class that implement a singl interfac .
a client of that interfac need not know the detail of the class us to implement that interfac .
in linear algebra , data abstract give us the concept of a field , think of a field as a class that implement the oper plu , minu , time , and divid .
as long as a class's implement of these oper satisfi certain algebra rule , we can us it to do linear algebra .
be abl to slot in ani field , give linear algebra greater gener and therefor greater applic .
for exampl , the field of real number can be us in do comput graphic or comput vision .
the field consist just of <num> and <num> can be us for applic like cryptographi .
and the field of complex number come up in signal process and in analyz dynam process , process that unfold over time .
at the begin of thi cours , we inform describ the field and we us it throughout the cours .
i will sai though it's a somewhat leaki abstract .
toward the end of the cours , we have to get more from our field so , that field that consist just of <num> and <num> ha to be put asid for that part in the cours .
the field consist of the complex number , is crucial for some of the advanc topic in linear algebra .
unfortun , we won't get to some of those topic in thi version of the cours , more on that topic later .
there's a lot to learn here , but it boil down to learn certain kind of addit and multipl oper .
in thi part of the cours , in order to better learn these oper , you'll implement your own vector and matric .
you won't have to do thi from scratch .
sinc you'll be work from a templat , all you have to do is fill in the implement of these oper .
second , procedur abstract , programm quickli learn to work with api , applic program interfac .
thi mean , thei learn what a suit of procedur call do , and how you can us these in combin to get thing done .
programm don't need to know how each of these procedur is implement , it's enough to know what it accomplish .
in the middl third of thi cours , there ar a lot of concept roll around , coordin represent , base , dimens , rank .
each concept on it own is not so hard , but it might be hard to keep them straight , to develop an understand of the relationship between these concept .
to help you develop a feel for the connect between these concept , you will write program that realiz the concept and that build on upon the other .
thei all ultim reli howev , on some black box , procedur whose implement we won't studi , at least at first .
onli onc we've gotten through thi middl part of the cours , will we be abl to open up the black box and see how it's implement .
in the meantim howev , i expect you to work with thi black box without know what's insid .
just as you would with the procedur of an api .
third , if you've done a fair bit of program , i expect you've develop what i call , procedur sophist .
you're much better than the averag person , and quit possibl better than even mathematician from the pre comput past , at understand and cope with complic procedur .
you're not afraid of a bit of complex , even if you don't understand a procedur at first , you're abl to work through it .
try some exampl , get to know it , develop a feel for it over time .
if you do have thi skill , it will help you a lot in the middl third of the cours and in the final third .
in the middl third of the cours , while we're deal with all these concept swirl around , you're go to see some fairli complic mathemat proof .
thi sound intimid and with good reason , these proof ar a littl difficult to follow .
but fundament , thei're procedur in natur , thei're algorithm proof .
and so , becaus of your procedur sophist , you'll be better abl to follow them .
understand these proof , might requir you to think harder than your us to , but it turn out that mani of these mathemat proof ar procedur in disguis .
keep that in mind and mayb thei won't turn out to be quit so difficult .
to help you along , i'm assign problem in which you'll write program that mimic the structur of the proof , to help you in the process of relat proof to procedur .
i'll assign some problem , in which you write program that embodi the idea of the proof .
in the final third of the cours , we'll start open up those black box and learn the procedur that ar insid .
here too , your procedur sophist will help you .
we'll code these procedur and your program abil , will help you develop greater understand .
you ar here , at the end of the cours if you're still with us , you'll be here .
the first third of the cours consist of a lot of mechan and definit , work with vector and matric .
thi section of the cours , introduc more question than it answer .
the fundament question and comput problem that ar introduc in thi part of the cours , will be address throughout the rest of the cours .
the middl third of the cours , the concept we will studi will illumin the topic enabl us to answer mani of the question that have come up so far .
we'll get , onli a hint at thi point though of the comput solut , the procedur that we'll studi in the last third of the cours .
the real solut to the comput problem come in the final third of the cours , where we studi what make the black box , the solver work .
at thi point i must confess , there's a fourth third to the cours that i teach my brown student .
the materi around here consist of advanc topic that build on everyth we've done befor .
some of the most interest applic can onli be address in that part of the materi , includ imag compress .
page rank , dimension reduct and principl compon analysi .
i veri much want to teach these advanc part to you , but eight week wa deem quit long enough for an onlin cours .
so , instead i plan to offer an addit cours for those who endur thi cours .
so , hold on to your code .
a word about thi diagram .
i'll make it avail on the cours site , but don't try to read it all .
it's a map , and just as you wouldn't read all of a road map , you won't find it us look at thi until you've cover some of the territori .
it's there to help you keep track of where you ar and where we're go .
and now a word about program , i have chosen to teach thi cours in python , it ha built in set , list and dictionari .
data structur that make it particularli well suit to the somewhat idiosyncrat approach i take to implement vector and matric .
if you've work with python befor , you ar probabl acquaint with python's us of these data structur .
howev , my favorit featur of python is on that even python programm might not be so familiar with , the comprehens .
a comprehens is an express , that produc a set , a list , or a dictionari .
it's veri concis , but also easi to read , as long as you're us to it .
a comprehens get you some of the power of function program , but ar access even to those who think lambda is some kind of risqu danc .
a comprehens syntact resembl the notat us by mathematician , to write down set .
perhap most import for our purpos , a comprehens allow you to write a procedur , with onli a singl line without sacrif readabl .
thi is import , becaus in mani of the quizz we ask you to write a singl line procedur .
your answer to the quiz is match against pattern that we've prepar .
that mean that in order for your quiz answer to be judg correct , you have to write it the wai we have in mind .
anoth reason you need to understand comprehens is that , i us them in the code that i write and show you .
final , if you've master comprehens , your python code will be more concis and more readabl .
okai , as you can probabl tell , i'm a littl obsess with comprehens .
anywai , we'll teach you the part of python that you need to know for the cours .
the first lab assign we'll go through set , list , dictionari , and comprehens for all these thing .
even if you alreadi know python , you should realli skim through that first assign to , review the featur of python that we us and to learn my terminolog for them .
the second lab assign , is intend to give you more practic in program with python .
these two assign , don't depend at all on the lectur and you can start them right awai .
also , thei don't count that much toward your grade , so don't worri over much about your perform on these assign .
my main bit of advic , try stuff out , my intent is that you be empow to work with vector and matric and the algorithm that oper on them .
bring it home , give these concept substanc .
don't be content to just watch some video , whether on paper or with the comput , you need to work with the concept we ar develop , in order to gain understand .
that's where the real learn take place , not when you're listen to me drone on .
i can't emphas thi enough , if you don't understand someth or even if you do , try it out .
in the video lectur i'll show you my work with python , thi isn't just for show , thi is how i've manag to learn the concept .
by try thing out with python .
in thi cours , i don't assign a lot of drill .
mani linear algebra cours do involv a lot of drill and there's actual a good reason for that .
you need a lot of practic .
my favorit scene in the movi , the matrix , is when morpheu strap neo into a chair , and insert what look like a 70s era video cassett into a machin .
and stream into neo the knowledg of how to fight .
in a few minut , he's an expert .
i wish i could strap my student into chair and teach them that wai .
but the brain doesn't work that wai .
the input devic is not what's limit , you need to practic .
i'm give you the tool , but you have to take the initi .
i trust that you can find lot of exampl , and drill out there on the web or in the mani book on the subject .
my second bit of advic is , unfortun you're go to have to do a littl bit of memor .
there ar a lot of concept and definit , and you need to keep them straight .
in particular , in the earli part of the cours we'll discuss differ interpret of matrix vector , vector matrix and matrix matrix multipl .
you need to , realli learn these interpret in order to even understand the lectur that come afterward .
now a word about proof , mathemat statement , lemma , proposit , theorem , ar an essenti part of linear algebra .
thei underli the concept that we us .
sinc it is easi to be fool by your intuit , we need mathemat proof to convinc us that these statement ar true .
in thi cours , i present proof for most of the theorem relev to the topic we discuss .
due to limit of massiv onlin cours , i'm not go to requir you to produc mathemat proof .
if you don't consid yourself mathemat inclin , you might be tempt to just skip the proof .
that would be a mistak , mathemat proof ar not there just to convinc , but to provid insight .
the best kind of proof help us understand why a theorem is true .
work through the proof , try to understand it step , help us understand the mean of the theorem and also help us learn the theorem .
sinc i'm a coder , i tend to think of thing algorithm or procedur .
so , i've chosen proof that lend themselv to that kind of think , procedur or algorithm proof .
sometim , i'll ask you to code a procedur that follow the structur of the proof .
the result procedur is not gener the most practic wai to solv the problem , but it will help you gain insight into the proof .
thi will help you learn the proof , it doesn't necessarili give you the best wai to solv the problem .
now a disclaim , i'm not try to train you to develop the next linear algebra librari .
for on thing , that would requir a deep knowledg of numer analysi .
which is at least in part , the abil of numer algorithm to toler round off error .
you won't alwai learn the most effici or most accur wai to solv a problem .
the method i teach ar a compromis between , on the on hand , effici and accuraci and , on the other hand , pedagog valu .
now , a word about the assign .
there ar three kind of assign each week first , quizz .
quizz ar given in the video or right after the video .
and , thei're there to reinforc the materi .
your perform on quizz doesn't enter into your grade , but you will be expect to know and understand the answer to all the quizz .
and in fact , some of the later program assign build on those answer .
anoth word about quizz , we us pattern match to judg your answer right or wrong .
if your particular solut doesn't match the pattern , it'll be judg wrong .
i know how frustrat it is to be told your answer is wrong , when you ar pretti sure that it's a correct answer .
we plan to provid a button for you to click on , when you're sure your answer is right .
now , we won't get back to you about the answer , but we'll us thi feedback to improv the cours for the next time .
a big chunk of the work you do each week , is the homework assign .
a homework assign is just a collect of problem , some of those problem we won't ask you to submit .
thei're there onli to help you learn .
other , both numer problem and program problem , we'll ask you to submit and we'll explain the submiss process to you .
final lab .
a lab is like a homework assign .
it's a collect of task that you're suppos to carri out , but all these task ar orient toward on goal .
it's in the lab , that you'll see some of the fun applic of linear algebra .
i've written a textbook that student us in the brown version of thi cours .
it cover everyth , includ the advanc topic .
we won't get to in thi eight week cours .
it's absolut not necessari for thi onlin cours , we'll present everyth you need in the video lectur and in materi that accompani them .
but , for those student who feel the need for the written record of the materi and topic cover in the cours , i'll link to it from their webpag .
the cours is difficult , it's go to take a lot of work on your part , but you're not alon .
there's the forum where you'll be abl to post question and get help from your colleagu who ar also take the cours .
let's get to it .
befor we get to vector and matric and the like , i'll present some basic mathemat definit and notat that we're go to us throughout the cours .
a lot of these that you mai alreadi know .
so , feel free to go through them veri quickli , or skip over part you know .
a set is an unord collect of object .
so spade .
so heart , spade , club , and diamond .
the order doesn't matter .
we us the , thi symbol to mean that an element belong to a set .
so , the heart belong to thi set .
thi mean that a is a subset of b .
what that mean is that everi element of the set a is also an element of b .
we sai two set ar equal if everi element of on is an element of the other .
rememb , the order doesn't matter .
and , a conveni wai to prove that two set ar equal , is to prove that each is a subset of the other .
the proof usual ha that form .
first you prove that a is a subset of b , then you prove b is a subset of a .
here's a notat that we're go to us a lot .
call it a set express .
the set of non neg number would be written like thi the set of all number x in the real number such that x is greater than or equal to <num> .
so i us the colon to mean such that .
so there ar two part to thi express .
the part befor the colon , which tell us where these element come from and introduc a variabl to refer to them so that i can impos condit in the , in the second part .
second part give a rule or , constraint or condit that sai which of these element belong to the whole set as an analog python express .
let's sai thi set , s is defin to be these integ .
the express x for x in s if x is greater than or equal to <num> give you onli the element of s that ar non neg .
veri often instead of write thi we'd write just thi .
we'd leav out the part that's specifi that x is a member of the real number .
if it's suppos to be clear to you that , that's where these number x ar come from .
here's anoth exampl .
the set of x such that x squar minu <num> over <num> time x plu <num> <num>th equal <num> .
implicitli , we're talk about real number x .
and thi set consist of just two number , on half and <num> 3rd .
if a set s is not infinit , we us these vertic bar to denot the number of element in a set .
it's call the cardin of the set for exampl thi set ha cardin form .
now , i introduc the cartesian product .
given set a and b , the cartesian product of a and b is the set of all pair , littl a , littl b , where littl a belong to big a and littl b belong to big b .
so , here's an exampl .
we can take the cartesian product of the set consist of on , two , and the set consist of heart , spade , club , and diamond .
the cartesian product is the set of all these pair .
thi is name for descart , and we'll see him later on in the cours .
so for exampl , what's the cardin of the cartesian product of a with b , in thi case ?
well , we have two choic for the element of big a and four choic for the element of big b , so we end up with eight in total .
there's a simpl rule that if a and b ar finit set , the cardin of the cartesian product is the product of the cardin of the two set .
us thi , what's the cardin of thi cartesian product .
there ar <num> element in thi set and four element in thi set , so the cardin of the cartesian product is <num> .
thi express denot the set of all pair of real number , in which the second equal the squar of the first .
and of cours we might abbrevi that in thi wai , leav out thi part .
so just a set of pair , xy , such that y equal x squar .
you're suppos to guess from the context that x and y ar element of the real number .
here's anoth exampl .
the set express tell us that the set consist of all tripl , x , y , and z .
where x , y , and z ar element of the real number , such that x is greater than <num> and y is greater than <num> , and z is greater than <num> .
that is , it's the set of all tripl of non neg real number .
you're suppos to interpret the comma here as an and all the condit on the right have to be satisfi for the tripl to belong to the set .
and as befor we might abbrevi that by leav out thi part and write it in thi wai .
what's a function ?
well intuit a function for each input element in a set a , a function assign a singl output from anoth set , b .
and in thi context , a is call the domain of the function , and b is call the co domain .
formal , in math , a function is often defin as a set of pair , ab no two of which have the same first element a .
so here's an exampl .
the function with domain <num> , <num> , <num> and so on that doubl it input is repres by thi set thi set of pair the first element of the set is the pair <num> , <num> the second is <num> , <num> and so on .
here is anoth exampl .
in thi case , the domain is the cartesian product of the posit integ with itself , and thi function involv multipli the two element that form it's input .
so <num> time <num> is <num> , <num> time <num> is <num> , and so on .
now , the output for a given input is call the imag of that input under the function .
the imag of q under the function f is denot f of q .
thi should all be veri familiar .
and we would sai that , if f of q equal r we that we sai that q map to r under f .
in mathes , we write it thi wai q map to r .
so thi symbol repres map to .
now rememb that thi set from which the output ar all chosen is the co domain .
we us thi notat to mean that f is a function whose domain is d and whose co domain is f .
now we have some flexibl in defin a function , as to the choic of the co domain .
we're allow to have element in the co domain that ar not imag of ani element in the domain .
here's a quick exampl , caesar cryptosystem , a caesar cypher .
each letter is map to the on three step ahead .
so matrix would map to pdwula .
so , the function map letter to letter can be written in thi wai .
in map a to d , b to e , c to f , and so on .
now , we might us a diagram like thi to repres that same function .
a map to d , b map to e , and so on .
in thi case , both the domain and the co domain ar the letter a through z .
now , the imag of a function is the set of all the imag of the input .
the imag of element of the domain .
it's written , im of f .
for exampl , the cosin function , we can defin the cosin function to have the domain the set of rule number and the co domain also the set of real number .
howev , the imag of the cosin function is just those real number that lie between <num> and <num> .
becaus those ar the onli number that ar the imag under the function cosin of element of the domain .
and notic that the imag in thi case is not the same as the co domain .
the imag of the caesar encrypt function is a through z , which is the same as the co domain .
here's anoth exampl depict here .
the domain is the number <num> through <num> .
and , the co domain is a , b , c , d and e .
and you notic , the imag of thi function is the set a , b , c and e .
d is not in , in the imag .
becaus there's no element of the domain that map to it .
you might be familiar with the term rang .
some peopl us rang to mean the co domain of a function , and some peopl us rang to mean the imag .
becaus there's thi confus , i tend to avoid the word rang altogeth .
so i just us co domain and imag .
for set f and d , f to the power of d repres all the function from d the expon to f .
so for exampl , the set of all function from the set of word in some languag , the set of real number will be written in thi wai , r to the w .
and note that for finit set , the cardin of f to the d equal the cardin of f to the power of the carnal of d .
for ani domain d , ani set there's an ident function .
written id , sometim with a subscript , the domain , it domain is d , it co domain is d .
and it simpli map each element of the domain to itself .
so here's an exampl .
it map the integ <num> , <num> , <num> , and <num> to the integ <num> , <num> , <num> , and <num> .
it's not veri interest , but it's us in the next definit .
now for function f with domain a and co domain b , and g with domain b and co domain c .
the function composit of f and g is the function which we write , g compos with f .
the domain is a and the co domain is c and it defin in it wai , g compos with f appli to an input x is g appli to the result of f appli to x .
so for exampl , here's a function f whose domain is <num> , <num> , <num> , whose co domain is a , b , c , and d .
here's a function g whose domain is a , b , c , and d and whose co domain consist of <num> and <num> .
here's when we compos them we get thi function .
thi is g compos with f , it take element from the domain of f , and map them to the element of the co domain of g .
here's anoth exampl , if g is the function that squar it's input , and f is the function that add <num> to it input .
g compos with f appli to x is x plu <num> squar .
now , let's us composit to , deriv the caesar encrypt function .
first , we defin the function f by map a to <num> , b to <num> , c to <num> , and so on .
defin g to be the function that add <num> mod <num> .
and defin h to be the function , that goe back from the integ , zero through <num> to the letter a through z .
then h compos with g compos with f is the caesar encrypt function .
so , here ar the three function indic , and here is the function we get by compos all of them togeth .
the parenthes ar not need becaus function composit satisfi associ .
thi is what associ mean .
h compos with the result of compos g with f is the same as h compos with g compos with f .
simpl proof for ani element x of the domain of f , we take h compos with the composit of g and f and appli it to x .
that's the same as h appli to the result of appli , the composit of g and f to x .
and that's the same as appli h to the result of appli the composit of g to the result of appli f to x , and then we can unfold that to get the other form .
we sai that function f and g ar function invers of each other if f compos with g and g compos with f ar defin and ar ident function .
and a function that ha an invers is call an invert function .
now , a function f from d to f is said to be on to on if f of x equal f of y impli x equal y , for everi x and y in the domain .
that mean that there ar no two distinct element that have the same imag .
well , here's a pictur of a function that's not on to on becaus these two element of the domain have the same imag .
a function f is onto if for everi z in the co domain there exist an element , sai a , in the domain , that map to z under that function .
so here's an exampl of a function that is not onto .
becaus here's an element in the co domain that's not the imag of ani element in the domain .
now , invert function ar on to on .
here's the proof .
suppos , you have an invert function f and it's not on to on .
so there exist two element , x1 and x2 that ar differ .
where thei have the same imag , y under f .
well what's the invers of f ?
the invers of f appli to y , is x <num> .
but the invers of f appli to y is also x <num> , by definit of the invers .
and both can't be true .
a function such as f invers ha to have onli on imag for each input .
so that , that prove the the proposit .
similarli , invert function ar onto .
suppos you have an invert function f , and it's not onto .
so there exist some element , sai y hat , in the co domain that's not the imag of ani element in the domain .
well , let's consid the invers , f invers .
thi is a function .
so on input , y hat , it ha some output some valu x hat .
in the co domain of f invers , that is in the domain of f .
by the definit of invers , that would mean that f map x hat to y hat .
but that's a contradict , so that prove the proposit .
in fact , and thi is an import theorem we'll us .
a function is invert if and onli if it is on to on and onto .
the proof is fairli simpl .
it us the two proposit we just saw and a littl bit more work .
that mean that if a function is invert , it's on to on and onto .
we alreadi saw that .
and if a function is on to on and onto it invert .
a procedur is a descript of a comput that , given an input , produc an output .
here's an exampl , a comput problem is an input output specif that procedur might be requir to satisfi .
on that we'll look at later is integ factor .
where the input is an integ , m , greater than <num> .
and the output is a pair of integ whose product is m .
now , there ar some differ between these idea .
function and comput problem don't tell us how to comput an output from an input .
wherea a procedur doe .
and there mai be multipl procedur satisfi for the same spec , so solv the same comput problem .
a comput problem might allow sever output for each input .
that's true of thi integ factor problem , for exampl .
and the same procedur can be us to comput differ function .
in thi cours , we'll write procedur in python .
for exampl , thi is the definit of a procedur to multipli the two input .
you might be us to call these procedur function , but we're go to reserv the term function to refer onli to the mathemat object .
now , in python we will often us a structur call a dictionari to repres a function whose domain is finit .
for exampl , the function depict here can be repres by thi dictionari .
it map a to <num> , b to <num> , c to <num> and d to <num> .
now , a special kind of function is a probabl distribut function .
it's us to specifi the rel likelihood of differ outcom of a singl experi .
the sign of probabl , which is a non neg number to each possibl outcom .
and the probabl of all the posit outcom must sum to <num> .
so , for exampl in the game of scrabbl , at the veri begin the , the bag is fill with , fill with tile .
there ar <num> as <num> bs , and so on .
so at the veri begin consid the experi of draw a tile from the bag .
sinc the total number of tile is <num> , the probabl of draw an e , is <num> over <num> becaus there ar <num> e's .
the probabl of draw an a is <num> over <num> and so on .
the denomin is <num> so that all these probabl will sum up to <num> .
we repres that function by thi python express .
often the probabl distribut is what's call a uniform distribut which simpli mean that it assign the same probabl to all the outcom .
so for exampl roll a die , the possibl outcom ar <num> through <num> and the probabl ar all the same .
thei all have to be <num> 6th becaus rememb probabl have to sum to <num> .
in python , you'd repres thi function by thi dictionari .
map <num> to <num> <num> , <num> to <num> <num> , and so on .
anoth exampl .
to model the flip of two coin .
the possibl outcom ar head head , head tail , tail head , and tail tail .
and the probabl ar all <num> <num> .
we repres that function in python by thi dictionari .
it map the pair head , head to <num> 4th , and so on .
here's an equat .
x squar equal minu <num> .
what ar the solut ?
well , if we stick to the regular number , the real number , there aren't ani solut .
mathematician invent i to be on solut .
you can us i to solv other equat .
for exampl , x squar equal minu <num> , the solut is <num> time i .
now , number such as i minu i , <num> time i , and so on , ar call imaginari number .
you can us the imaginari number to solv other equat .
x minu <num> quantiti squar equal minu <num> ha the solut <num> plu <num> time i .
when you add a real number to an imaginari number , you get a complex number .
a complex number ha a real part and an imaginari part .
the complex number is the real part plu the imaginari part time i .
so , both real part and imaginari part ar real number .
let's try work with complex number in python .
instead of i , python us j becaus in electr engin , i tradition mean current .
we enter the imaginari number 3j and python sai yeah , i got it .
if you enter just j by itself , python think you're refer to a variabl .
so instead , we can type 1j .
now , we can us the usual arithmet oper , such as plu , minu , time and divid .
and thei work pretti much as you'd expect .
know that ad two complex number mean separ ad their real part and their complex part .
we can check our solut to x squar equal minu <num> .
that work out .
we can extract the real and imaginari part of a complex number us a dot notat .
x . real and x . imag .
now , thi mai remind you of object dure the program .
and access to instant field .
yup , complex is a class in python .
we see that in python you us plu to add real number or complex number .
us of the same name for differ procedur is call overload .
and , overload turn out to be quit us .
let's write a procedur , solv .
to solv the equat a x plu b equal c .
well , thi is straightforward in python , and we can us thi to solv an equat like <num> x plu <num> equal <num> , right ?
we plug in the number , and we get the solut .
but becaus of python us of overload , we can us the same procedur to solv an equat that involv complex number .
we just plug in the same complex number , and we get the solut .
also a complex number .
so , the same procedur that we defin for real number happen to work , or complex number as well .
when we want to refer to a field without specifi exactli which field , we'll us thi notat , with thi blackboard f .
so , why doe thi procedur give the correct result for complex number as well as for real number ?
it's becaus it's just base on a few simpl fact about the arithmet oper .
for exampl , divis is the invers of multipl .
subtract is the invers of addit .
similarli , much of linear algebra is base on a few simpl fact about the oper plu , minu , time and divid .
divis is the invers of multipl .
subtract is the invers of addit , and other algebra properti such as that addit is commut .
the order doesn't matter .
and multipl distribut over addit .
so , you can plug in ani collect of number with their own arithmet oper , plu , minu , time and divid .
and as long as these satisfi these basic algebra properti .
you can do linear algebra with that kind of number .
a collect of number that ha these properti is call a field .
so , we're just go to studi three field in thi class .
the field of real number , becaus that's a veri familiar on .
the field of complex number , and the finit field , which i call gf <num> , which consist just of <num> and <num> .
now here's why we're studi the complex number .
well , for on thing , the set of complex number is veri similar to the set of real number .
so we can , we can experi thi idea of abstract and gener of , of , of choos differ field without it be that differ .
now , anoth reason that complex number ar conveni is that thei ar built right into python .
also , complex number ar , in some sens , the intellectu ancestor of vector .
so , some of the basic oper that we can do with complex number .
we'll later learn how to do in higher dimens with vector .
and final , in more advanc part of linear algebra , complex number ar essenti .
now , we can interpret the real and imaginari part of a complex number as x and y coordin .
thu , we can interpret a complex number as a point in the plane .
in thi context , we call it the complex plane .
so , here the complex number z is repres as a point .
it's x coordin is it's real part and it's y coordin it , is it's imaginari part .
now , i'll illustr the idea of complex number as point in a complex plane by plot some complex number .
i'll import a plot procedur we provid and plot thi list of number .
let's plot a longer list of complex number , on deriv from an imag .
i'll first import some imag manipul procedur , defin in a modul we provid .
and now load an imag .
now , we find the length of thi list which is the number of row and the length of on of it element .
just the number of column .
now , we'll defin a collect of complex number base on the intens of the pixel in the imag and plot that .
the plot function take an option second argument , given the scale of the plot .
and an option third argument , given the size in pixel of the point displai .
onc we've interpret complex number as point in the plane , we can take advantag of geometr properti , like length and distanc .
so , we defin the absolut valu of a complex number to be the length of the line segment between that complex number , repres as a point , and the origin .
that is it's the distanc between that point and the origin .
in math , we would write it with vertic bar .
and in python , the absolut valu of a complex number is written ab of complex number of z .
now here's a function .
it map the input complex number to that number plu <num> plu 2i .
how do we interpret that geometr ?
the effect of thi function is to add <num> to the real part of z and <num> to the imaginari part of z .
we can think of that as oper on a point .
and get anoth point that's on unit to the right , and two unit up .
so , appli that function to all these point would shift them , up and to the right .
we call a function of thi form a translat .
it said to translat a set of point .
let's us python to translat these point in l .
we can serial translat the point from the imag .
we'll take thi imag .
translat them so that the imag is center at the origin .
given the input , it add a complex number , z0 , to the input .
and a translat can move the pictur anywher in the complex plane .
all right .
so we can interpret the complex number , z0 , as repres the translat that add z0 to the input .
onc we interpret a complex number as a translat , we can think of it as an arrow in the complex plane .
the arrow's tail can be locat at ani point z .
then the arrow's head is locat at z plu z0 .
so , the arrow show an exampl of how the translat act on a point .
so , let's try repres thi complex number as an arrow .
we can choos anywher to put it tail and on conveni place to put it is at the origin .
so , the tail will be here .
and the head should be at the locat with x coordin minu <num> and y coordin <num> .
so , on , two , three , four , five , six .
on , two , three , four , five .
so the head should be here .
so , the arrow would look like that .
now , consid two complex number .
each of them correspond to a translat .
let's take the function composit of those two translat .
so , first we appli f2 to the input , then we appli f1 .
that's the same as ad first z2 and then z1 .
so , we can repres function composit by ad arrow .
here's an exampl .
let's sai we're first go to appli f <num> .
so that take a point .
let's start with the origin .
and translat it three unit to the right and on unit up .
on , two , three , on .
so , that goe here .
next , we'll write down the arrow repres thi complex number .
thi complex number sai move two unit to the right and three unit up .
and we can write it as an arrow with the tail locat anywher and a conveni place to put the tail is at the head of the last arrow .
so we could have better write here .
here is the tail .
the head will be two unit to the right and three unit up .
so , thi arrow is repres .
thi complex number is repres by thi arrow .
now , what about the function composit ?
the function composit add z1 plu z2 to it input .
you can find that arrow by choos it tail to be the tail of the first arrow , and it head to be the head of the second arrow .
so , z1 plu z2 is repres by thi arrow .
so , we see that addit of complex number can be repres by put arrow togeth .
ad them in thi wai consid the oper of multipli a complex number by <num> .
what's the geometr interpret ?
how doe thi affect arrow repres complex number ?
so , we're appli the function f of z equal <num> time z .
let's sai we start with a complex number <num> plu 4i .
we repres that by an arrow that move two unit to the right and on , two , three , four unit up .
so , thi arrow , when we multipli the complex number by <num> .
what we're do is multipli the real part by <num> , halv the real part and halv the imaginari part .
as a consequ , the arrow repres that complex number goe on unit to the right and two unit up .
it give you an arrow in the same direct but half the length .
thi is call scale .
let's see what it look like when we scale all the complex number in the list l and plot them .
or the number in the list m deriv from the imag .
what about if we multipli a complex number by minu <num> ?
let's try that .
let's start with the same complex number <num> plu 4i .
multipli thi by minu <num> .
mean multipli the real part by minu <num> and the imaginari part by minu <num> .
so , we end up with minu <num> plu minu 4i , which is an arrow that goe in exactli the opposit direct .
so , thi is call reflect .
now , we'll multipli each of the point in the list l , by neg <num> and plot the result .
and the same for the point in the list m .
how would we rotat by <num> degre ?
let's sai we start with the complex number <num> plu 4i .
so , that's repres by the arrow that goe on , two , three , four .
rotat that <num> degre should give us thi arrow repres by the arrow that goe four unit to the left and two unit up .
thi is the complex number <num> plu 4i .
thi is the complex number minu <num> plu 2i .
so , we need a wai of map .
from the complex number x plu y i to the complex number minu y plu x i .
how can we do that ?
we us the properti of i , that i squar is minu on .
so we multipli i time x plu y i .
us the distribut law , you get x time i plu y time i squar , which is x time i minu y .
so , the function will us for rotat by <num> degre is f of z equal i time z .
what about rotat by anoth angl ?
well , let's start with thi definit .
the argument of a complex number is the angl , measur in radian , between the x axi and the arrow repres the complex number .
to see how to increas the argument of a complex number , we turn to a formula due to euler , a remark mathematician .
contribut to mani area of mathemat not to mention music theori and cartographi .
euler's formula state that for ani real number theta , e to the theta time i is the point z in the complex plane on the unit circl whose argument is theta .
here e is the famou transcendent number , <num> . <num> and so on .
so , here's an exmapl .
we plug in theta equal pi  over <num> , which correspond to <num> degre .
e to the i time pi  divid by <num> is thi , is thi point in the complex plane .
notic that the arrow to that point form a <num> degre angl with the x axi .
we plug in theta equal pi  , that correspond to an angl of <num> degre .
so , the complex number is thi on , which turn out to be minu <num> .
so , e to the i time pi  is minu <num> .
let's form a bunch of complex number by plug in multipl of <num> pi  over <num> for theta in euler's formula .
first , we have to get pi  and e .
now that form a circl of dot .
next , let's try multipli all these complex number by <num> .
let's see how we can us the euler's formula to rotat point by ani angl tau .
ani complex number can be written in thi form .
z equal r time e to the theta i , where r is a real number call which is the absolut valu of z , and theta is the argument of z .
what we want to do is increas the argument of z .
we'll us the exponenti law e to the a time e to the b is e to the a plu b .
so , if we start with the complex number z , which is r time e to the theta i .
and we multipli it by e to the tau i .
by the exponenti law , that's the same as r time e to the theta i plu tau i , which is the same as r time e to the theta plu tau i .
so we get a complex number whose absolut vallu is the same as the on we start with , but whose argument is theta plu tau .
so , the function multipli by e to the tau time i , carri out rotat by an angl of tau .
to illustr thi , we'll rotat all the complex number in the list l by pi  divid by <num> radian .
basic , <num> 8th of the circl , which is equival to <num> degre .
and the same for the complex number in the list m .
now we tune into anoth field , galoi field <num> .
which ha just two element , <num> and <num> .
it's name after galoi , who wa a remark mathematician , who laid the foundat for group theori but di in a duel at the ag of <num> .
addit of <num> and <num> in the galoi field <num> is just like exclus or .
that is , ad <num> and <num> give you <num> .
multipl is just like ordinari multipl of <num> and <num> .
and the usual algebra law hold for exampl , multipl distribut over addit .
then we'll provid a simpl modul call gf2 that defin a valu , on .
thi valu act like the <num> in gf2 .
so , and we'll us <num> when we're , when we write program that oper on gf2 valu .
here's an applic of gf2 to cryptographi .
now , suppos alic want to commun with bob .
she onli want to commun on bit let's sai .
it's call p , the plaintext .
so , thei us a , a cryptosystem to ensur privaci .
now here's the tabl describ the cryptosystem .
alic and bob agre beforehand on a secret kei , k and alic will encrypt her plaintext , p by us thi tabl to figur out the cyphertext c , that she should transmit to bob .
by studi that encrypt tabl , you might notic that it's realli just the addit tabl for gf2 .
we can therefor implement encrypt like thi .
and here's how we would us it .
import the on from gf2 .
let's sai the kei is on , and the plain text is on .
we comput the cyphertext us encrypt and that's what we get .
now onc bob receiv that cyphertext , can he figur out what the plain text is ?
well , he know k the kei , he receiv <num> and <num> as the cyphertext .
now for ani particular valu of k and ani particular valu of c , there's onli on valu of plain text that's consist with those .
so , bob can determin what plain text wa intend by alic .
now , suppos an eavesdropp ev , observ the valu of c .
she doesn't know the secret kei , can she learn anyth about the plaintext ?
and here's the simpl answer , no and here's why .
suppos that the cyphertext is <num> , rememb ev doesn't know the kei .
she can look at thi tabl and sai oh , the cyphertext is <num> , so mayb the plain text is <num> .
that's the case if the kei is <num> or mayb the plain text is <num> if the kei is <num> .
sinc she doesn't know whether the kei is <num> or <num> , she can't figur out whether the plain text is <num> or <num> .
and here's a somewhat more sophist answer .
it depend on how the secret kei is chosen .
so , let's suppos the secret kei is chosen by flip a coin .
so , the probabl is on half that the kei is <num> and on half that the kei is <num> .
let's look at it from ev's perspect .
befor she even goe out to eavesdrop , she reason as follow suppos the plain text turn out to be <num> .
well the kei is chosen randomli .
so , look at the first two row of the tabl , the probabl that the correspond cyphertext is <num> is on half .
and the probabl that the cyphertext is <num> , is on half .
now suppos that the plain text wa actual <num> .
look at the last two row in the tabl , the kei is chosen randomli .
so , the probabl that the cyphertext is <num> is on half .
and the probabl of the cyphertext is <num> is on half .
so , the choic of the valu p , the plain text is not the reflect in the probabl distribut of the cyphertext .
ev doesn't learn anyth from observ c , she might as well just stai home and flip a coin becaus the cyphertext is just <num> with probabl on half , and <num> with probabl on half .
what is it about thi cryptosystem that lead to perfect secreci ?
why doe ev learn noth from eavesdrop ?
well , let's defin the function f0 as follow .
f0 take as input the kei , k and output the encrypt of the plaintext <num> with that kei .
so , accord to the first two row of thi tabl , f<num> of <num> equal <num> and f<num> of <num> equal <num> .
thi function is on to on and onto .
now , when the kei k is chosen randomli accord to the uniform distribut , that is when , when k is <num> with probabl of on half , and <num> with probabl of on half .
then , the probabl distribut of the output is also uniform .
that is , the probabl that the cyphertext is <num> is on half and the probabl that the cyphertext is <num> is also on half .
now let's turn to the function f1 .
f<num> is the encrypt of the plain text <num> with a kei k .
now , accord to the last two row of thi tabl , f<num> of <num> equal <num> and f<num> of <num> equal <num> .
so , thi function is also on to on and onto .
and so , when the kei is chosen uniformli at random , the probabl distribut of the output is also uniform .
that is , the probabl that the cyphertext is <num> is on half and the probabl that the cyphertext is <num> is also on half .
so , it seem regardless of what the plaintext is , the probabl distribut of the cyphertext is uniform .
on half probabl of <num> and on half probabl of <num> .
so , the probabl distribut of the cyphertext doesn't depend on the plaintext , when the kei is chosen randomli .
from ev's perspect , there's no point in observ the cyphertext .
she know it's just go to be a bit , either <num> or <num> , it show in accord to the uniform distribut .
she might as well stai home and flip a coin .
thi is the idea , for the cryptosystem call , the on time pad .
if each bit is encrypt accord to thi tabl with it own on bit kei , thi cryptosystem is unbreak .
no eavesdropp can learn anyth .
now , in the 1940s , the soviet seem to have run out of kei , and thei start reus bit that thei'd us from previou messag .
and thi wa discov by the us armi's signal intellig corp servic .
thei start slowli find place where thei could decrypt littl bit of the messag .
thi led to some veri import intellig includ inform about the soviet espionag on nuclear weapon .
and we onli learn about thi in <num> , when when inform on thi project , the , the venona project wa declassifi .
here's anoth applic of gf2 .
imagin you need to stream video through a network , start at thi point .
now , if there's onli on recipi of the , of the video stream , sinc there ar two path that share no edg , the video can be pump at two bit per unit time , from thi point to thi point .
on bit through each of these path .
but now suppos that there ar two recipi of the video stream .
well , on bit is be sent thi wai , on bit is be sent thi wai but there's content on thi link .
so , you can't directli stream two bit per unit time , through thi network to both receiv .
instead , we requir the network itself to do a tini bit of comput .
so , at thi point in the network , the two bit of the stream ar ad togeth us the addit rule for gf2 .
now , at thi point , thi recipi get the bit b1 and the bit b1 plu b2 .
thi recipi can obtain b2 by subtract b1 from the sum .
thi recipi get the bit b2 and the bit b1 plu b2 .
so , can obtain the bit b1 by subtract .
so , you can see in thi case , you could effect doubl the throughput from thi sourc to these two recipi us gf2 addit .
complex number ar so conveni for appli geometr transform like rotat , scale and translat in two dimens , that you kind of like find someth similar that work in higher dimens .
for exampl , three dimens .
hamilton thought a lot about thi problem .
hamilton wa kind of a prodigi , he learn latin , greek , and hebrew by five .
and by ten he'd learn a total of <num> languag includ persian , arab , hindustani , and sanskrit .
now , he'd been puzzl over the issu of how to go beyond two dimens , us someth like complex number for a long time .
when inspir hit him , and he came up with these equat .
unfortun , the time he came up with these equat , he wa on a walk with hi wife .
and he wa so taken with the idea , he , he wrote , wrote down the equat in , the most conveni place .
which wa the stone bridg he happen to be pass .
for thi act of vandal , in fact , there's a plaqu on the bridg commemor it .
now , as you can tell from thi quot , hamilton wa not a ma , a modest gui .
he thought thi wa the solut .
and it is veri conveni , the , the number that you get in thi wai ar call quaternion , and thei're still us todai .
but there's anoth concept that's us even more frequent and that's due to gibb .
gibb wa a yale man , start at yale at ag <num> and eventu becam a professor there .
he had an idea vector analysi , that displac quaternion for a lot of applic .
now he didn't publish hi note for a long time .
final , he publish them <num> year later .
and he wasn't a complet hit .
there were those who still believ in quaternion .
for exampl peter guthri tait who wa a support of quaternion , but even though quaternion ar still us todai vector ar us much more .
so what's a vector ?
thi is what you might think is a vector .
a list of number in thi case four number , thi is call a <num> vector over the field of real number .
we'll us python's list sometim to repres vector us thi notat and the set of all <num> vector over the real number is written r4 .
thi notat might remind you of the notat r to the d the set of function from d to r .
and in fact i want us to think about vector as function , so our <num> vector you might think of as a function from zero , on , two , three , to the real number .
f to the d is the notat for the set of function from zer , zero , through d minu <num> to f .
here's anoth exampl , us the field of gf2 .
gf2 to the <num> is the set of all <num> element sequenc made up of zero and on .
so for exampl , zero , zero , zero , zero , zero .
here's anoth exampl .
let word be the set of all english word .
now in inform retriev a popular wai of repres document is to forget the structur of the document , forget the syntax .
and just repres the document by a bag of word .
that is , a map from the set of word to the number , specifi for each english word , if the document's in english , how mani time that word occur .
so we're often go to us python's dictionari to repres function .
so , for exampl , thi is the function that repres the vector we just talk about .
what about repres a document that is a word bag , a function from the set of all english word to their real number ?
well , thi represent start look not so good , becaus thei ar a lot of english word and document don't tend to includ them all .
we adopt the convent that , kei valu pair where the valu is zero can be omit from the dictionari .
so the document , the rain in spain fall mainli on the plain , would be repres by , by thi function .
we haven't repres those word that don't occur in the document .
a vector most of whose entri ar zero is call a spars vector .
and if no more than k of those entri ar nonzero , we sai the vector is k spars .
a k spars vector can be repres , repres us space proport decai .
for exampl , when we're us thi bag of word model , we can repres all the document in a corpu of document .
and the total space requir is no more than the sum total of the length of the document .
now , most signal acquir us physic sensor such as imag or sound ar not spars come in .
but there ar wai of achiev a sort of artifici sparsiti by suppress some of that signal .
that's the idea of lossi compress , and we'll get to that later in the cours .
so what can we repres with vector ?
we've alreadi seen , we can repres document .
we can repres binari string .
and thi will be us in cryptograph applic .
we can us a vector to repres a collect of attribut .
for exampl the vote record of a senat , or the demogra , demograph record of a consum , or characterist of cancer cell .
we can also us it to repres the state of a system .
for exampl , a popul of differ countri in the world or the number of copi of a viru in a comput network .
the state of a pseudorando , a pseudorandom number gener , or the state of a game call light out .
you can also us it to repres a probabl distribut , which is , after all , a map from some set to the real number .
here's a wai we can us it to repres an imag .
an imag , you ordinarili think of an imag as a grid of pixel and each pixel is repres by an intens .
well , you can think of thi as a map from the pixel coordin to the real number .
so , thi imag is repres by thi function .
which we can interpret as a vector .
we can also repres point in space .
thi is on of the origin us of vector .
so we'll be take a closer look at thi applic .
we saw that complex number can be repres by point on the plane .
in such a wai that we can carri out geometr transform in a simpl wai .
we're go to us vector to repres point .
and we'll see how these same oper can be repres us oper on vector .
let's try thi in python .
let's start with a , a list of vector repres as list of length two .
we can plot these us the same modul complex number .
now with , with complex number we achiev to translat by addit .
so in order to do the same thing with vector , we have to introduc a vector addit oper .
so here is the basic definit of vector addit .
to add two vector , you just add them entri wise .
here is the , here is the code for , do addit of two vector , in python , when the two vector ar repres as list .
now there's a , alwai a <num> vector , and notic that ad the <num> vector to ani vector give you back that vector .
addit ha these variou algebra properti , associ and communit .
and we'll see how those get us .
now like complex number , we can repres vector as arrow in the plane .
so thi vector of <num> , <num> , <num> can be repres with it tail at the origin and it head here .
it could equal well be repres with it tail over here .
now , addit can be interpret as an oper on arrow .
just as in the case of complex number .
to add vector u and v , you place the tail of v's arrow at the head of u's arrow .
and now you draw a new arrow from the tail of u to the head of u .
now , with complex number , we're abl to scale them , make them bigger or smaller , by multipli by real number .
we're go to do the same thing for that group .
so we refer to field element such as real number such as scalar .
and we us them to scale vector us scalar vector multipl which is indic in thi wai .
now i us alpha , beta , gamma , greek letter to repres scalar in the context of scale or vector multipl .
the formal definit goe like thi .
to multipli a vector by a scalar , you simpli multipli each of the entri by that same scalar .
here's an exampl .
now let's interpret scale on , as an oper on arrow .
so here's an arrow repres the vector <num> , <num> , <num> .
and when we scale it by <num> , we get a vector that's in the same direct , but is twice as long .
scalar vector multipl satisfii an algebra properti .
multipli a vector by beta and then multipli the result by alpha is the same as multipli the origin vector by alpha time beta .
now , let's start with the vector 'v' sai <num> , <num> and consid a whole bunch of scalar multipl us scalar rang from zero to on .
each scale give you a differ size arrow in the same direct .
so let's try that in python .
we start with the vector v repres as a two element list .
now we're go to plot a whole bunch of scaler vector multipl .
and you could see it's start to form a line segment .
let's do the same thing , but with a lot more point .
what if we let the scalar alpha rang over all real number , rather than just the number between zero and on .
well , the scalar is bigger than on , will give rise to arrow that ar longer than the origin vector .
and the neg scalar will give rise to arrow in the opposit direct .
let's try it out in python .
our conclus is that if you let alpha rang over all real number the set of scalar multipl form the line go through the origin and the vector v repres as a point .
now , so far we know how to repres line and line segment that go through the origin and a given , given vector v .
but , for purpos of sai draw map , we want to be abl to draw line segment that don't necessarili go through the origin .
well let's see how we can deriv that .
we're go to us the idea of translat .
so , we know how to draw a line segment from zero to three two .
that's just thi .
instead of multipl alpha time <num> , <num> where alpha rang between <num> and <num> .
so here's that line segment .
what we're go to do is translat that .
now we know the translat is perform by do vector addit .
so we're go to add the vector . <num> , <num> to everi vector in that line segment .
and what we should get is the line segment from <num> plu <num> , <num> to <num> , <num> plu <num> , <num> .
scalar vector multipl distribut over vector addit .
for exampl , you can add these two vector and then multipli them by <num> or you could multipli each of the vector by <num> and then add the result .
and you'll get the same answer .
we'll us that in come up with anoth formul of the line segment between two point .
so here's our current formul of that line segment .
we take the set of point make the line segment from <num> to <num> and we add <num> , <num> .
thi is not a particularri nice formul .
it doesn't treat the end point in a symetr wai .
so we' re go to us the distribut law , to reformul it .
so alpha time <num> , <num> plu <num> , <num> can be rewritten in thi wai us the distribut law .
anoth applic of the distribut law give us thi , and we can rewrit that in thi wai .
so now , we've got thi express in term of the two end point and two scalar multipli , alpha and beta , where beta is <num> minu alpha .
so a more symmetr formul of the line segment between two point .
is alpha time on point , plu beta time the other .
rang over all alpha and beta that sum to and ar non neg .
and thi formul is symmetr .
so our new formul is alpha time on vector , plu beta time anoth .
for all alpha and beta that ar non neg and sum to <num> .
express of thi form where thi form , where the scaler multipli ar non neg and sum to on is call a convex combin .
and what we've seen is , that the u to v line segment , is the set of convex combin of the vector u and v .
we can us convex combin on vector that repres thing other than point .
here we're go to take two vector u and v that ar repres imag .
and on exampl of a convex combin assign alpha on half and beta on half , thi is just the averag .
and the averag of two imag is some mix of the two .
now we can also us the idea of a line segment between two face .
so here we're take a whole bunch of differ combin of alpha and beta to repres a sort of line segment between face .
we can get a kind of crossfad effect in thi wai .
and what about the infinit line through two given point .
we had a formul which is not so great , it's not symmetr between the two point , but we can get a nicer formul in thi wai .
alpha time on point plu beta time the other , for all alpha and beta that sum to on .
an express of thi form is call an affin combin of the two vector u and v .
and we see that the line through u and v consist of all affin combin of u and v .
we'll turn to other wai of repres vector in python .
i've told you that a vector is just a function from some domain d to a field .
and , we know how to repres function in python us dictionari .
so we're go to develop a class , a python class , call vec with two instanc variabl , two field .
on is f , which repres the function , us a python dictionari .
the other is d , which repres the domain us a python set .
and here we're go to adopt the convent that entri whose valu ar zero don't have to be repres in the dictionari .
thi is our sparciti represent .
so here's a kind of bare bone definit of a class that ha these two field .
we can us thi to creat an instanc by suppli two argument , the set , the domain d , and the function f , repres as a dictionari .
now , we can assign , sai , assign thi vector to a variabl and access the <num> field of v us a dot notat .
here's the code for the setter .
it take an instanc v of vec , an element of d of the domain of v , and a valu , an element of the field .
and it simpli chang the dictionari , v . f , so that d map the val .
so we can us it in thi wai .
here's a quiz .
write the correspond getitem procedur .
it take a vector v , and a domain element d , and it output the valu of entri d of the vector v .
here's the answer .
if the domain element d is on of the kei of the dictionari , v . f , then the procedur return the correspond valu , and if not , return <num> .
here is an altern definit , a littl less python .
why is , why is thi code insuffici ?
thi code just return the valu that d map to in the dictionari v . f .
well , thi isn't suffici , becaus d might not be a kei of v . f , becaus of our sparsiti convent .
if the 'd' entri of the vector 'v' is zero then 'd' need not be a kei of the dictionari .
now , earlier we gave the definit for a rudimentari python class for vector .
here it is .
but , we're go to code much more elabor version of the class that allow us of oper overload for element access , scaler vector multipl , vector addit , dot product and so on .
here's a tabl show the differ oper that thi class will allow for .
us thi class , we'll be abl to write much more concis vector code , such as thi .
thi set the a entri of v to <num> .
thi assign to the variabl b the vector obtain , by subtract from the current valu of b , a vector , a scalar multipl of v .
and the scalar is the dot product of the current valu of b with the vector v and thi print the vector b in a nice format .
you're go to code thi class start from a templat that we provid .
and the quizz will help you know how to fill out , the procedur .
you're go to write the bodi of name procedur , such as setitem , deaditem , add and scalar multipl .
now , in actual us vec , you're not go to us those name procedur , you're just go to us the oper .
so , for exampl , thi code instead of thi messi code .
in fact , in all your code outsid the vec modul itself you're not go to import those name procedur .
you're simpli go to import the class vec .
and that will come along with all these , oper overload .
so in short , in code outsid of vec , just us the oper when oper on vec .
for each procedur , you write , we'll provid the stub of the procedur .
so for exampl , for add , here's the stub we provid .
now thi first line is a , a document string .
it's basic a comment that tell us what the procedur suppos to do .
the second line is an assert .
it assert in thi case that to add two vector , the domain have to be equal set .
now , if thi procedur get past to two vector with differ domain it will be report an error .
the assert is there to remind us of a rule of vector addit , name that you can't add vector whose domain ar differ .
so let's keep the assert in the code , at least when write procedur that us it for thi class .
now , thi vec class you write ha got to be correct .
you're go to be us it a lot .
so we're provid a lot of test case in a file test_vec . py .
so , you can test your vec implement us all these exampl by just copi the exampl into python and see whether the result match the result we provid in test . vec .
if thei don't , someth is wrong with your vec implement , and you realli have to figur it out and fix it .
now , onc you think you've got someth that work , you can run all the test at onc .
from outsid python , in the command line , by execut , by type thi command , to a consol .
thi is the name of whatev python you ar us , m doctest and test_vec . py .
that will import your vec implement from vec . py and run all the test .
and it will print messag if some of the test fail .
so if noth get print , you're good .
all the test have pass .
the vec class is us for repres vector , but it's not the onli us represent .
well , we'll sometim repres vector by list .
a list of length n can be view as a function from <num> to n minu <num> .
it's easi to convert from a list base represent to a dictionari base represent such as that .
write the procedur list to vec , that take a list of field element and output an instanc of vec with domain zero to the length of the list minu <num> , such that entri i of the vector v equal element v of the list l for each integ i in thi domain .
here is the answer .
here's an altern .
thi first solut us thi handi enumer procedur , which allow you to enumer over the pair kx where k is an index of into the list , and x is the correspond element .
and thi is us a more tradit loop in which we iter through the indic into the list .
the procedur zero . vec and list2vec , which you've written in quizz ar defin for you in the file vecutil , which we've provid for you .
now , we turn to vector over gf <num> .
here's an exampl of addit of gf <num> vector .
we're ad them entri wise .
and , of cours , <num> plu <num> is <num> , <num> plu <num> is <num> , and so on .
now , we'll us the notat sometim , <num> , <num> , <num> , <num> instead of the list , <num> , <num> , <num> , <num> .
so , here's anoth exampl .
what's <num> , <num> , <num> , <num> plu <num> , <num> , <num> , <num> .
and the answer you should get is <num> , <num> , <num> , <num> .
now , let's see how we can us gf <num> edit to achiev perfect secreci in a cryptograph sens .
so , we're go to repres encrypt by n vector addit over gf <num> .
so , let's imagin that alic and bob agre on thi kei .
it's a ten , ten vector over gf <num> .
and later , alic want to send a messag to bob .
here's the plain text .
she encrypt it by ad p and k , the plain text to the kei to get the ciphertext .
so , here's the ciphertext .
when bob receiv c , he can decrypt it by subtract , which is the same as ad , the kei .
and he get back the origin messag .
now , i claim that if the kei is chosen accord to the uniform distribut , thi scheme is perfectli secret .
for each plain text , there's a function that map the kei to the ciphertext .
name , given the kei , k , it , it map k to k plu p .
now , thi function is invert .
what that mean is , that if the kei k is chosen accord to the uniform distribut , the output will also be distribut accord to the uniform distribut .
now , that doesn't depend on which plain text we chose .
regardless of the plain text alic choos , the distribut of the output is the uniform distribut .
so , an eavesdropp learn noth about the plain text by look at the output .
here's anoth us of the same idea .
suppos i have a secret , the midterm .
so , i'll repres it as an n vector over gf <num> .
now , i want to provid it to my teach assist so that i can go on vacat .
howev , i don't complet trust my ta .
on of them might be bribe to give awai the midterm befor it time .
so , the solut is to provid piec to the two teach assist .
i want the two of them jointli to be abl to reconstruct the midterm .
but i don't want ani on of them act alon to know anyth about the midterm .
so , here is the solut , i start by choos a random n vector over gf <num> , let's call it va .
i then comput vb by subtract , so is the same as ad in gf <num> , subtract the va from v .
now , i provid va to alic , on of my ta , and vb to bob , the other ta .
and i leav on vacat .
what ha alic learn form her part ?
well , all she receiv is a random n vector .
well , what about bob ?
the part he receiv is the output of a function f of x equal v minu x where the input is chosen accord to the uniform distribut .
sinc thi function is invert , the output is also distribut accord to the uniform distribut .
so , he learn noth .
it seem like a realli simpl trick , but rsa just introduc a product base exactli on thi idea .
their product split a password us essenti the techniqu we just show .
so , thei can be store on two separ server , make it more secur .
here's anoth applic of gf <num> .
thi is the light out puzzl .
it's a grid , <num> by <num> consist of button that light up .
when you push a button , it toggl the light , so if the light is on , it turn it off .
if the light's off , it turn it on .
it toggl the light on the button you push .
but it also toggl the light on the button immedi abov and immedi to the left and right of the button you push .
so , if i push thi button .
well , and the goal is to push enough button to turn off all the light .
all right , i'm obvious not veri good at thi , but i know linear algebra .
so , i'm go to look at how we can us linear algebra to figur out how to solv light out .
so , given a configur of light , we want to figur out what sequenc of button push will turn off all the light .
we're go to repres the state of light out us a vector .
there's go to be an entri in the vector for each light in light out .
so , for <num> by <num> light out , that mean there ar <num> entri .
and these ar vector over gf <num> .
here's a represent of the state of light out .
i'm us these black dot to repres light that ar on .
now , the trick is we can also repres each button as a vector over gf <num> .
we repres a button by the gf <num> vector with on in exactli the posit that ar toggl when we push that button .
rememb that in gf <num> , ad on mean flip a bit .
if you add <num> to a <num> , it turn it into a <num> .
if you add <num> to a <num> , it turn it into a on .
let's look at the <num> by <num> case .
so , suppos thi is the state of light out .
and we push the button in the top left .
well , the button in the top left toggl , the light in the top left , the light immedi toward right and the light , and the light immedi below it .
so , thi is the move vector correspond to that button where the dot repres 1s .
if we add thi vector to the vector repres the state , we get thi vector .
which repres the state obtain by push that button .
similarli , given thi state , we push the button in the middl .
it toggl the light in the middl , the light directli abov and below , and the light to the left and the right .
result in thi state .
final , from thi state , if we push the button in the bottom right , it toggl these posit , give you the state in which all the light ar out .
the kei idea here is when we us vector over gf <num> , ad a vector toggl exactli the posit where that vector we're ad ha 1s .
so , we can us gf <num> vector to model the process of push button in light out .
the question is which sequenc of button will lead to the configur in which all the light ar out .
here ar some simpl observ .
by the commut properti , the order in which you push those button doesn't matter .
also , if you add a button vector twice , thei cancel out .
so , realli instead of try to think about the sequenc of button we push , all we have to do is figur out which set of the button vector we have to push .
that is , which set of the button vector will sum up to the vector repres the initi configur .
thu , we've reduc the problem of solv an instanc of light out , to which set of button vector sum up to the vector repres the initi configur .
a more gener version of that problem is , given a bunch of vector over gf <num> , find a subset whose sum equal some target vector s .
now i'll introduc anoth vector oper , dot product .
the dot product of two vector is the sum of the product of correspond element .
so , for exampl , with vector repres .
as list u1 through un , and v1 through vn , the dot product is the sum of u1 time v1 , plu u2 plu v2 , and so on .
now notic that the output of dot product is a scaler not a vector .
for thi reason dot product , which is sometim call , scaler product here's on us of dot product .
defin d to be the set of the four main ingredi of beer .
we can defin a cost vector that map each of those ingredi to the cost per unit amount of that ingredi .
and a quantiti vector that map each of those ingredi to a quantiti .
then the total cost of the dot product of the cost vector with the quantiti vector .
we can also defin a valu vector that map each of the ingredi to sai the calor content .
and then the total calori repres by a pint of beer is comput as the dot product of these two vector .
a sensor node is a small hardwar devic that ha a bunch of compon in it , such as a cpu , radio , some kind of sensor and some memori .
now , these thing ar batteri driven .
thi is where you put the batteri , and usual you leav them in remot locat .
so usual of energi is veri import .
we want to be abl to we want the , the sensor node to not us much energi .
now , suppos we know for each of these <num> hardwar compon how much energi it draw .
okai , we'll repres that as a vector .
the domain of the vector would be the label of the individu hardwar compon .
so here's an exampl of such vector .
it map the radio to the amount of current that the radio take when it's on .
the sensor to the amount of current the sensor take when it's on and so on .
let's sai we have a test period .
dure which we know how long each hardwar compon is on .
so thi might be the vector repres a test period .
so the radio wa on dure the test period for <num> second and so on .
the total amount of energi consum dure the test period can be express as the dot product of the durat vector with a rate vector .
now , it turn out that for these devic .
we can't measur the current draw for each of the individu hardwar compon .
we can onli measur the total drawn by , by the sensor node .
and , we're interest in figur out how much each compon draw .
how can we do that ?
we can't , for exampl , turn on the memori without turn on the cpu as well .
so here is the idea , we run sever test on the sensor node and in each test we have an idea of how long each compon is dure the test .
we measur the total amount of current flow dure that test .
now we can set up an equat , a linear equat for each test period that sai that the dot product .
the durat vector for that test period with the rate of consumpt is some specifi amount .
the total draw of energi dure the test period .
now , thi , thi vector rate is actual a vector of variabl .
is , and the idea is that by solv thi collect of equat , we can figur out what the entri of the rate vector ar .
that is , how much current is drawn by each of the hardwar compon .
now there ar question that come up .
can we us these equat to find number for the rate of consumpt of the individu hardwar compon .
and suppos we find those equat , is that enough to pin down precis what those valu ar .
or is it in fact that the there might be multipl solut to thi list of equat ?
the answer to these question will have to wait a littl bit .
so more gener , given a set of linear equat like thi call a linear system , how do we know if there's onli on solut .
and what if your data ar slightli inaccur ?
can we , nevertheless get a solut that's veri close to the true solut .
so , we'll have to wait on these question .
here's anoth us of dot product to measur the similar of vector .
well , let's sai we , we look at a , a period of time in which senat ar vote on mani , mani bill .
you could repres each senat's vote record as a vector .
where for each bill , there is an entri , plu , minu , plu <num> , minu <num> , or <num> , depend on how the senat vote .
sai , plu <num> if the senat vote in favor of a bill , minu <num> if the senat vote against the bill , and <num> if the senat .
so we have a vector repres how the senat vote on mani bill .
now we can compar that senat vote record to anoth senat's vote record by take the dot product of those to vector .
for correspond entri , if both of them ar plu <num> , then thi contribut a <num> to the dot product .
if both of them ar minu <num> , thi contribut a <num> to the dot product .
in either case , that mean the senat agre on that bill .
if on of them vote , in favor and on vote against , then the product of correspond element is minu <num> .
and so that take awai from the dot product .
overal the valu of the dot product is high if the two senat agre a lot and low or even neg if the senat disagre a lot .
here's anoth applic , you want to search for a short audio clip within a larger audio segment .
now audio is , some crazi waveform , i've shown it here .
a digit version of audio look more like thi the , the audio signal is sampl at regular interv .
so realli , a digit represent of an audio segment is a bunch of number .
take the sampl of the signal at variou time .
so we can compar , let's sai , two equal length audio segment by take the dot product .
at a particular moment if both of them ar posit or both of them ar neg , that , that will contribut posit to the dot product .
if on is posit while the other is neg , that will contribut neg .
so , the higher the dot product , the greater the similar between these two audio segment .
but now let's get back to the problem of find a short audio clip within a longer audio segment .
we don't know exactli where the audio clip is suppos to appear in , in the longer segment .
but let sai we have some guess as to where it is .
so we can take a dot product of the vector repres the short clip with the correspond subsequ of the long audio segment .
and again the higher the dot product the greater the similar between them .
now ordinarili we don't know where the short clip appear in the long segment , that's why we're carri out thi comput .
the wai to handl that is to take lot of dot product .
think of all the differ possibl locat for for the , the short audio clip it might be at the begin of the segment , slightli in and so on .
lot and lot of dot product but perhap the higher dot product give us clue as to where the best match is .
now thi seem like a lot of dot product to take , but there ar shortcut in particular there's an algorithm call the fast fourier transform that enabl you to take all these dot product veri effici .
now we'll turn to dot product over gf <num> .
so , here's a coupl of gf <num> vector and we're take the dot product in the usual wai .
we line 'em up , multipli correspond entri , and then add the result .
the differ is that we're ad us gf <num> , so on plu zero plu on , plu zero plu on end up be , on .
let me give you an applic of thi , of dot product over gf <num> .
a usual wai of log into a comput is by send the password over the wire to the comput .
the comput check to see if the password match it record and let you in if it doe .
now that's danger , becaus if an eavesdropp manag to see the password go over the wire .
she could then break into the comput herself .
so here's an altern approach , it call challeng respons .
the comput ask you a question and you give the answer base on your knowledg of the password .
you do thi a few time until the comput is convinc , yeah thi human know the password , better let him in .
thi is potenti safer against an eavesdropp becaus the password is never sent over the wire .
here is a simpl authent scheme .
not on that's realli secur , but on that illustr the idea of , of a dot product over gf <num> .
so the password is some long n vector over g f two , we'll call x , and the question is anoth n vector , which we'll call a .
and the human send back on bit , name the dot product of the , the question a with the password x .
so here's an exampl .
let's sai the password is <num> , <num> , <num> , <num> , <num> .
okai ?
obvious , thi is too short to be secur .
but it's good for illustr .
mayb the comput choos as it question , the vector , <num> , <num> , <num> , <num> , <num> .
and send that to the human .
the human comput the dot product of that question .
with the password , and end up with <num> , and send back <num> as the respons to thi question .
let's call that respons beta <num> .
and thi is repeat sever time .
now how can an eavesdropp cheat ?
well let's sai she observ a sequenc of challeng , a1 , a2 , a3 , and so on .
and she observ the human' correspond respons .
beta <num> , beta <num> and so on .
can she us these to find the password ?
well , she know that the password must satisfi these equat .
so , if she can solv thi set of equat , can she find the password ?
well , there ar two question .
mayb thi set of equat isn't enough to precis pin down the true password .
so how mani solut ar there to thi system of linear equat ?
and how could you even comput them ?
so , we'll studi these question later .
what's anoth wai to cheat ?
there might be a wai that ev , even if she doesn't know the password , can figur out the answer to a challeng .
so , in order to explor that , we have to introduc a coupl of algebra properti of the dot product .
so , commut , homogen , and the distribut law .
so let's sai ev observ two challeng .
<num> <num> <num> <num> <num> and <num> <num> <num> <num> <num> and the respons that the human give for those challeng .
here's how she can figur out the respons for a challeng she hasn't yet seen .
the dot product of the sum of these two vector with x is equal to the sum of the dot product us the distribut law .
she know the dot product for each of these <num> , she can add them up to get the respons for the sum .
so for the challeng that's the sum of these <num> vector she can comput the right respons .
more gener suppos some vector unknown vector satisfi a bunch of equat ; ar there other equat that it also satisfi ?
the answer we'll have to wait .
now we introduc a techniqu for comput the answer to a linear system , that work onli if the linear system ha a veri special form .
it call a triangular system .
here's an exampl .
to solv thi let's rewrit x as the vector of x1 , x2 , x3 , and x4 .
then the system look like thi .
how would we solv thi system ?
well look at the last fourth equat .
from thi we can immedi deriv the valu of x4 .
have deriv the valu of x4 , we can plug it into the third equat and solv for x3 .
now we've go tx3 and x4 .
we can plug those into the second equat and solv for x2 and final plug x2 and x3 and x4 into the first equat and solv for x1 .
so , here's how that work .
we solv thi fourth equat to get the fourth equat state that 2x4 equal <num> .
we can solv that to get x4 .
we plug that into the third equat .
and we find out that on x of three equal minu <num> .
so x three is minu <num> .
we plug x three and x four into the second equat .
we find out that three x two equal <num> .
so x two equal <num> over three , is <num> , and final we plug x2 , x3 , and x4 into the first equat .
we find out that 1x1 equal minu <num> , so we've solv for all the variabl .
now how would we implement thi in python ?
well , i'm go to suggest a hack .
you initi vector x to the <num> vector .
and now , the procedur will popul the vector x , entri by entri .
at the point where you have to solv for some entri xi , the subsequ entri in the vector will have alreadi been popul .
so we can us the dot product to help simplifi the calcul for that , for that entri .
so for exampl , suppos we're solv for x2 us thi equat .
well at that point we alreadi know x3 and x4 and the vector ha those entri popul .
so that we can take the dot product and comput x2 in thi wai .
so here's the code in python .
given a list of vector , and given a list of the right hand side , thi calcul the valu of the vector x .
coupl thing to note , if the number we divid by is zero , thei'll be an error .
so we have to make sure that these number ar non zero .
but if thei're non zero , there's onli on solut , and thi , thi procedur will find it .
now our code so far onli work if the vector is in row list have the domain <num> through n minu <num> .
so we can , we can rewrit thi to be a bit more gener .
but if we do so we have to specifi in what sens thi , thi linear system is triangular , and that requir specifi an order on the domain of the vector .
so here's the code for that .
let's sai we have a bunch of vector v1 through vn .
we multipli each of them by a scalar and we add the result up .
that's call a linear combin of the vector v1 through vn .
and the scalar in thi context ar call the coeffici , so the coeffici , in thi case of v1 is alpha on .
so , here's a simpl exampl , on linear combin of these two vector is thi .
multipli the first on by minu <num> , the second by <num> , and add the result .
so , it's equal to thi .
now , anoth linear combin of the same vector is , multipli the first on by zero , the second on by zero , add them up , and of cours you end up with the all zero vector .
a linear combin where all the coeffici ar zero is call the trivial linear combin .
there's a factori call junkco that make a bunch of product , a garden gnome , a hula hoop , and so on .
there's a tabl that specifi for each product how much it us in each of five resourc .
for exampl , make a garden gnome take zero unit of metal , <num> unit of concret , and so on .
so , for each product , we can write down a vector that specifi how much of each resourc it us .
so , for exampl , for make a garden gnome .
the vector map metal to zero , concret to <num> , and so on .
so there's a vector like thi for each of the product that junkco make .
now , suppos the factori decid to make alpha on garden gnome , alpha two hula hoop , and so on .
then the total amount of each of the resourc is specifi by a vector that can be express as a linear combin of the vector v1 through v5 .
in fact , i don't know how much of each product junkco make .
that's what i want to find out .
i want to carri out industri espionag to figur out exactli how mani garden gnome junkco wa make .
how can i do that ?
well , let's sai i know how much of each resourc thei ar consum .
i know the vector b in thi equat .
and i know the vector v1 through v5 , becaus i know how much resourc make a garden gnome requir .
i want to figur out alpha on through alpha five .
how can i do that ?
thi rais the follow comput problem .
given a vector b , and a list of vector v1 through vn , can you comput the coeffici with which v is express as a linear combin of v1 through vn .
and even if we can comput that , am i go to get the right answer ?
in fact , is there a singl right answer ?
here's anoth exampl .
recal light out .
i'm go to us , for simplic i'll us the two by two light out as an exampl .
here ar the button vector for light out .
and here's an initi state vector .
for thi initi state vector , i want to know how do i solv the puzzl ?
in particular , which subset of the button vector have to be press in order to transform thi to the all light out state .
we can express that problem in term of linear combin .
we write that desir state vector as a linear combin of the button vector .
and we ask what valu of alpha do i need to make thi true ?
okai , and here's the solut .
we know that solv an instanc of light out can be transform into the question of which set of button vector add up to the target state s .
a more gener version of that is , given vector v1 through vn , which subset of those vector sum to a vector s .
and we that thi question can be reformul as the question of how to express s as a linear combin of v1 through vn .
so , we can solv that puzzl if we have an algorithm for the follow comput problem .
express a give factor as a linear combin of other vector .
the set of all linear combin of vector v1 through vn is call the span of those vector .
it's written thi wai .
let's go back to the challeng respons system .
so ev know the password satisfi a bunch of equat .
she can calcul the respons to ani challeng that li in the span of the vector a1 through am .
here's how .
so , ani vector in the span can be repres as a linear combin of the vector a1 through am .
now we us the distribut law , the dot product of a with the password x , by the distribut law is the sum of the dot product of these vector .
now , we us anoth algebra properti to move the alpha out .
and ev know these dot product becaus she's observ the challeng and the respons .
so she plug in the respons to those challeng , and she can get the respons to a .
so thi show that she can get , she can comput the respons to ani challeng that li in the span of a1 through am .
ar there ani other challeng for which you can deriv the respons ?
the answer to that question will have to wait .
here's an exampl .
how mani vector ar there in the span of thi set consist of just on vector over gf1 , <num> ?
well , there ar two possibl coeffici , zero and on .
so , turn out there ar two vector in the span .
how mani vector ar there in the span of an empti set ?
well , there's onli on , the zero vector .
how mani vector ar there in the span of thi singl vector over the real number ?
there ar an infinit number .
and these , these linear combin form a line through the origin and the <num> . <num> .
let big v be a set of vector .
if v1 through vn ar vector such that big v equal span of v1 through vn , we sai that v1 through vn form a gener set for big v .
we refer to these as gener .
here's an exampl .
i've claim that these vector ar a gener set for r3 .
so why is that ?
we have to toe , show two thing .
first that everi linear combin of these vector lai in r3 and everi vector in r3 is some linear combin of these three vector .
the first statement is pretti easi .
each of these vector is in r3 .
you multipli them by scalar , thei're still in r3 , you add them togeth .
still in r3 .
what about the second statement ?
we prove thi as fals .
let x , y , z be ani element of r3 .
and i want to show that i can express thi vector as a linear combin of these three vector .
well here's the formula of that .
the vector x , y , z can be express as x over <num> time the third vector plu y over <num> time the second vector plu z time the third vector .
now i claim that thi is anoth gener set for r3 .
now anoth wai of show that everi vector in r3 is in the span of these vector is thi , we alreadi know that r3 is equal to the span of these old vector .
what i'm go to do is show that each of these old vector is in the span of the new vector .
i do that by exhibit a linear combin .
the first vector is three time the old vector .
the second vector is minu <num> time the first old vector , plu <num> time the second old vector , and so on .
so i've shown that the new vector ar in the span of the old vector .
now , why doe that do the job ?
well , we alreadi know that ani vector in r3 can be written as a linear combin of the old vector .
and we know that each of the old vector can be written as a linear combin of the new vector .
to put these togeth , we us the fact that a linear combin of linear combin can be reduc to just a linear combin .
let's see how that goe .
so , we write x , y , z as a linear combin of the old vector .
then , we replac each of the old vector with an equival linear combin .
so we're just substitut from the equat on the previou slide .
now we multipli through , us our algebra properti .
and then we collect like term .
and we end up with a linear combin in term of the new vector .
now , write the vector x , y , z as a linear combin of these vector wa easi , becaus these have a special form .
it's even easier if we have a slightli more special form .
if we us the vector <num> , <num> , <num> , <num> , <num> , <num> , and <num> , <num> , <num> , becaus then the linear combin look like thi x , y , z is x time the first vector , plu y time the second vector , plu z time the third vector .
we call these , standard gener for r3 .
and thei're tradition written e1 , e2 , and e3 .
here's a wai we can us standard gener .
consid the question , can <num> by <num> light out be solv regardless of the start posit ?
what we're ask is whether the <num> by <num> button vector ar gener for the set of all initi state .
the answer is ye .
and here's how we prove it .
we show that each of the standard gener can be written as a linear combin of the button vector .
so these ar the standard vector for for <num> by <num> light out .
and we've written each of them as a linear combin of the button vector .
we alreadi know that the set of all state is , is the span of the standard gener , and now we've shown each of the standard gener in turn can be written in term of the button vector .
it follow that each of the possibl state for <num> by <num> light out can be written as a linear combin of the button vector .
what about the span of a set that contain onli on vector ?
that's the set of all scalar multipl of that vector , which we saw earlier , is the line through the origin and the point correspond to that vector .
it's a on dimension structur .
what about the span of the empti set ?
we saw that thi is just the origin .
that's a zero dimension object .
what about the span of <num> vector ?
in thi case , that get you all the point in the plane .
so , it's a two dimension object .
what about the span of <num> vector ?
similarli , that's a plane in three dimens .
look like thi , a plane is a two dimension object .
thi rais the question is the span of k vector alwai a k dimension geometr object ?
the answer is no .
for exampl , the span of the <num> vector , consist just of the <num> vector .
that's a zero dimension geometr object .
the span of these two vector is a line which is a <num> dimension geometr object .
the span of these three vector is , two dimension object , a plane , which rais a fundament question .
given k vector how can we predict the dimension of the geometr object that's form by their span ?
so we've seen that the span of these two three vector form a plane in three space .
and in fact , thi is us for plot the plane .
so here , here i've taken multipl choic of alpha and beta , and plot what you could , what you get .
so there's a more familiar represent of plane , which is thi , the set of tripl x , y , z , satisfi an equat of thi form .
now , we can us vector to repres the same equat .
so the set of vector x , y , z such that thi dot product is equal to <num> .
so we're describ a set of vector us a linear equat with a right hand side of zero .
we can similarli a line in three dimens by us two equat with right hand side equal to <num> .
so it seem we have two wai to repres a geometr object such as a line or a plane .
we can repres it as the span of some vector or we can repres it as the solut set to a set of linear equat .
where the right hand side ar <num> .
so we've got these two method of repres thing .
on of the great theme of comput scienc is have multipl represent , is veri often us .
and we'll see it's true in thi case as well .
so , for ex , here's a plane repres as the span of two vector .
and the same plane repres as the solut set to thi linear equat with the right hand side equal to <num> .
here's an exampl of a line , and thi line can be repres as the span of thi singl vector .
or as the solut set of these two linear equat , with right hand side equal to <num> .
each of these represent ha it us .
for exampl , suppos you have two line , and you want to find the plane that contain those two line .
let's sai , the first line , is the span of thi , set consist of on vector .
the second line is the span , of anoth set consist of anoth vector .
how would you find the plane contain both of them ?
well , it turn out it's the span of those two vector .
so thi represent is conveni for find the geometr object contain two smaller dimens geometr object .
now , suppos i want to find the intersect of two plane .
now let's sai i've repres on plane as the solut set of thi linear equat .
i've repres the other plane as the solut set of anoth linear equat .
how can you find a represent of the line that is the intersect of these two plane ?
it turn out you want the , you want the point .
the tripl x , y , and z that satisfi both these equat .
so , by us thi represent , we can get the line that's the intersect of these two plane .
what's common about these two represent for set of vector that form geometr object ?
the subset of , in thi case r to the d , satisfi three properti .
the first is the subset contain the zero vector .
the second is , if a subset contain some vector v , it contain everi scalar multipl of that vector .
and the third is , if the subset contain two vector , u and v , it also contain their sum .
so let's see why the span of a collect of vector satisfi these three properti .
the first on is easi .
the span of a , vector v1 through vn is the set of all linear combin of those vector .
here's on linear combin , where you take everi coeffici to be zero .
that obvious give you the zero vector .
so , properti v1 is satisfi .
what about properti v2 ?
let's take ani vector in the set that is a vector in the span which is a vector that can be written as a linear combin of v1 through vf .
so we have a vector that's written as some linear combin .
you have some scalar alpha .
then , the scala , vector product alpha , can be also written as a linear combin of those vector v1 through vn .
you just multipli all the coeffici by alpha .
now for properti v3 .
properti v3 state that if two vector u and v ar in the span then their sum is also in the span .
so let sai u and v ar in thi span that mean that u can be written as a linear combin and v can be written as anoth linear combin .
well then , we can repres their sum by just take the linear combin where each coeffici is the sum of the correspond coeffici in u and v .
now let's turn to the other represent , the solut set of the collect of linear equat where the right hand side ar all <num> .
now properti v1 is also easi .
take the <num> vector and plug it in , well a1 dot with a <num> vector is <num> .
a2 dot with a <num> vector is <num> and so on , all of the dot product with a <num> vector ar <num> , so clearli the <num> vector li in thi solut set .
now let's turn to v2 .
take some vector that's in the solut set , that is all these dot product ar equal to zero .
and now consid whether alpha time that vector also li in the solut set .
well what's the dot product ?
a1 dot with alpha time v .
that's the same as alpha time a1 , dot with v , which is alpha time zero , which is zero .
so similarli , all the linear equat also hold of alpha v .
so that prove properti v2 .
now let's turn to properti v3 .
similarli , suppos you have <num> vector , u and v , that lie in the solut set .
well , that mean u and v satisfi all these linear equat .
that is , the dot product ar all zero .
a1 . u is zero , and so on , up to am . u is zero .
and similarli , a1 . v is zero , all the wai up to am . v is zero .
well , then it's easi to see that the sum of u and v also li in the solut set .
why is that ?
let's look at the dot product .
a1 dot u plu v is the same as a1 dot u plu a1 dot v by the distribut law .
a1 dot u is <num> , a1 dot v is zero .
therefor their sum is also equal to zero .
so thi show that all those equat also hold of the sum u plu v .
ani subset big v of f to the d satisfi these three properti is call a vector space .
so for exampl , we've shown that for ani vector v1 through vn , the span of those vector is a vector space .
and for linear equat , a1 . x equal <num> up to am . x equal <num> .
the solut set of all these linear equat is a vector space as well .
now , if we have <num> set , big u and big v , and thei're both vector space , but u is a subset of v , we call u a subspac .
so , for exampl , the span of v1 through vn , and the solut set of these linear equat with right hand side equal <num> ar subspac of r to the d .
here's a fact that turn out to be not so hard , but quit essenti to linear algebra .
that everi subspac of r to the d can be written in each of those two form .
everi subspac can be written as the span of some vector and everi subspac can be written as the solut set of the linear equat .
where the right hand side equal <num> .
now , a disclaim .
in a tradit , mathemat cours on linear algebra , a more abstract cours that we take a more abstract approach .
so we wouldn't defin vector as sequenc or function .
instead , we would defin a vector space to be ani set that came along with an addit oper and a scaler multipl oper .
ani set that satisfi certain axiom and satisfi properti v1 , v2 and v3 .
thi approach ha it's advantag .
ani time you give a more abstract definit of someth you don't have to be concern with the intern structur detail of the , of the thing .
in thi case , we don't have to be concern .
if we took thi approach , we wouldn't have to be concern with the intern structur of vector .
thi is analog to encapsul or or inform hide in object orient program .
the advantag is it's more gener .
now , i didn't take thi approach .
i took a , a , a less abstract approach for thi cours , becaus i think in develop intuit about vector .
it's help to have thi concret represent .
now , much earlier , we saw that the u to v line segment could be repres in thi wai .
it's the set of linear combin , alpha u plu beta v , where alpha and beta ar non neg and sum to <num> .
we sai a linear combin of vector v1 through vn is a convex combin if the coeffici all ar non neg and thei sum to on .
for exampl , the convex hull of a singl vector is a point .
the convex hull of two vector is , gener , a line segment .
and the convex hull of three vector is a triangl .
so you would think that the more vector you have , the higher dimension the object , that's not alwai true .
for exampl if these three point ar co linear , thei , thei're in the same line , then their convex hull is a line segment .
similarli , if you have a bunch of point and thei're all on the same plane then their convex hull form a polygon .
we've seen how to repres line and plane that contain the origin .
how do we repres those that don't contain the origin ?
well let's sai we want to repres a line that doe not necessarili contain the origin .
well , we start with a line that doe go through the origin .
now we know that the point form that line form a vector space , big v .
we're go to translat that line by ad a vector c to everi vector in big v .
so here's the mathemat formul of that .
and we'll abbrevi that in thi wai , c v .
what we get is the line through the point c instead of through the origin .
let's try the same thing for a plane .
how do we repres a plane that doe not contain the origin ?
we start with a plane that doe contain the origin .
we know that the point of such a plane form a vector space big v .
we're go to translat thi by ad a vector c to everi vector in big v .
look like thi , and we abbrevi it c plu big v .
and what we get is a plain that goe through c and not through the origin .
you know , if c is a vector and big v is a vector space , c plu big v is call an affin space .
so exampl ar a line , or a plain that doesn't necessarili go through the origin .
let's do a more concret exampl .
take the point u1 , u2 , and u3 .
we want to express the plane through these point as u1 plu big v , where big v is the span of two vector .
okai ?
so big v look like that .
well , we defin big v as span of a and b , where a is the second vector minu the first , and b is the third vector minu the first .
now , let's look at u1 plu big v .
it's the translat of a plane so it , too , is a plane .
now span ab contain the zero vector .
so u1 plu span ab contain u1 .
span ab contain a , which is u2 minu u1 .
so u1 plu span ab contain u1 plu u2 minu u1 , which is u2 .
and similarli , span a contain b , which is u3 minu u1 .
so , so u1 plu the span of ab contain u1 plu u3 minu u1 , which is u3 .
so u1 plu big v contain u1 , u2 , and u3 .
and it's a plane .
there's onli on plane contain those three point , so thi is it .
now , we've written the plane contain these three point as thi sum u1 plu the span of u2 minu u1 , and u3 minu u1 .
there's a nicer wai to write thi .
let's rewrit u1 plu span of u2 minu u1 , u3 minu u1 .
thi is the set of all vector , u1 plu alpha u2 minu u1 , plu beta time u3 minu u1 , where alpha and beta rang over all real number .
we can us the distribut law and then gather like term .
then , it's the set of all linear combin where the first coeffici is <num> minu alpha minu beta , where alpha and beta ar the other two coeffici .
so we'll do a substitut .
we'll replac <num> minu alpha minu beta , with anoth variabl gamma , and requir that gamma plu alpha plu beta equal <num> .
so thi is the same set .
and thi is a nicer represent of that set .
so we call thi linear combin , where the coeffici ar requir to sum to <num> .
an affin combin .
more gener , if you have vector u1 through un , a linear combin of those vector is an affin combin if the coeffici sum to <num> .
and the set of all affin combin of u1 through un is call the affin hull of those vector .
so what us the same argument as befor , we can see that the affin hull of u1 , u2 , and so on , up to un , can be written as u1 plu the span of all these vector , u2 minu u1 , u3 minu u1 , and so on up to un minu u1 .
so thi show that the affin hull of vector is an affin space .
so we see that we can repres a plane as u1 plu a vector space , an affin space or the affin hull of some point .
there's a more familiar wai as the solut set of an equat , ax plu by plu cz equal d .
let's rewrit thi us vector notat .
it's the set of all x , y , z , such that the dot product of a , b , c with x , y , z equal d .
in gener , a point , a line , a plane can be written as the solut set of a system of linear equat .
rememb a linear equat is an equat involv the dot product with the vector variabl .
so here the linear equat ar a1 dot x equal beta <num> and so on up to am dot x equal beta m .
well , what about the convers ?
is the , is the solut set of a linear system alwai an affin space ?
there's a simpl counterexampl .
if you take a linear system , that's contradictori .
that ha no solut .
for exampl , <num>x equal <num> , 2x equal <num> , ha no solut .
so the solut set in that case is empti .
but we know that becaus an , a vector space alwai contain the zero vector , an affin space , which is u1 plu a vector space , alwai contain at least on vector , name u1 .
so it seem like it break down .
the solut set of a linear system is not alwai an affin space .
but we've identifi the on kind of counterexampl .
the on except .
and , in fact , there's a theorem that the solut set of a linear system is either empti or in an affin space , and we'll prove that .
so here's the theorem we're try to prove .
we start with a concept .
each linear system correspond to anoth linear system in which the right hand side .
beta <num> through beta m have all been replac by zero .
and thi , a linear equat a dot x equal zero , with a zero right hand side is call a homogen linear equat .
and a system of homogen linear equat is call a homogen linear system .
so what we've seen is from ani linear system , we can deriv the correspond homogen linear system .
now we alreadi know that the solut , the solut set of a homogen of a linear system is the vector space .
now we us a lemma .
let u1 be ani solut to some linear system .
then for ani other vector u2 , u2 is also a solut if and onli if u2 minu u1 is a solut to the correspond homogen linear system .
okai .
rememb , here's a linear system and here's the correspond homogen linear system .
now , let's prove thi lemma .
let u1 be a solut to a linear system .
and for ani other vector u2 , u2 is also a solut .
if and onli if u2 minu u1 is a solut to the correspond homogen linear system .
so we start with u1 , u1 is the solut which mean that it , it satisfi all these equat .
that is , a<num> dot u<num> equal beta <num> and so on .
now , u2 satisfi the same equat if and onli if the differ between a1 dot u2 and a1 dot u1 is zero and so on , up to am dot u2 minu am dot u1 to zero .
all those differ have to be zero becaus there , becaus the right hand side have to match .
and thi is true if and onli if a1 dot u2 minu u1 equal zero and so on , us the distribut law .
so we've shown that u2 satisfi those equat if and onli if u2 minu u1 satisfi all these equat .
that complet the proof .
so here's the lemma .
let's see how we can us it to prove the theorem .
we need to show that the solut set of a linear system is either empti or affin space .
okai ?
let big v be the set of solut to the correspond homogen linear system .
now there ar two possibl .
if the linear system ha no solut , then thi solut set is empti .
that's thi case .
otherwis , it ha some solut u1 .
and then , the solut , the set of solut to the linear system is the set of u2 such that u2 minu u1 belong to the set of solut to the homogen linear system .
now we us a substitut .
we substitut v for u2 minu u1 , which mean u2 equal u1 might plu v .
so we can rewrit thi set in thi wai .
and that prove what we want to prove .
that the set of solut is an affin space .
now , here's , we've prove more than the theorem .
we've prove that if u1 is a solut to a linear system , then the set of all solut to the linear system have thi form u1 plu v , for all of v in big v , where big v is the set of solut to the correspond homogen system .
here's some implic of that .
so long ago , we ask how can we tell if a linear system ha onli on solut ?
well , thi give us a hint .
if a linear system ha a solut u1 , then that solut is uniqu , if and onli if , a set of solut to the homogen linear system consist of just on solut .
we know that the homogen linear system alwai contain the zero vector as a solut .
so that must be the onli solut to the homogen linear system for u1 to be the uniqu solut to the origin linear system .
we also ask how can we find the number of solut to a linear system over gf <num> ?
well , now we know the number of solut could be zero , could be the nth the solut set the empti's , empti set , otherwis , the number of solut is equal to the number of solut to the correspond homogen linear system .
now we're go to look at , a simpl applic of these idea .
if you go and download python , you'll see these , these number to the left of the differ download .
these ar checksum .
a checksum function map long file to short sequenc to enabl you to check whether a file you've download , ha been corrupt .
so , the webpag show the checksum of the file you can download .
if you download a file , you run the checksum function on it .
and now , if the result of run the checksum function on the file you download isn't the same as the result post on the websit , you know the file's be corrupt en rout .
but what about the other wai around ?
could it be that the file is corrupt but you don't detect it by run the checksum it could happen , but how like is it ?
we're go to us a sort of toi checksum , to illustr some of the idea we've been explor .
so the checksum function look like thi .
we're go to repres a file as an end vector over gf2 .
that is an end bit sequenc .
and the function will be a <num> vector over g f two .
where the first entri is a1 . x .
the second entri is a2 . x and so on .
so and where a on through a64 ar vector we chose somehow .
so here's our checksum function .
it take an n vector x over gf <num> and it output the dot product a1 dot x , a2 dot x upto a64 dot x where a1 through a64 ar vector we choos somehow .
now let's us p to denot the origin file , and sai it is randomli corrupt dure the download process .
what's the probabl that that corrupt went undetect ?
here's the checksum of the origin file .
the first bit is a1 . p .
and we'll denot that by beta on , and so on .
now let write the corrupt .
version as p plu e .
rememb , we're do gf <num> addit , so in thi case , e ha 1s precis at the posit in in the file that were chang dure the download process .
then , the checksum of the corrupt file match the checksum of the origin file if and onli if the first bit math .
a1 . p plu e equal beta on .
the second match and so on down to the <num> .
that , that's true if and onli if the differ between the first bit of the origin , of the checksum of the origin file and the first bit of the checksum of the download file is zero , and so on .
and that's true if and onli if the error vector satisfi these equat .
a1 . e equal zero through a . <num> equal zero .
in other word , if e is a solut to the homogen linear system , a1 . x equal zero through a . <num> . x equal zero .
what is a matrix ?
the tradit notion of a matrix is the two dimension arrai with number in it like thi .
thi ha two row , the first row is <num> , <num> , <num> the second row is <num> , <num> , <num> .
it also ha column .
so , the first column is <num> , <num> , second column is <num> , <num> , third column is <num> , <num> .
we call thi a <num> by <num> matrix .
for matrix a , the i , j element at a , refer to the element in row i , column j and it's usual written .
a subscript ij , will sometim us the more python notat a bracket i , j .
and here's an obviou represent for a matrix .
we're go to repres thi matrix by a list of list each element of the top level list is a list consist of the element of a , a row .
so the first list is <num> , <num> , <num> , the first row , the second list is <num> , <num> , <num> .
you could similarli repres thi by a list of column list , where there's on element at the top level list for each of the column of the matrix .
i'm go to take a slightli differ approach to matric .
for finit set r and c and r by c matrix cartesian product of r by c to the field f .
now here is an exampl , we , a and b ar row label and at , sharp and question mark ar column label .
and in python we repres thi as a , thi function as a dictionari .
map from the cartesian product the set of pair of on element from t and on from c to the field .
and we can repres thi by a dictionari .
for thi matrix , the row label by a is the vector with domain at sharp and question mark .
map at to on , sharp to two , and so on .
and , the column label by sharp is the vector with domain a and b , map a to <num> and b to <num> .
here's on represent for matrix .
as a dictionari of row , it map each of the row label to a vector that is that row .
so , in thi dictionari , the row label a map to the vector <num> , <num> , <num> , and map b to the vector <num> <num> <num> .
a similar represent is as a dictionari of column .
here the dictionari map the column label to the vector .
so at sign is map to <num> , <num> , sharp is map to <num> , <num> , and question mark is map to <num> , <num> .
our primari represent for matric will be us a python class mat .
thi is a class with two field .
thi is analog two , but not exactli like vec .
the two field ar d and f , f just as in vec , is a dictionari .
d is instead of be a set a pair of set .
you would think that d would be the set , that's the cartesian product of the row label for the column label , but that get too big .
so , we repres it as a pair , r , c , where r is the set of row label and c is the set of column label .
f is a dictionari that map element of that cartesian product , pair , row label , column label , to the correspond field element .
and of cours our sparsiti convent is us here so we don't have to repres entri of the matrix whose valu ar zero .
so here's a rudimentari implement of that class mat .
we'll later add lot of matrix oper to thi class to exercis our understand of the mat class , we'll look at the ident matrix .
for a set d , the d by d ident matrix is the matrix such that the k , k element is <num> for everi element k , of d and all the other element ar zero .
i'm go to us the numer <num> to indic the ident matrix with a subscript of d .
but veri often , we'll just omit the subscript when it's clear what domain is intend .
veri often the letter i is us to repres the ident matrix instead of thi numer on .
so for exampl , here's the ident matrix on the set consist of a , b and c .
the set of row label is a , b and c .
the set of column label is also a , b , and c .
and the dictionari f , map a , a to on , b , b to on , and c , c to on .
we're omit all the other entri becaus their valu ar all zero .
we're exploit the sparsiti convent .
now , there's a quiz write the procedur ident of d that return the instanc of mat repres the d by d ident matrix .
and here's the solut .
we can convert between our differ represent of matric .
for exampl , consid thi matrix ; here's the represent as an instanc of mat .
and we can convert thi to a column dictionari .
that is a dictionari whose kei ar the column label , and whose correspond valu ar the vector that ar the column .
now , let's look at convert an instanc of mat to an , a column dictionari .
here's an exampl of an instanc of mat , and here's the correspond column dictionari .
write the procedur mat2coldict .
that given an instanc of mat return the column dictionari represent of the same matrix .
here's the solut .
we provid a modul mat util that defin variou convers routin .
such as mat2coldict , mat2rowdict , coldict2mat , rowdict2mat and listlist2ma .
that convert from a list of list of field element to a matrix such that the inner list ar the row of that matrix and also the ident procedur that you wrote .
i should note that coldict2mat and rowdict2mat can take as argument a coldict .
a column dictionari or a row dictionari or a list of column or a list of row .
so it's somewhat more flexibl .
now we gave the definit for a rudimentari matrix class .
but we're go to write a much more elabor on that incorpor all these differ oper .
and here's the syntax for each of them .
thi more elabor class definit allow us to write much more concis matrix and vector code , such as thi .
thi set the entri correspond to row label a , and column label uppercas b , to <num> .
thi assign to the variabl b the vector obtain by multipli the matrix m by the vector v .
thi assign to the variabl b the matrix obtain by multipli the matrix m by the matrix a , and thi pretti print the matrix b .
you'll learn more about these oper as we go on .
so you're go to code thi class start from a templat we provid .
as in the case of vec , you're go to write the bodi of , name procedur .
but in us that , you're just go to us the oper as we describ here .
thi is a much more concis wai of write than thi .
so in all code outsid the mat modul that us mat , you're go to import just the class mat itself , us thi command .
so the name procedur ar not us .
thei're not even import .
in short , us the oper .
and the method transpos defin in the class when work with mat .
for each procedur , just as in vec , we'll provid the stub .
as befor , you're go to replac the pass statement with the appropri line of code .
as befor , the first line is a document string , the second line is an assert .
in thi case , it assert that the second element of the d field of m ha to be a set that's equal to the domain of the vector , v .
if thi assert is violat by the argument , python will report an error .
so thi assert is there to remind us of a rule about , in thi case , matrix vector multipl .
so pleas keep the assert in your code when write code for thi class .
again , we're go to be us mat a lot .
we have to make sure that your mat implement is correct .
so we provid a file test mat . py with lot of exampl to test against .
so you should make sure that your mat implement work for all of these .
as befor you can copi in the test in from test . mat or you can run all the test at onc us thi command .
if it doesn't print anyth , all the test ar pass .
on simpl row for matric , is as a wai of pack togeth a bunch of row or a bunch of column .
we defin two vector space for each matrix m .
on is the column space , which is is the span of the column of that matrix m .
the other is and , and it's written col m .
the other is the row space of m which is just the span of the row of m and that's written row of m .
so for exampl the column space of thi matrix is the span of it column .
the first column is <num> , <num> , the second column is <num> , <num> , third column is <num> , <num> .
now in thi case , the span is just equal to the span of the first column , <num> , <num> , sinc the other two ar , ar scalar multipl of that .
similarli , the row space of thi matrix is the span of these of the two vector <num> , <num> , <num> , and <num> , <num> , <num> .
and again , thi is also equal to the span of just the first vector <num> , <num> , <num> , sinc the second on is a scalar multipl of that .
transpos swap row and column .
so if you start with thi matrix where the row label ar a and b , and the column label ar at , sharp and question mark .
you appli transpos , you get thi matrix .
so for exampl , the entri in row a and column sharp of the origin matrix , is the entri in column a and row sharp of the transpos matrix .
pretti soon we'll explor the oper on matric , but first let's note that a matrix can be interpret as a vector .
after all , an r by s matrix is just a function from the cartesian coordin r cross s to the field f .
so it can be interpret as an r cross s vector .
thu , we can do scalar vector multipl .
and vector addit , and our implement of matric will incorpor , those oper .
now we've seen that matric a and b correspond to function .
and the product correspond to anoth function .
if the function that result from these matric .
ar function invers of each other .
we sai the matric ar matrix invers of each other .
so here's an exampl .
thi is a , an elementari row addit matrix .
the function , appli to a vector , with entri x1 , x2 , x3 .
add twice the first entri x1 to the second .
therefor the function invers subtract the , twice the first entri from the second .
so here's the function invers .
that tell us that the invers of the matrix a is thi matrix which is also an elementari row addit matrix .
but thi time subtract twice the first entri from the second entri .
if a and b ar matrix invers of each other , we sai that a and b .
ar invert matric .
and it's not hard to show that each matrix ha at most on invers .
and we refer to the invers of a matrix a as a to the power minu <num> .
so you'd read thi a invers .
why do we care about invert matric ?
here's on reason .
a matrix vector equat is guarante to have exactli on solut if the matrix is invert , let's see that .
let a be an m by m matrix , and defin the function f by f of x equal a time x .
now suppos a is an invert matrix .
then f is an invert function .
that is f is on to on and onto .
sinc it's onto , for ani vector b in the co domain of f , there is some vector u in the domain of f such that the imag of u under f is b .
that is , there is at least on solut to the matrix vector equat , a time x equal b .
now sinc f is on to on , for ani vector b in the co domain of f , there is at most on vector u in the domain that map to b under f .
that is , there's at most on solut .
to the matrix vector equat , a time x equal b .
so , if a is invert , then , for everi right hand side vector b .
for everi vector b in the co domain of thi function f .
the matrix vector equat , ax equal b , ha exactli on solut .
here's an exampl the industri espionag problem .
given the vector b , specifi the amount of each resourc consum our goal wa to figur out how much of each product the factori wa produc .
so we set thi up as a matrix vector equat .
if we solv the vector matrix equat , for some right hand side b , give the amount of resourc consum , ar we guarante to get the true number of product produc by the factori ?
well , is there a uniqu solut ?
if there ar multipl solut , our industri espionag will fail .
we can't be certain that we found the true number of product produc .
but it turn out that m transpos , here , is an invert matrix .
so , the function is an invert function , and there's a uniqu solut .
for everi vector b that's the case .
the sensor node problem give us anoth exampl .
rememb that we're try to find a current draw for each of four hardwar compon and let's sai we us three test period .
we record the total power consum in each of those test period in a vector b .
and for each test period , we have a vector specifi for that test period what portion of the time each hardwar compon is on .
now , to find the vector give the current draw for each compon , we want to solv a matrix vector equat , ax equal b , where .
a is a matrix whose row ar these durat vector .
doe thi yield the current draw for each hardwar compon ?
it turn out in thi case that thi matrix is not invert .
in particular the function that map x to a time x is not on to on .
so there's no guarante that there's onli on solut to the equat .
and therefor by us solv to get a solut to thi we might not get the right solut , we might not get the solut give the current draw for each of the hardwar compon .
we have to add more test period .
let's us four test period instead .
in thi case .
the matrix consist of the correspond durat vector is an invert matrix .
and so , there's onli on solut to the matrix vector equat ax equal b .
and therefor , in principl at least , we'll find the correct current draw for each of the hardwar compon .
anoth reason for consid invert matric is that the matrix vector equat ax equal b is somewhat easier to solv in the case when a's an invert matrix .
later we'll learn two algorithm , to solv such equat .
but we'll also learn how to cope in the case when a is not an invert matrix .
and final , invert matric plai a kei role in an idea call chang of basi which we'll see later .
chang of basi is a veri import part of linear algebra .
and we'll see it be us in render an imag with perspect .
or in actual synthes a perspect .
free imag from an imag with perspect .
here is a simpl but us proposit about invert matric .
if a and b ar invert matric and their product a time b is defin , then it too is an invert matrix .
we'll see some exampl .
here ar two matric , a and b .
each correspond via matrix vector multipl to a function from r2 to r2 .
the matrix a correspond to the function that add the second entri to the first entri .
and thi function f is clearli invert .
becaus the function that subtract the second entri from the first entri is it invers .
the matrix b correspond to the function that add the first entri to the second entri .
thi function is also clearli invert .
sinc the function f and g ar invert , their composit is also invert .
and by the matrix multipl lemma their composit correspond to the matrix product a time b .
which is thi matrix , so that matrix is also invert .
in the second exampl , the two matric ar slightli bigger .
but like the previou two matric , these ar elementari row addit matric .
multipl of mat , vector by thi matrix a add four the time the first element to the second element .
and thi function is clearli invert becaus the function that subtract four time the first element , from the second element is it invers .
now multipl by the matrix b add five time the first element to the third element .
and that function is similarli invert .
again , by the matrix multipl lemma , multipl by the matrix a time b correspond to applic of the composit of the two function .
so the composit is also an invert function .
so the product a time b is an invert matrix .
on more exampl .
here ar two matric a and b .
here's the matrix product , it's not an invert matrix .
so the proposit impli that at least of on of a and b is not an invert matrix and in fact that first on a is not invert .
for the proof , we just follow the same line of reason we us in the first two exampl .
given the matric a and b , let f and g be the correspond function , the on defin by matrix vector multipl .
now suppos a and b ar both invert matric .
then the function f and g ar invert function .
i'm assum the matrix product a time b is defin , the function f and g can be compos .
and sinc f and g ar both invert function the composit is also invert .
so , by the matrix multipl lemma .
the correspond matrix is a time b and that's an invert matrix .
now here's a nice observ about matrix invers .
if a matrix a ha an invers then the product of a with it invers .
is the ident matrix .
here's the proof .
let b denot the invers of a .
as usual , we defin the correspond function , the function f which take x to a time x .
and the function g which take y to b time y .
by the matrix multipl lemma the composit f compos with g ha the properti that g compos with g appli to x is the same as take the product of ad and multipli it by x .
on the other hand .
becaus we've said that a and b ar matrix invers of each other , it must be that f compos with g is the ident function .
so , the product ab must be the ident matrix .
what about the convers ?
we've said that if a ha an , an invers , then a time a invers , is the ident matrix .
you might be tempt to conjectur , that if ab is an ident matrix , then a and b .
ar invers of each other .
but here's a counterexampl .
a matrix a and a matrix b .
their product is an ident matrix .
but in fact the function correspond to a and b ar not invert .
in fact , we can see here that multipli .
a by thi vector , and multipli it , a by thi vector , both give you the zero vector .
so , the function correspond to matrix , matrix multipl is not even onto .
the null space of a is not trivial , and we know that that impli that the function is not onto .
so , f is not an invert function .
so , it doesn't the matrix a doesn't even have an invers .
so , just becaus the product of two matric is the ident matrix doesn't mean these matric ar invers of each other .
so , it's a fals conjectur .
howev , we can show .
that matric a and b ar invers of each other if and onli if both the product ab and the product ba ar ident matric .
here's the proof .
suppos a and b ar invers of each other .
by the lemma a time b is an ident matrix .
appli the lemma with the role revers tell us that ba is also an ident matrix .
on the other hand , suppos ab and ba ar both ident matric .
we defin the function in the usual wai .
f is the function that map y to a time y .
and g is the function that map x to b time x .
becaus ab is the ident matrix , by the matrix , matrix multipl lemma , f compos with g is the ident function .
becaus , the product ba is an ident matrix , it follow us the same lemma that g compos with f is an ident function .
thi prove that f and g ar invers of each other , function invers of each other .
and therefor a and b ar matrix invers of each other .
how can we tell if a matrix is invert ?
well .
a matrix is invert if the correspond function is an invert function .
and we know that an invert , a function is invert if it's on to on and onto .
now , we have a criterion for linear function be on to on .
and the function correspond to matrix vector multipl we've seen is alwai a linear function .
so , by the on to on lemma the function is on to on if and onli if the kernel is trivial which is the same as sai the null space of the matrix is trivial .
what about onto ?
we're not yet in a posit to character linear function that ar onto .
so we can't quit answer thi question .
but if we did know how whether a linear function is onto , we could get a nice criterion .
for whether a matrix is invert .
what do we do with matric ?
mostli we multipli them by vector .
there ar two wai to multipli a vector and a matrix .
on is call matrix vector multipl , and the other is call vector matrix multipl .
for each of these , i'm go to give the two equival definit , and which definit is most appropri depend on the situat .
we start with the linear combin definit of matrix vector multipli .
so , given an r by c matrix m , if v is a c vector , then the product m time v is the linear combin of the column of m , where the coeffici ar given by the entri in d .
so , for exampl , given thi matrix and thi vector , we take the product by multipli the first entri of the vector by the correspond column .
the second entri of the vector by the second column .
and the third entri by the third column .
so we get thi .
on the other hand , if v is not a c vector , then the product m time v is not even allow .
so , for exampl thi matrix vector product is an error becaus the number of entri in the vector isn't the same as the number of column in the matrix .
here's anoth exampl .
the product of thi matrix by thi vector is obtain by take thi entri of the vector and multipli it by thi column of the matrix .
thi entri multpli by thi column and thi entri multipli by thi column .
and here's the result .
recal the light out puzzl .
we said that a solut to a given configur for light out , is a linear combin of the button vector .
we can write a linear combin as a matrix vector product .
for exampl , thi linear combin , which express thi configur in term of button vector , can be written as the matrix vector product .
where the column of the matrix ar the button vector .
and the vector specifi the coeffici in the linear combin .
solv instanc of light out therefor can be express as solv a matrix vector equat that is .
given the desir configur , and given the matrix , find the entri of the vector such that the matrix time the vector equal that desir configur .
thi is a fundament comput problem , solv a matrix vector equat .
the input is a matrix and a vector .
and , the goal is to find a vector x such that a time x equal v .
here's a wai to solv a special case where the matrix is two by two .
solv an equat of thi form we requir that ad is not equal to bc .
and if that's the case , we solv by set x equal to dp minu cq over ad minu bc .
and y equal aq minu bp over ad minu bc .
so , for exampl , to solv thi matrix vector equat , we would set x and y accord to the formula .
later we'll studi algorithm for the more gener case .
we provid a modul solver that defin a procedur solv a , b that tri to find a solut to the matrix vector equat ax equal b .
now , current solv a , b is a black box .
over the cours of time , we've figur out how to code it .
let see how we can us it to solv light out , for exampl .
we start with <num> by <num> light out , first we creat the domain for the button vector , it the cartesian product of <num> <num> <num> <num> .
now , we're go to creat some vector .
so we better import the vec class .
and these vector will be over gf2 so we'll import the valu <num> from the gf2 modul .
and now we ar readi to make these button vector .
so first we'll creat the button vector correspond to the button posit zero zero .
okai .
here is it .
notic that it ha a <num> in posit <num> , <num> and <num> <num> .
next we creat the button vector correspond to the button in posit <num> .
that ha on is posit <num> , <num> and <num> .
next we creat the button vector for the button in posit <num> <num> that ha on in posit <num> , <num> and <num> .
and final , we creat the button vector for the button in posit <num> <num> and notic that thi ha <num>'s in posit <num> <num> <num> <num> and <num> <num> .
now , we want to solv a <num> by <num> light out puzzl .
start from , thi configur , with light on in posit zero , zero and on , zero .
which button do we have to push to get all the light to go out ?
we formul thi as a matrix vector equat .
the matrix ha as it's column the button vector .
so the first thing we want to do is construct that matrix .
we us call dict to mat .
the label of the column will be the posit of the correspond button .
<num> <num> <num> <num> .
<num> <num> and <num> <num> our goal is to find the vector , alpha <num> , alpha <num> , alpha <num> , alpha <num> , such that thi matrix a time thi vector equal the vector correspond to thi , so let's construct thi vector .
we'll call it b .
it ha on in posit zero zero and on zero .
our goal is to solv a matrix vector equat .
so we'll import the solv procedur from the solver modul .
we'll try to find the solut .
all right , it came up with someth .
we have yet to know if it's realli a solut .
let's test it out .
a time x , is that equal to b ?
ye , good and here's the solut .
it's a littl easier to read out the solut if we .
print the vector .
all right .
so thi tell us that the solut is to press the button at zero , on and on , on .
that is , we press the button correspond to thi , and correspond to thi .
vector matrix multipl is differ from matrix vector multipl .
let's start with the definit of matrix vector multipl .
rememb it's the linear combin of the column of , the matrix , with coeffici given by the entri of the vector .
and here's the definit of vector matrix multipl .
to multipli a vector w time m , you take the linear combin of the row of matrix m with coeffici given by the entri of the vector .
so for exampl multipli thi vector by thi matrix , we take the linear combin of the two row with coeffici equal to the entri in the vector .
rememb our junk co exampl from a while back .
junk co make a bunch of product .
and for each on us a certain amount of each of these resourc per item .
we can write thi data as a matrix .
now , the total resourc us equal thi vector time m , where the entri of the vector tell us how mani of each item ar be manufactur .
recal that in industri espionag we might want to calcul how mani of each item junkco's produc .
assum that we know the total resourc us , and of cours we know the matrix m .
to find the number of item produc .
we would solv a vector matrix equat , b equal x time m , where b is the vector of total resourc us .
so again , solv a matrix vector equat is a fundament comput problem .
and of cours , if we had an algorithm for thi problem we could us it to also solv a vector matrix equat , just by us transpos .
when us the solver modul to solv equat over the real number , we have to be awar that python is us float point number , float , so round off error occur .
for exampl , <num> to the <num> plu <num> is equal to <num> to the <num> , accord to python .
so , algorithm such as that us in the solv procedur don't find exactli correct answer .
so to see if the solut obtain by the solver is a reason solut to the matrix vector equat we see if the differ between the target vector b and the vector a time u ha entri that ar close to zero .
so these entri ar veri close to zero so we consid that a success .
we've found the solut .
now thi vector , the differ between b the target vector and a time u is call the residu of the matrix vector equat .
an easi wai to test if the entri of the residu ar close enough to zero is to comput the dot product of the residu with itself .
in thi case , the dot product is thi tini number .
so we're pretti confid that we've gotten a solut to thi equat .
let's go ahead and us the solv procedur to solv the industri espionag problem .
it involv solv thi vector matrix equat .
so first we have to construct the matrix itself .
import of mat class .
now , the row label of our matrix will be the product and the column label will be the resourc .
now i'm go to actual construct that matrix of data .
next , suppos that thi factori specifi the observ resourc util , <num> unit of electr .
we want to solv thi vector matrix equat .
we us the solv procedur .
solv procedur inspect the solv matrix vector equat so we have to transpos the matrix .
now let's look at the solut .
all right it look like a thousand gnome were produc along with <num> group , <num> silli putti's , <num> salad shooter and <num> slinki .
should the fact that these valu ar integ give us some kind of confid in the solut ?
well , perhap , but let's look at the real entri of u .
you can see that the print procedur did some round .
let's just see if the solut make sens by multipli u by m and see if the result look anyth like b .
all right .
plastic <num> wa what we observ .
and thi give us <num> . <num> .
and so on .
so it's pretti good .
let's comput the residu .
now , comput the dot product of the residu with itself .
and it's thi veri tini number .
so we're convinc that the vector u is in fact a solut to thi vector matrix equat .
now , for some , matrix vector equat .
there is no solut .
and in thi case , the dot product of the residu will not be so small .
that'll indic that the vector we got is not a solut to the equat , and , in thi case , there is no solut .
and we'll learn later that the algorithm us here actual comput a solut that's in a sens , as close as possibl .
so that the residu is , in a sens , as small as possibl .
some matrix vector equat ar ill condit .
which mean , even if there is a solut , we won't be abl to get it us , the solver .
so thi is an exampl where there's a solut , but the residu is quit larg .
we're not go to studi condit in thi cours .
to learn more about that , studi numer analysi .
now i'm go to give you some other definit for matrix vector and vector matrix multipl .
the dot product definit of matrix vector multipl is thi .
the product m time u is the r vector v such that entri r of v is the dot product of row r of m with the vector u .
so to calcul the matrix vector product us thi rule , we would take the dot product of the row <num> , <num> with thi vector .
the dot product of row <num> , with it's vector , and the dot product of row <num> zero with it's vector .
and those dot product ar the valu of the entri of the result vector .
here's a simpl exampl , downsampl .
so , perhap i have a larg , high resolut imag .
and , in order to put it on a websit , i want to downsampl .
i want to get a lower resolut imag .
here's how i do that .
each pixel of the low re imag correspond to a littl grid of pixel of the high re imag .
and it's the intes valu of the pixel in the low re imag , is comput as the averag of all those littl pixel in that grid .
now averag can be express as a dot product .
we want to comput a dot product for each of the low re imag' pixel .
it's a lot of dot product .
but we can express all these dot product as a singl matrix vector multipl .
here's anoth exampl , blur .
to blur a face , we replac each pixel in the region we want to blur with an averag of pixel in the neighborhood .
again , averag can be express as dot product .
so , us the dot product definit of matrix vector multipl , we can express thi imag transform as a matrix vector product .
gaussian blur work the same wai your comput a sort of weight averag but that can also be express as a dot product .
here's anoth applic .
earlier we talk about search for a short audio clip within a longer audio segment .
these , these audio clip were record digit , so thei realli consist of number arrang in a sequenc .
and we saw that the wai to seek a a short clip in a longer audio segment is to carri out a whole bunch of dot product .
on for each of the possibl posit of the short clip within the longer audio segment .
lot of dot product .
but we can repres all those dot product as a singl matrix vector product .
recal the sensor node problem .
we want to know how much current is consum by each hardwar devic call a center node .
so we us test period , a seri of test period , in each on we measur the , the total power consum dure that period .
and for each test period , we have a vector that repres how long each hardwar compon is on dure that test period .
so , we have a bunch of those vector .
and now we want to us all these measur to calcul the energi consum per second , that is the current draw , for each hardwar compon .
we can formul thi as a system of linear equat .
then we solv for x to find out for each hardwar compon how much current it draw .
so here's a a linear , a system of linear equat .
each equat specifi the valu of a dot product of a known vector with our unknown vector x .
we take those vector a on through a m and put them in a matrix .
and now we can express all these dot product .
as a singl matrix vector equat .
so again the problem of comput the solut to a matrix vector equat is a fundament comput problem .
let see how to formul the sensori node problem as a matrix vector problem .
rememb our goal is to comput the current draw for each of the hardwar compon in our sensori node .
we find the domain to be radio sensor memori in cpu .
those ar the hardwar compon .
and our goal is to comput a vector u that map each hardwar compon to the current draw .
to do that we establish four test period .
for each of those test period we'll measur the total power us dure that test period .
and we'll put those measur in a vector b .
in addit , for each test period , we have a vector durat that specifi for each hardwar compon , how long that hardwar compon is on dure that test period .
to find thi vector u we solv the matrix vector equat , a time x equal b .
where a is the matrix whose row ar these durat vector .
let's solv thi matrix vector equat us the solv procedur .
first , we have to construct these vector .
thei all have the same domain .
now we construct them us that domain .
next we construct thi matrix whose row ar the vector .
we us row dict to map for that .
let's see how that matrix look .
next i'll construct thi vector b that give for each test period the total milliamper second consum in that test period .
howev we're readi to us the solv procedur to solv thi matrix vector equat .
we'll assign the result to the variabl rate .
now let's look at the entri of rate .
to check that we've realli gotten a solut to the equat , we'll comput the residu .
and comput it dot product with itself .
that number is plenti small , convinc us that we do have an accur solut to the matrix vector equat .
keep in mind two thing though , on it's not necessarili the onli solut .
we haven't shown that there's a uniqu solut .
and two .
even the valu in the vector rate ar onli repres approxim , due to the limit of float .
you'll recal , we studi triangular linear system that look like thi .
where the zero is down here .
and these correspond in a natur wai to triangular matrix vector equat .
and so we call a matrix of thi form a triangular matrix .
here's the formal definit .
we can us backward substitut to solv a matrix vector equat like thi on .
triangular matric will be veri import later on .
you'll be write code to do matrix vector multipl and vector matrix multipl .
now , you could us either of the definit i've given , the dot product definit or the linear combin definit and you'll do that in homework .
but , us those definit , it's not easi to exploit sparsiti in the matrix .
so , we'll look at anoth definit .
on i call the ordinari definit of matrix vector multipl .
entri r of the result vector , v is the sum over all the column label of mrc time entri c of u .
thi formul make it easier to write code to comput the matrix vector product .
so here's the obviou wai you'd write it .
you'd iter over all the entri in big r , the row label , and comput the valu of the correspond entri of the product as the sum .
thi still doesn't exploit sparsiti in the matrix .
so we can us anoth idea .
we initi the output vector v to the zero vector .
and then we iter over all the non zero entri of the matrix , and ad term as accord to the definit .
so here's pseudo code for that process .
now i'll present some veri fundament algebra properti of matrix vector multipl .
for ani vector v and ani scalar alpha , the matrix a time alpha time v is the same as alpha time the matrix a time v .
and , for ani vector u and v , a time the sum of u and v is the sum of a time u and a time v .
let's go through the proof .
to prove a time alpha v equal alpha time a v .
we just have to show that correspond entri of the left and right hand side ar equal .
that is that entri i , of a time alpha v , equal entri i of alpha time a time v .
well let's write a in term of it's row a on through a m .
now by the dot product definit of matrix vector multipl , entri i of a time alpha v is the dot product of row i , ai , with alpha v .
and that's equal to alpha time the dot product of ai with v by the homogen of dot product .
on the other hand , by the definit of scalar vector multipl , entri i of alpha time the vector a time v is alpha time entri i , a time v .
and by the dot product definit of matrix vector multipl , entri i of a time v is row i , ai dot with v .
so we've shown that correspond entri ar equal .
similarli we can show that a time the sum of u and v equal the sum of a time u and a time v .
we show that correspond entri ar equal .
so we need to show that entri i of a time u plu v equal entri i of a time u .
plu a time v .
so , again , we us the represent of a in term of it row .
by the dot product definit , of matrix vector multipl , entri i of a u v is the dot product of row i , name ai , with u v .
and thi is equal to ai time u plu ai time v , by the distribut properti of dot product .
on the other hand , by the dot product definit of matrix vector multipl , entri i of a time u is the dot product of row i , ai with u .
entri i of a time v is the dot product of row i , ai , with v .
and put these togeth , entri i , the sum , a time u plu a time v , is ai dot with u plu ai dot with v .
so we've shown that correspond entri ar equal .
and that complet the proof .
now we turn to the third vector space associ with the matrix .
the null space of a matrix a is the set of vector u such that a time u is the zero vector .
and it's written , null of a .
so , for exampl , thi matrix time the vector <num> , <num> , <num> is the zero vector .
so the null space of thi matrix includ <num> , <num> , <num> .
that's pretti trivial .
here's anoth exampl .
thi matrix time <num> minu <num> minu <num> is the zero vector .
so the null space also includ <num> minu <num> minu <num> .
by the dot product definit , the product of a matrix with row a1 through am with a vector u , is a vector whose entri ar the dot product of those row with u .
so , a vector u is in the null space of a matrix with row a1 through am .
if and onli if , u is a solut to the homogen linear system , a1 dot x equal <num> through am dot x equal <num> .
so we just saw the null space of a matrix with row a1 through am equal the solut set of the homogen linear system .
so thi show that the null space is in fact a vector space .
but , let's show that in a differ wai directli by show that it satisfi the algebra properti of vector space .
properti v1 requir that the set includ the zero vector .
well , sinc a time a zero vector is alwai a zero vector .
the null space doe contain a zero vector .
now for properti v2 .
if u is in the null space , then for ani scale or alpha , a time the scale or alpha time u equal alpha time a time the vector .
a time the vector is the zero vector .
so thi is alpha time the zero vector , which is zero .
which show that alpha u is also in the null space .
final , for properti three .
if u is in the null space , and v is in the null space , then a time the sum of u and v can be split up as a time u plu a time v , sinc each of u and v ar in the null space , each of these is zero vector .
so , their sum is also a zero vector .
that prove v3 , that the sum of u and v is in the null space of a .
so , thi show that the null space of a is a vector space .
earlier we saw that if you have a solut u1 , to a linear system , then the solut set of that linear system can be written as u1 plu big v , where big v is the solut set of the correspond homogen linear system .
we can restat that in the languag of matric .
if you want , a solut to the matrix vector equat , a time x equal b , then the solut set of thi matrix vector equat is u1 plu big v , where big v is the null space of a .
let's look at some simpl but import consequ of thi proposit .
if the vector space , big v , which is defin to be null a , is a trivial vector space , then the solut u1 is the onli solut to thi matrix vector equat .
and if big v is not trivial , then u1 is not the onli solut .
so , as a consequ , we get that the matrix equat a time x equal b , ha at most on solut if and onli if the null space of a is a trivial vector space .
now , how can we tell if the null space of a matrix is a trivial vector space ?
the answer to that will have to wait .
but now we turn to an applic of these algebra properti and the null space .
now error correct code ar us in cell phone , flash drive , and mani other devic .
ham came up with a code that's now call a linear binari block code .
linear becaus it base on linear algebra , binari becaus it us zero's and on's .
and block code becaus it encod block of fix length us the error correct code .
then here is how a linear binari block code work .
suppos i want to send a messag .
let's sai my messag is <num> bit .
i encod that as a block of , in thi case , <num> bit .
then i transmit it through what's abstract as a noisi channel .
thi is thi is a channel that sometim introduc error dure transmiss .
at the other end of the noisi channel , a <num> bit block is receiv that might differ from the , the block that's inject into the channel .
and then that's decod hopefulli to obtain the origin <num> bit that wa transmit .
in a linear code , the block that's actual inject into the noisi channel , is call a code word , and we'll denot it by c .
the block that's receiv at the other end might not be a code word .
we denot that by c tild .
we let big c denot the set of code word allow .
now ham's code wa a linear code .
and what that mean is we repres the <num> bit and <num> bit block as <num> vector and <num> vector over gf2 .
we can write the seven bit block that wa receiv , c tild as c plu e , e is the error vector .
sinc we're us gf2 , e ha on precis in the posit where c tild differ from c .
the kei idea in a linear code , is that the set of code word , big c , is the null space of a matrix h .
the advantag of do thi is it make the receiv's job easier .
now the receiv get c tild , and need to figur out what the error vector is .
how can the receiv do that ?
the receiv multipli c tild by the matrix h .
h time c tild equal , substitut for c tild , h time c plu e .
and now , us on of our algebra properti , we can split thi sum up .
h time c plu e is h time c plu h time e .
us the fact that the set of code word is precis the null space of the matrix h , we know that h time c is the zero vector .
so we end up with just h time e .
so the receiv can comput from c tild the product of h time e , and from that need to determin the error vector e .
how can he do that ?
in ham's origin code , thi is the matrix h , now you might notic someth interest about the column and their and the order .
well suppos that that noisi channel introduc just <num> bit error then e , the error vector ha onli <num> on the rest of it entri ar <num> .
can we determin the posit of that bit , from h time e ?
let's sai for exampl that e ha a <num> in it third posit .
so e look like thi .
h time e is then the linear , us the linear combin rule .
h time e is then the third column of h , which is <num> , <num> , <num> .
and that tell us where the error occur .
as long as e ha , at most , on bit error .
the posit of that bit can be determin from the product h time e .
thi show that the ham code allow the receiv to correct on bit error .
now , we're go to studi the relationship between a matrix m and the function that map a vector x to m time x .
now , in on direct , it's pretti easi .
given a matrix m , we can defin the function .
map x to m time x .
and the more interest thing is go the other wai .
given a function , can we find the matrix m such that that function map x to m time x ?
in studi thi relationship , we come up with thi fundament idea of linear function .
let's go the easi direct first .
we start with a matrix m and we defin the function f of x to be f of x equal m time x .
now , what ar the domain and co domain of thi function ?
let's sai m is an r by c matrix over the field f .
then , the domain of f is f to the c , becaus the input to the function ha to have as it domain , the label set of the matrix .
similarli , the output of the function is a vector with domain r .
so , the co domain of the function f is the field to the r .
for thi matrix , the function f of x equal m time x ha a domain of r to to the set sharp , at , and question mark .
and the co domain is r to the a and b .
so , for exampl , given thi as input .
thi is the output .
here's anoth exampl , given thi defin thi function as thi matrix time the input .
then , the domain of the function is r3 the co domain is r2 .
and for exampl , it map thi input to thi output .
now , let's sai we have a function and we want to comput a matrix m such that the function is f of x equal m time x .
okai , we know that the domain , let's sai the domain is f to the a .
so , we know the input is an a vector .
so , for the product m time x to be even legal , we need the column label set of m to be the set a .
similarli , sinc the co domain is f to the b , we know that the output is a b vector , and so we need that the row label set of m is the set b .
so , we know that m must be a b by a matrix .
now , what ar the entri of m ?
we have a function f , and let's sai it domain is fn and it co domain is fm .
we think there might be a matrix .
big m , such that f of x is the equal to m time x .
how can we find out what the entri of thi matrix ar ?
well , we start by write thi mysteri matrix in term of it column .
so , let's sai those column ar indic as v1 through vn .
now , we us the standard gener .
rememb , the first standard gener is <num> and the rest of the entri ar <num> .
the second is <num> and then <num> , and then the rest ar <num> and so on .
so , we combin standard gener with the linear combin definit of matrix vector multipl .
so , f of e1 is the matrix time the vector e1 .
and by the by the linear combin definit of matrix vector multipl , thi product is just the first column , v1 .
similarli , f of en is just the last column , vn .
let's take a simpl exampl .
the function that stretch by two in the horizont direct .
okai , and we assum thi function is defin as a matrix vector multipl for some matrix m and we want to figur out what it's entri ar .
well , we plug in the , we plug in the standard gener .
first standard gener is <num> , <num> .
we plug in <num> , <num> , we know that point get map to <num> , <num> , becaus we're stretch by two in the horizont direct .
now , we plug in the second standard vector , <num> , <num> .
and we know thi map to <num> , <num> , becaus we're not do ani stretch in the vertic direct .
so , we know s , appli to the first standard gener , is <num> , <num> and we know s appli to the second standard gener is <num> , <num> .
so , we take these two vector and we build a matrix with those as it column .
that's the matrix m , <num> , <num> as it first column and <num> , <num> as it second column .
let's try anoth exampl , rotat by <num> degre .
so , let r be the function that rotat the point , x , y by <num> degre , like thi .
and we assum that r can be defin by matrix vector multipl for some matrix m .
and we'll try to figur out what the entri ar .
now , we know that rotat the standard gener <num> , <num> by <num> degre give us <num> , <num> .
so , the function should map the standard , first standard gener <num> , <num> to <num> , <num> .
and we know that , rotat the second standard gener <num> , <num> by <num> degre should give us minu <num> , <num> .
so , the function should map <num> , <num> to minu <num> , <num> .
sinc the first standard gener map to <num> , <num> and the second standard gener map to minu <num> , <num> , we build the matrix by make these it column .
and there it is .
now , we consid a gener of the previou exampl .
thi time we defin r to take a point x , y and rotat by an angl of beta .
and we assum as befor that the function is defin by matrix vector multipl for some matrix m .
now , we know that rotat the first standard gener <num> <num> by an angl of theta should give us the point co theta , sin theta .
so , column on of the matrix m should be co , theta , sine theta .
we know rotat the point <num> , <num> , the second standard gener , by an angl of theta , should give us minu sine theta co theta .
so , column two of the matrix is minu sine theta , co theta , and here is the matrix for rotat by an angl of theta .
try on more exampl .
translat .
so , translat by <num> , <num> , mean we move the input on unit to the right , and two unit up .
assum thi function is defin by matrix vector multipl for some matrix m , and let figur out the entri of m .
we start with the point <num> , <num> translat it .
and we get <num> , <num> .
so , the first column would have to be <num> , <num> .
we start with the , the second gener <num> , <num> and translat it .
and we get <num> , <num> .
so , the second column of thi matrix would have to be <num> , <num> .
so , the matrix would look like thi .
here's a simpl exampl .
consid the function from r4 to r4 defin by f of x equal x .
that's just the ident function .
now , let's assum that f of x equal m time x for some matrix m , and let's figur out what matrix .
well , we plug in the standard gener .
f of e1 equal e1 .
and so , the first column is just e1 , similarli f of e2 is e2 , so the second column is e2 , f of e3 is e3 , so the third column is e3 , and f of e4 equal e4 , so the fourth column is e4 .
so , the matrix look like thi .
thi is the ident matrix .
so , we see that the ident function , f of x , correspond to an ident matrix , that's why we call it an ident matrix .
let's consid the function from rn to rn , defin as follow .
given a vector x1 through xn , return the vector d1x1 through dnxn .
so , what thi function is do , is scale in each coordin .
and the matrix , correspond to thi function , ha the , ha the valu d1 through dn , go down the diagon .
thi is call a diagon matrix .
all the entri off the diagon ar requir to be <num> .
now , a special case is where all the diagon element ar <num> .
in that case , the function is the ident function and the matrix is the ident matrix .
in the exampl we just saw , we assum for each function that the function could be repres by matrix vector multipl .
in fact , in on of the exampl that's not true .
so how can we tell for a given function whether it can be repres by matrix vector multipl ?
we'll state two algebra properti .
if a function can be express as a matrix vector product , then it ha those properti .
if a function from fc to fr ha those properti , then it can be express as matrix vector multipl .
we're go to state it in somewhat more gener term , howev .
let big v and big w be vector space over some field .
and suppos a function whose domain is big v and whose co domain is big w satisfi the follow two properti .
properti l1 is it for everi vector v in big v and everi scalar alpha f of alpha time v is the same as alpha time f of v .
and properti two is for everi two vector u and v in big v , f of u plu v equal f of u plu f of v .
if a function satisfi these properti , we call it a linear function .
now , suppos we have a r by c matrix and suppos the function is defin by .
multipl by m .
then f is a linear function .
how do we know ?
well , the domain and code domain ar vector space .
we earlier show that m time the scalar vector product , alpha b equal alpha time the matrix vector product , m time v .
so that prove that f satisfi properti <num> .
we also show earlier that m time the vector sum u plu v equal the vector sum of m time u and m time v .
and thi prove that the function satisfi properti l <num> .
so a function defin by matrix vector multipl , is a linear function .
now that we know that the function that can be repres by matrix vector multipl ar linear function , let's go back and look at some of our exampl .
our first exampl wa stretch by two in the horizont direct .
properti l on of linear function would requir that s of v <num> plu v <num> equal s of v <num> plu s of v <num> .
is , is that true for stretch by two in the horizont direct ?
we'll illustr that it is true , us an exampl .
here's a vector , v <num> , and here's it imag under s , s of v <num> .
here's anoth vector , v <num> .
and here's it imag , s of v <num> .
now if we add v <num> and v <num> we get thi vector .
v1 v2 and it imag of s of v1 v2 over here .
but thi same vector is also the sum of s of v1 s of v2 .
so we've shown that s of v1 v2 equal s of v1 plu s of v2 .
the second properti of linear function properti l2 requir that for ani scalar alpha and ani vector v in the domain s of alpha time v is the same as alpha time s of v .
let's illustr thi properti us our vector v on from the previou exampl .
rememb , here is the imag from s of v on .
we multipli v on by a scaler , sai <num> , and thi is what we get .
thi is <num> time v on .
and the imag of that under s is thi , s of <num> time v1 .
but notic that that imag is the same as take the imag s of v1 and scale it by <num> .
thi show that s of <num> time v1 is the same as <num> time s of v1 .
thi isn't a mathemat proof , but it illustr how you would go about prove thi .
and sinc the function , s , satisfi properti l on and l two , it is a linear function .
you can similarli show that rotat by theta degre is a linear function .
what about the translat function ?
we'll see that thi function violat properti l on of linear function .
for exampl , let's plug in the vector <num> , <num> for v<num> and <num> , <num> for v<num> .
the sum of these two vector is <num> , <num> .
translat that by ad <num> , <num> give us <num> , <num> .
on the other hand , translat of <num> , <num> .
plu the translat of <num> minu <num> is the vector <num> , <num> plu <num> , <num> which is <num> , <num> .
so thei don't match up .
properti l1 is violat .
so thi function is not a linear function .
in fact you can show that thi function doesn't satisfi properti l two either .
we now show and if f is a linear function with domain big u and codomain big b .
then it map the zero vector of big u to the zero vector of big b .
here's the proof .
let zero denot the zero vector of big u and let zero sub v denot the zero vector of big v .
now let's appli the function f to the zero vector .
f of the zero vector equal f of the zero vector plu the zero vector , which by a properti of linear , equal f of the zero vector .
plu f of the <num> vector .
now , we just subtract on of these , from both side and we get , on the left side , we get the <num> vector and on the right , we get f of the <num> vector .
that prove the lemma .
now , i'll show that linear function , have thi nice properti , i call , push linear combin through .
so , for a linear function f , and for ani vector v1 through vn , and ani scalar , alpha <num> through alpha n , f appli to the linear combin , alpha <num> vn plu and so on , is the same as the linear combin , alpha <num> time f of v<num> and so on .
so we've push the linear combin through .
i'll show how thi work in the case where n equal <num> .
when we appli f to the linear combin alpha <num> v <num> plu alpha <num> v <num> , by properti l2 , we can split up the sum .
so that's equal to f of alpha <num> v<num> plu f of alpha <num> v<num> .
and then by properti l1 , we can move the coeffici outsid .
so thi is equal to alpha <num> time f of v<num> plu alpha2 time f of v2 .
and the proof when , and is great than <num> , is similar .
here's a quick exampl of push through the linear combin .
we'll take the function to be matrix vector multipl , where thi is the matrix .
let's verifi that f appli to the linear combin is the linear combin of the valu of f .
on the left , i've deriv the valu of thi directli .
and on the right , i've deriv the valu of thi directli .
and thei turn out to have the same valu .
in the exampl we show how to deriv a matrix from a function assum the function could be defin by matrix vector multipl .
now i'm go to show that that method is justifi .
so , given a function from , sai , r n to r m , we want a matrix m such that f of x equal m time x .
the method involv plug in the standard gener e1 through e n and then defin the ith column of m to be f appli to the ith standard gener .
now we'll show that thi method realli work if such a matrix m exist .
so if there is such a matrix .
and we just show that f is a linear function .
that mean it satisfi these two properti .
take ani vector v .
let's sai these entri ar alpha <num> through alpha m .
we can right v in term of the standard gener .
so appli the function f to v we get thi .
now we us the properti of linear function .
us properti l1 and l2 we can convert thi to thi .
we defin the matrix m so that it first column .
is f of e1 , it second column is f of e2 and so on , so we , we've replac these by column <num> of m and so on .
so what we have is a linear combin of the column of n .
and by the linear combin defint of matrix vector multipl , that's the product of m time the vector v .
the kernel of our linear function f is the set of vector v , who's imag is the zero vector .
it's written ker of f .
for a function defin by matrix vector multipl , f of x equal m time x .
the kernel of f is just the null space of the matrix m .
now we'll prove what i call the on to on lemma .
a linear function is on to on if and onli if it kernel is a trivial vector space .
here's the proof .
let f be a linear function whose domain is big u and whose co domain is big v .
there ar two direct to prove .
first , suppos kernel of f contain some non <num> vector .
that is , it's not a trivial vector space .
then , f of that vector is the <num> vector by definit of kernel .
now , we've seen that a linear function alwai map the <num> vector to the <num> vector .
so f of <num> is also the <num> vector .
so thi show that the function is not on to on .
equival , we've shown that if a function is on to on , then it kernel must be trivial .
here's the second part .
suppos , on the other hand , that the kernel is trivial , it contain onli the zero vector .
and let v1 and v2 be ani two vector that have the same imag under f , f of v1 equal f of v2 .
move thi to the other side , we get f of v1 minu f of v2 is the <num> vector .
then by appli a properti of linear f of v1 minu v2 is the <num> vector .
and that show that v1 minu v2 is in the kernel of f .
but , we said that the kernel of f is trivial .
it consist onli of the <num> vector , so it must be that v1 minu v2 is the <num> vector .
which show that v1 equal v2 .
so that show that thi function is in fact on to on .
let f be the function defin by matrix vector multipl f of x equal a time x .
if the kernel is trivial , that is , if the null space of a is trivial , then there's onli on wai to get a particular output b .
b is the imag under f of onli on vector in the domain .
that is , there's at most on vector u such that a time u equal b .
in other word , the solut set of the matrix vector equat a time xx equal b ha at most on vector .
we've seen the criterion for tell whether a linear function is on to on .
how can we tell if a linear function is onto ?
recal that a imag of a function f is the set of all imag of element of the domain .
that is , it's the set of all f of v where v belong to the domain .
you might know thi as the rang , but that's an ambigu term and so , we avoid it .
the imag of a function f is written m of f .
now , the imag of a function is a subset of the co domain of that function and ask whether a function is onto is the same as ask whether it imag is , in fact , the entir co domain .
here's an exampl from light out .
to construct the matrix , who's column ar the button vector , for <num> by <num> light out .
what happen when we multipli thi matrix , by a vector , alpha <num> , alpha <num> , alpha <num> , alpha <num> .
the result is , a linear combin of the button vector .
where the coeffici ar , alpha <num> , alpha <num> , alpha <num> , and alpha <num> .
now let's defin a function , f , that map a vector , alpha <num> , alpha <num> , alpha <num> , alpha <num> , to thi matrix vector product .
and the imag of that function is the set of all configur that can be express as linear combin of those column .
so , sai that the function f is onto mean that everi configur can be written as a linear combin of the button vector .
that is everi configur of <num> by <num> light out can be solv .
is thi true ?
can two by two light out be solv for everi configur ?
and , what about five by five light out ?
these question amount to ask whether a particular linear function is onto .
now , we've studi matrix vector multipl , and vector matrix multipl .
now we're go to studi matrix matrix multipl .
suppos a is an r by s matrix , and b is an s by t matrix .
then it's legal to multipli a time b .
in mathes , we'd write it as ab and in our mat class , we'll us a star to denot multipl between matric , so we'd write it a star b .
now note that a time b is differ than b time a .
in fact , on of those product might be legal , while the other on is illeg .
we're go to see two equival definit of matrix matrix multipl .
on in term of vector matrix multipl , and on in term of matrix vector multipl .
we'll start with the definit that us vector matrix multipl .
sai we're multipli a and b .
for each row label r of the matrix a , row r of ab is the vector matrix product , the row r of a time b .
so , for exampl , let's sai we're multipli thi matrix by b .
row <num> of the product is row <num> of the first matrix time b .
row <num> of the product is row <num> of thi matrix time b , and row <num> of the product is row <num> of thi matrix time b .
how do we interpret thi product ?
thi is a vector matrix product , and we can us either of our definit , the linear combin definit or the dot product definit .
either on will do .
so we've defin a matrix product in term of some vector matrix product .
how do we interpret thi vector matrix product ?
let's us the linear combin definit , we write b in term of it row .
let's call them b1 , b2 , and b3 .
then the matrix vector product <num> , <num> , <num> time the matrix b , by the linear combin definit just pick out the first row , b1 of b .
similarli , the product of <num> , <num> , <num> with a matrix b , take <num> time the first row , and <num> time the second , so 2b<num> b2 .
and the product <num> , <num> , <num> time the matrix , pick out just the third row , b3 .
so in summari , we get thi product .
so what is thi do ?
multipli thi matrix by thi matrix realli add twice the first row to the second row .
for that reason we call thi an elementari row addit matrix .
now i'm go to give the matrix vector definit of matrix matrix multipl .
for each column label s of b , column s of the product ab is a time column s of b .
so for exampl , let a be thi matrix , and let b be the matrix with column <num> , <num> , <num> , <num> and <num> minu <num> .
so here's b , those ar it column .
the product ab is the matrix whose column i is the product of a , with column i of b .
so a time the first column <num> , <num> is <num> minu <num> , a time the second column , <num> , <num> is <num> minu <num> .
and a time the third column , <num> minu <num> , is neg <num> , neg <num> .
so the matrix matrix product is the matrix with those output as it column .
now we combin these definit , the definit , the matrix vector definit of matrix matrix multipl .
and the dot product definit of matrix vector multipl .
to get what i call the dot product definit of a matrix matrix multipl .
entri rc of the product ab is the dot product of row r of the first matrix with column c of the second matrix .
for exampl , to find the matrix matrix product of these two , we think of thi first matrix as row .
we think of the second matrix as column , and we take all of the dot product , and thi is the result .
now , matrix matrix multipl interact in a nice and predict wai with transpos .
but here's the rule .
the transpos of a time b is b transpos time a transpos .
so for exampl , here's a product of two matric , call thi a and thi b , thi is the product .
now , if we take the transpos and revers the order , we get the transpos of thi is thi , the transpos of thi is thi .
we take the product and we get thi matrix .
now , notic that thi matrix is the transpos of thi .
now , you might get confus and think the transpos of the product ab is a transpos time b transpos , but that's the wrong order .
thi is fals and in fact it might not even make sens .
it might be that the , that the row and column label make that an illeg product .
for a b to be a legal product , a's column label have to match b's row label .
for a transpos to b transpos to be legal a transpos column label , that is a's row label have to match b transpos row label , that is b's column label .
so for exampl , thi product is legal , but if you transpos them , you get an illeg product .
let's see what happen when we multipli a matrix by anoth matrix that happen to have a singl column .
let's call the column b .
well , by the matrix vector definit of matrix matrix multipl .
the result is a matrix with a singl column and that column is the matrix vector product a time b .
well thi show that matrix vector multipl is in some sens subsum by matrix matrix multipl .
if you want to express a matrix vector product , you could alwai formul it as a matrix matrix product , where the second matrix is actual on column wide .
now , there's a convent to interpret a vector as on of these on column wide matrix .
it's call a column vector .
so we would write the vector <num> , <num> , <num> in thi wai , as a matrix with on column , name <num> , <num> , <num> .
and then we'd write the matrix vector product a time the vector <num> , <num> , <num> as a time the column vector that is the on column matrix with <num> , <num> , <num> .
and gener we would write that as a time b without the star in the middl to be consist with our notat for matrix matrix product .
now , if we interpret vector as on column matric , how ar we go to get vector matrix product ?
we us the transpos , we can turn a column vector into a row vector .
so , suppos you have the vector b , <num> , <num> , <num> .
and you want to take the product of thi vector with the matrix .
consid thi vector as a , matri , a row matrix , that is , a matrix with onli on row .
then , by the vector matrix definit of matrix matrix multipl .
the product you get is a singl row matrix .
so we would write thi as b transpos time a , to be consist with our convent of interpret a vector as a column matrix .
sinc the vector b is a column matrix , the transpos of b is a row vector .
that is matrix with a singl row .
now that we know how to interpret vector as matric , either column vector or row vector let's see what it mean to multipli them .
there ar two wai to multipli vector interpret as matric .
first let's take the product of a row vector time a column vector .
we write that u transpos time v .
here's an exampl .
let's take thi row vector and multipli it by thi column vector .
now the , the first matrix ha on row , and the second matrix ha on column .
so , the product matrix ha on entri .
it ha on row and on column .
it's realli just a matrix with on number in it .
now by the dot product definit of matrix matrix multipl , that on entri is the dot product of the singl row of thi first matrix .
with the singl column of the second matrix .
so we're realli comput a dot product .
thi is sometim call the inner product , but we're go to us the inner product in a more special wai later on .
here's anoth wai to multipli vector interpret as matric .
we take a column vector , time a row vector .
here's an exampl .
thi column vector time thi row vector , us the dot product definit of matrix matrix multipl .
the entri in the first row and first column of the product is the dot product of the first row of thi matrix by the first column of thi matrix .
well that's just the product of thi on entri , u1 , by the on entri , v1 .
similarli , the ij entri of the product is the product of the ith entri of the first vector .
by the jth entri of the second vector .
thi is call an outer product of two vector .
correspond to a matrix , there is a function .
if the matrix is an r by c matrix then the function map f to the c for some field f to f to the r .
and the function is the function defin by the rule f appli to a vector y is a time y .
now , let's consid two matric , a and b , that we're go to multipli togeth .
these defin function as well .
a defin the same function f of y is a time y .
b defin a function , we'll call it g .
g appli to a vector x is b time the vector x , and we'll defin h of x to be the function correspond to the matrix product a time b .
that is , h is the function that take a vector x to a time b time x .
now , there's someth interest about the relationship between these function .
here's an exampl .
let's start with thi matrix .
the correspond function multipli a vector by the matrix .
and thi ha the effect of ad the second element to the first element .
let's take b to be thi matrix .
here's the correspond function that multipli the vector by the matrix .
and thi ha the effect of ad the first element to the second element .
now , let's take the product of these two matric .
here is the product .
thi correspond to a function as well .
multipli thi vector by thi matrix .
and the result is here .
now , if we take the composit of the two function , f and g , and appli that to a vector , it look like thi .
we appli g first to the vector x1 x2 , get x1 and x1 plu x2 .
then , we appli f to the result .
we get the vector 2x <num> plu x2 , and x<num> plu x2 .
and thi exactli match the output of the function h on input x1 , x2 .
so thi illustr thi idea that the composit of function correspond to multipl of matric .
let's see a formal proof , howev .
for the proof , let the column of b be the vector b1 through bn .
now , by the matrix vector definit of matrix matrix multipl , column j of the matrix product , ab , is a time column j of the matrix b .
so , let's take a vector x , let's sai it entri ar x1 through xn .
appli the function g to x is the same as multipli x by b .
by the linear combin definit of matrix vector multipl , we can write thi vector as the linear combin of the column of b , where the coeffici ar given by the entri of x .
now , let's appli f to g of x , f of g of x is f of thi linear combin .
us the properti of linear function , we can replac thi by thi .
we basic move the function in , move the coeffici and the sum out .
and now , us the definit of f , we can replac f of b1 by a time b on , f of bn by a time bn .
and now , us the matrix vector definit of matrix matrix multipl , column <num> of ab is a time column <num> of b , which is a time b<num> .
similarli , column n of the product ab is the same as a time column n of b , which is bn .
now , us the linear combin definit of matrix vector multipl , the linear combin of these column , can be written as a matrix vector product .
the , the matrix ab time the vector x , whose entri ar the coeffici .
and thi by definit is the result appli h to the vector x .
so , that prove , that prove the properti .
so , we've seen that matrix matrix multipl correspond to composit of function .
and thi give us a nice corollari .
matrix , matrix multipl is associ .
what that mean is , in take the product of three matric , a , b , and c , you can first take the product of the first two and then multipli it by the third .
or you can take the product of the second and third , and then multipli it by the first .
you get the same result .
the proof is veri simpl .
function composit is associ , therefor matrix matrix multipl is associ .
here's an exampl .
three matric .
let's sai , first we take the product of the second and third , get thi on , then we take the product of the first and we end up with thi matrix .
we could also first take the product of the first and the second , get thi matrix , and then multipli that by the third and we get the same matrix .
descart studi law in colleg becaus hi dad want him to .
after that , he gave up for awhil on book and decid to see the world .
he had a practic of ly in bed and think , includ about mathemat .
he had lot of great idea in math and philosophi .
we're go to focu on just on .
the stori goe he had an idea while ly in bed and look at a fly on the ceil .
he notic that he could describ the locat of the fly by two number .
that is the distanc of the fly from two wall .
two wall make a corner .
and he realiz that thi work even when the wall were not necessarili perpendicular .
thi led him to understand that he could formul geometr question us algebra .
now , the wall plai the role of what we would now call ax , and the two number ar call coordin .
the coordin represent of a vector v , in term of other vector a1 through an , is the vector of coeffici , the vector of number alpha <num> through alpha n , such that v equal alpha <num> time a<num> and so on , up to alpha n time an .
in thi context , we call the coeffici , the number in thi vector , coordin .
for exampl , thi vector can be written as thi linear combin .
so it's coordin represent in term of these vector is the vector of coeffici <num> , <num> , <num> .
so that's it's represent .
what's the coordin represent of thi vector in term of these vector ?
well , we can write thi vector as thi linear combin .
so the coordin represent is the vector consist of the coeffici , <num> , <num> , and minu <num> .
there's on more exampl .
what's the coordin represent of thi vector in term of these three vector .
here we've express thi vector as a linear combin of these vector .
the coeffici ar <num> , <num> and <num> .
so the coordin represent is the vector <num> , <num> , <num> .
now why ar we go around put coordin in the vector ?
it make sens when you think about the linear combin definit of matrix vector multipl .
oh , let a be the matrix whose vector ar the column a1 through an .
then , when we sai u is the coordin represent of a vector v in term of a1 through an , we can rewrit that as the statement that a time u equal v .
so to go from a coordin represent u , to the vector be repres , sai v , we multipli a time u .
i call thi rep to vec .
now , to go from a vector to it coordin represent , we have to solv a matrix vector equat .
we have to solv a time x equal v , and the solut is a coordin represent .
thi is a wiimot , a remot control for the wii , video system .
and it ha an infrar camera in here .
and , it can wirelessli report the locat of infrar point that it see to the comput .
johnni chung lee show we could us thi as a simpl light pen .
the , the first thing you have to do to us it is find the map from the point in the camera's coordin system to the point in the screen coordin system .
now , how do we find that transform ?
the transform can be repres as we'll see , by a matrix h .
and the challeng is , figur out the matrix h .
we can deriv h essenti onc we take four point whose coordin in the screen coordin system ar known .
and find their represent in the camera coordin system .
we're go to us the same math for a slightli differ problem , remov perspect .
here's an imag taken in my offic of a whiteboard , taken from an angl .
now , there might be some interest linear algebra written on thi board .
but we can't quit get it , becaus it's taken from an angl , so what we'd like to do is synthes a new imag from thi imag look straight at the board , and with no perspect at all .
and here's the result .
and how do we do that , we us the same camera orient basi as befor , rememb that the origin is at the camera center .
the first vector in the basi goe horizont , the second goe vertic and the third goe from the camera center .
from the origin to the top left corner of the imag sensor arrai .
we're go to make us of anoth coordin system , on that's particularli well suit to the to , to the , the whiteboard okai .
in thi coordin system the origin is as befor , the camera center .
the first vector in thi whiteboard basi goe horizont from the top left corner to the top right corner .
the second vector goe from the top left corner vertic down to the bottom left corner .
and the third vector in the basi goe from the origin , the camera center , to the top left corner of the whiteboard .
so you have to imagin these vector in the three dimension world .
let's sai we have a point in the world and we have it's coordin in term of the camera orient basi , a1 , a2 , a3 .
we can write the same point p in term of the whiteboard coordin system c1 , c2 , c3 .
here ar the coordin in term of the hammer basi , here ar the coordin in term of the whiteboard basi .
now combin these two equat we get thi equal thi becaus of cours , it's the same point .
so we've got thi equat , and i'm go to basic be recapitul an argument i made earlier .
have to do with chang of basi .
let a and c be there two matric and as befor , when we were discuss , chang of basi , thi matrix c ha an invers , c invers .
let's multipl thi equat on the left , by c invers and we get , thi equat .
now , c invers in c , cancel out , give the ident matrix , which multipli by thi vector , doesn't chang it .
so we get thi equat .
so , the product of the matrix c invers , and a , is a matrix h , such that h time the corner represent with respect to a1 , a2 , a3 equal the quarter represent with respect to c1 , c2 and c3 .
the challeng is comput h .
we don't actual comput thi matrix h by multipli two matric , we comput it by solv equat .
we think about the entri of the matrix h as unknown .
we set up some equat in , in these unknown , and we'll us the solver modul to solv thi .
the math is a littl hard to follow .
it'll make more sens onc you start actual do thi .
so to deriv the equat , let p be some point on the whiteboard .
and let q be the correspond point in the imag plane .
let x<num> x2 and <num> be the camera coordin of the point q in the imag plane .
that is , the coordin with respect to the camera basi .
and that , y1 , y2 , y3 be the white , whiteboard coordin of the same point q .
so then we have that the vector y1 , y2 , y3 is the matrix , h time x<num> , x2 , and <num> .
now let's multipli everyth out and we get these equat .
so here ar the equat .
the white board coordin of the origin point , p , ar y1 divid by y3 , y2 divid by y3 , and y3 divid by y3 , which is <num> .
so let's defin w1 to be y1 over y3 , and w2 to be y2 over y3 .
so we can write the whiteboard coordin of thi origin point p as w<num> , w2 , and <num> .
now , let's multipli through these equat , by y3 .
so we get these equat .
now , we us these to substitut for y1 , and y2 , and y3 in the , in these equat and we get these equat .
now , final multipli through and move thing to the other side , we get these fairli complic equat .
the equat ar equat in the unknown h entri .
and the coeffici in these equat ar known valu .
thei're , coordin of point we know about .
so , we got two equat , in these unknown from look at a point in the whiteboard and the correspond point in the in the imag plain .
now that give us two equat we're go to take <num> point in the whiteboard .
name the four corner of a whiteboard and find out us an imag viewer the coordin of those point in the in the imag plane .
we find out which pixel thei correspond to .
we can us that in thi wai to deriv eight equat in the unknown entri of the matrix ag .
unfortun , there ar nine entri in the matrix ag , so that doesn't quit give us enough inform .
we need on more equat .
but it turn out , we can't figur out what h is from these point after all .
thi correspond to the fact , that we don't know the scale of , of the imag , okai .
a tini build that's nearbi look just like a , a huge build that , that's far awai .
but it turn out , that doesn't matter .
the scale of the imag doesn't matter when we're do thi transform .
so we don't have to pin down exactli h .
as long as the h we comput is a scalar multipl of the true matrix h we'll be abl to perform the transform just fine .
so in order to pin down some h , we just add an equat .
we specifi that on of the entri is on .
and that should work out okai .
again , the math is fairli confus .
onc you start actual perform these calcul , i'm hope it'll becom more clear to you .
all right , let's sai we've comput the matrix ag .
how can we us thi to synthes an imag without perspect ?
an imag of the white board without perspect ?
we have an imag , it's a , it's a grid of pixel .
each pixel is a rectangl of color .
what we have to do is , transform that rectangl to find out the correspond quadrilater in the white board .
so , we know the coordin of the littl rectangl in in the imag plane , it's given by the , by , by the camera coordin .
what we want to do is find out the correspond point in the white board coordin system .
so we start with a point , q , in the represent of the imag , and we have it camera coordin .
we have , we know what pixel it correspond to .
take each point , each corner of a pixel , multipli it by h to get the represent of the same point with respect to the whiteboard coordin .
given the represent with respect to the whiteboard coordin , it's easi to find the correspond point on the whiteboard .
so here's a point in the imag plane , we want to map it to thi correspond point in the whiteboard .
and we know that the wai to do that is to just scale down .
divid these coordin by the third coordin .
and that give us the point in the whiteboard .
so you you white a program to carri that out for each corner of each rectangl of color in the imag .
transform those and you'll get a new imag that's of the whiteboard with no perspect look straight on .
thi will be more clear when you start do the lab and it's spell out in greater detail in the lab assign .
we need a tool , a technic tool , to transform on set of vector , to anoth .
so , let's sai , you have a set s of vector and you have anoth vector z , that you want to .
inject into the set s .
but you want to maintain that s ha the same cardin , so you have to eject anoth vector from s .
and you want to do thi in such a wai that you don't chang the span .
well , the exchang lemma is a technic wai of achiev that .
it tell you which vector to eject .
we'll start with a simplifi version .
so here's the simplifi exchang lemma .
suppos s is a set of vector and z is a nonzero vector in the span of the set s .
then there alwai exist anoth vector , w , in s , such that the span of the set obtain from s by ad z and remov w is the same as the span of s .
that is , w is a vector we can remov while maintain the same span .
here's how the proof goe .
we write s as the set consist of v1 through vn .
now , sinc z is in the span of thi set s , we can write z as a linear combin of the vector in s .
by the superflu vector lemma , the span of the set with z is the same as the span of the set without z .
now , sinc z is nonzero at least on of the coeffici in thi represent is also nonzero .
sai it's alpha i , the coeffici of vi .
well , we can rewrit thi by move everyth over except for alpha i time vi .
and now we divid through by alpha i , which us is guarante to be nonzero .
and we manag to repres vi as a linear combin of all the other vector .
us the superglu vector lemma , therefor the set span by s with z is the same as the span of the set s with z but not w .
and that prove thi simplifi exchang lemma .
so we see that the simplifi exchang lemma is not enough .
we need to enhanc thi lemma .
we introduc a set of protect element a .
here's the full exchang lemma .
suppos s is a set of vector , and a is the subset of s .
suppos z is a vector in the span of s such that the union of a with z is a linearli independ set .
then there is a vector w in s and not in the protect set a such that the span of s is the same .
as the span of the set obtain from s by ad in z and take awai w .
you see that unlik the simplifi lemma , we requir not just that z be nonzero , but in fact that the set , a union z is linearli independ .
so here's the statement of the lemma , let's go through the proof .
we'll write the set s in thi wai .
v1 through vk , follow by w1 through wl .
where the set of protect element , a , consist of v1 through vk .
now , sinc z is requir to be in the span of s , we can write z as the linear combin of the vector in s .
here's a linear combin .
z is alpha <num> time v<num> , up to alpha k time vk plu beta1 time w1 up to beta l time wl .
by the superflu vector lemma , span of the set obtain from s by ad in z is the same as span of s .
z is a superflu vector .
now if these coeffici , beta <num> through beta l , were all zero , then we would have written z as a linear combin just of the vector v on through vk .
but that would contradict the fact that a togeth with z is a linearli independ set , so at least on of these coeffici , beta <num> through beta l , must be nonzero .
so let's sai beta <num> is a nonzero coeffici .
then we can rewrit thi equat in thi wai , by move everyth from the right hand side to the left hand side .
except beta <num> , w<num> , and we get thi equat .
now , we divid the whole thing by beta <num> .
we can do that becaus we know beta <num> is nonzero .
and we get , thi equat , which express w1 as a linear combin of all the other vector .
therefor , by the superflu vector lemma .
the span of the set s togeth with z is the same as the span of the set s togeth with z with w1 omit .
and that complet the proof .
now i'll show how the exchang lemma can be us to prove that our minimum span forest algorithm is correct .
thi is not realli part of linear algebra .
i'm do it just as an illustr of the power of the exchang lemma .
here's the algorithm rememb for find a minimum span forest of a graph g .
we start by initi the forest to the empti set , and we consid the edg in increas order of weight .
for each edg e , if e's endpoint ar not yet connect , we add e to f .
we'll show that thi algorithm , thi greedi algorithm , actual find the minimum weight span forest .
and let's assum for simplic , that all the weight ar distinct .
here's how the proof goe , let f be the forc found by the algorithm and let f be the truli minimum weight span forc .
we want to show that f is equal to f .
to do that we us proof by contradict , we'll assum for a contradict that thei're just differ .
now , let e1 , e2 and so on up to em be the edg of g in increas order of weight .
now , let ek be the minimum weight edg on which f and f differ .
now we have to set ourselv up to appli the exchang level .
let a be the set of edg that occur befor ek , in thi order , that ar in both f and f .
sinc at least on of the four includ all of a and ek , it must be that a togeth with ek ha no cycl .
it's a linearli independ set .
now , consid the moment where the grow algorithm is decid whether to includ ek in f or not .
so far the algorithm ha chosen the edg in a to be includ in it forest .
now , we alreadi said that ek doe not form a cycl with the edg in a .
so the algorithm must choos ek to put in the forest f .
now sinc f and f differ on ek , it follow that f star doe not contain the edg ek .
now we can us the exchang lemma .
a is a subset of f , a togeth with ek is a linearli independ set .
therefor by the exchang lemma , there's an edg , call it en in f , but not in a , the protect set .
such that the span of f star togeth with ek but not includ the en is the same as the span of f .
that show that thi set , where we replac en with ek , is also a span set .
but when we did that replac , the set got cheaper , ek occur earlier in the order than en , so it ha smaller weight .
that show that , in fact , f must not have been the truli minimum weight span forest after all .
that's a contradict which complet the proof .
compress of imag .
sai you want to store or transmit some larg imag .
how do we repres the imag compactli so it's more effici store or transmit ?
onc obviou represent of an imag , a <num> megapixel imag , is to repres each pixel by a number .
that's straight forward .
can we do ani better ?
on idea , thi is br strategi <num> , is to us sparsiti .
so we find the nearest k spars vector .
we'll talk later about what it mean to be the nearest k spars vector .
for now , i'll sai that the method for do that involv suppress all but the largest k entri .
well , here's the result , it's not a veri good reproduct of the origin imag .
you lose a lot of detail by suppress all but sai , the top <num> of the pixel .
ar there better strategi that we can us ?
here's anoth idea .
we repres an imag vector by it coordin represent with respect to some set of gener .
so we select a set of gener sai v1 through vn and we replac each imag vector with it coordin represent .
now , for thi strategi to be us , we need to ensur , first of all , that everi imag vector is a linear combin of the vector v on through v n .
so more gener , thi is the question , how can we tell given some vector .
v1 though vn , whether everi vector can be written as a linear combin of these vector .
how do we tell whether these vector ar in fact gener ?
we also need the number of vector to be small becaus that wai the number of entri in the coordin represent will be small .
thi rais the question how can we find a smallest possibl set of gener ?
for the vector space .
it turn out that that strategi doesn't work well either .
you can't get a small enough set of vector that still gener the whole space , but here's a third strategi that work quit well .
as befor , we select some vector that span the whole vector space .
for each imag to compress , we view it as a vector and we find it coordin represent in term of these gener .
now , we replac that .
coordin represent with anoth vector that's k spars .
again we supress all but the k largest entri .
we'll call that u tild .
and the compact represent is the vector u tild .
it's compact becaus it's spars , so we onli need to store the non zero entri .
now , onc we need to recov an imag , we can do that by calcul the correspond linear combin of the gener .
of cours , the result imag won't be ident to the origin imag .
but it actual look quit good .
so here's the imag we obtain us that first strategi .
just suppress the pixel whose valu were not among the k largest .
and here's the result of us thi hybrid strategi which i just describ .
so , the first question that we're go to studi is for a given vector space , what is the minimum number of vector whose span equal that vector space ?
what's the minimum size of a set of gener ?
now , there ar two natur algorithm strategi that you might try to find a minimum size set of gener .
here is on , i call it the grow algorithm .
given a vector space , initi your set to the empti set .
and repeat , as long as it's possibl .
choos a vector in the vector space that's not alreadi span by the vector in s .
and add that vector to s .
repeat that until there ar no longer ani vector in the vector space .
thei're outsid the span of s .
at that point , you've got a set s that span the given vector space .
the question is , doe thi realli give you the smallest gener set for the vector space v ?
anoth question that we'll have to get to is , can thi algorithm be made to stop ?
doe it ever termin ?
here's an altern approach .
i call it the shrink algorithm .
given a vector space , it initi s to some finit set of vector that span the vector space , and then repeat , as long as possibl .
find a vector alreadi in s , such that the span of the set of vector obtain by remov the vector from s is the same , it's still the vector space .
and then , just remov the vector .
so , we're shrink down the set s .
the algorithm stop at the point when remov a vector from s would result in not span the origin vector space .
so , at the point that the algorithm termin , if it termin , the span of s is the vector space v .
the question is , is thi set of gener a smallest possibl set of gener for the vector space ?
there's an addit question of how we do the initi .
we're given two algorithm , the grow algorithm and the shrink algorithm , for find a set of gener .
is it obviou that each of these algorithm find the smallest set of gener ?
let's look at exampl from a problem in graph .
so , here's a graph .
the point ar call node or vertic and the link ar call edg .
each edg ha two endpoint .
so , for exampl , thi edg's endpoint ar these two node .
the two end point of an edg ar call neighbor .
now , a domin set in a graph is a set s of node such that everi node is either an s or is a neighbor of a node in s .
so , for exampl , the set of node i've circl here is a domin set .
our goal is to find a smallest domin set in a graph .
and here's on possibl algorithm .
the grow algorithm . you initi the set s to be the empti set , and while s is not a domin set , we add a node to s .
so , we might start by ad sai thi node .
it's not a domin set yet , so we might choos to add , sai thi node .
at thi point , we've got a domin set .
everi node is either in the set , or a neighbor of a node in the set .
so you we can stop .
but did thi algorithm give us a minimum size domin set ?
it turn out that , no , we could have gotten a much smaller domin set consist , sai just of thi note .
so , in thi case , thi greedi algorithm , the grow algorithm , came up with the wrong answer .
it didn't come up with the smallest solut .
an altern is the shrink algorithm , which initi s to be the set of all node and take awai node as long as take them awai leav you with a domin set .
similarli , thi algorithm can also fail to find a smallest domin set .
so , algorithm like grow and shrink don't alwai find you the smallest solut .
i'll illustr some of the concept with a graph problem .
now , thi is a graph .
these ar the node , thei repres area of a univers , and these ar the edg .
now , a sequenc of edg where the second element of the first edg match the first element of the second edg , the second element of the second edg match the first element of the third edg , and so on is call a path .
it's an x1 to xk path if the first element of the first edg is x1 and the last , second element of the last edg is x k .
so for exampl , here is a path from main quad to gregorian .
anoth path goe thi wai .
now a cycl is a collect of edg that form a path start and end at the same place .
so , here the dark edg form a cycl .
a set of edg in a graph is span if for everi edg of the graph , there's a path in the set of edg connect the two endpoint of the edg .
for exampl , let s be the set of dark edg in thi diagram .
thi is a span set .
for exampl , consid the edg between biom and athelet .
it end point ar connect by a path us edg of the set .
the edg from main to keenei it end point ar connect by a coupl of path among the edg in the set .
so thi is a span set .
now , later on , we'll understand the connect between thi us of span and the us and connect with vector .
a set of edg in a graph is a forest if the set includ no cycl .
so , for exampl , the set of dark edg illustr here is not a forest , becaus there is a cycl here .
if we remov on of those edg , the result set of dark edg is a forest .
the minimum span forest problem is a fundament problem in graph algorithm .
the input is a graph and an assign of weight to edg .
and the output is a set of edg that is span and a forest and subject to those requir ha minimum weight .
so , thi might come up , for exampl , in an applic in which you must select some of these edg to form a network that can deliv hot water between differ area of a campu .
the network must achiev the same connect as the input graph .
and the edg weight , repres the cost of instal pipe between the endpoint of the edg and the goal is , to find a set of edg that's span and of minimum cost .
it will turn out becaus the edg all have posit weight that the solut will be a forest .
let's consid algorithm for thi fundament problem .
there ar two natur approach you might take to come up with a solut .
on is call the grow algorithm .
given a graph , start by initi the set s to be the empti set .
and consid the edg of thi graph in increas order of weight .
for each edg in turn , consid whether it end point ar alreadi connect by a path , us edg in the set s of edg select so far .
if not , add that edg to the set s .
if so , move on to the next edg in increas order of weight .
let's try thi out .
the first edg is the weight two edg .
now , so far , we've select no edg .
so certainli , these end point ar not connect us the edg select so far .
so we'll add thi to our set of select edg .
next edg is <num> .
all right .
the endpoint ar not yet connect , so we'll add thi edg .
next is <num> .
it endpoint ar not connect , so we add that edg .
<num> , up .
now , the endpoint of the edg with weight <num> ar alreadi connect us edg we've select .
so we skip <num> .
move on to <num> , it's endpoint ar not connect so we add that edg in .
<num> , it's endpoint ar not yet connect so we add that edg .
<num> , oh , it's endpoint ar alreadi connect .
us a path of edg alreadi select .
so we skip <num> , and <num> , it end point ar also alreadi connect .
we've run out of edg so that's our solut .
is it inde a minimum span forest ?
here's anoth natur algorithm for solv the minimum span forest problem .
i call it the shrink algorithm .
you start by init s to the set of all edg .
and now you consid the edg in decreas order of weight .
for each edg in turn , if remov that edg still leav a path among the select edg , between the end point of the edg , then go ahead and remov that edg .
let's try it out .
we start with the heaviest edg .
the on of wake nine .
now , remov thi edg will leav it end point connect us the edg we haven't yet remov .
so we can cross that out .
now , we go to <num> .
remov the edg with weight <num> is safe .
we go to <num> .
remov the edg with weight <num> would remov the endpoint of that edg without a path between them among the edg .
we've kept so we don't remov <num> .
six if we remov the edg with weight <num> there won't be a path between it endpoint among the edg we haven't yet elimin .
so we leav that in .
<num> , well , we can remov thi edg .
becaus it endpoint ar connect us edg we have .
<num> , if we remov thi edg , there won't be a path , so we leav that in .
<num> , the same .
we leav that in .
and <num> , we'd better leav that in .
so , thi is the set of edg select by the shrink algorithm .
is thi truli a minimum span forest ?
you might've notic that the grow algorithm for minimum span forest close resembl the grow algorithm for build up a set of gener .
and the shrink algorithm for minimum span forest , close resembl the shrink algorithm for find possibl small set of gener .
it's not a coincid , we can formul minimum span forc as a problem in linear algebra .
so here we start with a graph .
we'll let d the domain of our vector be the set of , of note .
now , we can repres a subset of d by a vector over g of <num> .
we just put a on in everi posit repres by , in the set .
so the set pembrok , main , and gregorian is repres by thi vector , which ha on precis in the posit pembrok , main and gregorian .
so here's the represent of all the edg in thi graph .
for exampl , the edg between pembrok and athlet is repres by thi vector that ha a on in pembrok and a on in athlet and the rest ar zero .
now , the vector repres the subset keenei gregorian thi vector is the sum of of the vector repres the , the set keenei main .
main , wriston and wriston , gregorian .
so let's see that .
here's the vector for keenei , main .
here's the vector for main , wriston .
and here's the vector for wriston , gregorian .
if we add up these vector , the on in thi column sum to <num> .
the on in thi column sum to <num> .
and we're just left with <num>'s in the posit keenei and gregorian .
a vector with <num>'s in entri x and y is the sum of vector correspond to edg that trace out an x to y path in the graph .
in thi case the path from keenei gregorian through main and wriston .
so here's anoth exampl .
each of these set repres on of the edg shown in dark here .
the span of the correspond vector .
contain , for exampl , the vector main keenei becaus there's a path from main to keenei us those dark edg .
it contain the vector keenei gregorian becaus there's a path from keenei to gregorian us those edg .
but it doesn't includ , for exampl the pair athlet and biom , becaus there's no path us dark edg between those two node .
similarli , it doesn't repres the pair , athlet and main .
or biom and main becaus there's no path of dark edg connect those two node .
here's the grow algorithm for minimum span forc and here's the grow algorithm for vector .
consid the edg of the graph .
correspond to consid vector in the vector space .
test whether an edg's endpoint ar connect us edg we've alreadi ad to s correspond to test if a vector li in the span of the vector we've alreadi select .
so the grow algorithm .
for minimum span forest , there is a special of the grow algorithm for vector .
we can forc thi to make choic that exactli mimic the execut of thi algorithm .
the grow and shrink algorithm for vector both need to test whether a vector is superflu , so we need a criterion for test that .
so here it is .
for ani set of vector , and ani vector v in that set , if v can be written as a linear combin of the other vector in that set , then it's not need .
span of the set without that vector equal span of the set with that vector .
and here's the proof .
let s be the set of vector v1 through vn .
and suppos v n can be written as a linear combin of the other vector .
we need to show that everi vector in the span of s is also in span of the set obtain from s by remov v n .
everi vector in span of s can be written as a linear combin of the vector v1 through vn .
substitut for vn in thi express we obtain v equal thi linear combin , where notic that vn doe not appear .
we can rewrit that so that it's obviou it's just a linear combin in the vector v<num> through vn minu <num> .
and these ar the coeffici .
so thi show that the vector , v , arbitrari vector in span of s .
can be written as a linear combin of the vector in s minu vn .
and is therefor in the span of that set .
that complet the proof .
we sai that vector v1 through vn ar linearli depend .
if the zero vector can be written as a nontrivi linear combin of those vector .
nontrivi mean that at least on of those coeffici is non zero .
in that case , we'd refer to thi linear combin as a linear depend in the vector v on through vn .
on the other hand , if the onli linear combin that yield zero is the on where the coeffici ar all zero , we sai the vector v1 through vn ar linearli independ .
now here's an exampl .
these vector ar linearli depend .
and here's a wai of write the <num> vector as a nontrivi linear combin of the vector .
that show that thei're linearli depend and thi is a linear depend in those vector .
here's anoth exampl .
these vector ar linearli independ .
how do we know ?
in thi case , the structur of the vector make it easi to tell .
consid ani linear combin of these vector .
sum it up we get the vector alpha <num> , <num> alpha <num> and <num> alpha <num> .
so , if thi linear combin equal the zero vector .
it must be , that alpha <num> equal <num> , <num> alpha <num> equal <num> , therefor alpha <num> equal <num> and <num> alpha <num> equal <num> .
therefor , alpha <num> equal <num> .
so , that show , that in that case , the linear combin is trivial .
so , we've show , that the onli linear combin of these vector , that equal the <num> vector .
is the trivial linear combin , and therefor these vector ar linearli independ .
how can we tell if vector v1 through vn ar linearli depend ?
we're not yet in a posit to answer that question .
but we can relat it to other question we've alreadi ask recal the definit .
vector v on through v n ar linearli depend if the zero vector can be written as a nontrivi linear combin of v on through v n .
now , by the linear combin definit of matrix vector multipl , thi linear combin can be written as a matrix vector product where the column of the matrix ar the vector v1 through vn .
and the vector consist of the coeffici in linear combin .
it follow that vector v1 though vn ar linearli depend if and onli if there is a nonzero vector such that multipli that vector by thi matrix yield the zero vector .
therefor , the vector v1 through v n ar linearli depend if and onli if the null space of thi matrix is nontrivi .
thi show that the question , how can we tell if v1 through v n ar linearli depend is the same as the question how can we tell if the null space of a matrix is trivial ?
so we see that , onc we know how to answer on of these question , we know how to answer the other .
here's anoth exampl .
consid a homogen linear system , that is , a linear system in which all the right hand side valu ar <num> .
now , take these vector , a1 through am , and make them the row of a matrix .
then , the set of solut to thi homogen linear system no period is the same as the null space of thi matrix .
that tell us that thi question , how can we tell if a null space of a matrix is trivial , is the same as the question , how can we tell if the solut set of a homogen linear system is trivial .
so we see that these three question ar realli differ form of the same underli question .
here's yet on more exampl .
recal that if u1 is a solut to a linear system , then the set of all solut to thi linear system is exactli the set consist of all vector u <num> plu v , where v belong to the set of solut to the correspond homogen linear system .
thu the question we've ask ar also the same as the question , how can we tell if a solut u <num> to a linear system is the onli solut to that linear system .
so we've seen that all these question ar realli disguis version of the same question .
answer these question requir an algorithm .
so , thi is a fundament comput problem .
test linear depend , given a list of vector v1 through vn determin whether thei ar depend or independ .
and we'll see two algorithm for thi later on .
now , in minimum span forest , a zero vector can be obtain by take the vector that correspond to edg that form a cycl .
so in such a sum , for each node , or each each label , there ar exactli two vector that have a on in that posit so cancel give you a zero .
so , for exampl , take the vector correspond to main wriston , main keenei and keenei wriston .
in each posit , there ar an even number of on .
so , by sum these vector we get the zero vector .
now , if you have a set of edg .
that includ a cycl as a subset .
then there is a linear combin of the correspond vector that equal zero .
so , take the vector correspond to the dark edg in thi diagram .
thei ar linearli depend , becaus a subset of those edg form a cycl .
so , we can write , the zero vector as a linear combin of the vector correspond to these dark edg .
we assign coeffici on to each of the first three , and zero to the last .
and sum them up we get <num> for each posit .
what we see if a sub set of s form a cycl , then s is linearli deep .
on the other hand if a set of edg contain no cycl , that is , if it's a forest , then the set of edg correspond to a linearli independ set of vector .
in thi case , the dark edg form a forest , there ar no cycl , so the correspond set of vector is linearli independ .
in gener , a subset of linearli independ set is a linearli independ set .
in the case of graph , if the set of edg form no cycl then take awai edg from that set you still can't form a cycl .
so let's go through the proof of thi lemma .
let s and t be two subset of vector and suppos s is a subset of t .
we want to prove that if t is linearli independ , then s is linearli independ .
now that's equival to the contraposit .
if it's less , if s is linearli depend , then t is linearli depend , and we'll prove it in that form .
the idea is veri simpl .
if you can write <num> as a linear combin of some vector , then if you throw in some more vector , you can certainli write <num> as a non trivial linear combin of all the vector .
you can just assign <num> to the extra vector .
so , let's go through that formal .
so we'll write t as thi set of vector , where s is the subset consist of the first n .
now , suppos that s is linearli depend .
that is , there ar coeffici , not all with which you can write a linear combin that equal the <num> vector .
well , we throw in the addit vector t1 through tk .
we can , the same linear combin , togeth with <num> coeffici on the addit vector .
still give us the zero vector , and it's still a nontrivi linear combin , becaus at least on of the alpha <num> through alpha n is nonzero .
what that show that the set of vector in big t is linearli depend .
and that prove the lemma .
here's anoth lemma that's go to be us in reason about linear depend .
let v on through vn be vector .
on of the these vector , vi , is in the span of the other vector if and onli if the zero vector can be written as a linear combin of all these vector .
where the coeffici of vi is non zero .
in graph , for exampl , the linear depend lemma correspond to the fact that an edg is in the span of some other edg if and onli if there's a cycl consist of some of those other edg togeth with the edg .
let's go through the proof .
the proof ha two direct like mani , onli if statement .
let's do the first direct .
suppos vi is in the span of the other vector , that is you can write the i as an linear combin of all the other vector .
now we just move the i to the other side , and we get thi equat .
well here , we've written the zero vector as a linear combin of all the vector , includ vi .
and vi's coeffici is not zero .
that prove on direct .
let's prove the other direct .
suppos that there ar coeffici , such that the <num> vector can be written as a linear combin of the vector , where the coeffieci of v , i , is non zero .
divid all thi by that coeffici .
and you get thi equat .
and now we can move everyth to the other side except v1 , and we've manag to express v1 as a linear combin of the other vector .
that prove the other direct .
we can restat thi in the contraposit .
thi is an equival statement .
vi is not in the span of the other vector , if and onli if for everi linear combin equal zero , the coeffici of vi must be zero .
we'll us thi to argu about the grow algorithm .
we'll show that the vector obtain by the grow algorithm ar linearli independ .
in graph that mean that when you run the grow algorithm you'll end up with a forest , a set of edg that contain no cycl .
so now let's prove thi corollari .
for n equal <num> , <num> and so on , let vn be the vector ad .
in the nth iter of the grow algorithm .
and we'll show by induct that the vector v on through v n ar all linearli independ .
here's the basi of the induct .
for n equal zero , there ar no vector so the claim that thei're linearli independ is trivial true .
assum the claim hold for n equal k minu <num> , the induct step consist of then show that it's true for n equal k .
the vector , vk , ad to s in the kth iter is not in the span of the previous ad vector , v1 through vk minu <num> .
therefor by the linear depend lemma , if you write zero as a linear combin of the vector v <num> through v k .
it must be that the coeffici of v k equal zero .
you can rewrit the equat thi wai without vk .
but by the induct hypothesi , the claim for n equal k minu <num> , the vector v<num> through vk minu <num> ar linearli independ .
so that , that impli that all these coeffici must be <num> .
and that show that the linear combin is trivial .
and that is that the vector v1 through vk ar linearli independ .
and that prove the claim for n equal k .
by induct , it prove the whole corollari .
let's look at the shrink algorithm .
when the shrink algorithm stop the set of vector in s is liter independ .
in graph , that mean the shrink algorithm produc a forest .
we're go to us the superflu vector lemma .
rememb , that for ani set s of vector and ani vector v in s , if v can be written .
as a linear combin of the vector , the other vector , then v is superflu .
the span of s without v is the same as the span of s with v .
and now we've prove that the shrink algorithm eventu produc a linearli independ set of vector .
let v1 through vn be the set of vector obtain by the shrink algorithm .
and assum for a contradict that these vector ar linearli depend .
that mean that the zero vector can be written as a nontrivi linear combin of these vector , that is , a linear combin in which at least on of those coeffici is non zero .
so let alpha i be on of those non zero coeffici .
by the linear depend lemma then , vi , the correspond vector , can be written as a linear combin of the other vector .
by the superflu vector lemma we don't need vi .
the span of the set without vi is the span with vi .
but that mean that the shrink algorithm would have remov vi , becaus it wasn't necessari .
that complet the proof .
so , we see that if thei successfulli complet the grow algorithm and the shrink algorithm , it will produc linearli independ set of vector .
let big v be a vector space .
a basi for v is a linearli independ set of gener .
so , a basi for big v is a set of gener with two properti .
the vector span big v and the set of vector is linearli independ .
so , thi is the most import definit in all of linear algebra .
here's some exampl .
we know that the , a basi must satisfi these two properti , span properti and the independ properti .
let big v be the span of these three vector .
is thi a basi for big v ?
well , no , we've seen that though it's a set of span , it's not linearli independ .
in fact , here's a linear combin , a non trivial linear combin that equal the <num> vector .
so , it's not a basi .
on the other hand , we take on of these vector out , it is a basi .
it's obviou that these vector ar linearli independ becaus thi on ha a non zero entri in the , a non zero first entri .
and thi on ha a zero first entri , wherea thi on ha a non zero second entri and thi ha a zero second entri .
so , us an argument describ earlier , we can show that ani linear combin that equal the zero vector must be trivial .
how do we show though , that these two vector ar span ?
well , we can , we can write the third vector , the miss vector , as a linear combin of these two vector .
therefor , by the superflu vector lemma , the the set span by the three vector equal the set span by the three vector , minu the third vector .
here's a veri simpl exampl of a basi , a basi for r3 .
these ar the standard gener .
it's easi to see that thi set of vector span r3 becaus for ani vector in r3 we can easili write it as a linear combin of those three vector .
we can argu as befor that these vector ar linearli independ .
suppos , you could write zero as a linear combin of these vector .
let's add up the linear combin .
we get alpha <num> , alpha <num> , alpha <num> .
well , if that's equal to the zero vector it must be that alpha1 , alpha <num> , and alpha <num> ar all zero .
that is that the linear combin is trivial .
so , that show those vector ar linearli independ .
now , instead of standard gener , we'll call them standard basi vector .
we refer to the set of these vector as the standard basi for r3 .
and in gener , the standard gener ar realli call standard basi vector .
here's anoth exampl of the basi .
these vector form a basi .
to see that we have to show that thei're span , and that thei're linearli independ .
first , to see that thei're span , we can write the standard gener as linear combin of these new vector .
sinc the standard gener can be written in term of the new vector , it follow that everi vector in the span of these standard gener is in the span of the new vector as well .
sinc the span of the standard gener is r3 , that show that r3 equal the span of the new vector .
now , we see that the vector ar linearli independ .
suppos we write the zero vector as a linear combin of these vector .
sum it up , we get thi .
and equat correspond entri , we see that x plu y equal <num> , x plu y plu z equal <num> , and x plu z equal <num> .
now , if we plug x plu y equal <num> .
into the second equat , we see that z equal <num> .
we plug z equal <num> into thi third equat , we get x equal <num> , and we plug x equal <num> into the first equat , we get y equal <num> .
so , that show that the linear combin is trivial , and therefor these vector ar linearli independ .
now , in graph , on kind of basi is a set of edg form a span forest .
the fact that , that , it's span follow from the fact that for everi edg xy in g , there's an x to y path consist of edg in the set .
the fact that it's linearli independ correspond to the fact that these edg form no cycl .
so , here's an exampl of a span forest in the graph .
there ar no cycl and everi edg in the origin graph ha it end point connect us edg in the set of dark edg .
here's anoth exampl of a span forest for the same graph .
now , we'd like to sai that everi vector space ha a basi .
and we have a , a good approach to do that , the grow algorithm and the shrink algorithm provid , linearli independ set that span a given vector space .
so , we'd like to sai that those algorithm prove that everi vector space ha a basi , but we're not quit there yet .
the grow algorithm corollari state that if the grow algorithm termin , it termin with a linear , linearli independ and span set of vector .
but we don't know whether the grow algorithm alwai stop , whether it successfulli complet .
now , the shrink algorithm corollari state that if we can run the algorithm , at the end , it will give us a linearli independ and span set of vector .
but in order to run it , we have to initi the set s with a finit set of vector that span the vector space .
so , we haven't shown yet that there is even a finit set of vector that span everi vector space .
and thi is not a mere technic matter .
in the wider world of mathemat , on ha to deal with vector space for which there's no finit set of vector that span it .
in thi cours howev , we're go to keep thing simpl and it'll turn out that everi vector space doe have a finit set of gener and that everi vector space ha a basi .
there ar two natur wai to specifi a vector space .
on is by specifi gener for that vector space , and the other is specifi a homogen linear system whose solut set is the vector space .
so , thi rais two fundament comput problem .
find a basi of the vector space given by gener .
that is , given a list of vector , find a basi for the space span by those vector and find a basi for the solut set of a homogen linear system .
that is , given a list of vector , sai a1 through an find a list of vector that form a basi for the set of solut to the homeogen linear system a1 . x equal <num> , and so on .
recal the idea of a coordin system for a vector space v .
we have gener a1 through an sai of the vector space v .
so , that everi vector in v can be written as a linear combin of the gener .
and we repres a vector v by it coordin represent that is , the vector form by the coeffici in thi linear combin .
and we rais the question , how can we ensur that everi vector ha just on coordin represent .
the answer is to ensur that these gener form a basi .
so , we'll prove the uniqu represent lemma which sai that if a1 through an ar a basi for a vector space v , then for ani vector littl v in that vector space , there is exactli on represent of that vector in term of those basi vector .
so , here's the proof .
let v be ani vector in the vector space .
now , the vector a1 through an span the vector space , so there's at least on wai of repres v as a linear combin .
suppos there ar two such represent with the coeffici alpha <num> through alpha n and the coeffici beta <num> through beta n .
now , by subtract on from the other , we get the <num> vector .
and now , by collect coeffici correspond to the same vector , we get zero as thi linear combin .
now , becaus those vector ar linearli independ , it follow that the coeffici must all be zero .
it must be a trivial linear combin .
so , alpha <num> minu beta <num> equal <num> , and so on .
and that show that alpha <num> equal beta <num> and so on .
so , the two represent ar actual just on .
a basi in a graph is a span forc and the uniqu represent lemma show us that for each edg xy in the graph , there is a path from x to y in the span forc , and there's onli on such path .
a well establish theme of comput scienc is the us of have data and be abl to transform between them .
in linear algebra , the analog thing is chang of basi .
so , suppos we have a basi a1 through an for some vector space big v .
how do we go from a vector b in big v to the coordin representaiton u of b in term of a1 through an ?
we saw befor that by the linear combin definit of matrix vector multipl .
the coordin represent satisfi thi equat .
the matrix whose column ar the basi vector time the coordin represent equal the origin vector b .
we now know by the uniqu represent lemma that u is the onli solut to the matrix vector equat a time x equal b .
where a is the matrix with a1 through an in it column .
so , we can obtain the coordin represent by us a matrix vector equat solver .
let's defin the function that map from f to the n to the vector space big v , by f of x equal thi matrix time the vector x .
now , thi function is onto , becaus a1 through an ar gener for the co domain .
it's also on to on by the uniqu represent lemma .
so , thi function is an invert function .
now , let's consid two basi for the same vector space , a1 through an and c1 through ck .
we defin the correspond function .
f of x is thi matrix time x , g of y is thi matrix time y , then both f and g ar invert function by the argument we just gave .
now , consid the function f invers compos with g .
thi function map from the coordin represent of a vector in term of c1 through ck , to the coordin represent of the same vector in term of a1 through an .
now , here's a veri import special case .
where the vector space big v is f to the m for some m .
in that case , the fact that f is invert impli that thi matrix is an invert matrix .
similarli , the fact that g is invert impli that thi matrix is an invert matrix .
put these togeth .
the function f invers compos with g ha thi properti .
that appli f invers compos with g to a vector x is the same as multipli the vector x first by thi matrix whose column ar c1 through c k .
and then , by thi matrix , the invers of the matrix whose column ar a1 through an .
so , we see that if a1 through an , and c1 through ck , ar both basi for f to the m , then multipl by thi matrix map from the represent of vector with respect to c1 through ck to the represent of that same vector with respect to a1 through an .
we can conclud the given two base of f to the m , there is some matrix b .
such as that multipl by b converg from the coordin represent which is vector on basi , to the coordin represent of the same vector , with respect to the other place .
now , convert between a vector and it represent , can be seen as a special case of thi process .
where we think of the vector itself as just the coordin represent of the vector in term of the standard basi .
here is the exampl .
we want to map from the coordin represent with respect to these vector to the coordin represent with respect to these vector .
we us thi matrix .
it's the product of the invers of the matrix whose column ar the new basi time the matrix whose column ar the old basi .
now , thi , thi invers is thi matrix , so thi product is thi matrix .
as an applic of chang of basi , we'll see how to render an imag with perspect .
so we're go to us the same math in the next lab , where instead of ad perspect , we'll take some awai .
so , we start with the point make up a wire a wire frame cube .
now , and we're go to move them , we're go to translat them for reason that will becom appar later , so we'll move them over .
now , how doe a camera , or an ey see these point ?
so , we have to start talk about camera .
so , here is a simplifi model of a camera , call a , a pinhol model .
there is a box with a , a hole here and the light from the scene goe into the camera through the hole and hit the back of the box .
now , all , a photon , onli get into the box , if it goe through the hole .
so , the onli photon that hit the back , ar those that go straight through the hole .
the hole is call the camera center and in the back of the box , there is an imag sensor arrai .
that's what detect the photon .
okai .
so when the photon bounc off the scene and pass through the pin hole strike the imag sensor , the camera regist them .
and as you can see , the imag end up be invert .
so , there's an even simpler model in which we get rid of the invers .
thi simpler model is us to avoid the invers of the imag .
in thi model the imag sensor arrai is place between the camera's center and the scene .
and the plane contain the imag sensor arrai is call the imag plane .
and a photon is detect , onli when it goe right to the camera setter .
so , it ha to bounc off someth in the scene and head through the imag plane , to the camera center , to be detect by the sensor arrai .
and which sensor arrai element detect that photon ?
it's whichev sensor arrai is intersect by the line that the photon travel along from the scene to the camera center .
so , we need a wai to map between point in the world p , and the correspond point q in the imag plane .
and we're go to do that us a special design basi which i'll call the camera orient basi .
the origin is defin to be the camera center .
that's why we had to translat that wire frame cube .
to get it somewhat awai from the camera center , the origin .
the first vector in the basi goe horizont .
and i'm just go to make it the length of , of a pixel .
the length of a , of a sensor element in the sensor arrai .
the second vector in the basi goe vertic .
the length of a , of a , of a sensor element , and the third vector goe from the origin to , sai , the top left corner of the sensor arrai .
now , we'll see why the camera basi make it easi to perform thi transform .
so , here is a side view where we we don't see a1 becaus it's point directli at us .
but we do see a3 and a2 .
and here's the scene .
and there's a point p in the world .
but first let's express that point in term of a1 , a2 , and a3 , the camera basi .
so , we get the coordin of that point .
let's call them x1 , x2 , x3 .
and notic that the point is then the linear combin of a1 , a2 , and a3 given with these coeffici .
x1 time a1 plu x2 time a2 plu x3 time a3 .
and we onli show x2 time a2 plu x3 time a3 becaus x1 time a1 is point directli toward us becaus we have the side view .
now , and how do we go from the point p to the point q ?
we us similar triangl .
so , here's some big triangl .
and thi is a littl triangl .
the point p correspond to point q .
the coordin of point p ar x1 , x2 , and x3 .
what ar the coordin of point q ?
we know that the third coordin , x3 , is <num> , <num> becaus thi point li in the imag plane .
to get from x3 a3 to a3 , we divid by x3 .
but by similar triangl , we have to divid all the coordin .
so , the coordin of thi point ar obtain by divid all the coordin of thi point by x3 .
so , it coordin ar x1 over x3 , x2 over x3 , and x3 over x3 , which , of cours , is <num> .
so , to summar what we've discov , given the coordin x1 , x2 , x3 in term of the camera basi , a1 , a2 , a3 of a point in the scene .
we find the coordin represent of the correspond point in the imag plane by just divid all these coordin by x3 .
we got x1 over x3 , x2 over x3 and x3 over x3 .
which is alwai <num> .
now , i'll call thi scale down .
now , onc we have a point in the imag plane , it's pretti easi to find out which sensor element it correspond to .
let's sai the point ha coordin x1 , x2 , x3 , with respect to the camera basi .
then , all we have to do is drop that third coordin , after all , it's alwai equal to <num> .
and becaus of the wai we've construct thi camera basi , that tell us the coordin within the sensor arrai of the particular sensor element .
that , that q li in .
to go from the coordin of the point make up the wire frame cube to the pixel coordin , we go through the follow process .
first , we write the basi vector of the camera coordin system us the world coordin .
the coordin with which we've written the point of the wire frame cube .
now , for each point p in the wire frame cube , we find it represent in term of the camera basi .
we scale down that is divid by the third coordin to get the correspond point in the imag plane .
and then , we convert to pixel coordin by drop the third entri .
here's the camera arrang i'm go to us .
the camera center is at the origin .
thi squar is the imag sensor arrai , and here's the wire frame cube we're go to view .
when light goe from the wire frame cube directli in a straight line to the camera sensor .
if it intersect the sensor arrai , then the sensor element at the intersect point pick up that light .
the camera will have a view that's closer to thi .
onc again , here's the camera arrang .
the first thing we're go to do is construct the camera basi .
here's a diagram show the vector of the camera basi .
the imag sensor arrai is <num> by <num> .
here's a view with the z axi go straight into the screen .
well , the first vector a1 ha a length that's , that of a singl pixel , <num> over <num> .
and it goe in the direct of the x axi .
the second factor ha the same length , goe in the direct of the y axi .
now , the third vector goe from the origin to the top left corner of the sensor arrai .
which look like , it should be at minu <num> half , minu <num> half , <num> .
let's look at the result .
and thi is the coordin represent for thi point wai out of the scene .
what we want to do is find a correspond point in the imag plane .
and we do that by divid by the third coordin , eight in thi case .
and thi give us the locat in the sensor arrai .
so , the pixel coordin ar <num> , <num> .
now , we can plot thi .
now we're readi to try the same thing with the whole wire frame .
we us a procedur that give us line segment .
and now , we take the co , corner of the wire frame cube , suitabl translat .
and construct the line segment with the given corner .
and now , we put togeth all those list to get the set of point , that we want to render .
now , the first step in render these point is to find their coordin represent in the camera coordin system .
next , we have to find the correspond point in the imag plane .
we'll us that .
we do that by scale down by the third coordin .
and here we'll deriv those point .
now , from these , we want to find the pixel coordin .
i'll defin a procedur to do that .
just take the first and second entri .
and now , we deriv all those pixel coordin and we can plot the point .
i want to draw your attent to on step in thi process , find the coordin represent of the cube point with respect to the camera basi .
we us vector rep , but we could have done it us matrix multipl .
here's the matrix whose column ar the vector of the camera basi .
if we were to multipli thi matrix by the coordin represent of a point in term of the camera basi , we would get back the point repres in world coordin .
to go the other wai , from world coordin to camera coordin , we us the matrix invers .
first , i'll import a procedur for find the matrix invers .
you'll write thi procedur later .
although , you could've found thi invers just by hand .
now , we can get the coordin represent with respect to the camera coordin of all the point make up the cube by multipli them by thi matrix invers .
for exampl , here ar the coordin of the first point on the list .
the kei fact for thi week is that all base have the same size .
and we us thi as the basi for answer mani of the question that we have been struggl with for quit a while .
we start with the morph lemma .
the morph lemma state that for ani vector space , big v , span by a finit set s of vector , for an linearli independ set b of vector in big v , .
the cardin of b is at most the cardin of s .
and befor we prove it , let's see what we can us it for .
we can prove that ani basi for the vector space big v is a smallest gener set for that vector space big v .
so how do we prove that ?
let b be a basi for big v .
so , certainli b is a gener set for big v .
after all , it's a basi .
let s be a smallest gener set for big v .
by the morph lemma , the cardin of b is no more than the cardin of s .
so becaus s is a smallest gener set , so is b .
and here's anoth consequ .
all base for a vector space big v have the same size .
well , thei're all smallest gener set so thei have to have the same size .
so here's the lemma we're go to prove , and the wai we're go to prove it is .
we're go to start with a set of gener , s , and modifi it bit by bit , inject vector of b on by on while preserv the cardin .
and how ar we go to do that ?
we're go to us the exchang lemma .
so , here's the exchang lemma .
we discuss the exchang lemma a while back .
suppos s is a set of vector and a is a subset of that set .
now suppos there's a vector , z , in the span of s such that a togeth with z is a linearli independ set .
then there's a vector in s and not in a , the protect set , such that the span of s is the same as the span of the set attain from s by ad z and remov w .
now for the proof of the morph lemma .
we write the element of b as b1 through bn .
and we defin s0 to be s .
we're go to prove by induct on k , that there is a gener set , s sub k of the vector space , big b , that contain b1 through bk and ha the same cardin as s .
in particular , take k equal to n , there wa a gener set s n of big b that contain all n of the b vector , and ha the same cardal as s itself .
sinc s sub n contain all n of the b vector .
it ha size at least n .
so the case k equal <num> is trivial .
we're not requir , we're , s0 is the same as s and it's not requir to have ani of the vector in , in b .
for an induct step , we have to show that we can get from sk minu <num> to sk .
and the wai we do that is we us the exchang formula .
we write a k is the set of vector b<num> through bk minu <num> .
and the vector that we want to inject is bk .
then a togeth with c is just the set consist of b1 through bk which is a linearli independ set becaus it a subset of the set consist of all the b vector in that set is linearli independ .
by the exchang limit , therefor , there's a vector w in sk minu <num> that's not in ak such that the span of the set obtain from sk minu <num> by ad bk and take awai w , is the same as sk minu <num> .
so we just defin sk to be sk minu <num> togeth with the vector bk and not includ the vector w .
so thi show that we can go from a set sk minu <num> to a set sk .
thei span the same vector space , thei have the same cardin , but sk ha on more of our basi vector .
that complet the induct step .
now notic that thi proof is actual an algorithm .
it tell you how to go from s0 to s1 , to s2 , to s3 , and final to s f .
now here's an illustr of the process appli to graph .
so our basi for a graph is a span forc .
here's on span forc and we're go to show that we can us the exchang lemma iter go from thi span forc to thi on .
by do on chang at a time .
exchang lemma insert on edg , and remov anoth .
so , start by insert thi edg .
well , we have to take on out .
so we can take thi on out , while still preserv the properti that thi is a span forest .
we're not lose anyth in span , and we're preserv cardin .
so let's make that exchang .
now we have to find an , an , now we're on step closer to the target span forest .
now we're go to insert thi edg .
now we have to take on out to preserv cardin .
let's take out thi on .
put in thi on and take out thi on will preserv the cardin and preserv the properti that thi forest is span .
let's do that .
now we're go to insert thi edg .
we have to take on edg out .
we'll take thi edg out .
let's do that .
and final we've gotten to the point where our span forest is the target .
so we've transform from thi span forest to thi on us exchang oper .
now we've come to on of the most critic definit in the cours , dimens .
the dimens of a vector space is the size of a basi for it .
and it's written dim v .
and we defin the rank of a set of vector to just be the dimens of the span of those vector .
and we write it as rank s .
so here's an exampl , these vector ar liter depend .
so their rank is less than three .
the , thi is not a basi .
there must be a smaller basi .
well , in fact , two of those vector will form a basi .
so that show that the rank of thi of thi set of vector is two .
here's anoth exampl .
the vector face , consist of the span of the zero vector , is span by an empti set , and therefor the length of thi set is zero .
now , for a matrix , we defin the row length of that matrix to be the rank of the row of the matrix .
similarli , we defin the column rank to be the rank of the column .
so anoth wai of sai it is , that the row rank of a matrix m is the dimens of the row space of m , written row m .
and the column rank is the dimens of the col space of m .
so here's an exampl , the row of thi matrix , ar the vector we saw befor , and we saw earlier that the rank of those vector is two .
so the row rank of thi matrix is two .
and the column ar these vector .
and on of these vector is zero .
clearli not need for span .
so , again , the column rank , so the column rank of thi matrix is also <num> .
here's anoth exampl .
well , thi row ha a nonzero entri in the first column , and none of the other have nonzero in the first column .
thi row ha a nonzero in the second column , and none of the other do .
and thi on ha a nonzero in the third column , where none of the other do .
so these three row ar linearli independ .
therefor the row rank of m is three .
the column ar these vector .
now , the first three column ar linearli independ , but you can express the fourth column as a linear combin of the other three .
so , the column rank of thi matrix is three .
now we've seen it in a coupl of exampl we've look at .
the row rank happen to equal the column rank .
and we'll see later that that's not a coincid , it's true in everi matrix .
now , earlier we ask a fundament question , how can you predict the dimension of the span of some vector ?
so now we can answer that question .
but , we just comput the rank of those vector , and that give you the dimens .
now let's look at rank in the context of graph .
let t be the set of dark edg .
now , a basi for span of t is shown here , all right ?
it's not it's linearli independ becaus there ar no cycl .
and it ha the same span as the dark edg in thi graph .
sinc the thi basi ha size four , the rank of t , the set of dark edg in thi graph , is four , and here's anoth .
basi for the same graph .
now let's see how we can us dimens to argu about the cardin of a vector space over gf2 .
so now we're work with vector over gf2 .
you rememb the checksum problem .
the checksum function we us wa , map a , an n vector to a <num> vector over gf2 by take dot product with <num> vector .
let p be the origin file and let e be the transmiss error .
the corrupt version of the file then is written as p plu e .
what we want to know is the probabl that a corrupt file had the same checksum as the origin file .
well , if thi error is chosen accord to the uniform distribut .
distribut , the probabl that p plu e ha the same check sum as p is the same as the probabl that e is a solut to a homogen linear system , which is equal to the number of solut to the homogen linear system divid by the number of all possibl vector e , the number of n vector .
and we know the number of n vector is <num> to the n , becaus there ar n entri , each on can be <num> or <num> .
so in order to find thi probabl , we need to know the number of solut to a homogen linear system .
so thi rais the question , how do you find the number of solut to a homogen linear system over gf2 ?
well the solut set to a homogen linear system is a vector space .
so the question becom how to find out cardin of a vector space over gf2 .
well , suppos that vector space ha a basi b1 through bn , those ar gener for the vector space .
so the vector space is the set of all linear combin of those vector .
the number of linear combin is <num> to the n becaus there ar n coeffici , each on can be <num> or <num> .
and by the uniqu represent lemma everi linear combin give a differ vector in the vector space .
so the number of vector in the vector space is also <num> to the n .
so thi show that the cardin of a vector space v is <num> to the power of the dimens of v .
the cardin of the vector space .
well , it still leav unansw the question of how to find the dimens of the solut set of a homogen linear system .
now , a homogen linear system can be written as a matrix vector equat , ax equal <num> .
and the set of solut to thi is just the null space of the matrix a .
so , we're realli ask how can we find the dimens of the null space of a matrix a ?
and that question will be answer later .
here's a basic result on base .
i call it the subset basi lemma .
everi finit set t of vector contain a subset s that is a basi for span of t .
and the proof us the grow algorithm .
so here's the old grow algorithm .
initi s to the empti set and repeat while possibl .
select a vector v in a vector space , big v , that's not alreadi span by the vector at s and put it in s .
we're go to us a revis version .
initi s to the empti set , and repeat while possibl .
select a vector v in the set t , that is not alreadi span by the vector in s and put it in s .
now , the origin version , if it termin , wa guarante to find a basi for the vector space .
becaus the origin produc a basi for big v , thi on will produc a basi for span of t .
so how doe thi differ from the origin ?
well , thi variant stop onc span of s contain everi vector in t .
wherea the origin algorithm stop onli onc everi vector in the vector space is in span of s , but that's okai .
onc thi algorithm reach the point when span of s contain everi vector in t , it also contain all linear combin of vector in t .
and therefor , span of s equal span of t .
so that show that the origin algorithm can be guid to make the same choic as thi variant .
and therefor , the variant also produc a basi .
here's anoth basic result on base .
the superset basi lemma .
let big v be a vector space , and let c be a linearli independ set of vector belong to big v .
then big v ha a basi , s , con , contain all the vector in c .
so again we us a version of the grow algorithm .
the onli chang we make is that we ask the grow algorithm to prefer to includ vector that ar in c .
initi , the grow algorithm will just keep ad vector in c to s .
it can keep do thi becaus c is linearli independ , so at no point will there be a vector in c that's alreadi span by the vector we put into s .
after it's ad all those vector in c to s , it'll keep go , ad some more vector until span of s equal the vector space v .
at which point , s is a , in a linearli independ set of gener for big v , and it includ all the vector in c .
but so far our proof is incomplet , becaus we haven't shown that the algorithm is guarante to termin .
here's a proof of termin that will work onli when big v consist of vector with a finit domain , d .
recal the standard gener for f to the d .
a standard gener's entri ar all <num> , except for <num> .
for exampl , these ar the standard gener for r to the n .
the number of standard gener for f to the d is the cardin of d .
by the grow algorithm corollari , the set s in the grow algorithm , remain linearli independ throughout the algorithm .
therefor , by the morph lemma , the cardin of s is at most the number standard gener , that is , at most the cardin of d .
sinc s grow in each iter , the number of iter is at most the cardin of d .
we've shown that the grow algorithm is guarante to termin .
and that complet the proof of the superset basi lemma .
the superset basi lemma hold even when d is not finit , but the proof is more involv , and it depend on someth call the axiom of choic .
let's try estim the dimens of some vector space .
so , here's a set of vector .
what's it rank ?
that is , what's the dimens of the span of t ?
by the subset basi lemma , the set t contain a basi for span of t .
therefor , the dimens of the span of t is no more than the cardin of t .
that show that the rank of t is no more than the cardin of t .
and in gener , a set t of vector alwai contain a basi for it span and therefor alwai ha rank at most , it cardin .
now we're go to give an argument base on the notion of dimens .
i call it the dimens lemma .
so , let's sai u is a subspac of w .
in that case , the dimens of u is no more than the dimens of w .
and if the dimens of u is equal to the dimens of w , then we can conclud that in fact u equal w .
so , here's the proof .
let u1 through uk be a basi for the subspac u .
by the superset basi lemma , there is a basi for w that contain the vector u1 through uk , that form the basi for u .
so let's write down b .
it ha u1 through uk , and possibl some more vector , b1 through br .
well , it's clear that the number of vector , in the basi for u , which is k is no more than the cardin of thi set b .
furthermor , if k , the number of vector in the basi for u , equal the cardin of b , then there aren't ani addit vector .
b is precis equal to the set u1 through uk .
and therefor , the span of those vector , which is u , equal the span of b , which is w .
so that prove the second part .
here's an exampl , suppos v is the span of these two vector .
well , clearli v is a subspac of r2 becaus these vector ar in r2 .
howev , these vector ar linearli independ .
and so the dimens of v is <num> .
well , becaus the dimens of r<num> is <num> as well , properti d2 show us that v is actual equal to r2 .
these two vector span all of r2 .
here's anoth exampl .
well , we have some set s consist of four vector .
sinc everi vector in s is a <num> vector , span of s is a subspac of r4 .
now , sinc the dimens of r<num> is <num> , properti d1 show , the span of s , ha dimens at most <num> .
so , in gener , ani set of d vector , ha rank at most , the cardin of d .
now we'll prove a veri fundament fact about base .
for finit d , everi subspac of f to the d , where f is a field , contain a basi .
well here's the proof .
let v be a subspac of f to the d .
it follow that the dimens of v is at most the cardin of d .
and therefor , the grow algorithm will eventu termin .
after all , in each iter , the grow algorithm add anoth vector to s .
so after k iter , the cardin of s equal k .
okai , each point of the execut of the algorithm the set is linearli independ .
so after k iter , the rank of s equal k .
everi vector ad belong to the vector space .
so span of s is a subspac of , the vector space v .
so after dim v iter , span of s ha dimens , dim v .
so by the properti d2 of the dimens lemma , span of s equal the vector space v .
now , rememb , the row rank of a matrix is the rank of it row , that is the dimens of the row space .
the column rank is the rank of it column , that is the dimens of the column space .
when we look at exampl , we saw that row rank seem to equal column rank , at least for the exampl we look at .
it turn out thi isn't a coincid , as we'll prove .
for everi matrix , row rank equal column rank .
to prove thi , we'll prove a lemma that sai for ani matrix a , the row rank of a is no more than the column rank of a .
and , here's how we'll us the lemma to prove the theorem .
we appli the lemma to our matrix m to show that the row rank of m is no more than the column rank of m .
and then we'll appli the lemma to the transpos of m to show that the row rank of m transpos is no more than the column rank of m transpos .
well , the row rank of m transpos is just the column rank of m .
and the column rank of m transpos is the row rank of m .
so that prove that the row rank of m equal the column rank of m .
so let's go back and prove the lemma .
the lemma state that for ani matrix a , the row rank of a is no more than the column rank of a .
so let's start by write a in term of it column .
so let a1 through an be the column of a .
now , let's take a basi for the column space , let's sai b1 through br .
and that mean that the dimens of the column space is r .
that is , r is the column rank of a .
our goal , then , will be to show that the row rank is no more than r .
now , each column of a li in the column space and can , therefor , be written as a linear combin of the basi vector .
us the linear combin definit of matrix vector multipli , we can therefor write each column , as , a matrix whose column ar the basi vector , time some other vector .
now we us the matrix vector definit of matrix matrix multipl to write all these equat .
write it as a singl matrix matrix equat , a equal b time u .
so b ha r column , and u ha r row .
well , let's write a and b in term of row now .
so , row a , row i of a equal row i of b time the matrix u .
now we write u in term of row .
and us the linear combin definit of vector matrix multipli .
that is , we can express each row of a as a row of b time u , and a row of b time u is a linear combin of the row of u .
so we've shown that each row of a is a linear combin of these row .
how mani ar there ?
there ar r .
so , that show each row of a is in the span of these r vector .
now , these r vector includ a basi .
so the dimens of the row space of u is no more than r .
and that show that the dimens of the row space of a is no more than r .
thi show that the row rank of a is no more than r .
and that prove the lemma .
with what we know now , let's return to the simpl authent scheme .
recal that the password wa an n vector , x hat over gf <num> .
the comput would challeng the human by send a random n vector over gf <num> , a .
and the human wa suppos to respond by send back the dot product of a with the password .
and thi is repeat until the comput is convinc that the human probabl know the password .
and recal that ev , our eavesdropp listen in on thi commun .
in so do , she learn a bunch of pair of vector a1 , and the correspond dot product b1 , and so on , up to vector am , and the correspond dot product bm .
that mean that ev can calcul the right respons to ani challeng that li in the span of vector a1 through am .
suppos the challeng a is a linear combin of these vector a1 through am , then the right respons is the correspond linear combin of those bit , b1 through bm .
now it's a properti of random vector over gf2 that the rank of the list a1 through am is probabl not much less than the number of vector , m .
let's try thi out with some random <num> vector over gf2 .
now , we can build some vector .
now i'll defin a list consist of n hundr vector .
we want to comput the rank of thi list .
so we'll import the rank procedur from the modul independ , and comput the rank of l .
we expect the rank of l to be about ten , mayb a littl smaller , but veri like ten , and inde .
now , let's try the same thing with a slightli longer list , mayb <num> vector .
we still expect the rank to be <num> , and inde .
try a longer list .
and the rank now should be <num> .
onli when we get veri close to <num> is there a signific probabl that the rank would be even slightli less .
all right , so it's a littl smaller .
let's , let's take a few more vector .
and we got up to <num> .
so onc m is up to n or greater , it's probabl the case that the span of a1 through am includ all of gf2 to the n .
so ev can respond to ani challeng at that point .
in fact , note that the password x hat is a solut to the matrix vector equat , a time x equal b , where a is the matrix whose row ar those vector a1 through am .
and b is the vector whose entri ar , ar the bit , the dot product .
now the solut set of thi matrix vector equat is x hat plu the null space of a , but onc rank of a reach n , the column of a ar linearli independ , so the null space is the trivial vector space .
and that show that the onli solut to thi equat is the password x hat .
so ev , us the solver , can comput the password .
you've seen the idea that you can add two vector .
now , we'll see what it mean to add two vector space .
thi is call the direct sum .
so , let u and v be two vector space .
and suppos that thei share onli the <num> vector .
we defin the direct sum of u and v to be the set , littl u plu littl v , where littl u belong to big u , and littl v belong to big v , and it's written like thi u plu v .
that is , u plu v is the set of all sum of a vector in big u plu a vector in big v .
in python , you could write a list like thi .
so , here's an exampl .
let's start with vector over gf <num> .
we'll let big u be the span of these two vector .
and let big v be the span of thi on vector .
now , note that everi nonzero vector in big u ha a on in the first or the second posit , or both .
and everi nonzero vector in big v ha a on in the third posit .
there ar no vector in common other than the <num> vector .
so we can form the direct sum .
and here's the direct sum .
take the set of all vector obtain by take on vector from big u and on vector from big v .
and carri out these addit , thi is the set .
now , let's do an exampl of vector over r .
defin big u to be the vector space , the span of these two vector , and defin big v to be the null space of thi matrix .
well , the vector <num> , <num> , <num> , <num> , is in big u .
it can be written as a linear combin of these two vector , in particular it's thi on minu thi on .
that same vector is also in big v , becaus if you multipli the matrix by that vector , you get the <num> vector , which show that thi vector belong to the null space of the matrix .
there's a nonzero vector in both big u and big v .
therefor , we're not allow to form the direct sum of u and v .
let's do anoth exampl of direct sum of vector over the real .
we'll defin big u to be the span of thi set consist onli of thi vector .
you rememb the span of a set consist of on vector is the line through the origin and the point repres by the vector .
similarli , let big v be the span of a set consist of thi vector .
so , thi is also a line .
now , the onli intersect of these two line is at the origin .
that is , big u and big v share onli the <num> vector .
so , we can form the direct sum .
and what is the direct sum ?
it's the set of vector , littl u plu littl v , where littl u is in big u , and littl v is in big v .
so , that's just span of the set consist of these two vector .
and it's the plane that contain those two line .
now , let's us our knowledg of gener , basi , and dimens , to better understand direct sum .
so , it's easi to show that the direct sum of u and v is a vector space .
you just us the properti of vector space .
somewhat more interest is to show that the union of a set vector , a set of gener of big u and a set of gener of big v is a set of gener for the direct sum u plu v .
so , suppos u1 through ar gener for big u , and v1 through vn ar gener for big v .
well , everi vector in big u can be written as a linear combin of the vector u1 through becaus thei're gener .
similarli , everi vector in big v can be written as a linear combin of v1 through vn becaus thei're gener .
so , everi vector in u plu v can be written as a vector in u plu a vector in v .
but what we've written is , a linear combin of the vector u1 through um togeth with v1 through vn .
so , that show that those vector span the direct sum u plu v .
now , we're go to prove that the union of a basi for big u and a basi for big v is a basi for the direct sum u plu v .
well , a basi is a set of gener .
so we alreadi know from the previou lemma that the union of a basi for big u and a basi for a big b is a set of gener for u plu v .
so , what remain to show , to be shown is that the union is linearli independ .
all right .
so , let u1 through be a basi for u .
let v1 through vn be a basi for v .
and we need to show that the union is a linearli independ .
well , suppos that you can write the <num> vector , as a linear combin of all these vector .
by subtract these vector from both side , we get thi equat .
note that the left hand side is a vector in big u , becaus it's a linear combin of the basi vector , for big u .
and the right hand side is a vector in big v becaus it's a linear combin of the basi vector for big v .
so , we've found a vector in big u that's equal to a vector in big v .
well , for the direct sum to even be defin it need to be the case that big u and big v share onli the <num> vector .
so , we've shown that thi must be the <num> vector and thi must be the <num> vector .
that is <num> is equal to thi linear combin .
and <num> is equal to thi linear combin .
but u1 through form a basi .
so , the onli wai to get the <num> vector as a linear combin is with a trivial linear combin .
that is alpha <num> through alpha m have to all be <num> .
and similarli , v1 through vn form a basi .
thei're linearli independ .
and so , the onli wai to get the <num> vector .
by take a linear combin , is if the linear combin is trivial , that is if the coeffici ar all <num> .
so , that show that all the coeffici here must be <num> .
if the onli wai to get <num> is a linear combin of u1 through togeth with v1 through vn , is with a trivial linear combin .
and that show that thi whole set is linearli independ , and therefor , form a basi for the direct sum .
so , we've shown that the union of a basi for big u and a basi for big v is a basi for the direct sum .
an immedi corollari of thi lemma is the dimens of u plu the dimens of v equal the dimens of the direct sum of u and v .
the proof is that a basi for u togeth with a basi for v form a basi for u plu v .
if the direct sum of u and v is the space w .
we sai u and v ar complimentari sub space of w .
for exampl , suppos big u is a plane in r3 .
so , in that case , ani line through the origin , that doe not lie complet within thi plane is a complimentari sub space .
here's an exampl and here's anoth exampl .
thi show that there's potenti more than on complimentari subspac , but let's show that there alwai exist at least on .
we'll prove that for ani , ani finit dimension vector space big w , and ani subspac , big u , there's anoth sub space big v , such that u and v ar complimentari sub space .
we start with a basi for big u .
let sai u1 through uk form a basi for big u .
now , by the super set lemma .
we can extend that basi to be a basi for big w by ad some vector , let's sai v1 through vr .
now , let's defin big v to be the span of these extra vector v1 through vr .
we want to show that v is a complementari subspac .
that is that the direct sum of u and v is w .
there ar two thing to show .
on , we have to show that u and v share onli the <num> vector .
second , we have to show that the set of vector obtain by take a vector in u and ad it to a vector in v is exactli the vector space w .
let's do the second on first .
ani vector in w can be written as a linear combin of it basi vector .
here we've written an arbitrari vector , littl w in big w as a linear combin of the basi vector .
notic that thi first part of the linear combin is a linear combin of the basi vector of big u .
and the second part of linear combin is a linear combin of the vector span big v .
thi show that thi arbitrari vector littl w in big w can be written as the sum of a vector in big u and a vector in big v .
now , it remain to show that u and v share onli the <num> vector .
suppos some vector v li in the span of u1 through uk , that is it's in u , and also li in the span of v1 through vr , that is , it's in v .
so , we write v in , as a linear combin , of each of those vector .
that show that these two linear combin ar equal , and move these vector to the other side , that show that you can write the <num> vector as thi linear combin .
but becaus these vector , u1 through uk , togeth with v1 through vr , form a basi for w , thei're linearli independ .
and so , becaus you can write the <num> vector as thi linear combin , it must be that the coeffici ar all <num> .
so , that show that thi vector v must be the <num> vector .
so , we've shown that the onli vector in both u and v is the <num> vector , so you can form the direct sum of u and v .
and that complet the proof of the proposit .
let's see how we can us argument base on dimens to tell whether a linear function , f , is invert .
we know a function is invert if it's on to on and onto .
a linear function is on to on .
if it kernel is trivial , that is , if it kernel ha dimens zero .
and now , what about onto ?
well , a function is onto if it imag equal it co domain .
we call that the imag of a function f is the set of all vector f of v , where v is in the domain .
long back we learn that the imag of a linear function is a vector space , a subspac of the co domain .
now , how can we tell if the imag of f equal to co domain ?
we'll us someth i call the dimens lemma .
suppos big u is a subspac , of big w .
then the dimens of big u , is no more than the dimens of w and if the dimens of u , equal the dimens of w , it must be u equal w .
let's see the proof .
we start with the basi for big u , u1 through uk .
by the superset basi lemma , we can take that basi and extend it to get a basi for w by ad a few more vector .
so there's a basi b for w that includ u1 through uk .
the basi vector for big u .
well that show that k , the number of vector in the basi for u is no more than the cardin of b .
and in fact , if k equal the cardin of b , then we must not have ad ani vector to get b .
so the basi u on through u k of u is also a basi of w .
and therefor u ha the equal w .
so that prove the dimens lemma .
now let see how we can us it .
we'll appli thi second properti , properti d2 .
with big u be the imag of f .
rememb , we want a criterion for when the imag of f equal the co domain w .
properti d2 show that that u equal w if the dimens of u equal the dimens of w .
that is if the dimens of the imag of f equal the dimens of w .
so we can conclud that f is invert if and onli if the kernel ha dimens zero and the dimens of the imag equal the dimens of the co domain .
now , how doe that relat to the dimens of the domain ?
when my conjectur that for a function to be invert , the dimens of it domain should match the dimens of it co domain .
thi correspond to the intuit that the vector in the domain can be made to correspond with the vector in the co domain .
we'll eventu prove thi conjectur but we're go to take a littl detour .
we're go to start with a linear function and extract from it and invert function .
so here's a pictur of a function whose domain is v and whose co domain is w .
what we're go to do is extract an invert function from thi .
how doe thi function fail to be invert ?
well , on thing we note is that it's not onto .
there ar element of the co domain that ar not the imag of ani element of the domain .
so let's get rid of those element .
we'll set the co domain of the function that we're extract to be just the element of the co domain of the origin function that ar imag of thing in the domain .
now , we can make it on to on by choos for each element in thi new co domain just on element that map to it .
and we throw awai all the other on .
that's the intuit for extract an invert function .
so let's go into thi in more detail .
the first step , start with a linear function f whose domain is v and whose co domain is w , the first step is to choos the smaller co domain , which we'll call w .
the second step is choos a smaller domain , which we'll call v .
and then we'll defin the function f with domain v and co domain w .
we us the same rule to defin f .
so f differ onli in that it's domain is smaller , and it's co domain is smaller .
we end up choos a basi for v and for w .
all right , how do we choos w ?
as i said befor , we're just go to let w be the imag of the function f .
that is the set of all element in the co domain of the origin function that ar the imag of element in the domain .
and let's let w1 through wr be a basi for w , our new co domain .
now we'll choos the domain .
let v on through v r be pre imag of w on through w r .
that mean we choos v1 thru vr to be vector such that f of v1 equal w1 and so on up to f of vr equal r .
we defin the new domain , v , to be the span of vector v1 thru vr .
we're go to show that the result function f , whose domain is f v and whose co domain is w , will show that it's onto and that it's on to on , name that it kernel is trivial .
and will also show that v1 through vr , the pre imag form a basi for the new domain v .
first let's look at onto .
let w be ani vector in our new domain w .
well , becaus w1 through wr form a basi for w , there exist scalar , alpha <num> through alpha r , such that vector littl w can be written as a linear combin with those scalar as coeffici .
now becaus f is linear , when we appli f to the correspond linear combin of v1 through vr we get that linear combin of w1 through wr .
so that show that thi vector w we start with is the imag of someth in the new co domain .
name , the linear combin of v1 through vr given here .
now let's show <num> to <num> .
by the on to on lemma , all we need to do is show that the kernel is trivial .
that is , that is consist onli of the <num> vector .
well , suppos littl v is in big v and the imag of littl v is the <num> vector .
becaus v is the span of element v1 through vr .
there must be coeffici alpha on through alpha r , such that we can express littl v in term of v1 through vr .
appli f to both side of thi equat .
on the left side , f of v equal the zero vector , so we get thi .
let's appli f to the other side .
by appli linear , as we saw befor , we get thi linear combin .
now , w1 through wr form a basi .
for w .
and therefor thei ar linearli independ .
we've gotten zero as a linear combin of those vector .
therefor the coeffici must all be zero .
and that show that , in fact , the vector littl v which is a , thi correspond linear combin of v1 through vr is the zero vector .
all these co effici ar zero .
that complet the proof that that the function f is on two and on to on , and therefor it's invert .
and here's the promis bonu .
we want to show that v1 through vr form a basi for the new domain big v .
well we defin big v to be the span of v1 through vr .
so in order to show that v1 through vr form a basi , all we have to do show is that thei're linearli independ .
well suppos you can get the zero vector as some linear combin of v on through v r .
on the left hand side appli a linear function to the zero vector alwai give you a zero vector .
on the right hand side as we saw befor appli f to thi linear combin of v on through v r .
give you the correspond linear combin of w1 through wr .
now , w1 through wr ar linearli independ , so it must be that these coeffici ar zero .
and , that show that , the onli wai to get zero as a linear combin of v1 through vr , is with the trivial linear combin where all the coeffici ar <num> .
we've shown how to extract an invert linear function from the linear function f .
let's see an exampl of thi construct .
let a be thi matrix and let's defin the function f from r3 to r3 by the rule f of x equal a time x .
now we defin the new co domain w to be the imag of the function f .
that is , the column space of the matrix a , which is the span of it column .
now on basi for w consist of w1 and w2 .
next we find pre imag of these vector .
sai , v1 and v2 .
these ar pre imag becaus a time v1 equal w1and a time v2 equal w2 .
next , we defin the , the co domain to be the span of those two vector .
then the function f , from big v to the imag of f , w , is onto and on to on , and therefor invert .
now , we're go to show the origin function ha the follow properti .
that the origin domain big v is the direct sum of the kernel of f with thi smaller domain , big v .
so , we have to prove two thing for the direct sum to even be defin , we have to show that the kernel of f and big v share onli the <num> vector .
and onc we've done that , the direct sum is defin to show that these two thing ar equal .
we have to show that everi vector in the origin domain big v , can be written as a sum of a vector in the , in the kernel of f .
and a vector in v .
so we alreadi show that the kernel of f is trivial .
thi show that the onli vector in ker f that's also in v is the zero vector .
so we've prove the first thing .
so now let's prove the second thing .
let v be ani vector in the origin domain big v .
let w be imag under f of that vector v .
now sinc f is onto it domain v contain some vector v such that f of v equal w .
so we have two vector , v and v .
f of v equal f of v .
so f of v minu f of v is the zero vector .
and then us linear f of v minu v is the <num> vector .
so that show that v minu v , which we'll name u , is in the kernel of f .
chang thi around a littl bit , we can write v as the sum of u plu v .
that is we've written v the arbitrarili chosen vector in big v as the sum of a vector u which is in the kernel of f and a vector v which is in big v , the new domain .
so we've prove the second thing as well .
so , thi is what we've prove , for ani linear function .
here's an exampl .
let a be thi matrix , we defin the function f , from r <num> to r <num> by multipl by thi matrix .
v1 and v2 ar shown .
and v is the span of those two .
the kernel of f is the span of thi singleton set .
it follow , therefor , that the origin domain , big v is the direct sum of the kernel , the span of thi singleton set , with the span of v1 and v2 .
by the direct sum dimens corollari , the dimens of the origin domain equal the dimens of the kernel of f plu the dimens f plu the addit of the new dimens of the new domain , v .
now , sinc v1 through vr form a basi for v , we know that dimens of big v equal r , which is also the dimens of the imag of f .
so , what we've show is , for ani linear function , the dimens of the kernel plu the dimens of the imag equal the dimens of the domain .
we call thi kernal imag theorem and it a veri signific result in linear algebra and veri us .
let's see how we can us thi import theorem .
we'll revisit the question of when a linear function is invert .
we'll prove the follow theorem .
let f be a linear function from big v to big w .
then , f is invert if , and onli if , it kernel is equal to <num> , and the dimens of the domain equal the dimens of the co domain .
i like to interpret that condit as sai , the domain and the co domain ar basic the same size so that thei can be match up .
here's the proof .
well , we saw befor that a linear function f is on to on if the dimens of it's kernel is <num> and is onto , if the dimens of it imag equal the dimens of it co domain .
so , a function that f is invert if both condit hold .
that is , if the dimens of the kernel is <num> , and the dimens of the imag equal the dimens of the co domain .
but now , we have an addit tool , the kernel imag theorem , which tell us that the dimens of the kernel of f plu the dimens of the imag of f equal the dimens of the domain .
so , us that , the dimens of the kernel equal <num> and the dimens of the imag equal the dimens of the co domain , if and onli if the dimens of the kernel equal <num> and the dimens of the domain equal the dimens of the co domain .
and that complet the proof of the linear function invert theorem .
now , we'll prove an analogu of the kernel imag theorem specif for matric .
appli the kernel imag theorem to the function f of x equal a time x .
then , the kernel of f is just the null space of the matrix a , and the dimens of the imag of f is the dimens of the column space of a , which is just the rank of a .
now , we defin the nulliti of a matrix to be the dimens of the null space of a .
then , the rank nulliti theorem state that for ani n column matrix a , the nulliti of a plu the rank of a equal n .
thi is a direct translat of the kernel imag theorem into the terminolog of matric .
with what we now know , let's return to the checksum problem .
recal , we defin a checksum function that take n vector over gf <num> and map them to <num> vector over gf <num> .
the function is defin in thi wai us dot product with <num> vector , a1 through a64 .
we had an origin file we repres by an n vector p and the transmiss error repres by a vector e .
so , the corrupt file is p plu e and we were interest in find out the probabl that the corrupt file had the same checksum as the origin file .
we saw that if the the air wa chosen accord to the uniform distribut , the probabl that the corrupt file ha the same , same checksum as the origin file wa <num> to the dimens of v over <num> to the n where v is the null space of the matrix whose row ar these vector , a1 through a64 .
well , it's easi to choos a1 through a64 so that the rank of thi matrix a is <num> .
in fact just choos random vector will probabl work .
now , the rank nulliti theorem tell us the rank of a plu the nulliti of a equal n .
now the rank of a we said wa <num> .
the nulliti of a is the dimens of thi vector space v , the null space of the matrix .
so , that's equal to n , and that show that the dimens of v is n minu <num> .
plug that into our formula , you get that the probabl that the corrupt file ha the same checksum as the origin file is <num> to the n minu <num> divid by <num> to the n .
which is <num> over <num> to the <num> .
a tini , tini number .
so , there's a veri tini chanc that a random chang will go undetect by the checksum function .
now , let's us the rank nulliti theorem to help understand when a matrix is invert .
let a be an r by c matrix .
then a is invert if and onli if the cardin of r equal the cardin of c and the column of a ar linearli independ .
that is a ha to be a squar matrix .
here's the proof .
defin the function f , by f of x equal a time x .
then , a is an invert matrix , if and onli if , f is an invert function .
the function f is invert , we know , if the dimens of it kernel is <num> and the dimens of it domain equal the dimens of it co domain .
that is , if the nulliti of the matrix a is <num> , and the number of column equal the number of row .
well , the nulliti of a matrix a is <num> , space of a is <num> , which is true if , and onli if , the null space of a consist just of the <num> vector .
that is , if the onli vector x , such that ax is the <num> vector , is the <num> vector , itself .
and that's true if , and onli if the column of a ar linearli independ by the linear combin definit of matrix vector multipl .
and that complet the proof .
so , for exampl , thi matrix cannot be invert becaus it not even squar .
thi matrix is squar and it , and it column ar linearli independ .
so , it is an invert matrix .
and here is a matrix that is squar , but it column ar not linearli independ .
you can get the third column by ad the first two .
so , it's not invert .
now we can show that the transpos of an invert matrix is itself an invert matrix .
here's the proof .
suppos a's an invert matrix .
we've written it in term of it column .
the matrix is squar , and the column ar linearli independ .
let n be the number of column .
then , the rank of a equal n .
and becaus a is squar , it also ha n row .
here thei ar .
and by the rank theorem , it row ar also linearli independ .
now , the column of the transpos of a ar the row of a .
so , thei're linearli independ as well .
and of cours , the matrix is squar , it column ar linearli independ .
so , we can conclud that it's invert .
let's see what els we can learn about matrix invert .
earlier , we prove that if a ha an invers , then the product of a with it invers is an ident matrix .
and we might be tempt to conjectur the the convers , that is , if b time a is an ident matrix , then a and b must be invers .
well , that doesn't , that doesn't turn out to be true .
but if we add an addit condit , it is true .
and that condit is that the matric have to be squar .
so , suppos a and b ar squar matric , such that b time a is an ident matrix .
then , a and b ar invers of each other .
to show that a is invert , sinc we know it's alreadi , we alreadi know it squar , all we have to do is show that it column ar linearli independ .
well , to show that the column of a ar linearli independ , let u be ani vector such that a time u equal <num> .
that is , a time u is a linear combin of a column of a .
and we need to show that the coeffici , the entri of u , have to therefor all be <num> .
well , us thi equat , multipli thi equat by b on both side , give us b time a time u equal b time the <num> vector , which , of cours , is the <num> vector .
on the other hand , thi quantiti is equal by associ to thi quantiti .
now , b time a is the ident matrix .
so , b time a time the vector u is the ident matrix time u , which is u itself .
well , that show that u must be equal to the <num> vector .
that show that for ani linear combin of the column of a that equal <num> , the coeffici of that linear combin must be <num> .
and that show the column of a ar linearli independ .
so , we've been abl to show then , that a ha some invers , it's written a to the power of minu <num> .
now , we have to show that b is that invers .
well , we know a time a invers is an ident matrix .
we know that b time a is the ident matrix .
let's multipli that on the right by a invers .
we get b time a time a invers equal the ident matrix time a invers .
we can simplifi the quantiti on the right , the ident matrix time a invers is just a invers .
we can us associ on the left .
and now , we have a time a invers , which we know is the ident matrix .
and b time the ident matrix is b .
so , we've shown that b is equal to a invers , and that complet the proof .
long back , we saw that there were two import wai to repres a vector space , as the solut set of a homogen linear system and as the span of some vector .
equival , put it in term of matric , you can repres a vector space as the null space of a matrix or as the row space of some other matrix .
we've seen that each represent ha it's us .
so it's import to ask if we've specifi a line through the origin in our three by give a coupl of equat .
how can we find a vector that gener the line ?
if we have specifi a plane through the origin as the set of linear combin of a coupl of vector .
how can we find the equat for the plane ?
the same question can be ask more gener about affin space .
how can we go from the represent of an affin space as the solut set of a linear system to the it represent as the affin hull of some vector .
or from it represent as the affin hull of some vector to it represent as the solut set of a linear system .
if we can do convers in a vector space case , the homogen case , we can do convers in the affin space case , the inhomogen case .
as we've seen befor , we can translat inhomogen problem into homogen problem , solv them , and translat the solut back .
i'll illustr on such convers .
from the represent of an affin space as the solut set of a linear system to it represent as the affin hull of some vector .
we start with a linear system , ax equal b .
let's assum thi linear system ha at least on solut .
our goal is to find vector whose affin hull is the solut set of the linear system .
i'll illustr the process with thi exampl linear system .
first , find on solut u to the linear system .
here's our solut for thi exampl system .
i haven't told you how we can find such a solut .
we'll describ a coupl of method in the come week .
next , consid the correspond homogen system .
thi is the system obtain by just set these right hand side to <num> .
we know that the solut set of the homogen linear system is just the null space of thi matrix a and is a vector space , big v .
suppos we manag to find gener , b1 through bk for big v .
in our exampl system , the null space of the matrix a is gener by the set consist of a singl vector , b1 .
we can then infer that the solut set of the origin linear system is the affin hull of the vector u , b1 plu u , b2 plu u , and so on , up to bk plu u .
in our exampl , the solut set is the affin hull of u and b1 plu u .
i'll go through that exampl again .
on solut to thi matrix vector equat is thi .
now , the null space of thi matrix is the span of the set consist just of the vector b1 .
so in thi plot , the line is the null space of the matrix , and you can see it's gener by thi vector b1 .
the solut set to the origin system is obtain by translat thi line by ad the vector u to each of the vector make up the line .
that is the solut set is u plu the span of the set consist of b1 .
that's just the line through the two vector u and u plu b1 .
so it can also be written as the affin hull of u and u plu b1 .
so let's return to the two represent of vector space .
on represent is as the solut set to the homogen linear system , a1 dot x equal <num> through am dot x equal <num> .
or equival as the null space of a matrix whose row run a1 through am .
the second represent is as span of vector b1 through bk or equival as the row space of the matrix whose row ar b1 through bk .
how do we convert between on represent and anoth ?
oh , there ar two , two convers problem .
on , from left to right , you , take as input the homogen linear system and output gener for the solut set .
the other , from right to left , take the gener and produc a homogen linear system whose solut set equal the span of those gener .
let's focu on the first convers problem , find gener for the solut set of a homogen linear system given by a vector a1 through am .
the solut set of thi homogen linear system is the set of vector u , such that a1 dot u equal <num> , and so on up to am dot u equal <num> .
we can write the homogen linear system as a matrix vector equat where the right hand side ar all <num> .
the matrix a ha as it row the vector a1 through am .
so , find gener for the solut set is equival to find gener for the null space of a matrix whose row ar a1 through am .
suppos we had an algorithm for thi problem .
let's call it algorithm x .
the input to algorithm x is the row of a matrix a .
and the output is the set of gener for the null space of that matrix .
in fact , later in the cours , we'll see sever algorithm that can plai that role .
now , if u is a vector in the null space , that is if u ha a zero dot product with everi row , then u also ha a zero dot product with everi linear combin of the row .
thi motiv a new concept , the annihil of a vector space .
for a vector space big v , the annihil of big v is the set of vector u , such that u ha a zero dot product with everi vector in big v .
the annihil of big v is written as big v with an o as a superscript .
for exampl , the annihil of a , the span of vector a1 through am is the set of vector have zero dot product with everi linear combin of a1 through am .
which is just the set of vector have zero dot product with a1 through am .
which is the solut set of the homogen linear system , a1 dot x equal <num> through am dot x equal <num> .
which is , the null space of the matrix with row a1 through am .
so , we can interpret our mysteri algorithm x as an algorithm that , given gener for a vector space big v , output gener for the annihil of big v .
let's see some concret exampl of the annihil .
first , an exampl over the real number .
let big v be the span of these two vector .
then , i claim that the annihil of big v is the span of the set consist of just <num> , <num> , minu <num> .
first , note that <num> , <num> , minu <num> ha a zero dot product , which e , each of these two vector .
therefor , <num> , <num> , minu <num> ha a zero dot product with everi vector in the span of those two vector .
also , ani scalar multipl of <num> , <num> , minu <num> ha a zero dot product with everi such vector .
we've shown that everi scalar multipl of <num> , <num> , minu <num> li in the annihil of big v .
but , perhap the annihil of big v contain other vector than those in the span of <num> , <num> , minu <num> , no , everi vector with a zero dot product with all of big v , must be a scalar multipl of <num> , <num> , minu <num> .
so , that tell us that the annihil is exactli the span of <num> , <num> , minu <num> .
now , an exampl over gf <num> .
let big v be the span of these two vector .
then , i claim the annihil of big v is the span of the set consist just of the vector <num> , <num> , <num> .
note that over gf <num> , <num> , <num> , <num> ha a zero dot product with each of these two vector , so it ha a zero dot product with everi vector in the span of these two vector .
now , what other vector have a zero dot product with all the gener of big v .
well , the zero vector ha a zero dot product with those vector , but that's it .
those ar the onli two vector , and that show that thi is realli the annihil of big v .
observ someth about these two exampl .
in the first case , we were work with vector with three entri and the dimens of big v plu the dimens of big v equal <num> .
in the second exampl as well , we were work with vector with three entri , and again , the dimens of big v , plu the dimens of the annihil of big v , equal <num> .
here's on more exampl , us vector with four entri .
big v is the span of these two vector and the annihil of big v is the span of these two vector .
in thi case , the dimens of big v plu the dimens of the annihil of big v equal <num> .
in gener , if we have vector with n entri , the dimens of the vector space plu the dimens of the annihil of the vector space equal n .
the proof is simpl given what we alreadi know .
let a1 through am be gener for big v , and let a be the matrix whose row ar a1 through am .
then , the annihil of big v is just the null space of the matrix a .
the rank nulliti theorem state that the rank of a plu the nulliti of a equal n .
well , the rank of a is the dimens of big v , and the nulliti of a is the dimens of the annihil of big v .
so the theorem is true .
now that we know a littl about the annihil , let's return to think about convert between represent of a vector space .
we origin said , that our algorithm x take as input the row of a matrix a , and output gener for the null space of a .
but , we can equal , well , interpret algorithm x as an algorithm that take as input gener for a vector space big v and output gener for the annihil of big v .
as we've said befor , the convers problem , in which we go from a homogen linear system to gener for it solut set , is solv by thi algorithm x .
but , what about the other convers problem ?
i've interpret the left to right convers as give gener for the vector space big v , output gener for their annihil of big v .
accordingli , i'm go to interpret the revers convers problem as given gener for the annihil of big v come up with gener for big v itself .
mayb we could hope for a mysteri algorithm y to solv thi convers problem .
well , crazi idea but what would happen if we appli algorithm x to the gener for the annihil of big v ?
well , we know what would happen .
you feed in the gener for the annihil of big v to algorithm x , and it'll find you gener for the annihil of the annihil of big v .
what good will that do ?
it turn out , thi is exactli what we want .
sinc , as we will show , the annihil of the annihil of big v equal big v itself .
thi tell us that when we ar given gener for the annihil of a vector space big v , and we want to get back gener of big v itself , we can just us algorithm x .
we still have to prove thi theorem .
so here we go .
theorem , the annihil of the annihil of big v is big v itself .
here's the proof .
let a1 through am be a basi for big v , and let b1 through bk be a basi for the annihil of big v .
sinc b1 is in the annihil , it ha a zero dot product with everi vector in big v .
so in particular , it ha a zero dot product with the basi vector a1 through am .
similarli , each vector bi of the basi of the annihil ha a zero dot product with a1 through am .
now , sinc a1 ha a zero dot product with b1 through bk , it follow that a1 ha a zero dot product with everi vector in the span of b1 through bk .
we choos b1 through bk to be a basi for the annihil of big v .
so we see that a1 ha a zero dot product with everi vector in the annihil of big v .
thi show that a1 is in the annihil of the annihil of big v .
similarli , a2 is the annihil of the annihil of big v , and so on .
therefor , everi vector in the span of a1 through am is in the annihil of the annihil of big v .
thu , the span of a1 through am is a subspac of the annihil of the annihil of big v , but that span is just big v itself .
so big v itself is a subspac of the annihil , of the annihil of big v .
we're almost there .
we've shown the big v is a subspac of the annihil of the annihil .
to show it is equal by the dimens lemma , we onli need to show that the dimens of big v equal the dimens of the annihil of the annihil .
suppos we ar work with vector have n entri .
let's appli the annihil dimens theorem to big v .
it tell us that the dimens of big v plu the dimens of the annihil big v equal n .
now let's appli the annihil dimens theorem to the annihil of big v .
it tell us that the dimens of the annihil of big v plu the dimens of the annihil of the annihil of big v equal n .
togeth , these equat show that the dimens of big v equal the dimens of the annihil of the annihil of big v .
and that complet the proof .
recal all or noth secret share .
the method to split a secret into two part so that both part ar requir to reconstruct the secret .
so , we could gener thi to split the secret among , sai four teach assist , ta .
so that onli togeth thei could all recov the secret , but ani three of them would know noth about the secret .
howev , it's riski to depend on all four ta come togeth at a schedul meet .
so , instead , we're go to search for a secret share scheme that's base on a threshold .
that is , that ani three ta could jointli recov the secret , but ani two ta have no idea what the secret is .
there ar scheme that us field other than gf <num> .
but let's see if we can do it us gf <num> .
so , here's our first attempt .
we select five <num> vector over gf <num> .
a0 , a1 , a2 , a3 , and a4 .
a0 will plai a special role .
and these vector have to be chosen to satisfi thi requir , that everi set of three of them ar linearli independ .
to share a on bit secret s , among the ta , here's what i do .
i randomli select a <num> vector u , such that , a0 time u equal that bit s .
now , i keep u secret , but i comput these other dot product .
beta <num> is a<num> time , dot with u .
beta <num> is a<num> dot with u .
beta <num> is a<num> dot with u .
and beta <num> is a<num> dot with u .
then , i give each of these bit to a ta .
beta <num> goe to ta <num> and so on .
i call those the ta share .
now , suppos three ta want to come togeth and reconstruct the secret .
can thei do it ?
suppos , for exampl , the ta <num> through <num> want to reconstruct the secret .
what do thei do ?
thei solv the matrix vector equat .
a time x equal b , where a is the matrix whose row ar the vector a1 , a2 , a3 .
and the right hand side , b is the vector whose entri ar the dot product , beta <num> , beta <num> and beta <num> .
now , thi matrix is squar and the row ar linearli independ by their requir .
so , the matrix is invert .
so , there's onli on solut to thi matrix vector equat , and it must be , therefor , thi vector , u , which we know is the solut .
onc the ta solv thi matrix vector equat us the solver , thei have u .
and so , thei can reconstruct the secret , s , by just take the dot product of a0 with the vector u .
so , we see that three ta can reconstruct the secret .
now , suppos two ta decid that thei want the secret .
thei're not suppos to be abl to construct the secret .
but thei've gone rogu .
so , ta <num> and <num> know the bit , beta <num> and beta <num> .
can thei us that to figur out the secret ?
we'll see that the answer is no .
the inform that thei have is consist with the secret bit be <num> and consist with the secret bit be <num> .
well , consid thi matrix a whose row ar a0 , a1 , and a2 .
thi matrix is invert by the requir .
so , each of these two matrix equat ha a solut .
exactli on solut in fact .
i put <num> as the first entri in the right hand side of the first equat and <num> as the first entri in the right hand side of the second equat .
the solut to the first equat is a vector v such that the dot product of a0 with v is <num> .
and the solut to the second equat is a vector v such that the dot product of a0 with v is <num> .
so the inform that the two ta have alon is consist with the secret bit be <num> , and with the secret bit be <num> .
so , thei don't learn the valu of the secret bit .
thi scheme seem great .
so , what goe wrong ?
thi scheme requir us to choos five <num> vector over gf <num> that satisfi thi requir .
and it turn out there ar no such five vector .
so , we have to do someth a littl bit more sophist .
instead , we're go to seek ten <num> vector over gf <num> .
a0 , b0 , a1 , b1 , and so on , and these form pair .
the first pair is a0 and b0 .
the second pair is a1 and b1 and so on .
and the requir that these vector must satisfi is thi , that for ani three pair , the correspond six vector ar linearli independ .
how would we us these vector in secret share ?
to share two secret bit , s and t .
i'll , i'll do the follow .
i'll , i'll choos a secret vector u , such that a0 time u is the secret bit s and b0 time u is the secret bit t .
i give ta <num> the two bit beta <num> , which is the dot product of a<num> with u , and gamma <num> , which is the dot product of b1 with u .
similarli , i give ta <num> to the two bit , beta <num> , which is the dot product of a<num> with u , and gamma <num> , which is the dot product of b2 with u , and so on .
so , each ta ha a pair of bit .
as that ta share .
suppos three ta want to get togeth and figur out the secret bit s and t .
thei set up a matrix vector equat that allow them to deriv those bit .
suppos , for exampl , that ta <num> , <num> , and <num> came togeth .
thei would solv thi equat .
thei would put their pair of vector in to form thi matrix , and put the bit that thei know in the right hand side .
becaus of the requir on these vector , these six vector ar linearli independ .
and therefor , thi matrix is invert , so that there's exactli on solut to thi matrix vector equat .
that wai thei can get the vector u , and from that , deriv the secret bit .
on the other hand , suppos ta <num> and <num> go rogu , and want to discov the secret on their own .
thei possess the bit , beta <num> , gamma <num> , beta <num> , and gamma <num> .
ar these bit consist with all the possibl secret ?
for exampl , ar thei consist with s be <num> and t be <num> ?
well , thei ar if there's a vector that solv thi equat .
where i've put <num> and <num> as the first entri of the right hand side .
now , sinc these vector ar linearli independ , there doe exist a solut .
exactli on solut .
similarli , no matter how you set these first two entri , there exist a solut .
so , that show , that the share , that the ta want to have , don't tell them anyth about the valu of the secret bit .
the secret remain safe .
so far , we've been us solv as a black box .
now we're go to start to find out what's go on insid that box .
gaussian elimin is name after gauss , but it actual wa discov at least <num> year ago , it's been written up in a chines text .
in europ it wa discov by isaac newton and michel roll in franc .
gauss call the method common elimin .
he came up with a a wai to us it to solv anoth problem that we'll get to later and came up with a , a notat that wa wide adopt .
what's it good for ?
well , it can find a basi for the span of given vector , which also will give us an algorithm for rank .
and , therefor , an algorithm for test linear independ .
can be us for solv a matrix equat , which we know is the same as express a vector as a linear combin of other vector , which is the same as solv a system of linear equat .
it can be us for find a basi for the null space of a matrix , which is the same as find a basi for the solut set of homogen linear system , which we know is relev to repres the solut set of an arbitrari linear system .
the method is base on the idea of echelon form .
here is an exampl of a matrix in echelon form .
now notic that the first nonzero entri in row <num> is in column <num> .
the first nonzero entri in row <num> is in column <num> .
the first nonzero entri in row <num> is in column <num> .
and the first nonzero entri in row <num> is in column <num> .
a matrix is in echelon form if it satisfi the follow condit for everi row if that row's first nonzero entri is in posit k , than in all of the previou row the first nonzero is to the left .
as a consequ , as you go through the row , the non zero form a sort of staircas descend down .
so , for exampl , here is the staircas for thi on .
here's the staircas for thi matrix .
notic that if a row is <num> , then all subsequ row also have to be <num> .
what good is it , have a matrix in echelon form ?
on thing is that if , that the nonzero row of the matrix form a basi for the row space of the matrix .
for exampl , in thi matrix , a basi for the row space is given by these first <num> row .
in particular , if everi row is non zero , as in these matric , then the row form a basi for the row space .
we know that the row gener the row space of the matrix .
that's the definit of row space .
so what we have to show is that the non zero vector ar linearli independ .
and to do that , we ll us the grow algorithm .
so , rememb the grow algorithm .
let is try it out on thi matrix .
ad the row in revers order , initi s is the empti set .
the algorithm consid ad the last row .
now , sinc a span of the empti set doesn't contain thi row , the grow algorithm will go ahead and add it .
next .
now s consist just of that row .
now everi vector in span of s ha zero in it first <num> entri , posit <num> , <num> , and <num> .
so span s doesn t contain thi second row .
so the algorithm goe ahead and add that .
now s consist of these <num> vector .
now still everi vector in span of s ha a <num> in posit <num> and <num> , so span of s so far doe not includ thi vector .
so , the grow algorithm goe ahead and add that .
now s consist of these <num> vector .
everi vector in span of s ha a <num> in posit <num> .
so span of s doesn't includ thi .
vector .
so the grow algorithm goe ahead and add that as well .
we know that at everi stage in the execut of the grow algorithm , the set s is linearli independ .
so we've shown that all the row of thi matrix ar linearli independ .
so i've illustr that if a matrix is in echelon form , it non zero row form a basi for it row space .
how can we us thi idea , when our matrix doesn't happen to be in echelon form ?
what we want to do , is transform it into a matrix , that is in echelon form , that ha no none , that ha no zero row and such that , the row space is the same as the row space of the origin matrix .
so , in thi , we'll repres our current matrix as a row list , rather than us the mat class .
so let's assum the variabl row list ha been initi with a list of vec , such as thi on .
our code will mutat thi variabl .
to handl vec with arbitrari domain d , we have to decid on order of the column .
so we'll us the sort order as shown here .
so the goal is to , transform a matrix into on in echelon form and our first approach will be , us sort .
so , the algorithm will first choos a row with a non zero in the first column , then choos a row with a non zero in the second column and so on and it'll accumul these row in a list new , row list .
in order to carri thi out , the algorithm ha to keep track of which row ar remain to be sort .
it us row left , to store the set of indic of row that haven't been process yet .
so the initi we've alreadi discuss .
here's the code for the algorithm proper .
the algorithm iter through the column , and in each iter , it find the set of row indic among those row still remain to be sort that have a non zero entri in the current column .
it select on of those row , in thi case the first in the list , add that to new row list and remov the index from the set row left , of row yet to be process .
let's see how thi algorithm oper on a matrix .
the algorithm iter through the column on by on .
first , it consid the first column , it find a row with a non zero in that column .
so , thi row and add that to new row list , goe to the second column , find a row with a non zero in that column and add that to new row list .
now , the algorithm run into troubl , when it get to the third column , it doesn't find ani row that have non zero in that column .
so row with non zero , will end up be empti and thi line will caus an error .
now what the algorithm should realli do , is just move on at thi point to the next column .
so sinc column three doesn't have ani non zero among the remain row , it move on to column four and it find find row , add that to new rowlist and final , goe to the next column and find thi row and add that to new rowlist .
so we should chang the code to handl thi case .
so we add a check , to make sure that there ar some row with non zero element , if not , the algorithm just move onto the next column , the algorithm's still not correct .
let's see how it work on thi matrix .
it'll produc thi matrix , which unfortun is not an eschelon form , we don't have thi nice staircas go down becaus it whoop , thi is non zero , so we're go to need to make a chang to the algorithm .
the algorithm is actual go to have to chang the vector .
let's consid the algorithm at the point where it's elimin these row .
it's dealt with the first , second and third column and it's readi to deal with the fourth column .
at thi point it ha to appli a transform , it ha to chang the row .
what it doe is , it subtract thi twice the second row , from the fourth row , get thi .
thi ha the effect of zero out thi element , so , here's the result .
and thi three is call the pivot element , that's what we us to zero out thi element .
the transform we perform , is equival to multipl by an elementari row addit matrix .
and such a matrix is invert , in fact , these matric ar invers of each other .
we'll show that , if m time a equal b , where m is an invert matrix , then the row space of a equal the row space of b .
that mean that thi chang to the row that the algorithm perform , doesn't chang the row space .
therefor , a basi for the row space of the chang matrix , is also a basi for the row space of the origin matrix .
we'll first prove thi lemma .
given matric n and a , the row space of n time a is a subset of the row space of a .
let v be ani vector in the row space of n time a .
that is , v is a linear combin of the row , of n time a .
well , we can write it like thi , v equal some vector time n time a .
by us associ , we can rewrit thi as u time the matrix n , all time a .
and now , thi is a vector time a matrix , so thi show that thi vector is a product of vector time the matrix a .
so by the linear combin rule of vector matrix multipl , thi is a linear combin of the row of a .
we've shown that , ani linear combin of the row of na can be written as a linear combin of the row of a and that complet the proof .
so we have thi lemma , now let's go back to the proposit .
if m is invert in the row space of m time a equal the row space of a .
to prove that , we prove two direct .
we prove that , the row space of m time a is a subset of the row space of a and vice versa .
first , let's show that the row space of m time a , is a subset of the row space of a .
well , that's a direct applic of the lemma .
to get the other direct , we defin the matrix b to be m time a .
now , m is invert so it ha an invers , m invers , multipli thi equat by m invers , we get thi , m invers time b equal a .
now and applic of the lemma show that the row space of m invers time b , is a subset of the row space of b .
well , thi is just a and thi is just m time a .
so , what we've realli shown is that the row space of a is a subset of the row space of m time a and that wa the other direct .
so that complet the proof of the proposit .
so , appli elementari row addit oper doesn't chang the row space .
let's incorpor thi new featur into our algorithm .
you notic i've ad thi line in which , we add suitabl multipl of the row indic by the pivot index to each of the row that ha a non zero in the current column .
so appli to thi matrix for exampl , after some iter of the algorithm , thi matrix turn into thi matrix .
now the algorithm subtract multipl of thi row , from the other two remain row .
so thi is the pivot element in thi case and here's the result .
we've zero out thi column , it also happen to have zero out these other element as well .
so here's the new code , the algorithm iter through all the row with a non zero in the current column , other than the on we select , as the pivot row and then subtract an appropri multipl of the pivot row from each of those row .
now , thi algorithm is mathemat correct , howev , we have to cope with the fact that , our comput comput not with real number but , with float point number .
let's sai we start with thi matrix , we want to comput a basi for the row space of the matrix .
on on iter of our algorithm will produc thi matrix and notic thi on minu <num> to the <num> .
what doe python do with an express like that ?
let's find out .
the result is just neg <num> to the <num> becaus of round therefor the matrix that realli result , is thi on , where we've replac <num> minu <num> to the <num> with just minu <num> to the <num> .
on addit step , the algorithm result in thi matrix , which lead us to think that the first two row of thi matrix form a basi for the row space of the origin matrix .
but in fact , the row space of the origin matrix ha dimens three .
so we've been mislead .
the problem is , gaussian elimin got the wrong answer due to round off .
now , all of our algorithm ar subject to such error , there is a wai to help gaussian elimin get the right answer .
accord to partial pivot , the algorithm should select among the row remain , whichev row ha the element of largest magnitud in the current column .
complet pivot mean that , the order of column can't be decid in advanc and the algorithm should search among all remain row and column to find the entri with largest magnitud .
and these ar a bit complic to implement , we won't studi them .
instead , we'll see how gaussian elimin is us when the matric ar over gf2 , in which case , we don't have ani round error to worri about .
let's see how the algorithm oper on a matrix over gf2 .
the algorithm start with column a , the algorithm select row on , as the pivot row , so , it put that row into new row list and now , sinc row two and three have non zero in column a , the algorithm us the pivot row to wipe out those non zero and here is the result .
now , column b , the algorithm select row three as the pivot row , add it to new row list , the other row have zero in column b , so , we don't have to do ani row addit oper .
let's move on to column c , the algorithm select row zero as the pivot row add it to new row list and then , there's onli on row remain that ha a non zero in column c .
so , the algorithm add the pivot row to row two to make that zero .
final , column d , the onli remain row is row two .
so , the algorithm select row two and add it to new row list and no other row oper ar requir , the algorithm is done and it's come up with a basi for the row space .
so far , we've seen how to us gaussian elimin to transform a matrix into on , in echelon form and we know that non zero row form a basi for the row space of the origin matrix , but there ar other thing we can do with gaussian elimin as well .
we can us it to solv linear system and you'll see , that can be us for exampl in light out .
we can also us it to find vector in the null space of a matrix and that can be us for exampl in integ factor .
the kei idea is to keep track of the transform the algorithm perform , in put the matrix into echelon form .
now we'll see how to us gaussian elimin to solv a system of equat .
the kei idea is to keep track of the transform perform in convert a matrix to echelon form .
the algorithm actual comput matric m and u , such that , m time a is u , where u is in echelon form , and m is an invert matrix .
let's see how we can us thi to solv a matrix vector equat , ax equal b .
first we comput m and u , such that m time a equal u .
next , we comput the matrix vector product m time b and us that as the right hand side for anoth matrix vector equat ux time mb .
let's see why thi give us the solut to the origin matrix vector equat .
well , suppos we us a solut to thi equat .
so , u time v equal , m time b .
now , m is an invert matrix .
here's it's invers .
multipli both side of thi equat by m invers .
now us associ to reorgan it .
and notic that m invers time m is the ident matrix .
and us the fact that m invers time u equal a .
thi show that a time v equal the ident matrix time b which is b .
but why is thi matrix factor equat ani easier then the origin on .
well , u wa , if u wa triangular , then we can solv us back substitut .
and it more gener u is an echelon form and we can us a similar algorithm .
now let's see how we can us gaussian elimin to find the null space of a matrix .
well in fact we're go to find , given a matrix a , we're go to find the set of vector u such that u time a , is the zero vector .
which is actual , the null space of a transpos .
but of cours you can us thi algorithm on the transpos of the matrix .
let's sai thi is the input matrix .
so , we find , matric m and u , such that , m time a equal u and u is in echelon form , m , and m is invert .
here's the solut to that now notic the last two row of u ar <num> vector .
now row <num> of u is attain by multipli row <num> of m by a .
and row <num> of u is obtain by multipli row <num> of m time a .
so , we've identifi two vector , u , such that u time a is the zero vector .
name , row <num> and <num> of m .
do these vector form a basi for thi space ?
well , the dimens of the row space of a is <num> .
we alreadi know that the non zero row of u form a basi for the row space of a .
sinc there ar three non zero row , that show that the dimens of the row space of a is <num> .
by the rank nulliti theorem , the dimens of the row space of a plu the dimens of the null space of a transpos equal the number of row , which is <num> .
so that show that the dimens of the null space of a transpos is <num> .
now sinc m is invert , all it row ar linearli independ .
therefor , in particular , row <num> and <num> of m ar linearli independ .
so thei span a space of dimens too .
sinc these vector ar in thi space .
and have the same dimens as thi space , thei ar a basi for that space .
now let's see what it mean to record the transform .
let's recal how gaussian elimin work .
you start with a matrix and you start perform these oper , these elementari row addit oper on the matrix to chang the matrix .
eventu the row of the matrix can be reorder to get a matrix in echelon .
we're go to keep track of those transform .
so we start with thi matrix .
and initi thi matrix is the same .
now at some point the algorithm perform an elementari row addit oper .
ad some multipl of on row to anoth .
we repres that by a matrix , matrix multipli where thi matrix is an elementari row addit oper .
sai the algorithm perform anoth elementari row addit oper .
we repres that by multipli by anoth matrix .
all the time thi right hand side matrix is be transform .
thi is the current state of the matrix after those transform have taken place .
so , now we do anoth transform .
howev , it's go to be too cumbersom to keep track of all these elementari row addit matric .
so , we'll see there's a shortcut .
let's do a concret exampl .
we start with thi matrix .
and on the right is the same matrix becaus we haven't carri out ani transform yet .
the first step of the algorithm , we perform an elementari row addit oper .
we subtract two time the second row from the third row .
and thi is the result .
next we do anoth elementari row addit oper , we subtract two and a half time the second row from the fourth row .
and thi is the result matrix .
now these two transform can be combin to make a singl transform just by multipli them togeth .
now we can continu .
we carri out anoth transform repres by thi matrix in which we add half the first row to the third row .
and thi is what we get .
we again reduc the number of matric here by combin them .
here's how we record the transform .
we maintain a matrix m which is initi the ident matrix and a matrix u which is origin the input matrix a .
and whatev transform you do to a to start to move it toward echelon form , you do the same transform to m .
so let's go through gaussian elimin .
we start with thi equat , here's the matrix m thi is initi ident .
here is the origin matrix that we ar go to transform and here is the matrix we ar go to put into echelon form .
we go through the column of thi matrix on by on .
let is start with column a .
for that , we select row <num> as the pivot row .
and we add it to row <num> and <num> in order to zero out those entri .
so here's what we get , the entri have been zero out and we're done with row on .
next we move on to column b .
for thi , we select as our pivot row row <num> .
we add it to no row becaus all the other entri on row b ar alreadi zero .
next we go to column c and we select as our pivot row , row zero .
we ad to row <num> to zero out that entri and we get thi matrix .
final we consid column d .
we select as the pivot row , row <num> .
and we don't have to add it to anyth becaus there aren't ani row left .
so we're done .
now i'll give you the code for carri out that process .
as befor , we initi rowlist to be the list of row of a and we initi m rowlist to be the list of row of the ident matrix .
then we carri out the iter .
here ar the differ from the previou code .
everi time we choos a pivot row , we append to new_m_rowlist the correspond row of m .
and then when we do an oper that add a multipl of some row to anoth row , we do the same oper on the matrix m , repres by m row list .
now we've , we've been append the pivot row to new_m_row list , so that take care of all the row of m in order that correspond to pivot row .
but at the end there's some other row that never get chosen as pivot row .
thei're the on that correspond to zero row in the echelon form that we creat .
so we have thi loop at the end to just add those remain row to new_m_rowlist .
that will ensur that new_m_rowlist time the origin matrix will give us the whole matrix in echelon form includ the zero vector .
and final at the end we form the procedur will form a matrix m from row list and return that .
we provid that code in the modul echelon .
so , with gaussian elimin , the black box ha start to becom less opaqu .
we're start to figur out all what's insid it .
in particular , both the modul independ and solver us gaussian elimin in deal with matric and vector over gf <num> .
so the procedur solv a , b comput thi matrix m , such that m time a is in echelon form and then us m to try to find a solut as we describ earlier .
the procedur rank defin in the modul independ convert a matrix to echelon form and then count up vector that ar non zero .
that tell you the rank of the matrix in echelon form and therefor also the rank of the origin matrix form by the vector in l .
we also saw the gaussian elimin can be us to find non zero vector .
in fact the basi for the null space of a matrix .
and you'll us that in an algorithm for integ factor .
now we'll see an applic of gaussian elimin with matric over gf2 , integ factor .
the prime factor theorem state that for everi integ n greater than or equal to <num> , there is a uniqu bag of prime number whose product is n .
so , for exampl , the integ <num> is the product of the integ <num> , <num> and <num> , these ar all prime .
the integ <num> is the product of <num> , <num> , <num> and <num> , and the integ <num> is the product of <num> .
all the element in the bag must be prime , so if the number is itself prime , the bag onli ha that on number in it .
factor integ is a famou , long stand problem .
gauss himself point out that the problem of distinguish prime number from composit number and of resolv the latter into their prime factor .
factor composit number into prime , into , into their prime factor is on of the most import problem .
here's anoth author on the same problem .
bill gate point out that , that it would be a breakthrough to develop an easi wai to factor larg prime number .
well , actual he got that slightli wrong , larg composit number .
what he wa speak of wa the role of , of factor in secur .
when you go to a websit , sai a bank , the browser will show you thi lock and the , the , the url ha the letter http , the s stand for secur .
it's base on someth call ssl which is thi secur socket layer .
which in turn is base on rsa , a crypto system , name after it inventor rivest shamir adelman .
now , rsa in turn depend on factor integ be difficult .
test whether a number is prime turn out to be the easi part .
so , here's the on line script , it doesn't get all number right but there ar a few except .
with a few more line you can get correct answer , even for these special number call carmichael number .
so , the hard part of factor is thi , given an integ n , find ani nontrivi divisor other , that is a divisor other than on and n itself .
if you could do that reliabl , then you can factor the integ all the wai down to prime number .
here's a veri simpl algorithm for factor an integ .
it tri all of the possibl div , divisor from <num> to n minu <num> , and test whether n is divis by each on of them .
the first divisor it find it return .
well , in fact , if d is a divisor of n , then so is n over d .
and the minimum of d , and n over d is less than or equal to the squar rout of n .
which show that the algorithm actual need onli search between <num> and the squar root of n .
so , here's the revis version i'm us thi procedur intsqrt , which i'll provid .
unfortun or fortun for rsa , thi algorithm is veri slow .
if you plugin an integ n that ha <num> , <num> , <num> digit , it go to take a long , long time to find a divis .
here's a tool that's us and more sophist factor algorithm .
greatest common divisor gcd , goe long back and it's veri fast , veri easi to write in python .
it find the greatest common divisor of two integ , that is the largest of all integ that divid both of the two input .
so , for exampl , the gcd of <num> and <num> is <num> and the gcd of these two long number is thi number .
you can run thi , it'll take veri littl time to comput thi .
here's an approach to try to factor a larg number n .
we try to find integ a and b such that a squar minu b squar equal the integ n .
and we can factor the left hand side as a minu b time a plu b equal n .
so , in thi case a minu b and a plu b ar evid divisor of n .
ideal , thei're nontrivi divisor well , how do we find a and b ?
well we , we choos some integ a that's slight more than squar root of n and we check if the squar root of a squar minu n is an integ .
and if so , we found b .
now , a minu b is a divisor of n and , and there's at least a good chanc that it's a non trivial divisor and if not , repeat with anoth valu for a .
here's an exampl , start with the integ <num> .
i know you can factor that , but let's see if thi , how thi method would factor it .
we try a equal <num> , a squar minu n is a perfect squar , it squar root is <num> .
so we let b equal <num> , and now a minu b is <num> , that is a divisor of n , so we've successfulli factor in us thi approach .
let's try anoth exampl , n equal <num> time <num> , we try a equal <num> .
look at a squar minu n , that's <num> .
okai well , that's not a perfect squar .
let's try a equal <num> , well then a squar minu n is <num> and that is a perfect squar .
so , we've succeed onc again .
howev , when n is veri larg , it take a long time to find an integ a that work in thi wai .
so , instead we ll show how linear algebra can help us synthes a good a .
we're go to chang our goal slightli .
we're go to try to find integ a and b such that a squar minu b squar is k time n for some integ k .
in that case , we factor the left hand side a minu b , time a plu b is k time n .
now , the prime factor of a minu b , togeth with the prime factor of a plu b , equal the set of prime factor of a togeth with the set of prime factor of n .
so , let's sai that the prime factor of n ar p and q .
well , if p and q ar both factor of a minu b , or ar both factor of a plu b .
then , comput the gcd of a minu b with n won't find a nontrivi divisor of n .
howev , here's an exampl .
let's sai , n is <num> time <num> and k is <num> time <num> time <num> time <num> .
well , if a minu b is <num> time <num> time <num> and a plu b is <num> time <num> time <num> that , that'll work out .
then , when you take the gcd of a minu b with n it's not go to find a non trivial divisor .
it's just go to give you n .
so , that didn't quit work , but if , if , if , if p sai , is a divisor of a minu b , and q is a divisor of a plu b , or vice versa .
then , in fact the gcd of a minu b with n will find a nontrivi divisor .
for exampl , let's sai a minu b is <num> time <num> time <num> , a plu b is <num> time <num> time <num> .
well , on of the factor , on of the prime factor of n , is in the factor of a minu b and on of them is in the factor , factor of a plu b .
so , gcd of a minu b with n , will find you the factor <num> .
well , how can we find integ a and b , such that a squar minu b squar is even an integ multipl of n .
well , here's how , here's the strategi .
start by find sai , the first thousand prime number .
now , choos a and comput a squar minu n .
and we see if a squar minu n can be factor us onli these prime number .
and if not , we throw it awai and we choos anoth a .
if it can be , we record a and the factor of a squar minu n .
rememb , the factor of a squar minu n in thi case , consist just of these first , just of a subset of these first thousand prime .
we repeat thi process about a thousand time .
we get a tabl like thi .
these ar the integ a where we succeed .
we took a squar minu n and found that it could be factor us these first few prime .
we tri <num> , <num> , we tri <num> but that didn't work so , we went to <num> , and so on .
so , for , for each of these valu of a , we have the factor of a squar minu n .
how do we find the integ b ?
we want to find a subset , sai a1 through ak of those valu of a .
such that a1 squar minu n time a2 squar minu n and so on , is itself a perfect squar .
so , in thi case we can combin the number a1 equal <num> , a2 equal <num> , and a3 equal <num> .
so , a1 squar minu n time a2 squar minu n time a3 squar minu n is well , we know the factor of a1 squar minu n , it's <num> time <num> time <num> .
we know the factor of a2 squar minu n .
that's <num> time <num> squar time <num> time <num> , and we know the factor of a3 squar minu n that's <num> time <num> time <num> time <num> .
we , we multipli all these prime togeth and thi is the number we get .
you notic anyth interest here ?
all the expon ar even , what that mean is that , thi number is a perfect squar .
here's the squar root .
all right , well how do we find , a subset of those a's that will work in thi wai ?
a subset of a's such as the correspond product of a squar minu n is a perfect squar .
we're go to us linear algebra .
we repres each factor as a vector over gf <num> .
so , and a factor that look like thi p1 to the a1 , p2 to the a2 , up to pk to the ak .
is repres by a vector in which p1 map to either <num> or <num> depend on whether a1 is even or odd .
p2 map to , either <num> or <num> depend on whether , the expon a2 , is even , or odd , and so on .
now , let a be the matrix , who's row ar these , vector over gf <num> .
what we want to do is find , a subset , of those factor whose product is a perfect squar .
and that correspond to a subset of the row of a , whose sum is the zero vector .
we need to find a non zero vector in the set of vector us such that u time a equal the zero vector .
thi is basic , thi is the null space of a transpos .
now , how can we guarante that that there is a non trivial vector in in thi space ?
we just make sure that the number of row is greater than the rank of the matrix .
sinc the number of column is the number of prime that we start with sai <num> , <num> .
all we have to do is get <num> , <num> and we're guarante that there'll be some non trivial vector in thi set .
so , we repres each factor by the gf <num> , by a gf <num> vector , where the valu depend on whether the expon in the factor ar even or odd .
so , the factor <num> , <num> , <num> , all the expon ar <num> , therefor odd .
so , we repres by the vector where <num> map to <num> , <num> map to <num> , <num> map to <num> and all the other prime map to <num> .
similarli , thi factor <num> to <num> time <num> time <num> is repres by the vector where <num> map to <num> , becaus the expon <num> is odd .
<num> map to <num> , becaus the expon , in thi case <num> is odd and <num> map to <num> becaus the expon of <num> is <num> which is odd .
so , now we have a bunch of gf2 vector .
we build a matrix a , whose row ar these gf <num> vector .
here ar some other fun thing to do with gaussian elimin over gf <num> .
we can solv light out puzzl , we can attack python's pseudo random number gener .
so , if you import the modul random , you can us it to gener random bit .
but what's the next <num> bit to be gener ?
you can actual us gaussian elimin , to predict those bit accur .
and here's anoth applic break the simpl authent scheme .
you'll recal that the simpl authent scheme work like thi .
the password is an n vector , x hat over gf <num> , known onli to the comput and the human .
the comput authent the human by send challeng that the human ha to repli to .
so , a comput send a random n vector a , and the human send back the dot product of a with the password xhat .
and thi is repeat until the comput is convinc that the human know the password .
thi scheme isn't so secur , if our eavesdropp ev listen in on the commun , she'll learn a bunch of challeng and the right respons to those challeng .
the password is a solut to a matrix vector equat , consist of the challeng and the respons .
and onc the rank of the matrix reach n , the number of bit in the password the solut is uniqu .
so , ev can us gaussian elimin to find the password .
how can we make thi veri simpl authent scheme more secur ?
we introduc mistak .
in each round , the human after receiv the challeng and comput the dot product with the password , roll a die .
if the die come up six , the human intention flip the bit befor send it back to the comput .
now , the comput know to expect some of the bit to be wrong , so the comput authent the human .
if the human get the right answer sai , <num> of the time .
now let's look at it from the perspect of ev .
even if she know that the human is introduc intent error , she doesn't know in which round the error ar be introduc .
so , ev can't just take the challeng and respons that she observ and plug them into gaussian elimin , becaus it will get the wrong answer .
in fact , we don't know of ani effici algorithm that will find the password , when the right hand side ar wrong .
so , thi scheme in which mistak ar intention introduc , could actual be a secur authent scheme .
we continu to look insid the formerli black box .
we studi gaussian elimin , which is us in the modul solver and independ when work over gf <num> .
and we'll next studi the method us in these same modul when work over the real number .
there's a burn hous locat at coordin <num> , <num> .
now fortun , there's a street that run close to the hous .
but is it close enough ?
the street goe through the origin and to the point <num> , <num> .
and the fire engin ha a hose <num> unit long .
so , we can navig the fire engin to the point on the road closest to the hous .
but , if we do that , will the distanc from the fire engin to the hous be close enough for the hose ?
well , there , there ar two question that we're look at .
what point along the street is closest to the hous , and how far is it ?
and to answer that , we first have to sai what we mean by closest .
the distanc between two point , p and b , is the length of the differ , p minu b .
we first have to defin the length of a vector .
instead of us the term length , we us the term norm .
now the norm of the vector is written with these doubl vertic bar .
a norm should satisfi certain properti .
the norm of a vector should be a non neg real number , that's part of what we mean by length .
the norm of a vector should be zero , if and onli if the vector is the zero vector .
and the norm should scale , that is , if you scale a vector by a , an amount alpha , then that should chang the vector itself by the absolut valu of alpha .
and final , norm should satisfi someth call the triangl inequ .
so , on wai to defin a norm for vector is to first defin s , an oper on vector call inner product .
which is written thi wai , the inner product of u with v .
the inner product itself ha to satisfi certain axiom and we're go to get to those soon .
on thing to note , though , is there is no wai to defin an inner product for the field gf <num> , so we're go to have to sai goodby to gf <num> .
now , for the real and complex number , we can defin an inner product .
in fact , there's some flexibl in how we defin the inner product and that flexibl is veri us in applic .
onc we've defin an inner product , we get a norm .
the norm of a vector is the squar root of the inner product of the vector with itself .
for simplic , we'll focu on the field of real number , and we us the most natur and conveni definit of inner product .
and that definit will lead to the norm , be what you think of as the length of of a vector .
that is , the geometr length of it arrow .
so , for vector over the reel we'll defin the inner product of u and v to be just the dot product of u and v .
the inner product ha sever properti .
it's linear in the first argument which mean the inner product of u plu v with w is the inner product of u with w plu the inner product of v with w .
it's symmetr , that is the inner product of u with v is the same as the inner product of v with u and it satisfi homogen .
which mean the inter product of alpha u with v equal alpha time the inter product of u with v .
and it's easi to prove these properti when we defin our inner product to just be dot product .
all right , so we've defin inner product to be dot product .
and we've defin the norm of a vector to be the squar root of the inner product of a vector with itself .
do we therebi get the norm properti ?
doe our norm behav like a distanc ?
let's write a vector v in term of it's entri , v1 through vn .
then , the norm of that vector v is just the squar root of the sum of the squar of the entri .
now , the sum of squar is a nonneg real number .
then , we take the squar root , we still get a non neg real number .
so in fact , the norm of v is a nonneg real number .
that's the first properti .
now , if ani entri of the vector v is nonzero , then thi sum of squar is bigger than zero .
so , the norm is non zero in that case .
that show that the norm satisfi the second properti .
i'll go through the proof of the third properti .
let's look at the norm squar of alpha time v .
that's the inner product of alpha time v with alpha time v .
we can factor out on of those alpha .
so , we get alpha time the inner product of v with alpha v .
we factor out the other on , so we get alpha time alpha time the inner product of v with v .
and that's just alpha squar time the norm squar of v .
that show that the third properti is satisfi .
and we're go to skip the proof of the fourth properti .
here's an exampl , we have a two vector , u1 , u2 .
what's the norm of that vector ?
well , recal the pythagorean theorem .
for a right triangl with side a , b , and c , where c is the length of the hypotenus , a squar plu b squar equal c squar .
we can us thi equat to calcul the length of thi vector u .
the squar length of u equal the sum of the base squar , and the height squar .
so , at least in the case of two vector , thi notion of length agre with the on you're familiar with .
and in linear algebra , we don't sai perpendicular so much , we sai orthogon .
we're go to defin the notion of orthogon so that the pythagorean theorem is true .
let u and v be ani vector .
their length ar norm of u and norm of v .
and we draw the correspond arrow .
the arrow for u , the arrow for v , and the arrow for the sum , u plu v .
now , so far , we haven't requir that thi triangl be a right triangl .
so in fact , thi is not formal a hypotenus .
now the , the squar length .
of the vector u plu v is norm of u plu v squar .
which is , by definit of norm , the inner product of u plu v with u plu v .
now we us some of the properti of inner product .
by linear of the inner product .
we can break thi up as , be a product of u with u plu v , plu be a product of v with u plu v .
we can final break that up , as be a product of u with u , u with v , v with u and v with v .
now , the inner product of u with u is the norm of u squar .
the inner product of v with v is the norm of v squar .
and these two term ar realli the same by symmetri .
two time , combin them we get two time the inner product of u with v .
now thi last express is equal to norm of u squar plu norm of e squar if and onli if thi term is <num> .
we want the norm squar of u plu v to be equal to the norm squar of u plu the norm squar of v .
if and onli if the vector u and v ar orthogon .
so we'll defin orthogon in thi wai .
we defin the two vector to be orthogon if the inner product equal <num> .
and then we automat get the pythagorean theorem for vector .
if vector u and v ar orthogon .
then , the norm squar of u plu v equal the norm squar of u , plu the norm squar of v .
we're go to us orthogon to help us solv the fire engin problem .
first , we have to identifi some properti of orthogon .
if u is orthogon to v , than u is orthogon to ani scale or multipl of v .
and if u and v ar both orthogon to a third vector , w , than u plu v is is orthogon to w .
let's see the proof .
first we show properti <num> .
if u is orthogon to v then u is orthogon to ani scalar multipl to v .
okai , so we assum that u and v ar orthogon .
what's the inner product of u with a scalar multipl alpha time v ?
the inner product can be rewritten as alpha time uv , we've just factor out an alpha .
now , the end product of u with v is <num> , becaus u and v ar assum to be orthogon , so we have alpha time <num> , which is <num> .
so that show that the inner product of u with alpha v is <num> , which show that u and alpha v ar orthogon .
now , we , if u and v ar both orthogon to w , we want to show that u plu v is orthogon to w .
so what's the inner product of u plu v with w ?
well , we can us the properti of inner product to split up thi inner product as u , as the inner product of u with w plu the inner product of v with w .
and each of these inner product is <num> , becaus we've assum that u is orthogon to w and v is orthogon to w .
we get a sum of zero plu zero , show that thi inner product is also zero .
so u plu v is orthogon to w for exampl .
the inner product that is the dot product of thi vector u with thi thi vector v is zero .
so , the inner product , the dot product of u with ten time thi vector is also zero .
here's an exampl of the second properti .
we see that the inner product of thi vector u .
with thi vector w is zero .
and that the inner product of thi vector v with w is also zero .
and we can combin these to get that the inner product of the sum of these two vector with w is zero .
so the sum is orthogon to w .
now let's see how orthogon can help solv the fire engin problem .
we start with a vector b .
that repres the locat of the burn hous .
and a vector a that give us the line that the road goe along .
so the line is the set of set of scalar multipl of the vector a .
now , let p be the point on that line such that b minu p is orthogon to a .
then that's the point on the line that's closest to b .
as exampl , suppos the line is just the x axi , that is the set of pair x , y .
such that y is equal to <num> .
and let the point b be b1 , b2 .
so it look like thi .
the lemma state that the point on the line that's close to b is the point b1 , <num> .
and let's see why that should be .
for ani other point q , these three point form a triangl .
now , it's a right triangl becaus , becaus we chose p , so that b minu p is orthogon to thi line .
sinc q is differ from p .
the length of the base is non zero .
so , by the pythagorean theorum , the hypotenus's length squar equal the sum of the squar of the length of the height , and the squar of the length of the base .
but sinc the base , the length of the base is non zero , that show that the length of the hypotenus squar is greater than the length of the height squar .
that mean that the distanc from b to q , is greater than the distanc from b to p .
let's see thi in greater gener .
let q be ani point on the line .
now the point q , p , and b form thi triangl .
now , p and q ar both on the line .
so thei're both multipl of a .
so , their differ p minu q is also a multipl of a .
now b minu p is orthogon to a .
therefor , it's orthogon to p minu q , which is a multipl of a .
that's us on of the properti of orthogon we prove earlier .
so , by the pythagorean theorem , the length squar of the hypotenus .
that is , the length of b minu q squar equal the sum of the squar of a length of b minu p , and p minu q .
if q is not equal to p then the length of the base is non zero .
which show that the length of the hypotenus is greater than the length of the height .
which show that b is farther from q than it is from p .
so , the lemma state that .
among all the point on the line , the closest point to b is the point on the line such that b minu p is orthogon to a .
now to simplifi all of thi we introduc a new definit .
for ani vector b and ani vector a , we defin two vector .
i call thi on b parallel to a , and thi on b perpendicular to a .
these ar call the project of b onto span of a , or the project of b along a .
and the project of b orthogon to a .
and the defin equat ar thi b ha to be the sum of b parallel and b perpendicular .
and there ha to be a scalar sigma , such that b parallel is a , is sigma time a .
and final be perpendicular ha to be orthogon to a .
so , you should think of thi as break b up into a sum of two part , b parallel and b perpendicular , satisfi these properti .
anoth wai of state the fire engin lemma is thi .
for ani vector b and vector a ver the real .
the point in the span of a that is closest to b is the project of b onto span of a .
and the distanc between that point and b is the norm of b perpendicular .
the norm of the project of the orthogon to a .
let's look at a simpl exampl of thi .
what if a is the zero vector ?
if a is the <num> vector , then the onli vector b parallel to a satisfi thi equat is the <num> vector , as well .
no matter what you multipli the <num> vector by you're still go to get the <num> vector .
now , accord to the first equat if b parallel to a is the <num> vector , then b perpendicular to a must be equal to b .
but that satisfi thi third equat .
that is , b perpendicular is orthogon to a .
becaus , after all , a is the <num> vector .
for , so everi vector ha an inner product of <num> with the <num> vector .
everi vector is orthogon to the zero vector .
now what's the point in span of the <num> vector it's closest to b .
well , the span of the <num> vector contain onli on point , name the <num> vector itself .
so that ha got to be the closest point .
and the distanc is the norm of b perpendicular .
well , in that case , that's the norm of b itself .
all right , we're go to try to figur out how to comput the parallel and the perpendicular .
these ar the three equat that have to be satisfi by these vector .
we've alreadi seen that if a is the <num> vector then b parallel is also the <num> vector .
so let's consid the case where a is not the <num> vector .
we need to find the sigma for which b parallel equal sigma time a .
by the third equat b perpendicular to a ha to be orthogon to a .
therefor the inner product of b perpendicular with a must be <num> .
now let's substitut for b perpendicular us thi equat .
b perpendicular is just b minu b parallel .
so we requir that b minu b parallel , have an inner product with a of <num> .
now we us thi equat to substitut for b parallel .
the inner product of b minu sigma time a with a , must be <num> .
us homogen of inner product .
thi equat in is the same as thi equat .
the inner product of b with a , minu sigma time the inner product of a with itself equal <num> .
and thi give us the valu of sigma .
sigma is the ratio of the inner product of b with a , to the inner product of a with itself .
and in the special case where the norm of a is <num> , the denomin , the inner product of a with itself , is <num> .
so sigma is the inner product of b with a .
now let's us the procedur project along to write the procedur project orthogon <num> .
it take vector b and a , and return the project of b orthogon to a , b perpendicular .
the solut is just to take b and subtract the project of b along a .
the quiz is to write python code for project . along b , a , which is suppos to return the project of b along a .
here's the first answer you might give it return sigma time a .
there's a problem with thi in the case when a is the <num> vector .
in that case , we have a divid by <num> .
so the best answer look like thi .
it re , it return a multipl of a , and that multipl sigma is either thi ratio of inner product , if a is not the zero vector .
but if it is the zero vector the coeffici is <num> .
mathemat the implement of project_along we've given is correct .
howev , becaus of float point roundoff error , we have to make a chang to thi .
often the vector a will not be a truli <num> vector but , practic it will be <num> .
if the entri of a ar tini , the procedur should treat a as a zero vector .
in other word , sigma should be assign <num> in that case .
and the result vector should be the <num> vector .
we'll consid a to be a <num> vector if it squar norm is n more than some tini number , sai <num> to the minu <num> .
so here's a revis version of the implement of project along .
now we return at last to the fire engin problem .
we'll take the vector a to be the <num> , <num> , and the vector b as the locat of the hous <num> , <num> .
the closest point on the line consist of all scalar multipl of a .
is the point b parallel to a which is sigma time a , where sigma is the ratio of the inter product of a with b to the inter product of a with itself .
we calcul that .
it turn out to be on half .
therefor , the , the point closest to b is on half time the vector a which is <num> , <num> .
and the distanc to b is the norm of the project of b orthogon to a .
which turn out to be squar root of <num> .
which is just under <num> , the length of the fire hose .
the hous is save .
now thi fire engin problem can be restat as find the vector on the line that best approxim the given vector b .
and by best approxim we just mean closest .
but thi notion of best approxim come up again and again in linear algebra .
in least squar , which is a fundament data analysi techniqu .
in imag compress , in principl compon analysi , and in someth call latent semant analysi .
in the next part of the cours we'll address the problem of these squar .
the fire engin problem can be state in thi wai , given a vector b and a vector a , find the vector in span of the set consist just of a that's closest to b .
now a natur gener of thi problem is as follow .
given a vector b and a bunch of vector , a1 through an , find the vector in span of the set consist of a1 through an closest to b .
that's the next topic we studi .
given a point b and a plane , we want to find the point in the plane that's closest to b .
so here's plane and a point .
and we want to find the point of the plane that's closest to thi point .
now , by translat the plane and the point , we can ensur that the plane contain the origin , in which case , it's a vector space .
it ha a basi , let v1 , v2 be the basi for thi vector space .
then our goal becom , given a point b , and vector v1 and v2 find the point in the span of v1 and v2 that's closest to b .
here's the point .
for exampl suppos v1 and v<num> ar these <num> vector and our point b is thi .
then , the point in the plane closet to b is , <num> minu <num> , <num> .
so we want to come up with an algorithm that will solv problem of thi form .
more gener , given a vector b and vector v1 through vn .
we want the algorithm to find the vector in span of v1 through vn that's closest to b .
now as a special case , we could us such an algorithm to decid whether b li in the span of these vector v1 through vn .
after all , if , if the vector in span of v1 through vn closest to b is b itself , that mean that b is in the span .
if not , then b is not in the span .
so let a be the , the matrix who's column ar v1 through vn .
and us the linear combin interpret of matrix vector multipl , a vector in the span of v1 through vn can be written as a time x .
thu test if b is in the span of v1 through vn , is equival to test whether the matrix vector equat , ax equal b , ha a solut .
more gener , if ax equal b possibl doesn't have a solut , we can us the algorithm to find a point in the set , it's closest to b .
now , so far we've just discuss find the point itself , but we also want to be abl to find out how to express it as a linear combin of v1 through vn .
that is , we want to find the vector x that solv thi equat , or that minim the distanc between ax and b .
so as i'm sai it's not enough to find the point in the span of these vector that's closest to b .
we want to find the represent of that point in term of those vector .
so , our goal is to find the coeffici x1 through xn such that the linear combin x1 v1 and so on is the vector in the span in these vector closest to b .
i can write that as minim the norm of the differ between the vector b and the product of thi matrix with thi vector .
and that's equival to minim not the norm but the squar of the norm .
and we can rewrit thi matrix , not in term of it column , but in term of it row .
we've written it here , where the row ar the vector a1 through am .
and thi problem is equival to minim thi sum of squar differ .
and thi is the problem that we address in the with gradient descent .
all right , so , find the vector x that minim thi norm square .
which is equival to find a vector x that minim thi sum of squar differ .
thi is call least squar . , it goe back to legendr .
sometim attribut to gauss .
an equival wai of formul the question is , given a matrix vector equat ax b .
in case that equat doesn't have a solut , find the best solut avail .
find that solut that minim the error where the error is , the differ between the target vector b and the vector ax that you found .
you want to make that error have as small a norm as possibl .
now , there is an algorithm base on gaussian elimin .
but , we're go to develop a , an algorithm base on the notion of orthogon .
and we'll see that you can get solut much , much faster than sai , gradient descent .
here's the definit that help us solv the fire engin problem .
for ani vector b and anoth vector a , we defin the project of b along a , b parallel , and the project of b orthogon to a b perp , so that b is the sum of b parallel and b perpendicular .
where b parallel is a scalar multipl of a and b perpendicular , is orthogon to a .
we us a gener of thi definit to address the least squar problem .
for a vector b and now a vector space , big v , we defin the project of b onto big v , written b parallel , and the project of b orthogon to big v , written b perpendicular , so that b is the sum of b parallel and b perpendicular and b parallel to v , is a vector in the vector space v .
and b perpendicular to v is orthogon to everi vector in the vector space big v .
so again , we're decompos b as a sum of two part , the parallel part and the perpendicular part .
you recal that the fire engin lemma gave us a wai to identifi the point in span of a , closest to b .
it wa , the project of b parallel to a , and the distanc wa the norm of the project of b perpendicular to a .
we gener that as follow .
a point in a vector space , big v , that's closest to the vector b , is b parallel and the distanc is the norm of b perpendicular .
now suppos , big v is specifi by gener v1 through vn , then our goal is an algorithm for comput b perpendicular from the input , the vector b and the gener v1 through vn .
the output should be , the project of b orthogon to the vector space big v , which is the span of v1 through vn .
now , we alreadi know how to solv thi , when we onli have on gener , we us projector orthogon on .
given a vector b in a singl vector v , the solut is , to take b and subtract out from it , the project of b along the vector v .
so let's take thi algorithm and try to gener it , to higher dimens .
so here's the algorithm we have and here's the natur gener to higher dimens .
the input is a vector b and a list of vector and the algorithm goe through the list of vector and for each on , subtract out from b , the project along that vector , then return the result .
well , what do peopl think about thi algorithm ?
it's short , eleg and flaw .
beauti if onli it work , a tragic failur .
so let's see thi algorithm in action .
let's sai we're given the vector b which is <num> , <num> and our vlist consist of <num> , <num> and root <num> over <num> , root <num> over <num> .
so the red is the vector b , the first vector in v list is thi on <num> <num> and the second on is thi on root <num> over <num> , root <num> over <num> .
let's see what the algorithm doe to b .
we'll let bi , denot the valu of the variabl b after i iter .
so , initi at input , the valu of b is b <num> .
in on iter , the algorithm deriv b1 by take b0 and subtract from it , the project of b0 along the first vector of v list .
okai .
so , the first vector of v list is <num> <num> .
so we're subtract the project of <num> , <num> along <num> , <num> .
well , here's the project , it's <num> , <num> itself .
so when we subtract that from b0 , we just get <num> , <num> .
so here's b1 , the valu of the variabl b after on iter of our propos algorithm .
next , we have to deriv b2 and b2 is deriv by take b1 and subtract from it , the project of b1 along the second vector in v list root <num> over <num> , root <num> over <num> .
so , here's the project of b1 along the second vector in v list and the result of subtract that , b1 minu on half on half , is here .
all right , well , thi is a failur .
of cours , the result vector b2 is orthogon , to the second vector in v list becaus , we just subtract off the project , along , that second vector .
but , do so , destroi , the orthogon , between , b and the first vector in v list .
so we establish that in the first iter , and then we destroi it in the second iter .
the result is not orthogon to the first vector in v list .
so , thi algorithm , beauti as it is , doesn't get us the right answer .
well , mayb there's a wai to fix it , mayb if we instead , find the project of b along each of the vector in v list and then subtract off , all those project .
here's the algorithm , i call it classic project orthogon .
it initi the output to the all zero vector and then , run through each of the vector in v list , find the project of b , along that vector , and ad up all those project .
at the end , it return the result of subtract the sum of those project from b .
doe thi algorithm work ?
no , thi give us the wrong answer as well .
in fact , if you run it on these input the output vector , is not orthogon to either of the two vector in v list , so thi fail spectacularli .
but here's an exampl where it work , you take these two vector v1 and v2 .
these vector ar orthogon , so these two vector repres here and the vector b repres here , in the first iter , the algorithm take the initi valu of b and subtract off the project of that vector along v1 , get b1 .
so here it is , it get thi vector .
in the second iter , it take b1 , the valu after the first iter , and subtract off the project of that vector along v2 and here's the vector and here's the result .
thi vector is orthogon to v1 and v2 .
wa it a coincid ?
let's do the math under the assumpt that v1 and v2 ar orthogon .
rememb , bi is the valu of the variabl b after i iter .
in the first iter , we obtain b1 by subtract from b0 , the project of b0 along v1 .
so that give you a vector b1 , it's orthogon to v1 , the first vector in v list .
so the inner product is <num> .
in the second iter , the algorithm deriv b2 by take b1 and subtract off the project along v2 , give a vector b2 that is orthogon to v2 , it's inner product with v2 is <num> .
but , what about the inner product of b2 with v1 , have we lost orthogon ?
let's see .
the inner product of v1 with b2 is the inner product of v1 with b1 minu sigma v2 .
the project of b1 along v2 , the thing we subtract off , in the second iter .
us an algebra rule of inner product , we can break thi up as the inner product of v1 with b1 minu the inter product of v1 with sigma time v2 .
we can factor out the sigma to get the inner product of v1 with b1 , minu sigma time the inner product of v1 with v2 .
now , the inner product of v1 with b1 is <num> , becaus b1 result from subtract off the project along v1 .
so thi inner product is zero .
thi inner product is also <num> becaus we assum that v1 and v2 were orthogon .
so , we inde get <num> , when we take the inner product of v1 with b2 .
thu the result is orthogon to both vector in v list .
the solut then , for project orthogon is not to throw awai the procedur , it's to chang the spec .
so , we'll now requir , that the input list , v list consist of mutual orthogon vector , that is all the vector , everi vector on v list is orthogon to everi other vector on v list .
so the spec for the procedur is , it's given a vector b , and a list , v list of mutual orthogon vector and it's requir to output the project of b orthogon to all the vector in v list .
to show that thi procedur satisfi it spec we'll defin the loop invari and we'll prove it's correct .
as befor let bi be the valu of the variabl b after i iter .
the loop invari requir that bi is the project of b , orthogon to the first i vector in v list .
that mean , it bi is orthogon to those first i vector and b minu bi , is in the span of those first i vector .
we'll prove thi invari hold by induct .
and the case i equal <num> is veri easi , b<num> is certainli orthogon to the first <num> vector .
everi vector's orthogon to an empti set of vector and b minu b0 , is in the span of the first <num> vector , becaus b minu b<num> , is the <num> vector .
so now we want to prove the induct step .
here's the invari that we're try to show , bi is the project of b , orthogon to the first i vector in v list and what that mean is that bi is orthogon to those first i vector and b minu bi is in the span of those first i vector .
here's the procedur and let's assum that the invari hold after k minu <num> iter and will show that it also hold after k iter .
in the kth iter , the algorithm comput bk , which is bk minu <num> minu the project of bk minu <num> along the vector vk .
so , that project is of cours a multipl of vk .
now , by the induct hypothesi , we assum that bk minu <num> satisfi the invari , that is , bk minu <num> is the project of b , orthogon to the first k minu <num> vector .
what we have to prove is that bk , the next iter , is orthogon to the first k vector and b minu bk is in the span of those first k vector .
we comput bk from bk minu <num> by subtract off the appropri multipl of vk , the kth vector in v list .
the multipli wa chosen to ensur that bk wa orthogon to vk but , what about all the vector in v list that occur befor vk ?
we have to show that bk is also orthogon to them , to vj for j equal <num> , <num> , <num> and up to k minu <num> .
let's take the inner product , the inner product of bk with vj .
well we know what bk is , it's bk minu <num> , minu sigma k , vk , so we plug that in .
the inner product of bk minu <num> minu sigma k vk with vj and us some algebra properti of inner product , we can re write thi as the inner product of bk minu on with vj minu sigma k time the inner product of vk with vj .
now , the inner product of bk minu <num> with vj is <num> becaus by the induct hypothesi , bk minu <num> is orthogon to all the vector in v list up to vk minu <num> .
thi inner product is also <num> becaus we have assum that , the vector in v list ar all mutual orthogon .
so the result is that the inner product is <num> .
so that show that bk is orthogon to the vector v1 through vk but , we also have to show that b minu bk li in the span of the first k vector of v list .
well , b minu bk is b minu bk minu <num> minu sigma kvk .
we can rewrit that as b minu bk minu <num> plu thi multipl sigma k of vk .
well , thi first quantiti is a vector in the span of the first k minu <num> vector in v list by the induct hypothesi .
the second quantiti is just a multipl of vk .
sinc we're ad someth that's in the span of v<num> through vk minu <num> , and a multipl of vk , the result is a vector in a span of v1 through vk .
so we've prove the second properti , and that complet the proof .
all right , we've gotten through that proof , we've shown that thi procedur ha the follow properti .
that given a vector b and a v list consist of vector v1 through vn , it output the vector b perpendicular such that b equal b parallel plu b perpendicular where b parallel li in the span of those vector in v list and b perpendicular is orthogon to each of them .
now we're , we're go to work with a code a littl bit and for that reason i want to restat the correct , us <num> base address .
so , the list consist of the vector v0 through vn .
ah , and b parallel is in the span of vector v0 to vn and b perpendicular is orthogon to v0 through vn .
we're go to need a procedur that give us a littl bit more inform .
sinc b parallel which is b minu b perpendicular is in the span of v0 through vn , there exist coeffici alpha <num> through alpha n such that b minu b perpendicular equal the correspond linear combin , alpha <num> time v<num> and so on .
we can move b perpendicular to the other side , so we get thi , b equal thi linear combin plu <num> , time the vector b perpendicular .
we can write that in matrix form , as b equal the matrix whose column ar v0 through vn togeth with b perpendicular , time thi column vector consist of alpha <num> through alpha n follow by the on the coeffici of n perpendicular .
so we're go to augment the procedur project orthogon , to actual output thi vector of coeffici , as well as b perpendicular .
and for technic reason , we're go to repres that not as a vec but as a dictionari .
so , here's the defin equat .
the procedur ha to creat thi dictionari , that ha on entri for each of the vector in vlist , togeth with on addit entri , the <num> that's the coeffici of b perpendicular .
so , we initi the dictionari , with that on element , we're go to drive the code from two previou procedur , project along and project orthogon and here's the augment procedur , it initi the dictionari .
in each iter , it pull out the vector , comput the scalar multipl sigma , then popul the dictionari with that valu of sigma and updat the valu of b .
at the end it return , the valu of the variabl b , which is b perpendicular and the dictionari of the alpha valu togeth with a <num> .
later on we'll us thi procedur .
and recal our origin goal wa to find a project of a vector b , orthogon to a vector space big v , span by some arbitrari vector .
and all we've been abl to do so far , us project orthogon , is find the project of b orthogon to the space span by neutral orthogon vector .
so , how ar we go to go about solv thi origin problem ?
well , the procedur we have would suffic .
if onli we had a wai of go from arbitrari vector , v1 through vn , to mutual orthogon vector , v1 through vn , that happen to span the same space as v1 through vn .
thi is call orthogon .
we're given vector v1 through vn , and we want to produc a list of neutral orthogon vector , v1 through vn star , such that the span of those vector equal the span of the origin vector .
how can we solv thi problem ?
here's the kei idea , we're go to us project orthogon in an iter fashion to make a longer and longer list of mutual orthogon vector .
so , let's start with v1 .
we defin v1 to be just v1 , sinc the set consist just of v1 is trivial , mutual orthogon .
next , we defin v2 .
what's v2 ?
v2 is the project of v2 orthogon to the vector that's alreadi in our list , v1 .
now , sinc v2 is orthogon to v1 star , our set is a set of mutual orthogon vector .
now let move on to v3 .
we defin v3 , to be the project of v3 , orthogon , to both v1 , and v2 .
so the set v1 , v2 , v3 is a set of mutual orthogon vector .
in each iter , all we have to do is project a vector orthogon to a collect of mutual orthogon vector .
and we can us project orthogon for that .
so in the ith iter , we project the ith vector in vlist , vi , orthogon to the i minu <num> vector that ar alreadi in our mutual orthogon list , v1 through vi minu <num> .
and that's how we find vi .
we just add that to the list .
so , here's the procedur .
if given a list of vector , vlist , initi the list of mutual orthogon vector is empti .
the procedur iter through the vector in vlist .
and for each on , project that vector orthogon to the vector alreadi in the list of mutual orthogon vector , vstarlist , take the result , and append it to vstarlist .
preserv thi properti that all the vector in vstarlist ar mutual orthogon .
at the end the procedur return the valu of vstarlist .
so , it's pretti easi to see that at each stage in the algorithm the valu of vstarlist is a list of mutual orthogon vector , in particular at the end .
the valu return consist of mutual orthogon vector .
so here is the exampl let sai we want to orthogon on the list consist of these three vector .
will show that it return .
thei list consist of these three vector , v1 , v2 , and v3 .
in the first iter the vector v is v1 .
the vstarlist is empti so the first vector ad to vstarlist is just v1 .
the next iter we're work on v2 ; vstarlist consist onli of v1 .
so , the procedur project v2 orthogon to the list consist onli of v1 .
and thi is the vector it come up with .
so , thi is the vector that's ad to v list in the second iter .
in the third iter , we're work on v3 .
v list consist ov v1 and v2 star .
we take v3 , project it orthogon to v1 star get <num> , <num> , <num> .
and then take that vector and project it orthogon v2 get <num> minu <num> , <num> so thi is the vector that's ad to vstarlist , thi is v3 .
as we mention befor , at ani point in the algorithm the vector in v list ar our mutual orthogon .
but what we need to show that after i iter of the algorithm , the span of the vector in v list at that point , equal the span of the first i vector in vlist .
and we us induct .
the case i equal <num> is trivial .
so , we do the induct step .
after i minu <num> iter , v list consist of the vector v1 through vi minu <num> .
now , assum the lemma hold at thi point .
that mean that the span of these vector , v<num> through vi minu <num> , equal the span of the first i minu <num> vector in vlist , v<num> , through vi minu <num> .
now we take the vector vi , we insert it into both of these set .
well , the span of thi set is still equal to the span of thi set .
so what we need to show is that the span of v<num> through vi minu <num> togeth with vi equal the span of v1 star through vi .
the ith iter comput vi by project vi orthogon to v1 through vi minu <num> .
therefor , there ar coeffici such that these equat hold , vi is the linear combin of v1 through vi .
but thi equat show that ani linear combin of v<num> through vi minu <num> togeth with vi , can be re written as the linear combin of v1 through vi .
becaus vi can be written in that wai and vice versa .
so thi show the induct step and complet the proof .
now notic that the order of the vector in vlist doe matter .
if you ran the procedur orthogon with differ order on vlist , you'd get differ answer .
thi is differ from project orthogon becaus the project of a vector orthogon to a vector space is uniqu .
there's onli on such project .
so at least in principl the order of the vector in vlist shouldn't matter .
now , for project orthogon , we were abl to express the result us thi matrix equat .
the vector b is the product of thi matrix , column v0 through vn , and b perpendicular , time thi column vector .
for orthogon we have the follow equat ; v0 is just v0 time <num> .
v1 is the matrix with v0 and v1 as it column , time thi column vector v2 , v3 , and so on .
we can combin all these equat in a singl matrix matrix equat .
the matrix whose column ar v0 , v1 , v2 and v3 is the product of the matrix whose column ar v0 , v1 , v2 , v3 time thi matrix .
well , in gener , the solut look like thi .
now notic that these two matric have a special form .
the column of thi matrix ar all mutual orthogon .
and thi is an upper triangular matrix .
so we ll us those properti later on in algorithm .
here's an exampl .
if vlist consist of v0 , v1 and v2 , the output v list consist of v0 , v1 and v2 .
we'd write a matrix equat in thi wai .
these ar the input vector , these ar the output vector .
these column ar mutual orthogon .
and thi is an upper triangular matrix .
now let's get back to the origin problem .
we're given a vector space big v , which is express the span of input vector v0 through vn .
the factor in big v is closest to b .
is b parallel ?
which is b minu b perpendicular .
so how can we find b perpendicular ?
there ar two equival wai .
here's on method .
we first appli orthogon to v0 through vn .
so we get v0 through vn .
these ar mutual orthogon and thei span the same vector space as v0 vn , name big v .
now we can call project orthogon with b as the first argument , and the list consist of v0 through vn is the second argument .
thi satisfi the spec of project orthogon becaus v0 to vn ar mutual orthogon .
so we get the correct result .
so here's anoth method .
we just call orthogon with an input list consist of v0 through vn togeth with b .
and exactli the same comput take place we get as it output for less consist of v0 through vn and a final vector i'll call b .
well , in the last iter of orthogon , the vector b is obtain by project the input vector b , orthogon , to the previou star vector , v0 through vn .
so that also give you b perpendicular .
we've shown how orthogon , can find a vector , in , span of , v0 through vn , closest to b .
name , b parallel .
and later we'll find out how to give the coordin represent of the b parallel in term of these vector .
for now we ar go to look at how we can us our orthogon to give algorithm for other problem .
let's start with the mathemat result about mutual orthogon vector .
we'll show that mutual orthogon nonzero vector ar linearli independ .
so let v0 through vn be mutual orthogon nonzero vector .
we'll show that these vector ar linearli independ .
by show that , if you can write the zero vector as a linear combin of those vector , then the coeffici , alpha <num> through alpha n , must be zero .
so , here we'll show that alpha <num> is zero .
we do that by take the inner product with v0 on both side of the equat .
on the left side , we take the inner product of v0 with the zero vector .
and on the right side we take the inner product of v0 with thi whole express , which us algebra properti of inner product .
we can replac with thi express .
so now let's look at each of these inner product .
the inner product of v0 with v0 is the norm squar of v0 .
these other inner product ar all <num> becaus the vector ar mutual orthogon .
so we end up with alpha <num> time the norm squar of v0 .
now , thi inner product , v0 with the zero vector , is zero .
so we've shown that alpha <num> time the norm squar of v0 squar star is zero .
well , sinc v0 is non zero vector , it norm is non zero .
so the onli solut to thi equat is alpha <num> equal <num> .
so we've shown that alpha <num> must be equal to <num> .
the same argument can be us to show that all the other coeffici also have to be <num> , and that complet the proof .
now we have thi proposit .
mutual orthogon non zero vector ar linearli independ .
let's see how we can us thi in an algorithm .
what happen when we call the orthogon procedur on a list , v list consist of the vector v0 to vn .
when those vector ar not necessarili linearli depend .
so , let's imagin that the dimens of the span of these vector is less than the number of vector .
we run orthogon on the list of the vector and it return some output list v0 through vn .
now , we know that those vector in the output ar mutual orthogon .
thei can't be linearli independ , becaus thei span a space of dimens less than their number .
must be that some of them must be <num> .
let's consid these vector but leav out the <num> vector .
that doesn't chang the space span by them .
so let s be the subset of the output vector v0 through vn , consist just of the non <num> vector .
well , the span of s is equal to the span of all the vector , v0 through vn star , becaus <num> vector don't contribut to anyth to the span .
thi is equal to the span of the origin vector v0 through vn .
that's the correct properti of orthogon .
and the proposit impli that the set s is linearli independ .
so we got a set of vector that ar linearli independ and span the same space as v0 through vn .
so s is a basi for that vector space .
so in principl thi algorithm should find a basi for the space span by the input vector v0 through vn .
it first comput vo through vn by run orthogon on the input vector v0 through vn and then it return the list consist of those star vector that ar non zero .
for exampl , suppos we run orthogon on the vector v0 through v6 , and it return the vector v0 through v6 .
and suppos from among these output vector , v2 , v4 , and v5 ar <num> .
in that case , the remain output vector , v0 , v1 , v3 and v6 form a basi for the span of those initi input vector .
now , you might rememb we had a lemma that said that everi finit set t of vector contain a subset that's a basi for span of t .
can we adapt thi algorithm to give us such subset basi .
given vector v0 through vn find a subset of these input vector that is a basi for their span .
here's the propos algorithm .
we run orthogon on the list of input vector , v0 through vn , get vector , v0 through vn .
now , we return the list consist of those origin vector that correspond to star vector that ar non zero .
doe thi algorithm work ?
i'll illustr by exampl that the algorithm is correct .
so let's sai we ran orthogon on v0 , v1 , through v6 .
and got back v0 through v6 .
let's suppos as befor that v2 , v4 and v5 ar <num> vector .
so consid how orthogon would run .
in it's third iter it take v3 and project it orthogon to the vector v0 v1 and v2 to comput v3 .
well , how doe it do that ?
it subtract the project of v3 along v0 , then it subtract the project along v1 , then it subtract the project along v2 .
but sinc v2 is <num> , the project is the <num> vector , <num> so subtract doe noth .
so the result is the same as if the algorithm had project v3 orthogon to v0 and v1 .
v2 plai no role .
<num> vector in the second argument of project orthogon ar ignor .
so if we ran orthogon on just the vector v0 , v1 , v3 and v6 , the output would be exactli those vector v0 , v1 , v3 and v6 as we got here .
we alreadi know that those vector , v0 , v1 , v3 and v6 form a basi for the vector space that's the span of v0 through v6 .
and , we've seen that v0 , v1 , v3 , and v6 span the same space , thei have the same cardin .
so thei also form a basi for that vector space .
here's anoth wai to see that our procedur is correct .
recal that we had a matrix equat , relat the origin vector to the star vector .
the matrix whose column ar the origin vector , equal the matrix whose column ar the star vector .
time thi invert triangular matrix .
now suppos we run find subset basi on the vector v <num> through v <num> .
let big v be the span of those vector .
here's the matrix equat that in which we write those vector in term of the star version time the invert upper triangular matrix .
and let's suppos , as befor , that v0 star , v4 and v5 ar <num> vector .
but let's delet those vector , so thi is <num> , thi is <num> and thi is <num> .
we go to delet those column from thi matrix and delet the correspond row , from the triangular matrix .
let me get thi .
thu the span of v0 through v6 .
is the subset of the span of v0 , v1 , v3 , and v6 .
so that show that these star vector form a basi for big v .
now let's delet the origin column correspond to the <num> vector , v2 , v4 and v5 .
and delet the correspond column of thi matrix .
and we get thi relationship .
now , thi triangular matrix is invert .
we can move it to the other side , multipli by the invers .
and we get thi relationship .
now , thi show that v0 , v1 , v3 linear combin of v0 , v1 , v3 , and v6 .
well , that show that these remain star vector ar in the span of the remain unstar vector .
so that show that the remain unstar vector , v0 , v1 , v3 , and v6 ar a basi for big v .
now , in principl we said , thi algorithm find a basi .
for the space span by v1 through vn .
we us orthogon to comput v1 though vn and then return the list consist just of the nonzero vector .
howev , the comput us float point number , and due to round off error vector that ar suppos to be <num> , won't end up be exactli <num> .
so instead , we'll modifi the algorithm to consid a vector to be effect <num> if it's norm squar , that is , the dot product of v with itself , is veri small , sai less than <num> to the minu <num> .
so here's the revis algorithm , it appli orthogon , and then it return a list consist just of those vector .
whose squar norm ar greater than , sai , ten to the minu <num> .
now thi procedur which find a basi for the space span by v1 through vn can in turn be us to defin the rank procedur and the is independ procedur .
and we can us the same idea in find subset basi as well .
now i'll defin orthogon complement .
let big u be a subspac of big w .
and for each vector b in big w , we can break it up into it parallel part and it perpendicular part .
the parallel part is the project b onto the space big u .
and the perpendicular part is the project of b orthogon to the space big u .
note that b parallel is in big u , and b perpendicular is orthogon to big u .
that is it's orthogon to everi vector in big u .
so , we can take everi vector b in w and split it up thi wai .
and we'll defin big v to be the set of b perpendicular obtain thi wai , take all the vector b in big w .
and we call thi set big v , the orthogon complement of big u in big w .
now , it's easi to see that everi vector in big v is orthogon to everi vector in big u .
that's how we construct it .
also everi vector b in big w can be written as the sum of a vector in big u , the parallel part , plu a vector in big v , the perpendicular part .
now , thi second condit that everi vector in big w can be written as the sum of a vector in big u .
plu a vec , vector in big v suggest that mayb there's a there's a direct sum here .
so , that rais the question is big w the direct sum of big u and big v .
well , for the direct sum to even to be defin it ha to be the case , that big u and big v share onli the zero vector .
so , let's see if that's the case .
so , consid ani vector w , in both big u and big v .
it must be orthogon to itself .
it ha to be both the parallel part and the perpendicular part .
so , that mean the inner product of w with itself is zero .
but the inner product of a vector with itself is the squar of it norm .
by a properti of norm , if a vector ha norm <num> , it must be the <num> vector .
so , that show that the onli vector common to u and v is the <num> vector .
and so , direct sum is , in fact , defin .
and becaus of thi properti , big w is the direct sum of big u and big v .
now rememb , that , that mean that the dimens of big u plu the dimens of big v equal the dimens of the inner product u plu v , which is w .
so , here's an exampl , let big u be the span of these two vector and let big v denot the orthogon complement of u in r to the forth power .
what vector form a basi for big v ?
well , by look at these gener we can see that ani vector in big u ha it's first two entri the same and it's last two entri the same .
so , it ha the form a , a , b , b .
so , ani vector of the form c minu c , d minu d is orthogon to everi vector in big u .
so , let consid the space span by these two vector .
everi vector in thi space ha thi form c minu c , d minu d so is orthogon to everi vector in big u .
so at , so we know atleast taht the span of these two vector is a sub space of big v , the orthogon compliment of , of big u .
is it in fact the whole thing ?
is it all of v ?
well , we know that the direct sum of u and v , is r4 , so the dimens of u , plu the dimens of v , is the dimens of r<num> , which is <num> .
now , these gener for big u , thei're linearli independ .
so , that show that the dimens of u is <num> .
plug that in , we see therefor that the dimens of v is <num> .
now , these two vector in fact ar linearli independ so the dimens of their span is <num> as well .
so , that show that in fact thi span cover all of big v .
so , it's equal to big v .
so , we found the orthogon complement of u in r4 .
so , here's a us of orthogon complement .
our goal is to find a basi for the null space of a matrix .
now , by the dot product definit of matrix vector multipl , a vector v is in the null space of thi matrix if the dot product of everi row with v is zero .
so , that tell us that the null space of the matrix equal the orthogon complement of the row space in r4 .
now , these three row ar linearli independ so the dimens of the row space is three .
we know the dimens of r<num> is <num> , so the dimens of the orthogon complement is <num> minu <num> , which is <num> .
and now here is a vector that ha a dot product of , of zero with each of these row .
so , thi vector form the basi for the orthogon complement .
it's definit in the orthogon complement and the space it span ha the right dimens .
so , the space it span must in fact be the orthogon complement .
so , we found a basi for the null space of thi matrix a .
let's us these idea to find the intersect of two plane .
we take thi plane , the plane span by these two vector , and thi plane , the plane span by these two vector and we want to comput the intersect .
well , the orthogon complement in r3 of thi first plane is the span of thi vector .
that show that the first plane equal the set of xyz , such that thi vector dot with xyz is zero .
now , the orthogon complement in r3 of thi second plane is the span of thi vector .
therefor the second plane is the set of xyz such that the dot product of thi vector with xyz is <num> .
therefor , the intersect of these two set is the set of xyz that satisfi both condit .
thi dot product is <num> and thi dot product is <num> .
okai , so we have express thi essenti as the null space of a matrix .
by the row space null space dualiti a basi for thi vector space is a basi for the null space of thi matrix .
notic that the row of thi matrix ar the vector in thi formul of the set .
and the null space of a is the orthogon complement of the span of it row in r3 , which we can determin is the span of thi vector .
that show that the intersect is span of the vector <num> , <num> minu <num> .
how would we actual comput the orthogon compliment ?
suppos we have a basi u1 through uk .
for the vector space , big u , and a basi w1 through wn for the vector space , big w .
how can we comput a basi for the orthogon complement of big u in big w ?
note that here , we're assum that big u is a subspac of big w .
on wai is to us orthogon .
appli it to a vlist consist of first the vector u1 through uk that form a basi for big u , follow by the vector w1 through wn that form a basi for big w .
thi seem like the strang thing to do becaus after all , the vector u1 through uk ar alreadi span by the vector w1 through wn .
the vector u1 through uk lie in big u , which is a subspac of big w .
so it's counter intuit to includ them in thi list , but you'll see why we need them .
the output of orthogon is a list of vector i'll write as u1 through uk follow by w1 through wn .
and , these span the same space as the input vector .
the space span by the input vector is exactli big w .
big w ha dimens n we see that it ha a basi of cardin .
these span the same space thei for , therefor thei span big w , so the space thei span also ha dimens n .
we saw earlier that the non zero vector in the list output by orthogon form a basi for the space span by the input vector .
so , the non zero vector in thi output list ar a basi for an n dimension space , therefor there must be n of them .
the number of non zero vector in the output is exactli n .
now , the vector u1 star through uk1 span exactli the same space as the input vector u1 to uk .
and thei ar all non zero vector becaus u1 through uk ar linearli independ .
thei form a basi for big , big u .
so , thei account for k , so u1 star through uk account for k non zero vector in the output .
so , exactli n minu k of the remain output vector , w1 through wn ar non zero .
now , everi on of those output vector is orthogon to u on through un .
so , thei're orthogon to everi vector in big u .
so , thei lie in the orthogon complement of big u .
now , by the direct sum dimens lemma , the dimens of the orthogon complement is n minu k .
so , those remain non zero vector , among u , among w1 to wn ar exactli a basi for the orthogon complement .
so at thi point , we've given an algorithm for a problem we've been wonder about for a while , find the basi for the null space of a matrix .
given the matrix , we think of it in term of row .
and we find the orthogon complement of the span of the row in rn , where n is the number of column .
and to do that let e1 through en denot , as usual , the standard basi vector for rn , and we find the non <num> vector among the output of orthogon with the input list a1 through am follow by e1 through en .
here's a anoth approach to find basi for the null space of matrix .
thi time we'll write the matrix in term of it column .
now here is the equat that relat the origin vector suppli to orthogon to the output vector .
the origin vector form a matrix , it's equal to the matrix form by the output vector time thi matrix .
thi is invert matrix , so we can move it to the other side , and we get thi equat .
it express the star vector , the output vector , in term of the origin vector .
i'll illustr the algorithm through an exampl .
suppos we suppli the vector v0 through v6 to orthogon , and it output the vector v0 through v6 .
so thi is the relat between them .
the matrix consist of the input vector is the product of the matrix consist of the output vector time thi invert matrix .
we can move the invert matrix to the other side , multipli by it invers .
and now , suppos it's befor that v2 , v4 , and v5 ar <num> vector .
these ar <num> vector , okai ?
so the correspond column of the of the triangular matrix ar these .
now , it's clear that these ar linearli independ vector and notic that by the matrix vector definit of matrix , matrix mutipl , when you multipli thi orgin matrix by each of these vector , you get a <num> vector .
so these vector lie in the null space of thi matrix .
thei're linearli independ , so thei span a space of dimens <num> .
and the rank nulliti theorem show that the null space of thi matrix is exactli <num> becaus the non zero vector in the output form a basi .
and there ar <num> , <num> , <num> , <num> of them .
so the column that we've identifi ar inde a basi for the null space of thi matrix .
so let's review the algorithm .
to find the null space of a matrix .
we appli orthogon to the column of that matrix .
and find the upper triangular matrix t , such that the origin matrix equal the matrix whose column ar the output vector time the triangular matrix .
then we take the invers of the triangular matrix , and return exactli those column of the invers that correspond to the zero vector among the output vector of orthogon .
so thi algorithm rais <num> question .
how to find thi triangular matrix t , and how to find it invers ?
first we'll address find the matrix t .
we'll write a procedur i call augment orthogon that take a v list sai v1 through vn of vector and output as befor the vector v1 through vn , that ar mutual orthogon .
and also , some other vector r1 through rn .
these have the properti that the matrix form by the origin vector equal the matrix form by the star vector time the matrix form by r1 through rn .
the procedur is base on our orthogon procedur .
togeth with augment projector orthogon .
so , here's the procedur .
it veri much resembl orthogon .
it us r vec to accumul these r vector .
instead of call project orthogon , it call augment project orthogon .
which return not just a vstar vector but also the correspond column of the r's repres as a dictionari .
and the procedur just packag that dictionari up into a vec and return in the end the list of star vector and the list of r vector .
us augment orthogon we can fill out thi prodecur a bit .
so , we us aug orthongon on the column of a and we get back a list of star vector and list of r vector .
we let t be the matrix whose column ar these vector in r vex .
and then , we return the column of t invers correspond to those vector in v list that ar zero vector .
well , how do we find a column of t invers ?
from our knowledg of matrix invers , we know that t time t invers is the ident matrix .
so we can find column j of t invers by solv an equat , t time the unknown column , which we call x , equal the correspond column of the ident matrix , which is the standard vector .
and how do we solv thi equat ?
we can us triangular solv becaus t is a triangular matrix .
build on our orthogon procedur , we're go to develop the qr factor .
we're go to be abl to show that certain matric can be written as the product of matric in special form .
now in gener matrix factor ar an import part of comput in linear algebra .
thei're import mathemat , becaus thei provid insight into the structur of matric .
and thei're import computation , thei're the basi for sever algorithm in linear algebra .
now notic that a matrix whose column ar mutual orthogon ha a special properti .
if you take the transpos of , of thi matrix and multipli it by the matrix itself .
then you get a matrix whose onli non zero element ar the diagon element , and those diagon element ar the squar norm of the column .
why is that ?
well let's us on of our definit of matrix matrix multipl .
the entri of the product in the first row in the first column is the dot product of the first row of the first matrix .
time the first column of the second matrix and so on .
the off diagon element ar all zero , becaus these vector ar mutual orthogon .
now we can chang thing around , so that instead of get thi diagon matrix we get the ident matrix by normal the column .
what doe normal mean ?
normal a vector , mean scale it , multipli it by a scaler , so as to make it norm on .
and here's the definit of normal .
it just take a vector and divid it by it norm , which is the squar root , of it inner product with itself .
so , for exampl the vector with entri <num> , <num> , <num> , onc it's normal , it norm squar is <num> , and the entri ar <num> over root <num> .
now , if we take these column and we normal them , renam q1 through qn .
then we take the transpos of that matrix multipl it by the matrix becaus the norm of the column ar all <num> .
the diagon element of the product ar also , all <num> .
so we see that if the column of a matrix q ar mutual orthogon , and thei all have norm <num> then q transpos time q is the ident matrix .
well we sai that vector that ar mutual orthogon ar orthonorm .
and if a matrix q ha orthonorm column , we call q a column orthogon matrix .
now , i know it should be call column orthonorm , but that's the wai it goe .
and if q is a squar matrix , and column orthogon we call q an orthogon matrix .
it realli should be call an orthonorm matrix , but thi is the convent .
and we see that if q is an orthogon matrix it invers is it transpos .
we'll learn a littl bit more about these orthonorm vector .
suppos q1 through qn ar orthonorm vector .
the project of a vector b onto on of these vector , sai , qj , b parallel is a scalar multipl sigma j time qj .
and the scaler sigma j is the ratio of the inner product of qj with b by the inner product of qj with itself .
the inner project of qj with itself is <num> , becaus these vector all have norm <num> .
so it's just the inner product of qj with b .
so the vector of these scalar , the vector sigma on through sigma n can be written us the dot product definit of matrix vector multipl .
as sigma <num> through sigma n which is the dot product of q1 with b through the dot product of qn with b .
that's the product of thi matrix time the vector b .
thi matrix ha as it row , the vector q1 through qn .
and the sum of these project is the linear combin sigma <num> time q<num> plu up to sigma n q n .
can be written as thi matrix , whose column ar the vector q1 through qn , time sigma <num> through sigma n .
now , we'll start to develop procedur for produc the qr factor .
rememb , that the result of orthogon is thi relationship .
here's the matrix whose column ar the origin vector suppli to orthogon .
here's the star version , and thei're relat by matrix multipl with thi upper triangular matrix .
now , these star vector ar mutual orthogon , but thei're not orthonorm .
so , let's assum that the input vector linearli independ .
in that case , the star vector ar all non zero .
so we can normal them .
we'll normal these vector , replac them with their normal version and we'll we'll call the normal version q1 through qn .
now to maintain thi matrix relationship , becaus we're normal these , that mean divid each of these by it's norm , we have to multipli the correspond row of thi matrix by the norm of thi vector .
and so we get a slightli differ triangular matrix .
instead of <num>'s along the diagon , it ha the norm of the vector v1 through vn star .
and the other entri ar modifi as well .
thi is call the qr factor of the matrix form by the origin vector v1 to vn .
in thi case the matrix whose column ar q1 to qn is call q .
and the upper triangular matrix is call r .
we can us the qr factor to solv a matrix vector equat ax equal b , in the case when a is squar and it column linearli independ .
in thi case , a is an invert matrix .
so , we know there exist exactli on solut , becaus we can write it as a invers time b .
and here's the algorithm we can us in thi case .
first , we find the qr factor .
a pair of matric , q and r , such that a equal the product of q and r .
q is column orthogon and r is triangular .
next , we comput the vector c by multipli q transpos time b .
and final , we solv rx equal c and we can do that sinc r is a triangular matrix .
so , we can us backward substitut and return the solut to that .
why is that the correct solut ?
let x hat be the vector return by thi algorithm .
now , becaus we solv thi equat , we have that r time x hat equal q transpos time b .
let's take thi equat , multipli both side by q .
so , we get q time r time x hat equal q time q transpos time b .
now , we can rewrit thi us associ of matrix multipl .
so , q time r time x hat equal q time q transpos time b .
now , qr is equal to a .
so , we have a time x hat equal q time q transpos time b .
but q and q transpos ar invers of each other so q time q transpos is the ident matrix .
so , we get ax hat equal the ident matrix time b .
in other word , a time x hat is b and we've solv the system .
we've seen how to solv a matrix vector equat ax equal b where a is squar and it column ar linearli independ .
what if the column ar not linearli independ ?
here's an exampl .
let's sai the matrix a consist of the column v1 , v2 , v3 , v4 , and these were linearli depend vector .
well , then there's a basi consist of a subset of these .
let's sai , a basi consist of v1 , v2 , and v4 .
we're try to find a vector a time x that's equal to b .
we're , we're try to find a vector of thi form .
but the set of all vector of thi form , a time x , is the same as the set where we omit the vector v3 .
becaus v1 , v2 , and v4 span the same space as v1 , v2 , v3 , and v4 .
so , if we want to solv a matrix vector equat but the , but the column don't happen to be linearli independ , get rid of some of them .
so , you have a basi as your column set .
and then , solv that system instead .
so now , we're go to assum that a is an m by n matrix , and it column ar linearli independ .
let's consid thi exampl .
it's a <num> by <num> matrix .
now , we're assum that the column ar linearli independ .
each of these column is a three vector .
it live in r3 .
the dimens of r<num> is onli <num> and we have five vector .
so , these can't possibl be linearli independ so we don't have to worri about thi case .
we've shown that the number of column ha to be less than or equal to the number of row .
what if it's strictli less than ?
let's take thi exampl .
thi is a <num> by <num> matrix .
the input is a three vector , the output is a four vector .
but the dimens of the imag is <num> becaus the imag is the vector space span by the three column .
the dimens of the output space is <num> .
so , not everi vector in the output space , in the co domain is in the imag .
that mean that it's not the case that for everi vector b , there's some vector x , such that a time x equal b .
more gener , given a matrix a , that's m by n , defin the function that goe from rn to rm by f x equal a time x .
the dimens of the imag is the number of column , n .
the dimens of the co domain is the number of row , m and we're look at the case where n is less than m , in that case the function f is not onto .
so , not everi vector b ha a correspond solut x .
so , we have to lower our standard .
instead of look for an algorithm that will solv a matrix vector equat ax equal b .
given such an equat , we'll try , we'll look for an algorithm that find the vector x hat that minim the norm of the differ between the target vector b and the vector we get , a time x hat .
and the algorithm that we're go to us to solv thi is exactli the same algorithm as we us in the case when a wa squar .
although the analysi is somewhat more difficult .
recal the high dimension fire engin lemma .
it's state that the point in a vector space big v , that wa closest to a vector b is b parallel .
the project of b onto the space big v .
and the distanc is the norm of b perpendicular .
that is the project of b orthogon to the space big v .
given the matrix vector equat ax equal b , let big v be the column space of a .
we need to show that our algorithm will return a vector x hat , such that ax hat is as close as possibl to b while still ly in the column space of a .
that is , that ax hat equal b parallel .
now , let q be a column orthogon matrix , such as we get from qr factor .
and let b be a vector .
write b in term of it parallel and perpendicular part .
b equal b parallel plu b perpendicular , where b parallel is the project of b onto the column space of q .
and b perpendicular is the project of b orthogon to the column space of q .
and let u be the vector that's the coordin represent of b parallel in term of the column of q .
by the linear combin definit of matrix vector multipl , the vector we're repres , b parallel , is the matrix q time the coordin represent u .
let's take thi equat and multipli both side on the left by q transpos .
we get thi equat .
q transpos time b parallel equal q transpos time q time u .
now , we know that q transpos time q is the ident matrix .
so , we get the q transpos time b parallel equal the ident matrix time u , that is u itself .
so , we've seen that q transpos time b parallel is u , the coordin represent of b parallel in term of the column of q .
but now , let's look at b perpendicular , the project of b orthogon to the column of q .
for everi column , sai qi , of the matrix q , qi , dot with b perpendicular is <num> becaus thei're orthogon .
therefor , by the dot product definit of matrix vector multipl , when we multipli q transpos time b perpendicular .
sinc the row of q transpos ar exactli the column of q , we get zero for everi row .
so , we've seen that q transpos time b perpendicular is the zero vector .
now let's put these togeth .
q transpos time b , well , b is the sum of b parallel and b perpendicular .
so , thi is q transpos time b parallel plu b perpendicular .
now , we can us an algebra properti of matrix vector multipl to rewrit thi as q transpos time b parallel plu q transpos time b perpendicular .
well , q transpos time b perpendicular is <num> .
so , we're left with q transpos time b parallel which is u .
the coordin represent of b parallel in term of the column of u .
now , to go from the coordin represent u to b parallel itself , we simpli multipli by q , us a linear combin definit of matrix vector multipl .
so , q time the coordin represent u is b parallel .
so , put these togeth , q time q transpos time b is b parallel .
so , here's what we found out , q time q transpos time b is b parallel .
now let's us thi .
we're go to here's the propos algorithm for solv the least squar problem , that is find the vector x such that ax best approxim the vector b .
here's the algorithm .
find matric q and r such that a is the product of q and r .
and q is a column orthogon matrix and r is upper triangular .
then , comput c , the product of q transpos time b .
and then , solv the matrix vector equat rx equal c , us backward substitut sinc r is an upper triangular matrix .
return the solut which we'll call x hat .
we want to show that thi algorithm is correct , that it find the best solut .
well , everi vector of the form a time x is a linear combin of the column of a .
and therefor , li in the column space of a .
the column space of a equal the column space of q .
now , by the high dimension fire engin lemma , the vector in the column space of a closest to b is b parallel .
the project of b onto the column space of a .
the solut x hat , given by thi algorithm , satisfi the equat r time x hat equal q transpos time b becaus , becaus that's how we got it .
we multipli thi equat by q , we get q time r time x hat , equal q time q transpos time b .
well , on the left q time r is the matrix a .
and q time q transpos time b is the vector b parallel .
so , we find that thi particular x hat satisfi that a time x hat is b parallel , which is the vector that's closest to b in the span of the column of a .
so , we're given on algorithm for solv the least squar problem where we want to approxim b as a time x .
but there ar other wai to find such solut .
it's not hard to show that a transpos time a is an invert matrix in the case where a is a matrix with linearli independ column .
and that the solut to thi equat is also the solut that we want , it's exactli the same solut .
thi is a matrix vector equat with a squar and , in fact , invert matrix .
so , you can solv thi equat thi equat us other method such as gaussian elimin .
and the equat make up thi matrix vector equat ar call the normal equat .
for a long time , thi wa the wai to find a solut to least squar .
here's an applic of least squar , fit a line to data .
so here's some complet made up data that give averag brain mass as a function of ag after ag <num> .
here's the data plot .
now let f x be the function that predict averag , brain mass for a given , number of year x .
you might have the hypothesi that brain mass decreas linearli at least after ag <num> .
that is , that f x ha the form f of x equal m time x plu b , for some number m and b .
and our goal is to figur out what those number ar .
which number m and b should we choos in order that thi function best match our data ?
and what do we mean by best match ?
our goal will be to minim the sum of squar of predict error .
so here's a line .
these ar the point .
we're try to find the line that best fit these point .
the predict error on a particular observ is the absolut valu of the differ between the predict and the actual valu .
and the sum of squar of predict error is just the sum of squar of those differ .
here we're zoom in on the graph .
now , you might think that the wai to measur error correspond to an individu data point is to comput the distanc of that data point from the line .
okai .
in thi case , the line is not exactli vertic .
that's the wrong wai to do it in fact .
keep in mind that the unit of the horizont direct ar year and the unit of the vertic direct ar pound .
so in what unit would thi distanc be ?
it just doesn't make sens in the context of thi problem .
instead , you measur just the vertic distanc .
that's the distanc between the predict valu and the actual valu .
to find the line that best fit the data , we us our algorithm for least squar .
we formul the problem as thi least squar problem , where we have a matrix a .
whose first column consist of the first coordin , x1 , x2 , x3 , x4 , x , <num> , and whose second column just consist of on .
the unknown ar m and b , and the right hand side vector consist of y1 , y2 , y3 , y4 , y5 .
what doe thi have to do with fit a line to data ?
note that the dot product of row i of the matrix a , with the vector m b .
is m time x i plu b , which is the predict of the line model for that particular data .
so the vector of predict is thi matrix a time the vector mb .
it's thi product .
the vector of differ between predict and observ valu therefor is a time n b minu the observ valu .
and the sum of squar of differ , that is the the measur of the error of thi of thi line is just the squar norm of thi vector .
so , the method of least squar will find us the vector m , b such that m time x plu b is the best line , the line that best fit thi data .
there ar a bunch of product , and we want to figur out how mani of each product a factori wa make by measur the resourc that thei were consum .
we had a tabl that told us for each unit of each product how much of each of these resourc wa need .
and we found out how much of each product wa made by solv the vector matrix equat , u time m equal b .
where b is the vector , given the amount of each resourc us .
so here's the vector b .
we us solv , and what we end up with is thi vector u , which give the amount of each product be us .
so that work great , except that it's realli an unrealist scenario .
when you measur someth like the amount of a resourc be us , you're probabl go to get not the exact valu but an approxim valu .
so instead of the vector b repres the true amount of each resourc be consum .
what we'll probabl get is a vector , we'll call it b tild , which is an approxim to those .
where each number here is an approxim to the true amount .
now , but solv with b tild instead of b , give us thi .
which is a realli bad answer right for exampl here the number of shooter that were manufactur were <num> but our solver came up with <num> . <num> .
it , it seem like we can't get accur output when we onli have approxim input .
slight chang in the input data lead to big chang in the output .
so that the output data's not accur and , and possibl useless to us .
so how can we improv the accuraci of the output without get more accur measur of the resourc , of the , without have more accur input .
and the answer is , we take more measur .
so , in thi , problem , we have to measur some other resourc .
thi isn't realli a resourc , but let's sai we could measur the amount of wast water produc by thi factori .
so now we get a slightli bigger tabl with on more column .
the new column tell us , for each product , how much wast water is produc per item manufactur .
now our measur ha on more number , the total amount of wast water that's produc , by the factori .
now if we look at the equat , u time m equal b tild , it's more constrain .
it is an addit equat .
as a consequ in fact sinc we're us thi approxim data thi equat ha no solut .
it's too constrain .
so what do we do ?
well , we find the least squar solut .
the least squar solut is thi which is a pretti good approxim of the real answer .
so we saw that we can get better output accuraci without improv the input accuraci by ad more equat and by us least squar .
here we want to estim the current draw for each hardwar compon in our sensor node .
we defin the domain d to consist of the name of the harder compon .
and our goal is to comput a d vector u , that for each hardwar compon give the current drawn by that compon .
we did thi by run <num> test period .
we know the total milliamper second .
for the sensor node in each of these test period , which we write in thi vector b .
and in each test period , we know how long each compon wa run .
we specifi those durat in vector durat <num> through durat <num> .
now we form a matrix , a , whose row ar the durat vector and we solv the equat , ax equal b .
if the measur we put into the vector b ar exactli accur , when we solv ax equal b , w e get back the true current draw for each of the compon .
howev , in a more realist scenario , our measur ar onli approxim .
let's call the result vector tild b .
when we solv the equat ax equal tild b , we get onli rough approxim to the true current draw of our compon .
how can we get more accur result without make more accur measur ?
we need to collect more data .
we add some test period .
here we've ad four test period and correct the origin data .
the measur ar still onli approxim .
now , when we form the matrix vector equat ax tild b , we find it ha no solut becaus of the approxim the constraint conflict with each other .
howev , we can find the least squar solut which give us more accur estim of the current draw for each hardwar compon .
onc again , collect more data and us least squar , give us more accur output without have to improv the accuraci of our input .
final , let's recal the breast cancer lab that we did .
the problem wa thi .
we had a bunch of vector , specifi featur of differ specimen and valu specifi plu on or minu on accord to whether the specimen wa malign or benign .
inform , the goal wa to find a vector , w , that help you predict whether a specimen is malign or benign from the featur vector .
and the wai it would do that is the sign of the dot product of the i , featur vector ai , with thi vector w .
is suppos to predict the sign of bi , which is whether the whether the specimen is malign or benign .
formerli , our goal wa to find the vector , w , that minim thi loss function , minim the sum of squar of the error .
and the approach we us in the lab wa gradient descent .
i don't know about you for me that took a few minut and it actual came up with an error rate of mayb <num> , <num> .
can we do better with our least squar algorithm ?
well rememb thi is the goal , to find a vector w , it minim thi sum of squar .
well we can rewrit that sum of squar as the squar norm of a vector b minu a time x .
thi is just the least squar problem .
so we can go ahead and us the algorithm base on qr factor .
it take a fraction of a second and it get a better solut , a solut with smaller error .
now thi is just the veri begin of machin learn .
you can us a lot more sophist method , to get even better solut .
such as us a differ inner product , not the dot product .
you want an inner product that reflect the the , the varianc of the variou featur .
.
you can us linear program to optim a slightli differ cost function , a slightli differ loss function .
you can even us convex program to minim some more sophist loss function .
all of thi is beyond the scope of thi cours , but now you have the ingredi so you can go learn it .
