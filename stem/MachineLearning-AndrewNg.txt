welcom to thi free onlin class on machin learn .
machin learn is on of the most excit recent technolog .
and in thi class , you learn about the state of the art and also gain practic implement and deploi these algorithm yourself .
you've probabl us a learn algorithm dozen of time a dai without know it .
everi time you us a web search engin like googl or bing to search the internet , on of the reason that work so well is becaus a learn algorithm , on implement by googl or microsoft , ha learn how to rank web page .
everi time you us facebook or appl's photo type applic and it recogn your friend' photo , that's also machin learn .
everi time you read your email and your spam filter save you from have to wade through ton of spam email , that's also a learn algorithm .
for me on of the reason i'm excit is the ai dream of somedai build machin as intellig as you or me .
we're a long wai awai from that goal , but mani ai research believ that the best wai to toward that goal is through learn algorithm that try to mimic how the human brain learn .
i'll tell you a littl bit about that too in thi class .
in thi class you learn about state of the art machin learn algorithm .
but it turn out just know the algorithm and know the math isn't that much good if you don't also know how to actual get thi stuff to work on problem that you care about .
so , we've also spent a lot of time develop exercis for you to implement each of these algorithm and see how thei work fot yourself .
so why is machin learn so preval todai ?
it turn out that machin learn is a field that had grown out of the field of ai , or artifici intellig .
we want to build intellig machin and it turn out that there ar a few basic thing that we could program a machin to do such as how to find the shortest path from a to b .
but for the most part we just did not know how to write ai program to do the more interest thing such as web search or photo tag or email anti spam .
there wa a realiz that the onli wai to do these thing wa to have a machin learn to do it by itself .
so , machin learn wa develop as a new capabl for comput and todai it touch mani segment of industri and basic scienc .
for me , i work on machin learn and in a typic week i might end up talk to helicopt pilot , biologist , a bunch of comput system peopl so my colleagu here at stanford and averag two or three time a week i get email from peopl in industri from silicon vallei contact me who have an interest in appli learn algorithm to their own problem .
thi is a sign of the rang of problem that machin learn touch .
there is autonom robot , comput biologi , ton of thing in silicon vallei that machin learn is have an impact on .
here ar some other exampl of machin learn .
there's databas mine .
on of the reason machin learn ha so pervad is the growth of the web and the growth of autom all thi mean that we have much larger data set than ever befor .
so , for exampl ton of silicon vallei compani ar todai collect web click data , also call clickstream data , and ar try to us machin learn algorithm to mine thi data to understand the user better and to serv the user better , that's a huge segment of silicon vallei right now .
medic record .
with the advent of autom , we now have electron medic record , so if we can turn medic record into medic knowledg , then we can start to understand diseas better .
comput biologi .
with autom again , biologist ar collect lot of data about gene sequenc , dna sequenc , and so on , and machin run algorithm ar give us a much better understand of the human genom , and what it mean to be human .
and in engin as well , in all field of engin , we have larger and larger , and larger and larger data set , that we're try to understand us learn algorithm .
a second rang of machineri applic is on that we cannot program by hand .
so for exampl , i've work on autonom helicopt for mani year .
we just did not know how to write a comput program to make thi helicopt fly by itself .
the onli thing that work wa have a comput learn by itself how to fly thi helicopt .
helicopt whirl handwrit recognit .
it turn out on of the reason it's so inexpens todai to rout a piec of mail across the countri , in the us and internation , is that when you write an envelop like thi , it turn out there's a learn algorithm that ha learn how to read your handwrit so that it can automat rout thi envelop on it wai , and so it cost us a few cent to send thi thing thousand of mile .
and in fact if you've seen the field of natur languag process or comput vision , these ar the field of ai pertain to understand languag or understand imag .
most of natur languag process and most of comput vision todai is appli machin learn .
learn algorithm ar also wide us for self custom program .
everi time you go to amazon or netflix or itun geniu , and it recommend the movi or product and music to you , that's a learn algorithm .
if you think about it thei have million user ; there is no wai to write a million differ program for your million user .
the onli wai to have softwar give these custom recommend is to becom learn by itself to custom itself to your prefer .
final learn algorithm ar be us todai to understand human learn and to understand the brain .
we'll talk about how research ar us thi to make progress toward the big ai dream .
a few month ago , a student show me an articl on the top twelv it skill .
the skill that inform technolog hire manag cannot sai no to .
it wa a slightli older articl , but at the top of thi list of the twelv most desir it skill wa machin learn .
here at stanford , the number of recruit that contact me ask if i know ani graduat machin learn student is far larger than the machin learn student we graduat each year .
so i think there is a vast , unfulfil demand for thi skill set , and thi is a great time to be learn about machin learn , and i hope to teach you a lot about machin learn in thi class .
in the next video , we'll start to give a more formal definit of what is machin learn .
and we'll begin to talk about the main type of machin learn problem and algorithm .
you'll pick up some of the main machin learn terminolog , and start to get a sens of what ar the differ algorithm , and when each on might be appropri .
what is machin learn ?
in thi video we will try to defin what it is and also try to give you a sens of when you want to us machin learn .
even among machin learn practition there isn't a well accept definit of what is and what isn't machin learn .
but let me show you a coupl of exampl of the wai that peopl have tri to defin it .
here's the definit of what is machin learn doe to arthur samuel .
he defin machin learn as the field of studi that give comput the abil to learn without be explicitli program .
samuel's claim to fame wa that back in the <num>'s , he wrote a checker plai program .
and the amaz thing about thi checker plai program , wa that arthur samuel himself , wasn't a veri good checker player .
but what he did wa , he had to program for it to plai <num>'s of <num>'s of game against itself .
and by watch what sort of board posit tend to lead to win , and what sort of board posit tend to lead to loss .
the checker plai program learn over time what ar good board posit and what ar bad board posit .
and eventu learn to plai checker better than arthur samuel himself wa abl to .
thi wa a remark result .
although samuel himself turn out not to be a veri good checker player .
but becaus the comput ha the patienc to plai ten of thousand of game itself .
no human , ha the patienc to plai that mani game .
by do thi the comput wa abl to get so much checker plai experi that it eventu becam a better checker player than arthur samuel himself .
thi is somewhat inform definit , and an older on .
here's a slightli more recent definit by tom mitchel , who's a friend out of carnegi mellon .
so tom defin machin learn by sai that , a well pose learn problem is defin as follow .
he sai , a comput program is said to learn from experi e , with respect to some task t , and some perform measur p , if it perform on t as measur by p improv with experi e .
i actual think he came up with thi definit just to make it rhyme .
for the checker plai exampl the experi e , will be the experi of have the program plai <num>'s of <num>'s of game against itself .
the task t , will be the task of plai checker .
and the perform measur p , will be the probabl that it win the next game of checker against some new oppon .
throughout these video , besid me try to teach you stuff , i will occasion ask you a question to make sure you understand the content .
here's on , on top is a definit of machin learn by tom mitchel .
let's sai your email program watch which email you do or do not flag as spam .
so in an email client like thi you might click thi spam button to report some email as spam , but not other email and .
base on which email you mark as spam , so your e mail program learn better how to filter spam e mail .
what is the task t in thi set ?
in a few second , the video will paus .
and when it doe so , you can us your mous to select on of these four radio button to let , to let me know which of these four you think is the right answer to thi question .
that might be a perform measur p .
and so , our task perform on the task our system's perform on the task t , on the perform measur p will improv after the experi e .
in thi class i hope to teach you about variou differ type of learn algorithm .
there ar sever differ type of learn algorithm .
the main two type ar what we call supervis learn and unsupervis learn .
i'll defin what these term mean more in the next coupl video .
but it turn out that in supervis learn , the idea is that we're go to teach the comput how to do someth , wherea in unsupervis learn we're go let it learn by itself .
don't worri if these two term don't make sens yet , in the next two video i'm go to sai exactli what these two type of learn ar .
you will also hear other buzz term such as reinforc learn and recommend system .
these ar other type of machin learn algorithm that we'll talk about later but the two most us type of learn algorithm ar probabl supervis learn and unsupervis learn and i'll defin them in the next two video and we'll spend most of thi class talk about these two type of learn algorithm .
it turn out on of the other thing we'll spend a lot of time on in thi class is practic advic for appli learn algorithm .
thi is someth that i feel pretti strongli about , and it's actual someth that i don't know of ani other univers teach .
teach about learn algorithm is like give you a set of tool , and equal import or more import to give you the tool is to teach you how to appli these tool .
i like to make an analog to learn to becom a carpent .
imagin that someon is teach you how to be a carpent and thei sai here's a hammer , here's a screwdriv , here's a saw , good luck .
well , that's no good , right ?
you , you , you have all these tool , but the more import thing , is to learn how to us these tool properli .
there's a huge differ between , between peopl that know how to us these machin learn algorithm , versu peopl who don't know how to us these tool well .
here in silicon vallei where i live , when i go visit differ compani even at the top silicon vallei compani veri often i see peopl ar try to appli machin learn algorithm to some problem and sometim thei have been go at it for six month .
but sometim when i look at what thei're do i , i , i sai , you know , i could have told them like , gee , i could have told you six month ago that you should be take a learn algorithm and appli it in like the slightli modifi wai and your chanc of success would have been much higher .
so what we're go to do in thi class is actual spend a lot of time talk about how , if you actual tri to develop a machin learn system , how to make those best practic type decis about the wai in which you build your system so that when you're appli learn algorithm you're less like to end up on of those peopl who end up pursu some path for six month that , you know , someon els could have figur out it just wasn't gonna work at all and it's just a wast of time for six month .
so i'm actual go to spend a lot of the time teach you those sort of best practic in machin learn and ai and how to get thi stuff to work and how we do it , how the best peopl do it in silicon vallei and around the world .
i hope to make you on of the best peopl in know how to design and build seriou machin learn and ai system .
so , that's machin learn and these ar the main topic i hope to teach .
in the next video , i'm go to defin what is supervis learn and after that , what is unsupervis learn .
and also , start to talk about when you would us each of them .
in thi video i am go to defin what is probabl the most common type of machin learn problem , which is supervis learn .
i'll defin supervis learn more formal later , but it's probabl best to explain or start with an exampl of what it is and we'll do the formal definit later .
let's sai you want to predict hous price .
a while back , a student collect data set from the institut of portland oregon .
and let's sai you plot a data set and it look like thi .
here on the horizont axi , the size of differ hous in squar feet , and on the vertic axi , the price of differ hous in thousand of dollar .
so .
given thi data , let's sai you have a friend who own a hous that is , sai <num> squar feet and hope to sell the hous and thei want to know how much thei can get for the hous .
so how can the learn algorithm help you ?
on thing a learn algorithm might be abl to do is put a straight line through the data or to fit a straight line to the data and , base on that , it look like mayb the hous can be sold for mayb about <num> , <num> .
but mayb thi isn't the onli learn algorithm you can us .
there might be a better on .
for exampl , instead of send a straight line to the data , we might decid that it's better to fit a quadrat function or a second order polynomi to thi data .
and if you do that , and make a predict here , then it look like , well , mayb we can sell the hous for closer to <num> , <num> .
on of the thing we'll talk about later is how to choos and how to decid do you want to fit a straight line to the data or do you want to fit the quadrat function to the data and there's no fair pick whichev on give your friend the better hous to sell .
but each of these would be a fine exampl of a learn algorithm .
so thi is an exampl of a supervis learn algorithm .
and the term supervis learn refer to the fact that we gave the algorithm a data set in which the right answer were given .
that is , we gave it a data set of hous in which for everi exampl in thi data set , we told it what is the right price so what is the actual price that , that hous sold for and the toss of the algorithm wa to just produc more of these right answer such as for thi new hous , you know , that your friend mai be try to sell .
to defin with a bit more terminolog thi is also call a regress problem and by regress problem i mean we're try to predict a continu valu output .
name the price .
so technic i guess price can be round off to the nearest cent .
so mayb price ar actual discret valu , but usual we think of the price of a hous as a real number , as a scalar valu , as a continu valu number and the term regress refer to the fact that we're try to predict the sort of continu valu attribut .
here's anoth supervis learn exampl , some friend and i were actual work on thi earlier .
let's see you want to look at medic record and try to predict of a breast cancer as malign or benign .
if someon discov a breast tumor , a lump in their breast , a malign tumor is a tumor that is harm and danger and a benign tumor is a tumor that is harmless .
so obvious peopl care a lot about thi .
let's see a collect data set and suppos in your data set you have on your horizont axi the size of the tumor and on the vertic axi i'm go to plot on or zero , ye or no , whether or not these ar exampl of tumor we've seen befor ar malign which is on or zero if not malign or benign .
so let's sai our data set look like thi where we saw a tumor of thi size that turn out to be benign .
on of thi size , on of thi size .
and so on .
and sadli we also saw a few malign tumor , on of that size , on of that size , on of that size . . .
so on .
so thi exampl . . .
i have five exampl of benign tumor shown down here , and five exampl of malign tumor shown with a vertic axi valu of on .
and let's sai we have a friend who tragic ha a breast tumor , and let's sai her breast tumor size is mayb somewher around thi valu .
the machin learn question is , can you estim what is the probabl , what is the chanc that a tumor is malign versu benign ?
to introduc a bit more terminolog thi is an exampl of a classif problem .
the term classif refer to the fact that here we're try to predict a discret valu output zero or on , malign or benign .
and it turn out that in classif problem sometim you can have more than two valu for the two possibl valu for the output .
as a concret exampl mayb there ar three type of breast cancer and so you mai try to predict the discret valu of zero , on , two , or three with zero be benign .
benign tumor , so no cancer .
and on mai mean , type on cancer , like , you have three type of cancer , whatev type on mean .
and two mai mean a second type of cancer , a three mai mean a third type of cancer .
but thi would also be a classif problem , becaus thi other discret valu set of output correspond to , you know , no cancer , or cancer type on , or cancer type two , or cancer type three .
in classif problem there is anoth wai to plot thi data .
let me show you what i mean .
let me us a slightli differ set of symbol to plot thi data .
so if tumor size is go to be the attribut that i'm go to us to predict malign or benign , i can also draw my data like thi .
i'm go to us differ symbol to denot my benign and malign , or my neg and posit exampl .
so instead of draw cross , i'm now go to draw o's for the benign tumor .
like so .
and i'm go to keep us x's to denot my malign tumor .
okai ?
i hope thi is begin to make sens .
all i did wa i took , you know , these , my data set on top and i just map it down .
to thi real line like so .
and start to us differ symbol , circl and cross , to denot malign versu benign exampl .
now , in thi exampl we us onli on featur or on attribut , mainli , the tumor size in order to predict whether the tumor is malign or benign .
in other machin learn problem when we have more than on featur , more than on attribut .
here's an exampl .
let's sai that instead of just know the tumor size , we know both the ag of the patient and the tumor size .
in that case mayb your data set will look like thi where i mai have a set of patient with those ag and that tumor size and thei look like thi .
and a differ set of patient , thei look a littl differ , whose tumor turn out to be malign , as denot by the cross .
so , let's sai you have a friend who tragic ha a tumor .
and mayb , their tumor size and ag fall around there .
so given a data set like thi , what the learn algorithm might do is throw the straight line through the data to try to separ out the malign tumor from the benign on and , so the learn algorithm mai decid to throw the straight line like that to separ out the two class of tumor .
and .
you know , with thi , hopefulli you can decid that your friend's tumor is more like to if it's over there , that hopefulli your learn algorithm will sai that your friend's tumor fall on thi benign side and is therefor more like to be benign than malign .
in thi exampl we had two featur , name , the ag of the patient and the size of the tumor .
in other machin learn problem we will often have more featur , and my friend that work on thi problem , thei actual us other featur like these , which is clump thick , the clump thick of the breast tumor .
uniform of cell size of the tumor .
uniform of cell shape of the tumor , and so on , and other featur as well .
and it turn out on of the inter , most interest learn algorithm that we'll see in thi class is a learn algorithm that can deal with , not just two or three or five featur , but an infinit number of featur .
on thi slide , i've list a total of five differ featur .
right , two on the ax and three more up here .
but it turn out that for some learn problem , what you realli want is not to us , like , three or five featur .
but instead , you want to us an infinit number of featur , an infinit number of attribut , so that your learn algorithm ha lot of attribut or featur or cue with which to make those predict .
so how do you deal with an infinit number of featur .
how do you even store an infinit number of thing on the comput when your comput is gonna run out of memori .
it turn out that when we talk about an algorithm call the support vector machin , there will be a neat mathemat trick that will allow a comput to deal with an infinit number of featur .
imagin that i didn't just write down two featur here and three featur on the right .
but , imagin that i wrote down an infinit long list , i just kept write more and more and more featur .
like an infinit long list of featur .
turn out , we'll be abl to come up with an algorithm that can deal with that .
so , just to recap .
in thi class we'll talk about supervis learn .
and the idea is that , in supervis learn , in everi exampl in our data set , we ar told what is the correct answer that we would have quit like the algorithm have predict on that exampl .
such as the price of the hous , or whether a tumor is malign or benign .
we also talk about the regress problem .
and by regress , that mean that our goal is to predict a continu valu output .
and we talk about the classif problem , where the goal is to predict a discret valu output .
just a quick wrap up question suppos you're run a compani and you want to develop learn algorithm to address each of two problem .
in the first problem , you have a larg inventori of ident item .
so imagin that you have thousand of copi of some ident item to sell and you want to predict how mani of these item you sell within the next three month .
in the second problem , problem two , you'd like you have lot of user and you want to write softwar to examin each individu of your custom's account , so each on of your custom's account ; and for each account , decid whether or not the account ha been hack or compromis .
so , for each of these problem , should thei be treat as a classif problem , or as a regress problem ?
when the video paus , pleas us your mous to select whichev of these four option on the left you think is the correct answer .
so hopefulli , you got that thi is the answer .
for problem on , i would treat thi as a regress problem , becaus if i have , you know , thousand of item , well , i would probabl just treat thi as a real valu , as a continu valu .
and treat , therefor , the number of item i sell , as a continu valu .
and for the second problem , i would treat that as a classif problem , becaus i might sai , set the valu i want to predict with zero , to denot the account ha not been hack .
and set the valu on to denot an account that ha been hack into .
so just like , you know , breast cancer , is , zero is benign , on is malign .
so i might set thi be zero or on depend on whether it's been hack , and have an algorithm try to predict each on of these two discret valu .
and becaus there's a small number of discret valu , i would therefor treat it as a classif problem .
so , that's it for supervis learn and in the next video i'll talk about unsupervis learn , which is the other major categori of learn algorithm .
in thi video , we'll talk about the second major type of machin learn problem , call unsupervis learn .
in the last video , we talk about supervis learn .
back then , recal data set that look like thi , where each exampl wa label either as a posit or neg exampl , whether it wa a benign or a malign tumor .
so for each exampl in supervis learn , we were told explicitli what is the so call right answer , whether it's benign or malign .
in unsupervis learn , we're given data that look differ than data that look like thi that doesn't have ani label or that all ha the same label or realli no label .
so we're given the data set and we're not told what to do with it and we're not told what each data point is .
instead we're just told , here is a data set .
can you find some structur in the data ?
given thi data set , an unsupervis learn algorithm might decid that the data live in two differ cluster .
and so there's on cluster and there's a differ cluster .
and ye , supervis learn algorithm mai break these data into these two separ cluster .
so thi is call a cluster algorithm .
and thi turn out to be us in mani place .
on exampl where cluster is us is in googl new and if you have not seen thi befor , you can actual go to thi url new . googl . com to take a look .
what googl new doe is everydai it goe and look at ten of thousand or hundr of thousand of new stori on the web and it group them into cohes new stori .
for exampl , let's look here .
the url here link to differ new stori about the bp oil well stori .
so , let's click on on of these url's and we'll click on on of these url's .
what i'll get to is a web page like thi .
here's a wall street journal articl about , you know , the bp oil well spill stori of bp kill macondo , which is a name of the spill and if you click on a differ url from that group then you might get the differ stori .
here's the cnn stori about a game , the bp oil spill , and if you click on yet a third link , then you might get a differ stori .
here's the uk guardian stori about the bp oil spill .
so what googl new ha done is look for ten of thousand of new stori and automat cluster them togeth .
so , the new stori that ar all about the same topic get displai togeth .
it turn out that cluster algorithm and unsupervis learn algorithm ar us in mani other problem as well .
here's on on understand genom .
here's an exampl of dna microarrai data .
the idea is put a group of differ individu and for each of them , you measur how much thei do or do not have a certain gene .
technic you measur how much certain gene ar express .
so these color , red , green , grai and so on , thei show the degre to which differ individu do or do not have a specif gene .
and what you can do is then run a cluster algorithm to group individu into differ categori or into differ type of peopl .
so thi is unsupervis learn becaus we're not tell the algorithm in advanc that these ar type <num> peopl , those ar type <num> person , those ar type <num> person and so on and instead what were sai is yeah here's a bunch of data .
i don't know what's in thi data .
i don't know who's and what type .
i don't even know what the differ type of peopl ar , but can you automat find structur in the data from the you automat cluster the individu into these type that i don't know in advanc ?
becaus we're not give the algorithm the right answer for the exampl in my data set , thi is unsupervis learn .
unsupervis learn or cluster is us for a bunch of other applic .
it's us to organ larg comput cluster .
i had some friend look at larg data center , that is larg comput cluster and try to figur out which machin tend to work togeth and if you can put those machin togeth , you can make your data center work more effici .
thi second applic is on social network analysi .
so given knowledg about which friend you email the most or given your facebook friend or your googl circl , can we automat identifi which ar cohes group of friend , also which ar group of peopl that all know each other ?
market segment .
mani compani have huge databas of custom inform .
so , can you look at thi custom data set and automat discov market segment and automat group your custom into differ market segment so that you can automat and more effici sell or market your differ market segment togeth ?
again , thi is unsupervis learn becaus we have all thi custom data , but we don't know in advanc what ar the market segment and for the custom in our data set , you know , we don't know in advanc who is in market segment on , who is in market segment two , and so on .
but we have to let the algorithm discov all thi just from the data .
final , it turn out that unsupervis learn is also us for surprisingli astronom data analysi and these cluster algorithm give surprisingli interest us theori of how galaxi ar born .
all of these ar exampl of cluster , which is just on type of unsupervis learn .
let me tell you about anoth on .
i'm gonna tell you about the cocktail parti problem .
so , you've been to cocktail parti befor , right ?
well , you can imagin there's a parti , room full of peopl , all sit around , all talk at the same time and there ar all these overlap voic becaus everyon is talk at the same time , and it is almost hard to hear the person in front of you .
so mayb at a cocktail parti with two peopl , two peopl talk at the same time , and it's a somewhat small cocktail parti .
and we're go to put two microphon in the room so there ar microphon , and becaus these microphon ar at two differ distanc from the speaker , each microphon record a differ combin of these two speaker voic .
mayb speaker on is a littl louder in microphon on and mayb speaker two is a littl bit louder on microphon <num> becaus the <num> microphon ar at differ posit rel to the <num> speaker , but each microphon would caus an overlap combin of both speaker' voic .
so here's an actual record of two speaker record by a research .
let me plai for you the first , what the first microphon sound like .
on uno , two do , three tre , four cuatro , five cinco , six sei , seven siet , eight ocho , nine nuev , ten y diez .
all right , mayb not the most interest cocktail parti , there's two peopl count from on to ten in two languag but you know .
what you just heard wa the first microphon record , here's the second record .
uno on , do two , tre three , cuatro four , cinco five , sei six , siet seven , ocho eight , nuev nine y diez ten .
so we can do , is take these two microphon record and give them to an unsupervis learn algorithm call the cocktail parti algorithm , and tell the algorithm find structur in thi data for you .
and what the algorithm will do is listen to these audio record and sai , you know it sound like the two audio record ar be ad togeth or that have be sum togeth to produc these record that we had .
moreov , what the cocktail parti algorithm will do is separ out these two audio sourc that were be ad or be sum togeth to form other record and , in fact , here's the first output of the cocktail parti algorithm .
on , two , three , four , five , six , seven , eight , nine , ten .
so , i separ out the english voic in on of the record .
and here's the second of it .
uno , do , tre , quatro , cinco , sei , siet , ocho , nuev y diez .
not too bad , to give you on more exampl , here's anoth record of anoth similar situat , here's the first microphon on , two , three , four , five , six , seven , eight , nine , ten .
ok so the poor gui's gone home from the cocktail parti and he 's now sit in a room by himself talk to hi radio .
here's the second microphon record .
on , two , three , four , five , six , seven , eight , nine , ten .
when you give these two microphon record to the same algorithm , what it doe , is again sai , you know , it sound like there ar two audio sourc , and moreov , the album sai , here is the first of the audio sourc i found .
on , two , three , four , five , six , seven , eight , nine , ten .
so that wasn't perfect , it got the voic , but it also got a littl bit of the music in there .
then here's the second output to the algorithm .
not too bad , in that second output it manag to get rid of the voic entir .
and just , you know , clean up the music , got rid of the count from on to ten .
so you might look at an unsupervis learn algorithm like thi and ask how complic thi is to implement thi , right ?
it seem like in order to , you know , build thi applic , it seem like to do thi audio process you need to write a ton of code or mayb link into like a bunch of synthes java librari that process audio , seem like a realli complic program , to do thi audio , separ out audio and so on .
it turn out the algorithm , to do what you just heard , that can be done with on line of code shown right here .
it take research a long time to come up with thi line of code .
i'm not sai thi is an easi problem , but it turn out that when you us the right program environ , mani learn algorithm can be realli short program .
so thi is also why in thi class we're go to us the octav program environ .
octav , is free open sourc softwar , and us a tool like octav or matlab , mani learn algorithm becom just a few line of code to implement .
later in thi class , i'll just teach you a littl bit about how to us octav and you'll be implement some of these algorithm in octav .
or if you have matlab you can us that too .
it turn out the silicon vallei , for a lot of machin learn algorithm , what we do is first prototyp our softwar in octav becaus softwar in octav make it incred fast to implement these learn algorithm .
here each of these function like for exampl the svd function that stand for singular valu decomposit ; but that turn out to be a linear algebra routin , that is just built into octav .
if you were try to do thi in c or java , thi would be mani mani line of code link complex c or java librari .
so , you can implement thi stuff as c or java or python , it's just much more complic to do so in those languag .
what i've seen after have taught machin learn for almost a decad now , is that , you learn much faster if you us octav as your program environ , and if you us octav as your learn tool and as your prototyp tool , it'll let you learn and prototyp learn algorithm much more quickli .
and in fact what mani peopl will do to in the larg silicon vallei compani is in fact , us an algorithm like octav to first prototyp the learn algorithm , and onli after you've gotten it to work , then you migrat it to c or java or whatev .
it turn out that by do thing thi wai , you can often get your algorithm to work much faster than if you were start out in c .
so , i know that as an instructor , i get to sai trust me on thi on onli a finit number of time , but for those of you who've never us these octav type program environ befor , i am go to ask you to trust me on thi on , and sai that you , you will , i think your time , your develop time is on of the most valuabl resourc .
and have seen lot of peopl do thi , i think you as a machin learn research , or machin learn develop will be much more product if you learn to start in prototyp , to start in octav , in some other languag .
final , to wrap up thi video , i have on quick review question for you .
we talk about unsupervis learn , which is a learn set where you give the algorithm a ton of data and just ask it to find structur in the data for us .
of the follow four exampl , which on , which of these four do you think would will be an unsupervis learn algorithm as oppos to supervis learn problem .
for each of the four check box on the left , check the on for which you think unsupervis learn algorithm would be appropri and then click the button on the lower right to check your answer .
so when the video paus , pleas answer the question on the slide .
so , hopefulli , you've rememb the spam folder problem .
if you have label data , you know , with spam and non spam e mail , we'd treat thi as a supervis learn problem .
the new stori exampl , that's exactli the googl new exampl that we saw in thi video , we saw how you can us a cluster algorithm to cluster these articl togeth so that's unsupervis learn .
the market segment exampl i talk a littl bit earlier , you can do that as an unsupervis learn problem becaus i am just gonna get my algorithm data and ask it to discov market segment automat .
and the final exampl , diabet , well , that's actual just like our breast cancer exampl from the last video .
onli instead of , you know , good and bad cancer tumor or benign or malign tumor we instead have diabet or not and so we will us that as a supervis , we will solv that as a supervis learn problem just like we did for the breast tumor data .
so , that's it for unsupervis learn and in the next video , we'll delv more into specif learn algorithm and start to talk about just how these algorithm work and how we can , how you can go about implement them .
by now you have seen a lot of differ learn algorithm .
and if you've been follow along these video you should consid yourself an expert on mani state of the art machin learn techniqu .
but even among peopl that know a certain learn algorithm .
there's often a huge differ between someon that realli know how to powerfulli and effect appli that algorithm , versu someon that's less familiar with some of the materi that i'm about to teach and who doesn't realli understand how to appli these algorithm and can end up wast a lot of their time try thing out that don't realli make sens .
what i would like to do is make sure that if you ar develop machin learn system , that you know how to choos on of the most promis avenu to spend your time pursu .
and on thi and the next few video i'm go to give a number of practic suggest , advic , guidelin on how to do that .
and concret what we'd focu on is the problem of , suppos you ar develop a machin learn system or try to improv the perform of a machin learn system , how do you go about decid what ar the proxi avenu to try next ?
to explain thi , let's continu us our exampl of learn to predict hous price .
and let's sai you've implement and regular linear regress .
thu minim that cost function j .
now suppos that after you take your learn paramet , if you test your hypothesi on the new set of hous , suppos you find that thi is make huge error in thi predict of the hous price .
the question is what should you then try mix in order to improv the learn algorithm ?
there ar mani thing that on can think of that could improv the perform of the learn algorithm .
on thing thei could try , is to get more train exampl .
and concret , you can imagin , mayb , you know , set up phone survei , go door to door , to try to get more data on how much differ hous sell for .
and the sad thing is i've seen a lot of peopl spend a lot of time collect more train exampl , think oh , if we have twice as much or ten time as much train data , that is certainli go to help , right ?
but sometim get more train data doesn't actual help and in the next few video we will see why , and we will see how you can avoid spend a lot of time collect more train data in set where it is just not go to help .
other thing you might try ar to well mayb try a smaller set of featur .
so if you have some set of featur such as x1 , x2 , x3 and so on , mayb a larg number of featur .
mayb you want to spend time carefulli select some small subset of them to prevent overfit .
or mayb you need to get addit featur .
mayb the current set of featur aren't inform enough and you want to collect more data in the sens of get more featur .
and onc again thi is the sort of project that can scale up the huge project can you imagin get phone survei to find out more hous , or extra land survei to find out more about the piec of land and so on , so a huge project .
and onc again it would be nice to know in advanc if thi is go to help befor we spend a lot of time do someth like thi .
we can also try ad polynomi featur thing like x2 squar x2 squar and product featur x1 , x2 .
we can still spend quit a lot of time think about that and we can also try other thing like decreas lambda , the regular paramet or increas lambda .
given a menu of option like these , some of which can easili scale up to six month or longer project .
unfortun , the most common method that peopl us to pick on of these is to go by gut feel .
in which what mani peopl will do is sort of randomli pick on of these option and mayb sai , oh , let go and get more train data . and easili spend six month collect more train data or mayb someon els would rather be sai , well , let's go collect a lot more featur on these hous in our data set . and i have a lot of time , sadli seen peopl spend , you know , liter <num> month do on of these avenu that thei have sort of at random onli to discov six month later that that realli wasn't a promis avenu to pursu .
fortun , there is a pretti simpl techniqu that can let you veri quickli rule out half of the thing on thi list as be potenti promis thing to pursu .
and there is a veri simpl techniqu , that if you run , can easili rule out mani of these option , and potenti save you a lot of time pursu someth that's just is not go to work .
in the next two video after thi , i'm go to first talk about how to evalu learn algorithm .
and in the next few video after that , i'm go to talk about these techniqu , which ar call the machin learn diagnost .
and what a diagnost is , is a test you can run , to get insight into what is or isn't work with an algorithm , and which will often give you insight as to what ar promis thing to try to improv a learn algorithm's perform .
we'll talk about specif diagnost later in thi video sequenc .
but i should mention in advanc that diagnost can take time to implement and can sometim , you know , take quit a lot of time to implement and understand but do so can be a veri good us of your time when you ar develop learn algorithm becaus thei can often save you from spend mani month pursu an avenu that you could have found out much earlier just wa not go to be fruit .
so in the next few video , i'm go to first talk about how evalu your learn algorithm and after that i'm go to talk about some of these diagnost which will hopefulli let you much more effect select more of the us thing to try mix if your goal to improv the machin learn system .
in thi video , i would like to talk about how to evalu a hypothesi that ha been learn by your algorithm .
in later video , we will build on thi to talk about how to prevent in the problem of overfit and underfit as well .
when we fit the paramet of our learn algorithm we think about choos the paramet to minim the train error .
on might think that get a realli low valu of train error might be a good thing , but we have alreadi seen that just becaus a hypothesi ha low train error , that doesn't mean it is necessarili a good hypothesi .
and we've alreadi seen the exampl of how a hypothesi can overfit .
and therefor fail to gener the new exampl not in the train set .
so how do you tell if the hypothesi might be overfit .
in thi simpl exampl we could plot the hypothesi h of x and just see what wa go on .
but in gener for problem with more featur than just on featur , for problem with a larg number of featur like these it becom hard or mai be imposs to plot what the hypothesi look like and so we need some other wai to evalu our hypothesi .
the standard wai to evalu a learn hypothesi is as follow .
suppos we have a data set like thi .
here i have just shown <num> train exampl , but of cours usual we mai have dozen or hundr or mayb thousand of train exampl .
in order to make sure we can evalu our hypothesi , what we ar go to do is split the data we have into two portion .
the first portion is go to be our usual train set and the second portion is go to be our test set , and a pretti typic split of thi all the data we have into a train set and test set might be around sai a <num> , <num> split .
worth more todai to grade the train set and rel less to the test set .
and so now , if we have some data set , we run a sine of sai <num> of the data to be our train set where here m is as usual our number of train exampl and the remaind of our data might then be assign to becom our test set .
and here , i'm go to us the notat m subscript test to denot the number of test exampl .
and so in gener , thi subscript test is go to denot exampl that come from a test set so that x1 subscript test , y1 subscript test is my first test exampl which i guess in thi exampl might be thi exampl over here .
final , on last detail wherea here i've drawn thi as though the first <num> goe to the train set and the last <num> to the test set .
if there is ani sort of ordinari to the data .
that should be better to send a random <num> of your data to the train set and a random <num> of your data to the test set .
so if your data were alreadi randomli sort , you could just take the first <num> and last <num> that if your data were not randomli order , it would be better to randomli shuffl or to randomli reorder the exampl in your train set .
befor you know send the first <num> in the train set and the last <num> of the test set .
here then is a fairli typic procedur for how you would train and test the learn algorithm and the learn regress .
first , you learn the paramet theta from the train set so you minim the usual train error object j of theta , where j of theta here wa defin us that <num> of all the data you have .
there is onli the train data .
and then you would comput the test error .
and i am go to denot the test error as j subscript test .
and so what you do is take your paramet theta that you have learn from the train set , and plug it in here and comput your test set error .
which i am go to write as follow .
so thi is basic the averag squar error as measur on your test set .
it's pretti much what you'd expect .
so if we run everi test exampl through your hypothesi with paramet theta and just measur the squar error that your hypothesi ha on your m subscript test , test exampl .
and of cours , thi is the definit of the test set error if we ar us linear regress and us the squar error metric .
how about if we were do a classif problem and sai us logist regress instead .
in that case , the procedur for train and test sai logist regress is pretti similar first we will do the paramet from the train data , that first <num> of the data .
and it will comput the test error as follow .
it's the same object function as we alwai us but we just logist regress , except that now is defin us our m subscript test , test exampl .
while thi definit of the test set error j subscript test is perfectli reason .
sometim there is an altern test set metric that might be easier to interpret , and that's the misclassif error .
it's also call the zero on misclassif error , with zero on denot that you either get an exampl right or you get an exampl wrong .
here's what i mean .
let me defin the error of a predict .
that is h of x .
and given the label y as equal to on if my hypothesi output the valu greater than equal to five and y is equal to zero or if my hypothesi output a valu of less than <num> and y is equal to on , right , so both of these case basic respond to if your hypothesi mislabel the exampl assum your threshold at an <num> .
so either thought it wa more like to be <num> , but it wa actual <num> , or your hypothesi store wa more like to be <num> , but the label wa actual <num> .
and otherwis , we defin thi error function to be zero .
if your hypothesi basic classifi the exampl y correctli .
we could then defin the test error , us the misclassif error metric to be on of the m test of sum from i equal on to m subscript test of the error of h of x i test comma y i .
and so that's just my wai of write out that thi is exactli the fraction of the exampl in my test set that my hypothesi ha mislabel .
and so that's the definit of the test set error us the misclassif error of the <num> <num> misclassif metric .
so that's the standard techniqu for evalu how good a learn hypothesi is .
in the next video , we will adapt these idea to help us do thing like choos what featur like the degre polynomi to us with the learn algorithm or choos the regular paramet for learn algorithm .
suppos you like to decid what degre of polynomi to fit to a data set , sort of what featur to includ to give you a learn algorithm .
or suppos you'd like to choos the regular paramet lambda for the learn algorithm .
how do you do that ?
these ar call model select problem .
and in our discuss of how to do thi we'll talk about not just how to split your data into a train and test set but how to split your data into what we'll discov is call the train valid and test set .
we'll see in thi video just what these thing ar and how to us them to do model select .
we've alreadi seen a lot of time the problem of overfit , in which just becaus the learn algorithm fit a train set well , that doesn't mean there's a good hypothesi .
more gener , thi is why the train set error is not a good predictor for how well the hypothesi will do on new exampl .
concret , if you fit some set of paramet theta <num> , theta <num> , theta <num> and so on to your train set then , the fact that your hypothesi doe well in the train set , well , thi doesn't mean much in term of predict how well your hypothesi will gener to new exampl not seen in the train set .
and the more gener princip is that , onc your paramet were fit to some set of data mayb the train set , mayb someth els then the error of your hypothesi as measur on that same data set , such as the train error , that's unlik to be a good estim of your actual gener error , that is , of how well the hypothesi will gener to new exampl .
now let's consid the model select problem .
let's sai you try to choos what degre polynomi to fit to data .
so , you should you choos a linear function , a quadrat function , a cubic function , all the wai up to a 10th power polynomi ?
so it's as if there's on extra paramet in thi algorithm , which i'm go to denot d , which is what degre of polynomi do you want to pick ?
so it is as if doe thi , in addit to the theta paramet it's as if there's on more paramet d that your try to determin us your data cell .
the first option is d equal <num> , which is for the linear function we can choos d equal <num> , d equal <num> , all the wai up to d equal <num> , so we would like to fit thi extra sort of paramet , which i am denot by d , and concret , let's sai that you want to choos a model , that is choos a degre of polynomi choos on off these ten model , and fit that model and also get some estim of how well your fit hypothesi will gener to new exampl .
here's on thing you could do you could take your first model and minim the train error and thi would give you some paramet vector theta , and you can then take your second model , the quadrat function and for that your train set and thi will give you some other paramet vector theta .
in order to distinguish between these differ paramet vector , i'm go to us a superscript <num> , superscript <num> there where theta superscript <num> just mean the paramet i get by fit thi model to my train data , and theta superscript <num> just mean the paramet i get by fit thi quadrat function to my train ata and so on .
and by fit a cubic model i get paramet theta <num> up to , you know , sai theta <num> .
and on thing we could do is then take these paramet and look at the test set error .
so i can comput on my test set , j test of <num> , j test of theta <num> and so on , j test of theta <num> and so on .
so i'm go to take each of my hypothesi with the correspond and just measur the perform on the test set .
now on thing i could do then is , in order to select on of these model , i could then see which model ha the lowest test set error , and let just sai for thi exampl , that i end up choos the fifth order polynomi .
so thi seem reason so far .
by now , let sai , i want to take my fit hypothesi , thi fifth order model and let's sai i want to ask how well thi model gener .
on thing i could do is look at how well my fifth order polynomi hypothesi , had done on my test set .
but the problem is thi will not to be a fair estim of how well my hypothesi gener .
and the reason is , what we've done is , we've fit thi extra the paramet d , that is thi degre of polynomi , and we'll fit that paramet d us the test set .
name , we chose the valu of d that gave us the best possibl perform on the test set , and so , the perform of my paramet vector theta five on the test set , that's like to be to be an overli optimist estim of gener error .
right ?
so that becaus i have fit thi paramet d to my test set , it is no longer fair to evalu my hypothesi on thi test set .
that's becaus i've fit my paramet to the test set .
i've chosen the degre d of polynomi us the test set .
and so our hypothesi is like to do better on thi test set than it would on new exampl that it hasn't seen befor and that's which is what we hear about .
so , just to reiter on the previou slide we saw that if we fit some set of paramet , sai theta <num> , theta <num> , and so on , to some train set , then the perform of the fit model on the train set is not predict of how well the hypothesi we gener the new exampl ; is becaus these paramet would fit to the train set .
so thei ar like to do well on the train set , even if the paramet don't do well on other exampl .
and in the procedur i've just describ on thi slide , we've just done the same thing and specif what we did is we fit thi paramet d to the test set .
and by have fit the paramet to the test set , thi mean that the perform of the hypothesi on that test set mai not be a fair estim of how well the hypothesi is like to do on exampl we haven't seen befor .
to address thi problem in a model select set , if we want to evalu a hypothesi thi is usual what we do instead .
given the data set , instead of just split it into a train and test set , what we ar go to do is instead split it into three piec .
and the first piec is go to be call the train set as usual .
so you call thi first part , the train set , and then were go to coddl the second piec of data , which is call the cross valid set , and i'm go to abbrevi cross valid cv , and the second piec of thi data , i'm go to call the cross valid set cross valid , and i am go to abbrevi cross valid as cv .
sometim it's also call the valid set , instead of cross valid set .
and then the last part i am go to call my usual test set .
and the pretti typic ratio i wish to split these thing ; would be to send <num> of your data to your train set , mayb <num> to your cross valid set , and <num> to your test set .
and these number can vari a littl bit but thi sort of ratio will be pretti typic .
and so our train set will now be onli , mayb <num> of the data , and our cross valid set or our valid set will have some number of exampl .
i'm go to denot that m subscript cv , so that's the number of cross valid exampl .
and as follow our earlier notat convent , i'm go to us xicv , yicv .
follow our earlier notat convent i'm go to us xicv , yicv to denot the i cross valid exampl .
and final we also have a test set over here ; with m subscript test , be the number of test exampl .
so , now that we have defin the train valid or cross valid and test set , we can also defin the train error , cross valid error , and test error .
so here's my train error , and i'm just write thi as j j subscript train of theta .
thi is pretti much the same thing .
it's usual the same thing as the j of theta that we'll be write so far , thi is just a train set error you gui measur on your train set .
and then j subscript cv is my caus valid error is pretti much what you'd expect .
just select the train error , except measur it on the cross valid data set , and here's my test set error , same as befor .
so when theta with the model select problem like thi is , instead of us the test set to select the model , we're instead go to us valid set or the cross valid set to select the model .
concret , we're go to first take our first hypothesi , take thi first model and sai , minim the co function , and thi would give me some paramet vector theta for the linear model and as befor i'm go to put the superscript <num> just to denot that thi is a paramet for the linear model .
we do the same thing for the quadrat model , get some paramet vector theta <num> , get some paramet vector there <num> , and so on down to , sai , the tenth by the polynomi , and what we i'm go to do is , instead of test these hypothesi on the test set , instead i'm go to test them on the cross valid set .
i'm go to measur j subscript cv , to see how well each of these hypothesi do on my cross valid set and then i'm go to pick the hypothesi with the lowest cross valid error .
so for thi exampl , let's sai for the sake of argument that it wa my fourth order polynomi that had the lowest cross valid error .
so in that case , i'm go to pick thi fourth order polynomi model and final what thi mean is that that paramet d , rememb d wa the degre of polynomi , right d equal <num> , d equal <num> , up to d equal <num> .
what we've done is we fit that paramet d , and we'll set d equal <num> , and we did so us the cross valid set .
and so thi degre of polynomi , so the paramet is no longer fit to the test set .
and so we've now save a wai the test set and we can us the test set to measur or to estim the gener error of the model that wa select by thi algorithm .
so , that wa model select and how you can take your data and split it into a train valid and test set , and us your cross valid data to select model and evalu it on the test set .
on final note i should sai that in the machin learn as of thi practic todai , there ar mani peopl that will do that earli thing that i talk about , and said that isn't such a good idea of select your model us the test set and thei're us the same test set to report the error , as though select your degre of polynomi on the test set , and then report the error on the test set as though that were good estim of gener error .
that sort of practic is unfortun mani peopl do do it ; and if you have a massiv massiv test set is mayb not a terribl thing to do , but most practition of machin learn tend to advis against that and is consid better practic to have separ train valid of test set .
i'll just warn you that just sometim peopl do you know , us the same data for the purpos of the valid set and for the purpos of the test set .
you onli have a train set and the test set and that's becaus that's good practic .
so , you will see some peopl do it but if possibl i will recommend against do .
if you run the learn algorithm and it doesn't do as well as you ar hope , almost all the time it will be becaus you have either a high bia problem or a high varianc problem .
in other word thei're either an underfit problem or an overfit problem .
and in thi case it's veri import to figur out which of these two problem is bia or varianc or a bit of both that you actual have .
becaus know which of these two thing is happen would give a veri strong indic for whether the us and promis wai to try to improv your algorithm .
in thi video , i would like to delv more deepli into thi bia and variou issu and understand them better as well as figur out how to look at and evalu know whether or not we might have a bia problem or a varianc problem .
sinc thi would be critic to figur out how to improv the perform of learn algorithm that you implement .
so you've alreadi seen thi figur a few time , where if you fit two simpl hypothesi , like a straight line that that underfit the data .
if you fit a two complex hypothesi , then that might fit the train set perfectli but overfit the data and thi mai be hypothesi of some intermedi level of complex , of some , mayb degre two polynomi ar not too low and not too high degre .
that's just right .
and give you the best gener error out of these option .
now that we're arm with the notion of train and valid in test set , we can understand the concept of bia and varianc a littl bit better .
concret , let our train error and cross valid error be defin as in the previou video , just sai , the squar error , the averag squar error as measur on the <num> set or as measur on the cross valid set .
now let's plot the follow figur .
on the horizont axi i am go to plot the degre of polynomi , so as i go the right i'm go to be fit higher and higher order polynomi .
so , we'll do that for thi figur , where mayb d equal <num> , were go to be fit veri simpl function where as we ar the right of thi thi mai be d equal <num> or rel mai be even larger number .
i'm go to be fit veri complex high order polynomi that might fit the train set with much more complex function wherea we're here on the right of the horizont axi , i have much larger valu of these of a much higher degre polynomi , and so here that is go to correspond to fit much more complex function to your train set .
let's look at the train error and caus valid error and plot them on thi figur .
let's start with the train error .
as we increas the degre of the polynomi , we're go to fit our train set better and better and so , if d equal <num> that ever rose to the high train error .
if we have a veri high degre of polynomi , our train error is go to be realli low .
mayb even zero , becaus it will fit the train set realli well .
and so as we increas of the greater polynomi we find typic that the train error decreas , so i'm go to write j subscript train of theta there , becaus our train error tend to decreas with the degre of the polynomi that we fit to the data .
next , let's look at the cross valid error .
often that matter , if we look at the test set error we'll get a pretti similar result as if we were to plot the cross valid error .
so , we know that if d equal <num> , we're fit a veri simpl function , and so we mai be underfit the train set , and so we're go to go veri high cross valid error .
if we fit , you know , an intermedi degre polynomi ; we have a d equal <num> in our exampl in the previou slide , we ar go to have a much lower cross valid error , becaus we ar just fit , find a much better fit to the data .
and convers if d were too high , so if d took on sai a valu of four , then we're again overfit and so we end up with a high valu for cross valid error .
so if you were to vari thi smoothli and plot a curv you might end up with a curv like that , where that's jcv of theta , and again if you plot j test of theta you get someth veri similar .
and so thi sort of plot also help us to better understand the notion of bia and varianc .
concret , if you have a learn algorithm that's not perform as well as you want it to , how can you figur out if your learn algorithm is suffer .
concretli , suppos you have appli a learn algorithm and it is not perform as well as your ar hope , so your cross valid set error or your test set error is high .
how can we figur out if the learn algorithm is suffer from high bia or if it is suffer from high varianc .
so the set of a cross valid error be high correspond to either thi regim or thi regim .
so thi regim on the left correspond to a high bia problem , that is , if you ar fit an overli low order polynomi such as a plu on , when we realli need a higher order polynomi to fit the data .
wherea in contrast , thi regim correspond to a high varianc problem .
that is , if d the degre of polynomi wa too larg for the data set that we have .
and thi figur give us a clue for how to distinguish between these two case .
concret , for the high bia case , that is , the case of under fit , what we find is that both the cross valid error and the train error ar go to be high .
so , if your algorithm is suffer from a bia problem , the train set error would be high and you mai find that the cross valid error will also be high .
it might be close , mayb just slightli higher then a train error .
and so , if you see thi combin , that's a sign that your algorithm mai be suffer from high bia .
in contrast ; if your algorithm is suffer from high varianc ; then , if you look here , we'll notic that , j train , that is the train error , is go to be low .
that is , you're fit the train set veri well .
wherea , your cross valid error , assum that thi sai the squar error which we're try to minim .
wherea in contrast ; your error on a cross valid set or your cross function like cross valid set , will be much bigger than your train set error .
thi doubl greater than sign , here , it mean much bigger than , all right .
so , it's much greater than to multipli great to great .
so thi is a doubl greater than sign , that is the map symbol for much greater than denot by two greater than sign .
and so if you see thi combin , then what you find .
and so if you see thi combin of valu , then that is a clue that your learn algorithm mai be suffer from high varianc and might be overfit .
and the kei that distinguish these two case is if you have a high bia problem your train set error will also be high as your hypothesi just not fit the train set well .
and if you have a high varianc problem , your train set error will usual be low , that is much lower than the cross valid error .
so , hopefulli that give you a somewhat better understand of the two problem of bia and varianc .
i still have a lot more to sai about bia and varianc in the next few video .
but what we will see later ; is that by diagnos , whether a learn algorithm mai be suffer from high bia or a high varianc .
i'll show you even more detail on how to do that in later video .
we'll see that by figur out whether a learn algorithm mai be suffer from high bia or a combin of both that that would give us much better guidanc for what might be promis thing to try in order to improv the perform of the learn algorithm .
you've seen how regular can help prevent overfit , but how doe it affect the bia and varianc of a learn algorithm ?
in thi video , i like to go deeper into the issu of bia and varianc , and talk about how it interact with , and is effect by , the regular of your learn algorithm .
suppos we fit a linear regress model with a veri high order polynomi , but to prevent overfit , we ar go to us regular as shown here .
suppos we're fit a high order polynomi like that shown here , but to prevent overfit , we're go to us regular , like that shown here , so we have thi regular term to try to keep the valu of the paramet small .
and as usual , the regular sum from j equal <num> to m rather than j equal <num> to m .
let's consid three case .
the first is the case of a veri larg valu of the regular paramet lambda , such as if lambda were equal to <num> , 000s of huge valu .
in thi case , all of these paramet , theta <num> , theta <num> , theta <num> and so on will be heavili penal and so , what end up with most of these paramet valu be close to <num> and the hypothesi will be roughli h or x just equal or approxim equal to theta <num> , and so we end up a hypothesi that more or less look like that .
thi is more or less a flat , constant straight line .
and so thi hypothesi ha high bia and a valu underfit thi data set .
so the horizont straight line is just not a veri good model for thi data set .
at the other extrem beam is if we have a veri small valu of lambda , such as if lambda were equal to <num> .
in that case , given that we're fit a high order polynomi , thi is a usual overfit set .
in that case , given that we're fit a high order polynomi , basic without regular or with veri minim regular , we end up with our usual high varianc , overfit set , becaus basic if lambda is equal to zero , we ar just fit with our regular so that overfit the hypothesi and is onli if we have some intermedi valu of lambda that is neither too larg nor too small that we end up with paramet theta that we end up that give us a reason fit to thi data .
so how can we automat choos a good valu for the regular paramet lambda ?
just to reiter , here is our model and here is our learn algorithm subject .
for the set where we're us regular , let me defin j train of theta to be someth differ to be the optim object but without the regular term .
previous , in earlier video when we ar not us regular , i defin j train of theta to be the same as j of theta as the cost function but when we ar us regular with thi extra lambda term we're go to defin j train my train set error , to be just my sum of squar error on the train set , or my averag squar error on the train set without take into account that regular chart .
and similarli , i'm then also go to defin the cross valid set error when the test set error , as befor to be the averag sum of squar error on the cross valid and the test set .
so just to summar , my definit of j train and j c v and j test ar just the averag squar error , or on half of the averag squar error on my train valid and test set without the extra regular chart .
so , thi is how we can automat choos the regular paramet lambda .
what i usual do is mai be have some rang of valu of lambda i want to try it .
so i might be consid not us regular , or here ar a few valu i might try .
i might be consid along becaus of o1 , o2 from o4 and so on .
and you know , i usual step these up in multipl of two until some mayb larger valu thi in multipl of two you i actual end up with <num> . <num> ; it's ten exactli , but you know , thi is close enough and the <num> decim place won't affect your result that much .
so , thi give me , mayb twelv differ model , that i'm try to select amongst , correspond to <num> differ valu of the regular paramet lambda and of cours , you can also go to valu less than <num> . <num> or valu larger than <num> , but i've just truncat it here for conveni .
given each of these <num> model , what we can do is then the follow we take thi first model with lambda equal <num> , and minim my co function j of theta and thi would give me some paramet vector theta and similar to the earlier video , let me just denot thi as theta superscript <num> .
and then i can take my second model , with lambda set to <num> . <num> and minim my co function , now us lambda equal <num> . <num> of cours , to get some differ paramet vector theta , we need to know that theta <num> , and for that i end up with theta <num> so that thi is correct for my third model , and so on , until for for my final model with lambda set to <num> , or <num> . <num> , or i end up with thi theta <num> .
next i can take all of these hypothes , all of these paramet , and us my cross valid set to evalu them .
so i can look at my first model , my second model , fit with these differ valu of the regular paramet and evalu them on my cross valid set basic measur the averag squar error of each of these paramet vector theta on my cross valid set .
and i would then pick whichev on of these <num> model give me the lowest error on the cross valid set .
and let's sai , for the sake of thi exampl , that i end up pick theta <num> , the fifth order polynomi , becaus that ha the noah's cross valid error .
have done that , final , what i would do if i want to report a test set error is to take the paramet theta <num> that i've select and look at how well it doe on my test set .
and onc again here is as if we fit thi paramet theta to my cross valid set , which is why i am save asid a separ test set that i am go to us to get a better estim of how well my a paramet vector theta will gener to previous unseen exampl .
so that's model select appli to select the regular paramet lambda .
the last thing i'd like to do in thi video , is get a better understand of how cross valid and train error vari as we as we vari the regular paramet lambda .
and so just a remind , that wa our origin cosin function j of theta , but for thi purpos we're go to defin train error without us the regular paramet , and cross valid error without us the regular paramet and what i'd like to do is plot thi j train and plot thi jcv , mean just how well doe my hypothesi do for on the train set and how well doe my hypothesi do on the cross valid set as i vari my regular paramet lambda so as we saw earlier , if lambda is small , then we're not us much regular and we run a larger risk of overfit .
where as if lambda is larg , that is if we were on the right part of thi horizont axi , then with a larg valu of lambda we run the high risk of have a bia problem .
so if you plot j train and jcv , what you find is that for small valu of lambda you can fit the train set rel well becaus you're not regular .
so , for small valu of lambda , the regular term basic goe awai and you're just minim pretti much your squar error .
so when lambda is small , you end up with a small valu for j train , wherea if lambda is larg , then you have a high bia problem and you might not fit your train set so well .
so you end up with a valu up there .
so , j train of theta will tend to increas when lambda increas becaus a larg valu of lambda correspond a high bia where you might not even fit your train set well , wherea a small valu of lambda correspond to , if you can you know freeli fit to veri high degre polynomi , your data , let's sai .
as for the cross valid error , we end up with a figur like thi .
where , over here on the right , if we have a larg valu of lambda , we mai end up underfit .
and so , thi is the bia regim wherea and cross valid error will be high and let me just leav all that .
so , that's jcv of theta becaus with high bia we won't be fit .
we won't be do well on the cross valid set .
wherea here on the left , thi is the high varianc regim .
where if we have two smaller valu of then we mai be overfit the data and so by over fit the data then it a cross valid error will also be high .
and so , thi is what the cross valid error and what the train error mai look like on a train set as we vari the paramet lambda , as we vari the regular paramet lambda .
and so , onc again , it will often be some intermedi valu of lambda that you know , subsequ just right or that work best in term of have a small cross valid error or a small test set error .
and wherea the curv i've drawn here ar somewhat cartoonish and somewhat ideal .
so on a real data set the pro you get mai end up look a littl bit more messi and just a littl bit more noisi than thi .
for some data set you will realli see these poor sourc of trend and by look at the plot of the whole or cross valid error , you can either manual , automat try to select a point that minim the cross valid error and select the valu of lambda correspond to low cross valid error .
when i'm try to pick the regular paramet lambda for a learn algorithm , often i find that plot a figur like thi on show here , help me understand better what's go on and help me verifi that i am inde pick a good valu for the regular paramet lambda .
so hopefulli that give you more insight into regular and it's effect on the bia and varianc of the learn algorithm .
by know you've seen bia and varianc from a lot of differ perspect .
and what i'd like to do in the next video is take a lot of the insight that we've gone through and build on them to put togeth a diagnost that's call learn curv , which is a tool that i often us to try to diagnos if a learn algorithm mai be suffer from a bia problem or a varianc problem or a littl bit of both .
in thi video , i'd like to tell you about learn curv .
learn curv is often a veri us thing to plot .
if either you want to saniti check that your algorithm is work correctli , or if you want to improv the perform of the algorithm .
and learn curv is a tool that i actual us veri often to try to diagnos if a physic learn algorithm mai be suffer from bia , sort of varianc problem or a bit of both .
here's what a learn curv is .
to plot a learn curv , what i usual do is plot j train which is , sai , averag squar error on my train set or jcv which is the averag squar error on my cross valid set .
and i'm go to plot that as a function of m , that is as a function of the number of train exampl i have .
and so m is usual a constant like mayb i just have , you know , a <num> train exampl but what i'm go to do is artifici with us my train set exercis .
so , i deliber limit myself to us onli , sai , <num> or <num> or <num> or <num> train exampl and plot what the train error is and what the cross valid is for thi smallest train set exercis .
so let's see what these plot mai look like .
suppos i have onli on train exampl like that shown in thi thi first exampl here and let's sai i'm fit a quadrat function .
well , i have onli on train exampl .
i'm go to be abl to fit it perfectli right ?
you know , just fit the quadrat function .
i'm go to have <num> error on the on train exampl .
if i have two train exampl .
well the quadrat function can also fit that veri well .
so , even if i am us regular , i can probabl fit thi quit well .
and if i am us no neural regular , i'm go to fit thi perfectli and if i have three train exampl again .
yeah , i can fit a quadrat function perfectli so if m equal <num> or m equal <num> or m equal <num> , my train error on my train set is go to be <num> assum i'm not us regular or it mai slightli larg in <num> if i'm us regular and by the wai if i have a larg train set and i'm artifici restrict the size of my train set in order to j train .
here if i set m equal <num> , sai , and i train on onli three exampl , then , for thi figur i am go to measur my train error onli on the three exampl that actual fit my data too and so even i have to sai a <num> train exampl but if i want to plot what my train error is the m equal <num> .
what i'm go to do is to measur the train error on the three exampl that i've actual fit to my hypothesi <num> .
and not all the other exampl that i have deliber omit from the train process .
so just to summar what we've seen is that if the train set size is small then the train error is go to be small as well .
becaus you know , we have a small train set is go to be veri easi to fit your train set veri well mai be even perfectli now sai we have m equal <num> for exampl .
well then a quadrat function can be a longer fit thi data set perfectli and if i have m equal <num> then you know , mayb quadrat function will fit to stai there so so , then as my train set get larger .
it becom harder and harder to ensur that i can find the quadrat function that process through all my exampl perfectli .
so in fact as the train set size grow what you find is that my averag train error actual increas and so if you plot thi figur what you find is that the train set error that is the averag error on your hypothesi grow as m grow and just to repeat when the intuit is that when m is small when you have veri few train exampl .
it's pretti easi to fit everi singl on of your train exampl perfectli and so your error is go to be small wherea when m is larger then get harder all the train exampl perfectli and so your train set error becom more larger now , how about the cross valid error .
well , the cross valid is my error on thi cross valid set that i haven't seen and so , you know , when i have a veri small train set , i'm not go to gener well , just not go to do well on that .
so , right , thi hypothesi here doesn't look like a good on , and it's onli when i get a larger train set that , you know , i'm start to get hypothes that mayb fit the data somewhat better .
so your cross valid error and your test set error will tend to decreas as your train set size increas becaus the more data you have , the better you do at gener to new exampl .
so , just the more data you have , the better the hypothesi you fit .
so if you plot j train , and jcv thi is the sort of thing that you get .
now let's look at what the learn curv mai look like if we have either high bia or high varianc problem .
suppos your hypothesi ha high bia and to explain thi i'm go to us a , set an exampl , of fit a straight line to data that , you know , can't realli be fit well by a straight line .
so we end up with a hypothes that mayb look like that .
now let's think what would happen if we were to increas the train set size .
so if instead of five exampl like what i've drawn there , imagin that we have a lot more train exampl .
well what happen , if you fit a straight line to thi .
what you find is that , you end up with you know , pretti much the same straight line .
i mean a straight line that just cannot fit thi data and get a ton more data , well the straight line isn't go to chang that much .
thi is the best possibl straight line fit to thi data , but the straight line just can't fit thi data set that well .
so , if you plot across valid error , thi is what it will look like .
option on the left , if you have alreadi a miniscul train set size like you know , mayb just on train exampl and is not go to do well .
but by the time you have reach a certain number of train exampl , you have almost fit the best possibl straight line , and even if you end up with a much larger train set size , a much larger valu of m , you know , you're basic get the same straight line , and so , the cross valid error let me label that or test set error or plateau out , or flatten out pretti soon , onc you reach beyond a certain the number of train exampl , unless you pretti much fit the best possibl straight line .
and how about train error ?
well , the train error will again be small .
and what you find in the high bia case is that the train error will end up close to the cross valid error , becaus you have so few paramet and so much data , at least when m is larg .
the perform on the train set and the cross valid set will be veri similar .
and so , thi is what your learn curv will look like , if you have an algorithm that ha high bia .
and final , the problem with high bia is reflect in the fact that both the cross valid error and the train error ar high , and so you end up with a rel high valu of both jcv and the j train .
thi also impli someth veri interest , which is that , if a learn algorithm ha high bia , as we get more and more train exampl , that is , as we move to the right of thi figur , we'll notic that the cross valid error isn't go down much , it's basic fatten up , and so if learn algorithm ar realli suffer from high bia .
get more train data by itself will actual not help that much , and as our figur exampl in the figur on the right , here we had onli five train .
exampl , and we fill certain straight line .
and when we had a ton more train data , we still end up with roughli the same straight line .
and so if the learn algorithm ha high bia give me a lot more train data .
that doesn't actual help you get a much lower cross valid error or test set error .
so know if your learn algorithm is suffer from high bia seem like a us thing to know becaus thi can prevent you from wast a lot of time collect more train data where it might just not end up be help .
next let us look at the set of a learn algorithm that mai have high varianc .
let us just look at the train error in a around if you have veri smart train set like five train exampl shown on the figur on the right and if we're fit sai a veri high order polynomi , and i've written a hundredth degre polynomi which realli no on us , but just an illustr .
and if we're us a fairli small valu of lambda , mayb not zero , but a fairli small valu of lambda , then we'll end up , you know , fit thi data veri well that with a function that overfit thi .
so , if the train set size is small , our train error , that is , j train of theta will be small .
and as thi train set size increas a bit , you know , we mai still be overfit thi data a littl bit but it also becom slightli harder to fit thi data set perfectli , and so , as the train set size increas , we'll find that j train increas , becaus it is just a littl harder to fit the train set perfectli when we have more exampl , but the train set error will still be pretti low .
now , how about the cross valid error ?
well , in high varianc set , a hypothesi is overfit and so the cross valid error will remain high , even as we get you know , a moder number of train exampl and , so mayb , the cross valid error mai look like that .
and the indic diagnost that we have a high varianc problem , is the fact that there's thi larg gap between the train error and the cross valid error .
and look at thi figur .
if we think about ad more train data , that is , take thi figur and extrapol to the right , we can kind of tell that , you know the two curv , the blue curv and the magenta curv , ar converg to each other .
and so , if we were to extrapol thi figur to the right , then it seem it like that the train error will keep on go up and the cross valid error would keep on go down .
and the thing we realli care about is the cross valid error or the test set error , right ?
so in thi sort of figur , we can tell that if we keep on ad train exampl and extrapol to the right , well our cross valid error will keep on come down .
and , so , in the high varianc set , get more train data is , inde , like to help .
and so again , thi seem like a us thing to know if your learn algorithm is suffer from a high varianc problem , becaus that tell you , for exampl that it mai be be worth your while to see if you can go and get some more train data .
now , on the previou slide and thi slide , i've drawn fairli clean fairli ideal curv .
if you plot these curv for an actual learn algorithm , sometim you will actual see , you know , pretti much curv , like what i've drawn here .
although , sometim you see curv that ar a littl bit noisier and a littl bit messier than thi .
but plot learn curv like these can often tell you , can often help you figur out if your learn algorithm is suffer from bia , or varianc or even a littl bit of both .
so when i'm try to improv the perform of a learn algorithm , on thing that i'll almost alwai do is plot these learn curv , and usual thi will give you a better sens of whether there is a bia or varianc problem .
and in the next video we'll see how thi can help suggest specif action is to take , or to not take , in order to try to improv the perform of your learn algorithm .
we've talk about how to evalu learn algorithm , talk about model select , talk a lot about bia and varianc .
so how doe thi help us figur out what ar potenti fruit , potenti not fruit thing to try to do to improv the perform of a learn algorithm .
let's go back to our origin motiv exampl and go for the result .
so here is our earlier exampl of mayb have fit regular linear regress and find that it doesn't work as well as we're hope .
we said that we had thi menu of option .
so is there some wai to figur out which of these might be fruit option ?
the first thing all of thi wa get more train exampl .
what thi is good for , is thi help to fix high varianc .
and concret , if you instead have a high bia problem and don't have ani varianc problem , then we saw in the previou video that get more train exampl , while mayb just isn't go to help much at all .
so the first option is us onli if you , sai , plot the learn curv and figur out that you have at least a bit of a varianc , mean that the cross valid error is , you know , quit a bit bigger than your train set error .
how about try a smaller set of featur ?
well , try a smaller set of featur , that's again someth that fix high varianc .
and in other word , if you figur out , by look at learn curv or someth els that you us , that have a high bia problem ; then for good sake , don't wast your time try to carefulli select out a smaller set of featur to us .
becaus if you have a high bia problem , us fewer featur is not go to help .
wherea in contrast , if you look at the learn curv or someth els you figur out that you have a high varianc problem , then , inde try to select out a smaller set of featur , that might inde be a veri good us of your time .
how about try to get addit featur , ad featur , usual , not alwai , but usual we think of thi as a solut for fix high bia problem .
so if you ar ad extra featur it's usual becaus your current hypothesi is too simpl , and so we want to try to get addit featur to make our hypothesi better abl to fit the train set .
and similarli , ad polynomi featur ; thi is anoth wai of ad featur and so there is anoth wai to try to fix the high bia problem .
and , if concret if your learn curv show you that you still have a high varianc problem , then , you know , again thi is mayb a less good us of your time .
and final , decreas and increas lambda .
thi ar quick and easi to try , i guess these ar less like to be a wast of , you know , mani month of your life .
but decreas lambda , you alreadi know fix high bia .
in case thi isn't clear to you , you know , i do encourag you to paus the video and think through thi that convinc yourself that decreas lambda help fix high bia , wherea increas lambda fix high varianc .
and if you aren't sure why thi is the case , do paus the video and make sure you can convinc yourself that thi is the case .
or take a look at the curv that we were plot at the end of the previou video and try to make sure you understand why these ar the case .
final , let us take everyth we have learn and relat it back to neural network and so , here is some practic advic for how i usual choos the architectur or the connect pattern of the neural network i us .
so , if you ar fit a neural network , on option would be to fit , sai , a pretti small neural network with you know , rel few hidden unit , mayb just on hidden unit .
if you're fit a neural network , on option would be to fit a rel small neural network with , sai , rel few , mayb onli on hidden layer and mayb onli a rel few number of hidden unit .
so , a network like thi might have rel few paramet and be more prone to underfit .
the main advantag of these small neural network is that the comput will be cheaper .
an altern would be to fit a , mayb rel larg neural network with either more hidden unit there's a lot of hidden in on there or with more hidden layer .
and so these neural network tend to have more paramet and therefor be more prone to overfit .
on disadvantag , often not a major on but someth to think about , is that if you have a larg number of neuron in your network , then it can be more computation expens .
although within reason , thi is often hopefulli not a huge problem .
the main potenti problem of these much larger neural network is that it could be more prone to overfit and it turn out if you're appli neural network veri often us a larg neural network often it's actual the larger , the better but if it's overfit , you can then us regular to address overfit , usual us a larger neural network by us regular to address is overfit that's often more effect than us a smaller neural network .
and the main possibl disadvantag is that it can be more computation expens .
and final , on of the other decis is , sai , the number of hidden layer you want to have , right ?
so , do you want on hidden layer or do you want three hidden layer , as we've shown here , or do you want two hidden layer ?
and usual , as i think i said in the previou video , us a singl hidden layer is a reason default , but if you want to choos the number of hidden layer , on other thing you can try is find yourself a train cross valid , and test set split and try train neural network with on hidden layer or two hidden layer or three hidden layer and see which of those neural network perform best on the cross valid set .
you take your three neural network with on , two and three hidden layer , and comput the cross valid error at jcv and all of them and us that to select which of these is you think the best neural network .
so , that's it for bia and varianc and wai like learn curv , who tri to diagnos these problem .
as far as what you think is impli , for on might be truth or not truth thing to try to improv the perform of a learn algorithm .
if you understood the content of the last few video and if you appli them you actual be much more effect alreadi and get learn algorithm to work on problem and even a larg fraction , mayb the major of practition of machin learn here in silicon vallei todai do these thing as their full time job .
so i hope that these piec of advic on by experi in diagnost will help you to much effect and powerfulli appli learn and get them to work veri well .
in the next few video i'd like to talk about machin learn system design .
these video will touch on the main issu that you mai face when design a complex machin learn system , and will actual try to give advic on how to strateg put togeth a complex machin learn system .
in case thi next set of video seem a littl disjoint that's becaus these video will touch on a rang of the differ issu that you mai come across when design complex learn system .
and even though the next set of video mai seem somewhat less mathemat , i think that thi materi mai turn out to be veri us , and potenti huge time saver when you're build big machin learn system .
concret , i'd like to begin with the issu of priorit how to spend your time on what to work on , and i'll begin with an exampl on spam classif .
let's sai you want to build a spam classifi .
here ar a coupl of exampl of obviou spam and non spam email .
if the on on the left tri to sell thing .
and notic how spammer will deliber misspel word , like vincent with a <num> there , and mortgag .
and on the right as mayb an obviou exampl of non stamp email , actual email from my younger brother .
let's sai we have a label train set of some number of spam email and some non spam email denot with label y equal <num> or <num> , how do we build a classifi us supervis learn to distinguish between spam and non spam ?
in order to appli supervis learn , the first decis we must make is how do we want to repres x , that is the featur of the email .
given the featur x and the label y in our train set , we can then train a classifi , for exampl us logist regress .
here's on wai to choos a set of featur for our email .
we could come up with , sai , a list of mayb a hundr word that we think ar indic of whether e mail is spam or non spam , for exampl , if a piec of e mail contain the word 'deal' mayb it's more like to be spam if it contain the word 'bui' mayb more like to be spam , a word like 'discount' is more like to be spam , wherea if a piec of email contain my name , andrew , mayb that mean the person actual know who i am and that might mean it's less like to be spam .
and mayb for some reason i think the word now mai be indic of non spam becaus i get a lot of urgent email , and so on , and mayb we choos a hundr word or so .
given a piec of email , we can then take thi piec of email and encod it into a featur vector as follow .
i'm go to take my list of a hundr word and sort them in alphabet order sai .
it doesn't have to be sort .
but , you know , here's a , here's my list of word , just count and so on , until eventu i'll get down to now , and so on and given a piec of e mail like that shown on the right , i'm go to check and see whether or not each of these word appear in the e mail and then i'm go to defin a featur vector x where in thi piec of an email on the right , my name doesn't appear so i'm gonna put a zero there .
the word by doe appear , so i'm gonna put a on there and i'm just gonna put on's or zero .
i'm gonna put a on even though the word by occur twice .
i'm not gonna recount how mani time the word occur .
the word due appear , i put a on there .
the word discount doesn't appear , at least not in thi thi littl short email , and so on .
the word now doe appear and so on .
so i put on and zero in thi featur vector depend on whether or not a particular word appear .
and in thi exampl my featur vector would have to mention on hundr , if i have a hundr , if if i chose a hundr word to us for thi represent and each of my featur xj will basic be <num> if you have a particular word that , we'll call thi word j , appear in the email and xj would be zero otherwis .
okai .
so that give me a featur represent of a piec of email .
by the wai , even though i've describ thi process as manual pick a hundr word , in practic what's most commonli done is to look through a train set , and in the train set depict the most frequent occur n word where n is usual between ten thousand and fifti thousand , and us those as your featur .
so rather than manual pick a hundr word , here you look through the train exampl and pick the most frequent occur word like ten thousand to fifti thousand word , and those form the featur that you ar go to us to repres your email for spam classif .
now , if you're build a spam classifi on question that you mai face is , what's the best us of your time in order to make your spam classifi have higher accuraci , you have lower error .
on natur inclin is go to collect lot of data .
right ?
and in fact there's thi tendenc to think that , well the more data we have the better the algorithm will do .
and in fact , in the email spam domain , there ar actual pretti seriou project call honei pot project , which creat fake email address and try to get these fake email address into the hand of spammer and us that to try to collect ton of spam email , and therefor you know , get a lot of spam data to train learn algorithm .
but we've alreadi seen in the previou set of video that get lot of data will often help , but not all the time .
but for most machin learn problem , there ar a lot of other thing you could usual imagin do to improv perform .
for spam , on thing you might think of is to develop more sophist featur on the email , mayb base on the email rout inform .
and thi would be inform contain in the email header .
so , when spammer send email , veri often thei will try to obscur the origin of the email , and mayb us fake email header .
or send email through veri unusu set of comput servic .
through veri unusu rout , in order to get the spam to you .
and some of thi inform will be reflect in the email header .
and so on can imagin , look at the email header and try to develop more sophist featur to captur thi sort of email rout inform to identifi if someth is spam .
someth els you might consid do is to look at the email messag bodi , that is the email text , and try to develop more sophist featur .
for exampl , should the word 'discount' and the word 'discount' be treat as the same word or should we have treat the word 'deal' and 'dealer' as the same word ?
mayb even though on is lower case and on in capit in thi exampl .
or do we want more complex featur about punctuat becaus mayb spam is us exclam mark a lot more .
i don't know .
and along the same line , mayb we also want to develop more sophist algorithm to detect and mayb to correct to deliber misspel , like mortgag , medicin , watch .
becaus spammer actual do thi , becaus if you have watch with a <num> in there then well , with the simpl techniqu that we talk about just now , the spam classifi might not equat thi as the same thing as the word watch , and so it mai have a harder time realiz that someth is spam with these deliber misspel .
and thi is why spammer do it .
while work on a machin learn problem , veri often you can brainstorm list of differ thing to try , like these .
by the wai , i've actual work on the spam problem myself for a while .
and i actual spent quit some time on it .
and even though i kind of understand the spam problem , i actual know a bit about it , i would actual have a veri hard time tell you of these four option which is the best us of your time so what happen , frankli what happen far too often is that a research group or product group will randomli fixat on on of these option .
and sometim that turn out not to be the most fruit wai to spend your time depend , you know , on which of these option someon end up randomli fixat on .
by the wai , in fact , if you even get to the stage where you brainstorm a list of differ option to try , you're probabl alreadi ahead of the curv .
sadli , what most peopl do is instead of try to list out the option of thing you might try , what far too mani peopl do is wake up on morn and , for some reason , just , you know , have a weird gut feel that , oh let's have a huge honeypot project to go and collect ton more data and for whatev strang reason just sort of wake up on morn and randomli fixat on on thing and just work on that for six month .
but i think we can do better .
and in particular what i'd like to do in the next video is tell you about the concept of error analysi and talk about the wai where you can try to have a more systemat wai to choos amongst the option of the mani differ thing you might work , and therefor be more like to select what is actual a good wai to spend your time , you know for the next few week , or next few dai or the next few month .
in the last video , i talk about how when face with a machin learn problem , there ar often lot of differ idea on how to improv the algorithm .
in thi video let's talk about the concept of error analysi which will help me give you a wai to more systemat make some of these decis .
if you're start work on a machin learn product or build a machin learn applic , it is often consid veri good practic to start , not by build a veri complic system with lot of complex featur and so on , but to instead start by build a veri simpl algorithm , the you can implement quickli .
and when i start on a learn problem , what i usual do is spend at most on dai , liter at most <num> hour to try to get someth realli quick and dirti .
frankli not at all sophist system .
but get someth realli quick and dirti run and implement it and then test it on my cross valid data .
onc you've done that , you can then plot learn curv .
thi is what we talk about in the previou set of video .
but plot learn curv of the train and test error to try to figur out if your learn algorithm mai be suffer from high bia or high varianc or someth els and us that to try to decid if have more data and more featur and so on ar like to help .
and the reason that thi is a good approach is often when you're just start out on a learn problem , there's realli no wai to tell in advanc whether you need more complex featur or whether you need more data or someth els .
and it's just veri hard to tell in advanc , that is in the absenc of evid , in the absenc of see a learn curv , it's just incred difficult to figur out where you should be spend your time .
and it's often by implement even a veri , veri quick and dirti implement and by plot learn curv that that help you make these decis .
so if you like , you can think of thi as a wai of avoid what's sometim call prematur optim in comput program .
and thi is idea that just sai that we should let evid guid our decis on where to spend our time rather than us gut feel , which is often wrong .
in addit to plot learn curv , on other thing that's often veri us to do is what's call error analysi .
and what i mean by that is that when build , sai a spam classifi , i will often look at my cross valid set and manual look at the email that my algorithm is make error on .
so , look at the spam email and non spam email that the algorithm is misclassifi , and see if you can spot ani systemat pattern in what type of exampl it is misclassifi .
and often by do that , thi is the process that would inspir you to design new featur .
or thei'll tell you whether the current thing or current shortcom of the system and give you the inspir you need to come up with improv to it .
concret , here's a specif exampl .
let's sai you've built a spam classifi and you have <num> exampl in your cross valid set .
and let's sai in thi exampl , that the algorithm ha a veri high error rate , and it misclassifi a hundr of these cross valid exampl .
so what i do is manual examin these <num> error , and manual categor them , base on thing like what type of email it is and what cue or what featur you think might have help the algorithm classifi them incorrectli .
so , specif , by what type of email it is , you know , if i look through these hundr error i mai find that mayb the most common type of spam email in misclassifi ar mayb email on pharmaci , so basic these ar email try to sell drug , mayb email that ar try to sell replica those ar those fake watch fake you know , random thing .
mayb have some email try to steal password .
these ar also call phish email .
but that's anoth big categori of email and mayb other categori .
so , in term of classifi what type of email it is , i would actual go through and count up , you know , of my <num> email , mayb i find that twelv of the mislabel email ar pharma email .
and mayb four of them ar email try to sell replica , thei sell fake watch or someth .
and mayb i find that <num> of them ar these , what's call phish email , basic email try to persuad you to give them your password , and <num> email ar other type of email .
and it's by count up the number of email in these differ categori that you might discov , for exampl , that the algorithm is do realli particularli poorli on email try to steal password , and that mai suggest that it might be worth your effort to look more carefulli at that type of email , and see if you can come up with better featur to categor them correctli .
and also , what i might do is look at what cue , or what featur , addit featur might have help the algorithm classifi the email .
so let's sai that some of our hypothes about thing or featur that might help us classifi email better ar try to detect deliber misspel versu unusu email rout versu unusu , you know , spam punctuat , such as peopl us a lot of exclam mark .
and onc again , i would manual go through and let's sai i find five case of thi , and <num> of thi , and <num> of thi and a bunch of other type of email as well .
and if thi is what you get on your cross valid set then it realli tell you that , you know , mayb deliber spell is a suffici rare phenomenon that mayb is not realli worth all your time try to write algorithm to detect that .
but if you find a lot of spammer ar us , you know , unusu punctuat then mayb that's a strong sign that it might actual be worth your while to spend the time to develop more sophist featur base on the punctuat .
so , thi sort of error analysi which is realli the process of manual examin the mistak that the algorithm make , can often help guid you to the most fruit avenu to pursu .
and thi also explain why i often recommend implement a quick and dirti implement of an algorithm .
what we realli want to do is figur out what ar the most difficult exampl for an algorithm to classifi .
and veri often for differ algorithm , for differ learn algorithm , thei'll often find , you know , similar categori of exampl difficult .
and by have a quick and dirti implement , that's often a quick wai to let you identifi some error and quickli identifi what ar the hard exampl so that you can focu your effort on those .
lastli , when develop learn algorithm , on other us tip is to make sure that you have a wai , that you have a numer evalu of your learn algorithm .
now what i mean by that is that if you're develop a learn algorithm , it is often incred help if you have a wai of evalu your learn algorithm that just give you back a singl real number .
mayb accuraci , mayb error .
but the singl real number that tell you how well your learn algorithm is do .
i'll talk more about thi specif concept in later video , but here's a specif exampl .
let's sai we ar try to decid whether or not we should treat word like discount , discount , discount , discount , as the same word .
so mayb on wai to do that is to just look at the first few charact in a word .
like , you know , if you just look at the first few charact of a word , then you figur out that mayb all of these word ar roughli have similar mean .
in natur languag process , the wai that thi is done is actual us a type of softwar call stem softwar .
if you ever want to do thi yourself , search on a web search engin for the porter stemmer and that would be , you know , on reason piec of softwar for do thi sort of stem , which will let you treat all of these discount , discount , and so on as the same word .
but us a stem softwar that basic look at the first few alphabet of the word more or less , it can help but it can hurt .
and it can hurt becaus , for exampl , thi softwar mai mistak the word univers and univers as be the same thing becaus , you know , these two word start off with veri similar charact , with the same alphabet .
so if you're try to decid whether or not to us stem softwar for a stem classifi , it is not alwai easi to tell .
and in particular , error analysi mai not actual be help for decid if thi sort of stem idea is a good idea .
instead , the best wai to figur out if us stem softwar is good to help your classifi is if you have a wai to veri quickli just try it and see if it work .
and in order to do thi , have a wai to numer evalu your algorithm , is go to be veri help .
concret , mayb the most natur thing to do is to look at the cross valid error of the algorithm's perform with and without stem .
so , if you run your algorithm without stem and you end up with , let's sai , five percent classif error , and you re run it and you end up with , let's sai , three percent classif error , then thi decreas in error veri quickli allow you to decid that , you know , it look like us stem is a good idea .
for thi particular problem , there's a veri natur singl real number evalu metric , name , the cross valid error .
we'll see later , exampl where come up with thi , sort of , singl row number evalu metric mai need a littl bit more work .
but as we'll see in the later video , do so would also then let you make these decis much more quickli of , sai , whether or not to us stem .
and just thi on more quick exampl .
let's sai that you're also try to decid whether or not to distinguish between upper versu lower case .
so , you know , is the red mom with uppercas m versu lower case m , i mean , should that be treat as the same word or as differ word ?
should these be treat as the same featur or as differ featur ?
and so onc again , becaus we have a wai to evalu our algorithm , if you try thi out here , if i stop distinguish upper and lower case , mayb i end up with <num> error and i find that therefor thi doe wors than , you know , if i us onli stem , and so thi let me veri quickli decid to go ahead and to distinguish or to not distinguish between upper and lower case .
so when you' re develop a learn algorithm , veri often you'll be try out lot of new idea and lot of new version of your learn algorithm .
if everi time you try out a new idea if you end up manual examin a bunch of exampl , you begin to see better or wors , you know , that's go to make it realli hard to make decis on do you us stem or not .
do you distinguish upper or lowercas or not ?
but by have a singl rule number evalu metric , you can then just look and see oh , did the error go up or go down ?
and you can us that much more rapidli , try out new idea and almost right awai tell if your new idea ha improv or worsen the perform of the learn algorithm and thi will let you often make much faster progress .
so the recommend , strongli recommend wai to do error analysi is on the cross valid set rather than the test set .
but , you know , there ar peopl that will do thi on the test set even though that's definit a less mathemat appropri set of your list , recommend what you think to do than to do error analysi on your cross valid sector .
so , to wrap up thi video , when start on the new machin learn problem , what i almost alwai recommend is to implement a quick and dirti implement of your learn algorithm .
and i've almost never seen anyon spend too littl time on thi quick and dirti implement .
i pretti much onli ever see peopl spend much too much time build their first , you know , supposedli quick and dirti implement .
so realli , don't worri about it be too quick , or don't worri about it be too dirti .
but realli implement someth as quickli as you can , and onc you have the initi implement thi is then a power tool for decid where to spend your time next , becaus first we can look at the error it make , and do thi sort of error analysi to see what mistak it make and us that to inspir further develop .
and second , assum your quick and dirti implement incorpor a singl real number evalu metric , thi can then be a vehicl for you to try out differ idea and quickli see if the differ idea you're try out ar improv the perform of your algorithm and therefor let you mayb much more quickli make decis about what thing to fold , and what thing to incorpor into your learn algorithm .
in the previou video , i talk about error analysi and the import of have error metric , that is of have a singl real number evalu metric for your learn algorithm to tell how well it's do .
in the context of evalu and of error metric , there is on import case , where it's particularli tricki to come up with an appropri error metric , or evalu metric , for your learn algorithm .
that case is the case of what's call skew class .
let me tell you what that mean .
consid the problem of cancer classif , where we have featur of medic patient and we want to decid whether or not thei have cancer .
so thi is like the malign versu benign tumor classif exampl that we had earlier .
so let's sai y equal <num> if the patient ha cancer and y equal <num> if thei do not .
we have train the progress classifi and let's sai we test our classifi on a test set and find that we get <num> percent error .
so , we're make <num> correct diagnosi .
seem like a realli impress result , right .
we're correct <num> percent of the time .
but now , let's sai we find out that onli <num> percent of patient in our train test set actual have cancer .
so onli half a percent of the patient that come through our screen process have cancer .
in thi case , the <num> error no longer look so impress .
and in particular , here's a piec of code , here's actual a piec of non learn code that take thi input of featur x and it ignor it .
it just set y equal <num> and alwai predict , you know , nobodi ha cancer and thi algorithm would actual get <num> percent error .
so thi is even better than the <num> error that we were get just now and thi is a non learn algorithm that you know , it is just predict y equal <num> all the time .
so thi set of when the ratio of posit to neg exampl is veri close to on of two extrem , where , in thi case , the number of posit exampl is much , much smaller than the number of neg exampl becaus y equal on so rare , thi is what we call the case of skew class .
we just have a lot more of exampl from on class than from the other class .
and by just predict y equal <num> all the time , or mayb our predict y equal <num> all the time , an algorithm can do pretti well .
so the problem with us classif error or classif accuraci as our evalu metric is the follow .
let's sai you have on join algorithm that's get <num> accuraci .
so , that's a <num> error .
let's sai you make a chang to your algorithm and you now ar get <num> accuraci .
that is <num> error .
so , is thi an improv to the algorithm or not ?
on of the nice thing about have a singl real number evalu metric is thi help us to quickli decid if we just need a good chang to the algorithm or not .
by go from <num> accuraci to <num> accuraci .
you know , did we just do someth us or did we just replac our code with someth that just predict y equal zero more often ?
so , if you have veri skew class it becom much harder to us just classif accuraci , becaus you can get veri high classif accuraci or veri low error , and it's not alwai clear if do so is realli improv the qualiti of your classifi becaus predict y equal <num> all the time doesn't seem like a particularli good classifi .
but just predict y equal <num> more often can bring your error down to , you know , mayb as low as <num> .
when we're face with such a skew class therefor we would want to come up with a differ error metric or a differ evalu metric .
on such evalu metric ar what's call precis recal .
let me explain what that is .
let's sai we ar evalu a classifi on the test set .
for the exampl in the test set the actual class of that exampl in the test set is go to be either on or zero , right , if there is a binari classif problem .
and what our learn algorithm will do is it will , you know , predict some valu for the class and our learn algorithm will predict the valu for each exampl in my test set and the predict valu will also be either on or zero .
so let me draw a two by two tabl as follow , depend on a full of these entri depend on what wa the actual class and what wa the predict class .
if we have an exampl where the actual class is on and the predict class is on then that's call an exampl that's a true posit , mean our algorithm predict that it's posit and in realiti the exampl is posit .
if our learn algorithm predict that someth is neg , class zero , and the actual class is also class zero then that's what's call a true neg .
we predict zero and it actual is zero .
to find the other two box , if our learn algorithm predict that the class is on but the actual class is zero , then that's call a fals posit .
so that mean our algorithm for the patient is cancel out in realiti if the patient doe not .
and final , the last box is a zero , on .
that's call a fals neg becaus our algorithm predict zero , but the actual class wa on .
and so , we have thi littl sort of two by two tabl base on what wa the actual class and what wa the predict class .
so here's a differ wai of evalu the perform of our algorithm .
we're go to comput two number .
the first is call precis and what that sai is , of all the patient where we've predict that thei have cancer , what fraction of them actual have cancer ?
so let me write thi down , the precis of a classifi is the number of true posit divid by the number that we predict as posit , right ?
so of all the patient that we went to those patient and we told them , we think you have cancer . of all those patient , what fraction of them actual have cancer ?
so that's call precis .
and anoth wai to write thi would be true posit and then in the denomin is the number of predict posit , and so that would be the sum of the , you know , entri in thi first row of the tabl .
so it would be true posit divid by true posit .
i'm go to abbrevi posit as po and then plu fals posit , again abbrevi posit us po .
so that's call precis , and as you can tell high precis would be good .
that mean that all the patient that we went to and we said , you know , we're veri sorri .
we think you have cancer , high precis mean that of that group of patient most of them we had actual made accur predict on them and thei do have cancer .
the second number we're go to comput is call recal , and what recal sai is , if all the patient in , let's sai , in the test set or the cross valid set , but if all the patient in the data set that actual have cancer , what fraction of them that we correctli detect as have cancer .
so if all the patient have cancer , how mani of them did we actual go to them and you know , correctli told them that we think thei need treatment .
so , write thi down , recal is defin as the number of posit , the number of true posit , mean the number of peopl that have cancer and that we correctli predict have cancer and we take that and divid that by , divid that by the number of actual posit , so thi is the right number of actual posit of all the peopl that do have cancer .
what fraction do we directli flag and you know , send the treatment .
so , to rewrit thi in a differ form , the denomin would be the number of actual posit as you know , is the sum of the entri in thi first column over here .
and so write thing out differ , thi is therefor , the number of true posit , divid by the number of true posit plu the number of fals neg .
and so onc again , have a high recal would be a good thing .
so by comput precis and recal thi will usual give us a better sens of how well our classifi is do .
and in particular if we have a learn algorithm that predict y equal zero all the time , if it predict no on ha cancer , then thi classifi will have a recal equal to zero , becaus there won't be ani true posit and so that's a quick wai for us to recogn that , you know , a classifi that predict y equal <num> all the time , just isn't a veri good classifi .
and more gener , even for set where we have veri skew class , it's not possibl for an algorithm to sort of cheat and somehow get a veri high precis and a veri high recal by do some simpl thing like predict y equal <num> all the time or predict y equal <num> all the time .
and so we're much more sure that a classifi of a high precis or high recal actual is a good classifi , and thi give us a more us evalu metric that is a more direct wai to actual understand whether , you know , our algorithm mai be do well .
so on final note in the definit of precis and recal , that we would defin precis and recal , usual we us the convent that y is equal to <num> , in the presenc of the more rare class .
so if we ar try to detect .
rare condit such as cancer , hopefulli that's a rare condit , precis and recal ar defin set y equal <num> , rather than y equal <num> , to be sort of that the presenc of that rare class that we're try to detect .
and by us precis and recal , we find , what happen is that even if we have veri skew class , it's not possibl for an algorithm to you know , cheat and predict y equal <num> all the time , or predict y equal <num> all the time , and get high precis and recal .
and in particular , if a classifi is get high precis and high recal , then we ar actual confid that the algorithm ha to be do well , even if we have veri skew class .
so for the problem of skew class precis recal give us more direct insight into how the learn algorithm is do and thi is often a much better wai to evalu our learn algorithm , than look at classif error or classif accuraci , when the class ar veri skew .
in the last video , we talk about precis and recal as an evalu metric for classif problem with skew class .
for mani applic , we'll want to somehow control the trade off between posit and recal .
let me tell you how to do that and also show you some , even more effect wai to us precis and recal as an evalu metric for learn algorithm .
as a remind , here ar the definit of precis and recal from the previou video .
let's continu our cancer classif exampl , where y equal on if the patient ha cancer and y equal zero otherwis .
and let's sai we've train in logist regress classifi , which output probabl between zero and on .
so , as usual , we're go to predict on , y equal on if h of x is greater than or equal to <num> and predict zero if the hypothesi output a valu less than <num> and thi classifi mai give us some valu for precis and some valu for recal .
but now , suppos we want to predict that a patient ha cancer onli if we're veri confid that thei realli do .
becaus you know if you go to a patient and you tell them that thei have cancer , it's go to give them a huge shock becaus thi is serious bad new and thei mai end up go through a pretti pain treatment process and so on .
and so mayb we want to tell someon that we think thei have cancer onli if thei're veri confid .
on wai to do thi would be to modifi the algorithm , so that instead of set the threshold at <num> , we might instead sai that we'll predict that y is equal to <num> , onli if h of x is greater than or equal to <num> .
so thi , i think will tell someon if thei have cancer onli if we think there's a greater than , greater than or equal to <num> that thei have cancer .
and if you do thi then you're predict some of thi cancer onli when you're more confid , and so you end up with a classifi that ha higher precis , becaus all the patient that you're go to and sai , you know , we think you have cancer , all of those patient ar now pretti , onc thei hear , pretti confid thei actual have cancer .
and so , a higher fraction of the patient that you predict to have cancer , will actual turn out to have cancer , becaus in make those predict we ar pretti confid .
but in contrast , thi classifi will have lower recal , becaus now we ar go to make predict , we ar go to predict y equal on , on a smaller number of patient .
now we could even take thi further .
instead of set the threshold at <num> , we can set thi at <num> and we'll predict y1 onli if we ar more than <num> certain that the patient ha cancer , and so , you know , a larg fraction that those patient will turn out to have cancer and so , thi is the high precis classifi will have lower recal becaus we want to correctli detect that those patient have cancer .
now consid a differ exampl .
suppos we want to avoid miss too mani actual case of cancer .
so we want to avoid the fals neg .
in particular , if a patient actual ha cancer , but we fail to tell them that thei have cancer , then that can be realli bad .
becaus if we tell a patient that thei don't have cancer then thei ar not go to go for treatment and if it turn out that thei have cancer or we fail to tell them thei have cancer , well thei mai not get treat at all .
and so that would be a realli bad outcom becaus he di becaus we told them thei don't have cancer thei fail to get treat , but it turn out that thei actual have cancer .
when in doubt , we want to predict that y equal on .
so when in doubt , we want to predict that thei have cancer so that at least thei look further into it and thi can get treat , in case thei do turn out to have cancer .
in thi case , rather than set higher probabl threshold , we might instead take thi valu and thi then set it to a lower valu , so mayb <num> like so .
by do so , we're sai that , you know what , if we think there's more than a <num> chanc that thei have caner , we better be more conserv and tell them that thei mai have cancer , so thei can seek treatment if necessari .
and in thi case , what we would have is go to be a higher recal classifi , becaus we're go to be correctli flag a higher fraction of all of the patient that actual do have cancer , but we're go to end up with lower precis , becaus the higher fraction of the patient that we said have cancer , the higher fraction of them will turn out not to have cancer after all .
and by the wai , just as an asid , when i talk about thi to other student up until befor , it's pretti amaz .
some of my student sai is how i can tell the stori both wai .
why we might want to have higher precis or higher recal and the stori actual seem to work both wai .
but i hope the detail of the algorithm is true and the more gener principl is , depend on where you want , whether you want high precis , lower recal or higher recal , lower precis , you can end up predict y equal on when h x is greater than some threshold .
and so , in gener , for most classifi , there is go to be a trade off between precis and recal .
and as you vari the valu of thi threshold , thi valu , thi special that i have join here , you can actual plot us some curv that trade off precis and recal , where a valu up here , thi would correspond to a veri high valu of the threshold , mayb threshold equal over <num> . <num> , so that sai , predict y equal <num> onli where no more than <num> percent confid , at least <num> percent probabl thi onc , so that will be a precis rel low recal , wherea the point down here will correspond to a valu of the threshold that's much lower , mayb <num> . <num> .
when in doubt at all , put down y1 .
and if you do that , you end up with a much lower precis higher recal classifi .
and as you vari the threshold , if you want , you can actual trace all the curv from your classifi to see the rang of differ valu you can get for precis recal .
and by the wai , the posit recal curv can look like mani differ shape .
sometim it'll look thi , sometim it'll look like that .
now , there ar mani differ possibl shape in the posit of recal curv , depend on the detail of the classifi .
so thi rais anoth interest question which is , is there a wai to choos thi threshold automat ?
or , more gener , if we have a few differ algorithm or a few differ idea for algorithm , how do we compar differ precis recal number ?
complet .
suppos we have three differ learn algorithm , or actual mayb these ar three differ learn algorithm , mai be these ar the same algorithm , but just with differ valu for the threshold .
how do we decid which of these algorithm is best ?
on of the thing we talk about earlier is the import of a singl real number evalu metric .
and that is the idea of have a number that just tell you how well is your classifi do .
but by switch to the precis recal metric , we've actual lost that .
we now have two real number .
and so we often end up face situat , like if we ar try to compar algorithm <num> to algorithm <num> , we end up ask ourselv , is a posit of point five and a recal of point four , well is that better or wors than a posit of point seven or a recal point on ?
if everi time you try on a new algorithm you end up have to sit around and think well , mayb point five point four , is better than point seven point on , mayb not , i do not know .
if you end up have to sit around and think and make these decis .
that realli slow down your decis make process , for what chang ar us to incorpor into your algorithm .
where as in contrast , if we had a singl real number evalu metric , like a number that just tell us is either algorithm <num> or is algorithm <num> better .
that help us much more quickli decid which algorithm to go with and help us as well to much more quickli evalu differ chang that we mai be contempl for an algorithm .
so , how can we get a singl real number evalu metric .
on natur thing that you might try is to look at the averag between precis and recal .
so us p and r to denot posit and recal , what you could do is just comput the averag and look at what classifi ha the highest averag valu .
but thi turn out not to be such a good solut becaus , similar to the exampl we had earlier , it turn out that if we have a classifi that predict y1 all the time , then if you do that , you can get a veri high recal .
that's you end up with a veri low valu of vision .
convers , if you have a classifi that predict y <num> almost all the time , that is , if it predict y on veri sparingli .
thi correspond to set a veri high threshold us the notat of previou line .
and then you can actual end up with a veri high precis with a veri low recal .
so the two extrem of either ar a veri high threshold or a veri low threshold , neither of them would give it paticularari good classifi .
and we recogn that is by see if we end up with a veri low precis or a veri low recal .
and if you just take the averag of peopl's ro2 .
on doe the exampl the averag is actual highest for algorithm <num> .
even though you can get that sort of perform by predict y1 all the time .
and that is just not a veri good classifi , right ?
you predict y equal on all the time is just not a us classifi if all it doe is print out y equal on .
and so algorithm on or algorithm two would be more us than algorithm three , but in thi exampl algorithm three ha a higher averag valu of precis recal than algorithm on and two .
so we usual think of thi averag of precis recal as not a particularli good wai to evalu our learn algorithm .
in contrast , there is a differ wai of combin precis recal .
it is call the f score and it us that formula .
so , in thi exampl , here ar the f score .
and so we would tell from these f score and we'll sai algorithm <num> ha the highest f score .
algorithm <num> ha the second highest and algorithm <num> ha the lowest and so you know , if we go by the f score , we would pick probabl algorithm of <num> over the other .
the f score , which is also call the f1 score , is usual written f1 score that i have here , but often peopl will just sai f score .
it determin us is a littl bit like take the averag of precis of recal , but it give the lower valu of precis and recal whichev it is it give it a higher weight .
and so , you see in the numer here that the f score take a product or posit of equal .
and so , if either posit is <num> or recal is equal to <num> , the f score will be equal to o .
so in that sens , it kind of combin posit and recal .
but for the f score to be larg , both posit and recal have to be pretti larg .
i should sai that there ar mani differ possibl formula for combin posit and recal .
thi f score formula is realli , mayb just on out of a much larger number of possibl , but histor or tradition thi is what peopl in machin learn us .
and the term f score , you know , it doesn't realli mean anyth , so don't worri about why it's call f score or f1 score .
but thi usual give you the effect that you want becaus if either posit is <num> or recal is <num> , thi give you a veri low f score .
and so , to have a high f score you can't need a preserv qualiti <num> and complet if p equal zero or i equal zero then thi give you the f score equal zero .
where as a perfect f score , so if posit equal on and equal on that would give you an f score that's equal to on time on over two time two .
so the f score will be equal to <num> if you have perfect precis and perfect recal .
and intermedi valu between <num> and <num> , thi usual give a reason rank order of differ classifi .
so thi video we talk about the notion of trade off between posit and recal and how we can vari the threshold that we us to decid whether to predict y equal on or y equal zero .
thi threshold that sai do we need to be at least seventi percent confid or nineti percent confid or whatev befor we predict y equal on and by vari the threshold you can control a trade off between precis and recal .
ross talk about the f score which take precis and recal and give you a singl real number evalu metric .
and of cours , if your goal is to automat set that threshold , to decid which on of y equal <num> or y equal <num> , on pretti reason wai to do that would also be to try a rang of differ valu of threshold .
so , try a rang of valu of threshold and evalu these differ threshold on sai your cross valid set , and then to pick whatev valu of threshold give you the highest f score on your cross valid set .
that would be a pretti reason wai to automat chose the threshold for your classifi as well .
in the previou video , we talk about evalu metric .
in thi video , i'd like to switch track a bit and touch on anoth import aspect of machin learn system design , which will often come up , which is the issu of how much data to train on .
now , in some earlier video , i had caution against blindli go out and just spend lot of time collect lot of data , becaus it's onli sometim that that would actual help .
but it turn out that under certain condit , and i will sai in thi video what those condit ar , get a lot of data and train on a certain type of learn algorithm , can be a veri effect wai to get a learn algorithm to do veri good perform .
and thi aris often enough that if those condit hold true for your problem and if you're abl to get a lot of data , thi could be a veri good wai to get a veri high perform learn algorithm .
so in thi video , let's talk more about that .
let me start with a stori .
mani , mani year ago , two research that i know , michel banko and eric broul ran the follow fascin studi .
thei were interest in studi the effect of us differ learn algorithm versu try them out on differ train set scienc , thei were consid the problem of classifi between confus word , so for exampl , in the sentenc for breakfast i at , should it be to , two or too ?
well , for thi exampl , for breakfast i at two , <num> egg .
so , thi is on exampl of a set of confus word and that's a differ set .
so thei took machin learn problem like these , sort of supervis learn problem to try to categor what is the appropri word to go into a certain posit in an english sentenc .
thei took a few differ learn algorithm which were , you know , sort of consid state of the art back in the dai , when thei ran the studi in <num> , so thei took a varianc , roughli a varianc on logist regress call the perceptron .
thei also took some of their algorithm that were fairli out back then but somewhat less us now so when the algorithm also veri similar to which is a regress but differ in some wai , much us somewhat less , us not too much right now took what's call a memori base learn algorithm again us somewhat less now .
but i'll talk a littl bit about that later .
and thei us a naiv base algorithm , which is someth thei'll actual talk about in thi cours .
the exact algorithm of these detail aren't import .
think of thi as , you know , just pick four differ classif algorithm and realli the exact algorithm aren't import .
but what thei did wa thei vari the train set size and tri out these learn algorithm on the rang of train set size and that's the result thei got .
and the trend ar veri clear right first most of these outer room give remark similar perform .
and second , as the train set size increas , on the horizont axi is the train set size in million go from you know a hundr thousand up to a thousand million that is a billion train exampl .
the perform of the algorithm all pretti much monoton increas and the fact that if you pick ani algorithm mai be pick a inferior algorithm but if you give that inferior algorithm more data , then from these exampl , it look like it will most like beat even a superior algorithm .
so sinc thi origin studi which is veri influenti , there's been a rang of mani differ studi show similar result that show that mani differ learn algorithm you know tend to , can sometim , depend on detail , can give pretti similar rang of perform , but what can realli drive perform is you can give the algorithm a ton of train data .
and thi is , result like these ha led to a sai in machin learn that often in machin learn it's not who ha the best algorithm that win , it's who ha the most data so when is thi true and when is thi not true ?
becaus we have a learn algorithm for which thi is true then get a lot of data is often mayb the best wai to ensur that we have an algorithm with veri high perform rather than you know , debat worri about exactli which of these item to us .
let's try to lai out a set of assumpt under which have a massiv train set we think will be abl to help .
let's assum that in our machin learn problem , the featur x have suffici inform with which we can us to predict y accur .
for exampl , if we take the confus word all of them that we had on the previou slide .
let's sai that it featur x captur what ar the surround word around the blank that we're try to fill in .
so the featur captur then we want to have , sometim for breakfast i have black egg .
then yeah that is pretti much inform to tell me that the word i want in the middl is two and that is not word to and it not the word too .
so the featur captur , you know , on of these surround word then that give me enough inform to pretti unambigu decid what is the label y or in other word what is the word that i should be us to fill in that blank out of thi set of three confus word .
so that's an exampl what the futur ex ha suffici inform for specif y .
for a counter exampl .
consid a problem of predict the price of a hous from onli the size of the hous and from no other featur .
so if you imagin i tell you that a hous is , you know , <num> squar feet but i don't give you ani other featur .
i don't tell you that the hous is in an expens part of the citi .
or if i don't tell you that the hous , the number of room in the hous , or how nice furnish the hous is , or whether the hous is new or old .
if i don't tell you anyth other than that thi is a <num> squar foot hous , well there's so mani other factor that would affect the price of a hous other than just the size of a hous that if all you know is the size , it's actual veri difficult to predict the price accur .
so that would be a counter exampl to thi assumpt that the featur have suffici inform to predict the price to the desir level of accuraci .
the wai i think about test thi assumpt , on wai i often think about it is , how often i ask myself .
given the input featur x , given the featur , given the same inform avail as well as learn algorithm .
if we were to go to human expert in thi domain .
can a human expert actual or can human expert confid predict the valu of y .
for thi first exampl if we go to , you know an expert human english speaker .
you go to someon that speak english well , right , then a human expert in english just read most peopl like you and me will probabl we would probabl be abl to predict what word should go in here , to a good english speaker can predict thi well , and so thi give me confid that x allow us to predict y accur , but in contrast if we go to an expert in human price .
like mayb an expert realtor , right , someon who sell hous for a live .
if i just tell them the size of a hous and i tell them what the price is well even an expert in price or sell hous wouldn't be abl to tell me and so thi is fine that for the hous price exampl know onli the size doesn't give me enough inform to predict the price of the hous .
so , let's sai , thi assumpt hold .
let's see then , when have a lot of data could help .
suppos the featur have enough inform to predict the valu of y .
and let's suppos we us a learn algorithm with a larg number of paramet so mayb logist regress or linear regress with a larg number of featur .
or on thing that i sometim do , on thing that i often do actual is us neural network with mani hidden unit .
that would be anoth learn algorithm with a lot of paramet .
so these ar all power learn algorithm with a lot of paramet that can fit veri complex function .
so , i'm go to call these , i'm go to think of these as low bia algorithm becaus you know we can fit veri complex function and becaus we have a veri power learn algorithm , thei can fit veri complex function .
chanc ar , if we run these algorithm on the data set , it will be abl to fit the train set well , and so hopefulli the train error will be slow .
now let's sai , we us a massiv , massiv train set , in that case , if we have a huge train set , then hopefulli even though we have a lot of paramet but if the train set is sort of even much larger than the number of paramet then hopefulli these album will be unlik to overfit .
right becaus we have such a massiv train set and by unlik to overfit what that mean is that the train error will hopefulli be close to the test error .
final put these two togeth that the train set error is small and the test set error is close to the train error what thi two togeth impli is that hopefulli the test set error will also be small .
anoth wai to think about thi is that in order to have a high perform learn algorithm we want it not to have high bia and not to have high varianc .
so the bia problem we're go to address by make sure we have a learn algorithm with mani paramet and so that give us a low bia alorithm and by us a veri larg train set , thi ensur that we don't have a varianc problem here .
so hopefulli our algorithm will have no varianc and so is by pull these two togeth , that we end up with a low bia and a low varianc learn algorithm and thi allow us to do well on the test set .
and fundament it's a kei ingredi of assum that the featur have enough inform and we have a rich class of function that's why it guarante low bia , and then it have a massiv train set that that's what guarante more varianc .
so thi give us a set of condit rather hopefulli some understand of what's the sort of problem where if you have a lot of data and you train a learn algorithm with lot of paramet , that might be a good wai to give a high perform learn algorithm and realli , i think the kei test that i often ask myself ar first , can a human expert look at the featur x and confid predict the valu of y .
becaus that's sort of a certif that y can be predict accur from the featur x and second , can we actual get a larg train set , and train the learn algorithm with a lot of paramet in the train set and if you can't do both then that's more often give you a veri kind perform learn algorithm .
by now , you see the rang of differ learn algorithm .
within supervis learn , the perform of mani supervis learn algorithm will be pretti similar and when that is less more often be whether you us learn algorithm a or learn algorithm b but when that is small there will often be thing like the amount of data you ar creat these algorithm on .
that's alwai your skill in appli thi algorithm .
seem like your choic of the featur that you design to give the learn algorithm and how you choos the regular paramet and thing like that .
but there's on more algorithm that is veri power and it veri wide us both within industri and in academia .
and that's call the support vector machin , and compar to both the logist regress and neural network , the support vector machin or the svm sometim give a cleaner and sometim more power wai of learn complex nonlinear function .
and so i'd like to take the next video to talk about that .
later in thi cours , i will do a quick survei of the rang of differ supervis learn algorithm just to veri briefli describ them but the support vector machin , given it popular and how popular it is , thi will be the last of the supervis learn algorithm that i'll spend a signific amount of time on in thi cours .
as with our develop of ever learn algorithm , we ar go to start by talk about the optim object , so let's get start on thi algorithm .
in order to describ the support vector machin , i'm actual go to start with logist regress and show how we can modifi it a bit and get what is essenti the support vector machin .
so , in logist regress we have our familiar form of the hypothes there and the sigmoid activ function shown on the right .
and in order to explain some of the math , i'm go to us z to denot failur of transpos x here .
now let's think about what we will like the logist regress to do .
if we have an exampl with y equal <num> , and by thi i mean an exampl in either a train set or the test set , you know , order cross valuat set where y is equal to <num> then we ar sort of hope that h of x will be close to <num> .
so , right , we ar hope to correctli classifi that exampl and what , have h of x close to <num> , what that mean is that theta transpos x must be much larger than <num> , so there's greater than , greater than sign , that mean much , much greater than <num> and that's becaus it is z , that is theta transpos x is when z is much bigger than <num> , is far to the right of thi figur that , you know , the output of logist regress becom close to <num> .
convers , if we have an exampl where y is equal to <num> then what were hope for is that the hypothesi will output the valu to close to <num> and that correspond to theta transpos x or z pretti much less than <num> becaus that correspond to hypothesi of output a valu close to <num> .
if you look at the cost function of logist regress , what you find is that each exampl x , y , contribut a term like thi to the overal cost function .
all right .
so , for the overal cost function , we usual , we will also have a sum over all the train exampl and <num> over m term .
but thi express here .
that's the term that a singl train exampl contribut to the overal object function for logist regress .
now , if i take the definit for the full of my hypothesi and plug it in , over here , the on i get is that each train exampl contribut thi term , right ?
ignor the <num> over m but it contribut that term to be my overal cost function for logist regress .
now let's consid the <num> case of when y is equal to <num> and when y is equal to <num> .
in the first case , let's suppos that y is equal to <num> .
in that case , onli thi first row in the object matter becaus thi <num> minu y term will be equal to <num> if y is equal to <num> .
so , when y is equal to <num> when in an exampl , x , y when y is equal to <num> , what we get is thi term minu log <num> over <num> plu e to the neg z .
where , similar to the last slide , i'm us z to denot data transpos x .
and of cours , in the cost we actual had thi minu y but we just said that you know , if y is equal to <num> .
so that's equal to <num> .
i just simplifi it a wai in the express that i have written down here .
and if we plot thi function , as a function of z , what you find is that you get thi curv shown on the lower left of thi line and thu we also see that when z is equal to larg that is to when theta transpos x is larg that correspond to a valu of z that give us a veri small valu , a veri small contribut to the cost function and thi kind of explain why when logist regress see a posit exampl with y equal <num> it tri to set theta transpos x to be veri larg becaus that correspond to thi term in a cost function be small .
now , to build the support vector machin , here is what we ar go to do .
we ar go to take thi cost function , thi minu log <num> over <num> plu e to the neg z and modifi it a littl bit .
let me take thi point <num> over here and let me draw the cours function that i'm go to us , the new cost function is gonna be flat from here on out and then i'm go to draw someth that grow as a straight line similar to logist regress but thi is go to be the straight line in thi posh in .
so the curv that i just drew in magenta .
the curv that i just drew purpl and magenta .
so , it's a pretti close approxim to the cost function us by logist regress except that it is now made out of two line segment .
thi is flat potion on the right and then thi is a straight line portion on the left .
and don't worri too much about the slope of the straight line portion .
it doesn't matter that much but that's the new cost function we're go to us where y is equal to <num> and you can imagin you should do someth pretti similar to logist regress but it turn out that thi will give the support vector machin comput advantag that will give us later on an easier optim problem , that will be easier for stock trade and so on .
we just talk about the case of y equal to <num> .
the other case is if y is equal to <num> .
in that case , if you look at the cost then onli thi second term will appli becaus the first term goe a wai where if y is equal to <num> then nearli it wa <num> here .
so your left onli with the second term of the express abov and so the cost of an exampl or the contribut of the cost function is go to be given by thi term over here and if you plug that as a function z .
so , i have here z on the horizont axi , you end up with thi group and for the support vector machin , onc again we're go to replac thi blue line with someth similar and see if we can replac it with a new cost , there is flat out here .
there's <num> out here and then it grow as a straight line like so .
so , let me give these two function name .
thi function on the left , i'm go to call cost subscript <num> of z .
and thi function on the right , i'm go to call cost subscript <num> of z .
and the subscript just refer to the cost correspond to y is equal to <num> versu y is equal to <num> .
arm with these definit , we ar now readi to build the support vector machin .
here is the cost function j of theta that we have for logist regress .
in case thi the equat look a bit unfamiliar is becaus previous we had a minor sign outsid , but here what i did wa i instead move the minor sign insid thi express .
so it just , you know , make it look a littl more differ .
for the support vector machin what we ar go to do is essenti take thi , and replac thi with cost <num> of z , that is cost <num> of theta transpos x .
i'm go to take thi and replac it with cost <num> of z .
thi is cost <num> of theta transpos x where the cost <num> function is what we had on the previou line that look like thi and the cost <num> function , again what we have on the previou line that look like thi .
so , what we have for the support vector machin is an minimizationminim problem of on of <num> over m , sum over my train exampl of y i time cost <num> of theta transpos x i plu <num> minu y i time cost zero of theta transpos x i .
and then plu my usual regular paramet like so .
now by convent for the support vector machin , we actual write thing slightli differ .
we parametr thi just veri slightli differ .
first , we're go to get rid of the <num> over m term and thi just , thi just happen to be a slightli differ convent that peopl us for support vector machin compar to for logist regress .
but here's what i mean , you know , what i'm go to do is i am just gonna get rid of thi <num> over m term and thi should give me the same optim valu for theta , right .
becaus <num> over m is just a constant .
so , you know , whether i solv thi minim problem with <num> over m in front or not , i should end up with the same optim valu of theta .
here is what i mean , to give you a concret exampl , suppos i had a minim problem that you know minim over a real number u of u minu <num> squar , plu <num> , right .
well , the minimum of thi happen , happen to know the minimum of thi is u equal <num> .
now if i want to take thi object function and multipli it by <num> , so here my minim problem is minimum of u of <num> , u minu <num> squar plu <num> .
well the valu of u that minim thi is still u equal <num> , right .
so , multipli someth that you ar minim over by some constant , <num> in thi case , it doe not chang the valu of u that give us , that minim thi function .
so the same wai what i've done by cross out thi m is , all i am do is multipli my object function by some constant m and it doesn't chang the valu of theta that achiev the minimum .
the second bit of notat chang , we're just design the most standard convent , when us as the svm , instead of logist regress as a follow .
so , for logist regress , we had two term to our object function .
the first is thi term which is the cost that come from the train set and the second is thi term , which is the regular term and what we had , we had to control the trade off between these by sai , you know , that we want to minim a plu and then my regular paramet lambda , and then time some other term b , right ?
where as i am us a to denot thi first term , and i am us b to denot that second term , mai be without the lambda , and instead of priorit thi as a plu lambda b , we could , and so what we did wa by set differ valu for thi regular paramet lambda .
we could trade off the rel wai between how much we want to fit the train set well , as minim a , versu how much we care about keep the valu of the paramet small .
so that would be for the paramet b .
for the support vector machin , just by convent we're go to us a differ paramet .
so instead of us lambda here to control the rel wait between you know , the first and second term , we ar still go to us a differ paramet which by convent is call c and we instead ar go to minim c time a plu b .
so for logist regress if we send a veri larg valu of lambda , that mean to give b a veri high weight .
here is that if we set c to be a veri small valu .
that correspond to give b much larger weight than c than a .
so thi is just a differ wai of control the trade off or just a differ wai of parametr how much we care about optim the first term versu how much we care about optim the second term .
and if you want you can think of thi as the paramet c plai a role similar to <num> over lambda and it's not that it's two equat or these two express will be equal , it's equal <num> over lambda and it's not that these two equat or these two express will be equal .
it's equal t <num> over lambda .
that's not the case where it bother that if c is equal to <num> over lambda then these two optim object should give you the same valu , same optim valu of theta .
so just fill that in .
i'm gonna cross out lambda here and write in the constant c there .
so , that's give us our overal optim object function for the support vector machin and where you minim that function then what you have is the paramet learn by svm .
final on light of logist regress , the support vector machin doesn't output the probabl .
instead what we have is , we have thi cost function which we minim to get the paramet theta and what the support vector machin doe , is it just make the predict of y be equal <num> or <num> directli .
so the hypothesi , where i predict , <num> , if theta transpos x is greater than or equal to <num> and i'll predict <num> otherwis .
and so , have learn the paramet theta , thi is the form of the hypothesi for the support vector machin .
so , that wa a mathemat definit of what a support vector machin doe .
in the next few video , let's try to get back to intuit about what thi optim object lead to and whether the sourc of the hypothesi a svm will learn and also talk about how to modifi thi just a littl bit to learn complex , nonlinear function .
sometim peopl talk about support vector machin , as larg margin classifi , in thi video i'd like to tell you what that mean , and thi will also give us a us pictur of what an svm hypothesi mai look like .
here's my cost function for the support vector machin where here on the left i've plot my cost <num> of z function that i us for posit exampl and on the right i've plot my zero of 'z' function , where i have 'z' here on the horizont axi .
now , let's think about what it take to make these cost function small .
if you have a posit exampl , so if y is equal to <num> , then cost <num> of z is zero onli when z is greater than or equal to <num> .
so in other word , if you have a posit exampl , we realli want theta transpos x to be greater than or equal to <num> and convers if y is equal to zero , look thi cost zero of z function , then it's onli in thi region where z is less than equal to <num> we have the cost is zero as z is equal to zero , and thi is an interest properti of the support vector machin right , which is that , if you have a posit exampl so if y is equal to on , then all we realli need is that theta transpos x is greater than equal to zero .
and that would mean that we classifi correctli becaus if theta transpos x is greater than zero our hypothesi will predict zero .
and similarli , if you have a neg exampl , then realli all you want is that theta transpos x is less than zero and that will make sure we got the exampl right .
but the support vector machin want a bit more than that .
it sai , you know , don't just bare get the exampl right .
so then don't just have it just a littl bit bigger than zero .
what i realli want is for thi to be quit a lot bigger than zero sai mayb bit greater or equal to on and i want thi to be much less than zero .
mayb i want it less than or equal to <num> .
and so thi build in an extra safeti factor or safeti margin factor into the support vector machin .
logist regress doe someth similar too of cours , but let's see what happen or let's see what the consequ of thi ar , in the context of the support vector machin .
concret , what i'd like to do next is consid a case case where we set thi constant c to be a veri larg valu , so let's imagin we set c to a veri larg valu , mai be a hundr thousand , some huge number .
let's see what the support vector machin will do .
if c is veri , veri larg , then when minim thi optim object , we're go to be highli motiv to choos a valu , so that thi first term is equal to zero .
so let's try to understand the optim problem in the context of , what would it take to make thi first term in the object equal to zero , becaus you know , mayb we'll set c to some huge constant , and thi will hope , thi should give us addit intuit about what sort of hypothes a support vector machin learn .
so we saw alreadi that whenev you have a train exampl with a label of y <num> if you want to make that first term zero , what you need is is to find a valu of theta so that theta transpos x i is greater than or equal to <num> .
and similarli , whenev we have an exampl , with label zero , in order to make sure that the cost , cost zero of z , in order to make sure that cost is zero we need that theta transpos x i is less than or equal to <num> .
so , if we think of our optim problem as now , realli choos paramet and show that thi first term is equal to zero , what we're left with is the follow optim problem .
we're go to minim that first term zero , so c time zero , becaus we're go to choos paramet so that's equal to zero , plu on half and then you know that second term and thi first term is 'c' time zero , so let's just cross that out becaus i know that's go to be zero .
and thi will be subject to the constraint that theta transpos x i is greater than or equal to on , if y i is equal to on and theta transpos x i is less than or equal to minu on whenev you have a neg exampl and it turn out that when you solv thi optim problem , when you minim thi as a function of the paramet theta you get a veri interest decis boundari .
concret , if you look at a data set like thi with posit and neg exampl , thi data is linearli separ and by that , i mean that there exist , you know , a straight line , altough there is mani a differ straight line , thei can separ the posit and neg exampl perfectli .
for exampl , here is on decis boundari that separ the posit and neg exampl , but somehow that doesn't look like a veri natur on , right ?
or by draw an even wors on , you know here's anoth decis boundari that separ the posit and neg exampl but just bare .
but neither of those seem like particularli good choic .
the support vector machin will instead choos thi decis boundari , which i'm draw in black .
and that seem like a much better decis boundari than either of the on that i drew in magenta or in green .
the black line seem like a more robust separ , it doe a better job of separ the posit and neg exampl .
and mathemat , what that doe is , thi black decis boundari ha a larger distanc .
that distanc is call the margin , when i draw up thi two extra blue line , we see that the black decis boundari ha some larger minimum distanc from ani of my train exampl , wherea the magenta and the green line thei come awfulli close to the train exampl .
and then that seem to do a less a good job separ the posit and neg class than my black line .
and so thi distanc is call the margin of the support vector machin and thi give the svm a certain robust , becaus it tri to separ the data with as a larg a margin as possibl .
so the support vector machin is sometim also call a larg margin classifi and thi is actual a consequ of the optim problem we wrote down on the previou slide .
i know that you might be wonder how is it that the optim problem i wrote down in the previou slide , how doe that lead to thi larg margin classifi .
i know i haven't explain that yet .
and in the next video i'm go to sketch a littl bit of the intuit about why that optim problem give us thi larg margin classifi .
but thi is a us featur to keep in mind if you ar try to understand what ar the sort of hypothesi that an svm will choos .
that is , try to separ the posit and neg exampl with as big a margin as possibl .
i want to sai on last thing about larg margin classifi in thi intuit , so we wrote out thi larg margin classif set in the case of when c , that regular concept , wa veri larg , i think i set that to a hundr thousand or someth .
so given a dataset like thi , mayb we'll choos that decis boundari that separ the posit and neg exampl on larg margin .
now , the svm is actual sligthli more sophist than thi larg margin view might suggest .
and in particular , if all you're do is us a larg margin classifi then your learn algorithm can be sensit to outlier , so let just add an extra posit exampl like that shown on the screen .
if he had on exampl then it seem as if to separ data with a larg margin , mayb i'll end up learn a decis boundari like that , right ?
that is the magenta line and it's realli not clear that base on the singl outlier base on a singl exampl and it's realli not clear that it's actual a good idea to chang my decis boundari from the black on over to the magenta on .
so , if c , if the regular paramet c were veri larg , then thi is actual what svm will do , it will chang the decis boundari from the black to the magenta on but if c were reason small if you were to us the c , not too larg then you still end up with thi black decis boundari .
and of cours if the data were not linearli separ so if you had some posit exampl in here , or if you had some neg exampl in here then the svm will also do the right thing .
and so thi pictur of a larg margin classifi that's realli , that's realli the pictur that give better intuit onli for the case of when the regul paramet c is veri larg , and just to remind you thi correspond c plai a role similar to on over lambda , where lambda is the regular paramet we had previous .
and so it's onli of on over lambda is veri larg or equival if lambda is veri small that you end up with thing like thi magenta decis boundari , but in practic when appli support vector machin , when c is not veri veri larg like that , it can do a better job ignor the few outlier like here .
and also do fine and do reason thing even if your data is not linearli separ .
but when we talk about bia and varianc in the context of support vector machin which will do a littl bit later , hopefulli all of of thi trade off involv the regular paramet will becom clearer at that time .
so i hope that give some intuit about how thi support vector machin function as a larg margin classifi that tri to separ the data with a larg margin , technic thi pictur of thi view is true onli when the paramet c is veri larg , which is a us wai to think about support vector machin .
there wa on miss step in thi video which is , why is it that the optim problem we wrote down on these slide , how doe that actual lead to the larg margin classifi , i didn't do that in thi video , in the next video i will sketch a littl bit more of the math behind that to explain that separ reason of how the optim problem we wrote out result in a larg margin classifi .
in thi video , i'd like to tell you a bit about the math behind larg margin classif .
thi video is option , so pleas feel free to skip it .
it mai also give you better intuit about how the optim problem of the support vex machin , how that lead to larg margin classifi .
in order to get start , let me first remind you of a coupl of properti of what vector inner product look like .
let's sai i have two vector u and v , that look like thi .
so both two dimension vector .
then let's see what u transpos v look like .
and u transpos v is also call the inner product between the vector u and v .
us a two dimension vector , so i can on plot it on thi figur .
so let's sai that's the vector u .
and what i mean by that is if on the horizont axi that valu take whatev valu u1 is and on the vertic axi the height of that is whatev u2 is the second compon of the vector u .
now , on quantiti that will be nice to have is the norm of the vector u .
so , these ar , you know , doubl bar on the left and right that denot the norm or length of u .
so thi just mean ; realli the euclidean length of the vector u .
and thi is pythagora theorem is just equal to u1 squar plu u2 squar squar root , right ?
and thi is the length of the vector u .
that's a real number .
just sai you know , what is the length of thi , what is the length of thi vector down here .
what is the length of thi arrow that i just drew , is the normal view ?
now let's go back and look at the vector v becaus we want to comput the inner product .
so v will be some other vector with , you know , some valu v1 , v2 .
and so , the vector v will look like that , toward v like so .
now let's go back and look at how to comput the inner product between u and v .
here's how you can do it .
let me take the vector v and project it down onto the vector u .
so i'm go to take a orthogon project or a <num> degre project , and project it down onto u like so .
and what i'm go to do measur length of thi red line that i just drew here .
so , i'm go to call the length of that red line p .
so , p is the length or is the magnitud of the project of the vector v onto the vector u .
let me just write that down .
so , p is the length of the project of the vector v onto the vector u .
and it is possibl to show that unit product u transpos v , that thi is go to be equal to p time the norm or the length of the vector u .
so , thi is on wai to comput the inner product .
and if you actual do the geometri figur out what p is and figur out what the norm of u is .
thi should give you the same wai , the same answer as the other wai of comput unit product .
right .
which is if you take u transpos v then u transpos thi u1 u2 , it a on by two matrix , <num> time v .
and so thi should actual give you u1 , v1 plu u2 , v2 .
and so the theorem of linear algebra that these two formula give you the same answer .
and by the wai , u transpos v is also equal to v transpos u .
so if you were to do the same process in revers , instead of project v onto u , you could project u onto v .
then , you know , do the same process , but with the row of u and v revers .
and you would actual , you should actual get the same number whatev that number is .
and just to clarifi what's go on in thi equat the norm of u is a real number and p is also a real number .
and so u transpos v is the regular multipl as two real number of the length of p time the normal view .
just on last detail , which is if you look at the norm of p , p is actual sign so to the right .
and it can either be posit or neg .
so let me sai what i mean by that , if u is a vector that look like thi and v is a vector that look like thi .
so if the angl between u and v is greater than nineti degre .
then if i project v onto u , what i get is a project it look like thi and so that length p .
and in thi case , i will still have that u transpos v is equal to p time the norm of u .
except in thi exampl p will be neg .
so , you know , in inner product if the angl between u and v is less than nineti degre , then p is the posit length for that red line wherea if the angl of thi angl of here is greater than <num> degre then p here will be neg of the length of the super line of that littl line segment right over there .
so the inner product between two vector can also be neg if the angl between them is greater than <num> degre .
so that's how vector inner product work .
we're go to us these properti of vector inner product to try to understand the support vector machin optim object over there .
here is the optim object for the support vector machin that we work out earlier .
just for the purpos of thi slide i am go to make on simplif or onc just to make the object easi to analyz and what i'm go to do is ignor the indeceptrum .
so , we'll just ignor theta <num> and set that to be equal to <num> .
to make thing easier to plot , i'm also go to set n the number of featur to be equal to <num> .
so , we have onli <num> featur , x1 and x2 .
now , let's look at the object function .
the optim object of the svm .
what we have onli two featur .
when n is equal to <num> .
thi can be written , on half of theta on squar plu theta two squar .
becaus we onli have two paramet , theta on and thetaa two .
what i'm go to do is rewrit thi a bit .
i'm go to write thi as on half of theta on squar plu theta two squar and the squar root squar .
and the reason i can do that , is becaus for ani number , you know , w , right , the squar root of w and then squar , that's just equal to w .
so squar root and squar should give you the same thing .
what you mai notic is that thi term insid is that's equal to the norm or the length of the vector theta and what i mean by that is that if we write out the vector theta like thi , as you know theta on , theta two .
then thi term that i've just underlin in red , that's exactli the length , or the norm , of the vector theta .
we ar call the definit of the norm of the vector that we have on the previou line .
and in fact thi is actual equal to the length of the vector theta , whether you write it as theta zero , theta <num> , theta <num> .
that is , if theta zero is equal to zero , as i assum here .
or just the length of theta <num> , theta <num> ; but for thi line i am go to ignor theta <num> .
so let me just , you know , treat theta as thi , let me just write theta , the normal theta as thi theta <num> , theta <num> onli , but the math work out either wai , whether we includ theta zero here or not .
so it's not go to matter for the rest of our deriv .
and so final thi mean that my optim object is equal to on half of the norm of theta squar .
so all the support vector machin is do in the optim object is it's minim the squar norm of the squar length of the paramet vector theta .
now what i'd like to do is look at these term , theta transpos x and understand better what thei're do .
so given the paramet vector theta and given and exampl x , what is thi is equal to ?
and on the previou slide , we figur out what u transpos v look like , with differ vector u and v .
and so we're go to take those definit , you know , with theta and x i plai the role of u and v .
and let's see what that pictur look like .
so , let's sai i plot .
let's sai i look at just a singl train exampl .
let's sai i have a posit exampl the draw wa across there and let's sai that is my exampl x i , what that realli mean is plot on the horizont axi some valu x i <num> and on the vertic axi x i <num> .
that's how i plot my train exampl .
and although we haven't been realli think of thi as a vector , what thi realli is , thi is a vector from the origin from <num> , <num> out to the locat of thi train exampl .
and now let's sai we have a paramet vector and i'm go to plot that as vector , as well .
what i mean by that is if i plot theta <num> here and theta <num> there so what is the inner product theta transpos x i .
while us our earlier method , the wai we comput that is we take my exampl and project it onto my paramet vector theta .
and then i'm go to look at the length of thi segment that i'm color in , in red .
and i'm go to call that p superscript i to denot that thi is a project of the i th train exampl onto the paramet vector theta .
and so what we have is that theta transpos x i is equal to follow what we have on the previou slide , thi is go to be equal to p time the length of the norm of the vector theta .
and thi is of cours also equal to theta <num> x<num> plu theta <num> x<num> .
so each of these is , you know , an equal valid wai of comput the inner product between theta and x i .
okai .
so where doe thi leav us ?
what thi mean is that , thi constrain that theta transpos x i be greater than or equal to on or less than minu on .
what thi mean is that it can replac the us of constraint that p i time x be greater than or equal to on .
becaus theta transpos x i is equal to p i time the norm of theta .
so write that into our optim object .
thi is what we get where i have , instead of theta transpos x i , i now have thi p i time the norm of theta .
and just to remind you we work out earlier too that thi optim object can be written as on half time the norm of theta squar .
so , now let's consid the train exampl that we have at the bottom and for now , continu to us the simplif that theta <num> is equal to <num> .
let's see what decis boundari the support vector machin will choos .
here's on option , let's sai the support vector machin were to choos thi decis boundari .
thi is not a veri good choic becaus it ha veri small margin .
thi decis boundari come veri close to the train exampl .
let's see why the support vector machin will not do thi .
for thi choic of paramet it's possibl to show that the paramet vector theta is actual at <num> degre to the decis boundari .
and so , that green decis boundari correspond to a paramet vector theta that point in that direct .
and by the wai , the simplif that theta <num> equal <num> that just mean that the decis boundari must pass through the origin , <num> , <num> over there .
so now , let's look at what thi impli for the optim object .
let's sai that thi exampl here .
let's sai that's my first exampl , you know , x1 .
if we look at the project of thi exampl onto my paramet theta .
that's the project .
and so that littl red line segment .
that is equal to p1 .
and that is go to be pretti small , right .
and similarli , if thi exampl here , if thi happen to be x2 , that's my second exampl .
then , if i look at the project of thi thi exampl onto theta .
you know .
then , let me draw thi on in magenta .
thi littl magenta line segment , that's go to be p2 .
that's the project of the second exampl onto my , onto the direct of my paramet vector theta which goe like thi .
and so , thi littl project line segment is get pretti small .
p2 will actual be a neg number , right so p2 is in the opposit direct .
thi vector ha greater than <num> degre angl with my paramet vector theta , it's go to be less than <num> .
and so what we're find is that these term p i ar go to be pretti small number .
so if we look at the optim object and see , well , for posit exampl we need p i time the norm of theta to be bigger than either on .
but if p i over here , if p1 over here is pretti small , that mean that we need the norm of theta to be pretti larg , right ?
if p1 of theta is small and we want p1 you know time in all of theta to be bigger than either on , well the onli wai for that to be true for the profit that these two number to be larg if p1 is small , as we said we want the norm of theta to be larg .
and similarli for our neg exampl , we need p2 time the norm of theta to be less than or equal to minu on .
and we saw in thi exampl alreadi that p2 is go pretti small neg number , and so the onli wai for that to happen as well is for the norm of theta to be larg , but what we ar do in the optim object is we ar try to find a set of paramet where the norm of theta is small , and so you know , so thi doesn't seem like such a good direct for the paramet vector and theta .
in contrast , just look at a differ decis boundari .
here , let's sai , thi svm choos that decis boundari .
now the is go to be veri differ .
if that is the decis boundari , here is the correspond direct for theta .
so , with the direct boundari you know , that vertic line that correspond to it is possibl to show us linear algebra that the wai to get that green decis boundari is have the vector of theta be at <num> degre to it , and now if you look at the project of your data onto the vector x , let sai it befor thi exampl is my exampl of x1 .
so when i project thi on to x , or onto theta , what i find is that thi is p1 .
that length there is p1 .
the other exampl , that exampl is and i do the same project and what i find is that thi length here is a p2 realli that is go to be less than <num> .
and you notic that now p1 and p2 , these length of the project ar go to be much bigger , and so if we still need to enforc these constraint that p1 of the norm of theta is phase number on becaus p1 is so much bigger now .
the normal can be smaller .
and so , what thi mean is that by choos the decis boundari shown on the right instead of on the left , the svm can make the norm of the paramet theta much smaller .
so , if we can make the norm of theta smaller and therefor make the squar norm of theta smaller , which is why the svm would choos thi hypothesi on the right instead .
and thi is how the svm give rise to thi larg margin certif effect .
mainli , if you look at thi green line , if you look at thi green hypothesi we want the project of my posit and neg exampl onto theta to be larg , and the onli wai for that to hold true thi is if surround the green line .
there's thi larg margin , there's thi larg gap that separ posit and neg exampl is realli the magnitud of thi gap .
the magnitud of thi margin is exactli the valu of p1 , p2 , p3 and so on .
and so by make the margin larg , by these tyro p1 , p2 , p3 and so on that's the svm can end up with a smaller valu for the norm of theta which is what it is try to do in the object .
and thi is why thi machin end up with enlarg margin classifi becaus itss try to maxim the norm of these p1 which is the distanc from the train exampl to the decis boundari .
final , we did thi whole deriv us thi simplif that the paramet theta <num> must be equal to <num> .
the effect of that as i mention briefli , is that if theta <num> is equal to <num> what that mean is that we ar entertain decis boundari that pass through the origin of decis boundari pass through the origin like that , if you allow theta zero to be non <num> then what that mean is that you entertain the decis boundari that did not cross through the origin , like that on i just drew .
and i'm not go to do the full deriv that .
it turn out that thi same larg margin proof work in pretti much in exactli the same wai .
and there's a gener of thi argument that we just went through them long ago through that show that even when theta <num> is non <num> , what the svm is try to do when you have thi optim object .
which again correspond to the case of when c is veri larg .
but it is possibl to show that , you know , when theta is not equal to <num> thi support vector machin is still find is realli try to find the larg margin separ that between the posit and neg exampl .
so that explain how thi support vector machin is a larg margin classifi .
in the next video we will start to talk about how to take some of these svm idea and start to appli them to build a complex nonlinear classifi .
in thi video , i'd like to start adapt support vector machin in order to develop complex nonlinear classifi .
the main techniqu for do that is someth call kernel .
let's see what thi kernel ar and how to us them .
if you have a train set that look like thi , and you want to find a nonlinear decis boundari to distinguish the posit and neg exampl , mayb a decis boundari that look like that .
on wai to do so is to come up with a set of complex polynomi featur , right ?
so , set of featur that look like thi , so that you end up with a hypothesi x that predict <num> if you know that theta <num> and plu theta <num> x<num> plu dot dot dot all those polynomi featur is greater than <num> , and predict <num> , otherwis .
and anoth wai of write thi , to introduc a level of new notat that i'll us later , is that we can think of a hypothesi as comput a decis boundari us thi .
so , theta <num> plu theta <num> f<num> plu theta <num> , f<num> plu theta <num> , f<num> plu and so on .
where i'm go to us thi new denot f1 , f2 , f3 and so on to denot these new sort of featur that i'm comput , so f1 is just x1 , f2 is equal to x2 , f3 is equal to thi on here .
so , x1x2 .
so , f4 is equal to x1 squar where f5 is to be x2 squar and so on and we seen previous that come up with these high order polynomi is on wai to come up with lot more featur , the question is , is there a differ choic of featur or is there better sort of featur than thi high order polynomi becaus you know it's not clear that thi high order polynomi is what we want , and what we talk about comput vision talk about when the input is an imag with lot of pixel .
we also saw how us high order polynomi becom veri computation expens becaus there ar a lot of these higher order polynomi term .
so , is there a differ or a better choic of the featur that we can us to plug into thi sort of hypothesi form .
so , here is on idea for how to defin new featur f1 , f2 , f3 .
on thi line i am go to defin onli three new featur , but for real problem we can get to defin a much larger number .
but here's what i'm go to do in thi phase of featur x1 , x2 , and i'm go to leav x0 out of thi , the interceptor x0 , but in thi phase x1 x2 , i'm go to just , you know , manual pick a few point , and then call these point l1 , we ar go to pick a differ point , let's call that l2 and let's pick the third on and call thi on l3 , and for now let's just sai that i'm go to choos these three point manual .
i'm go to call these three point line up , so line up on , two , three .
what i'm go to do is defin my new featur as follow , given an exampl x , let me defin my first featur f1 to be some measur of the similar between my train exampl x and my first landmark and thi specif formula that i'm go to us to measur similar is go to be thi is e to the minu the length of x minu l1 , squar , divid by two sigma squar .
so , depend on whether or not you watch the previou option video , thi notat , you know , thi is the length of the vector w .
and so , thi thing here , thi x minu l1 , thi is actual just the euclidean distanc squar , is the euclidean distanc between the point x and the landmark l1 .
we will see more about thi later .
but that's my first featur , and my second featur f2 is go to be , you know , similar function that measur how similar x is to l2 and the game is go to be defin as the follow function .
thi is e to the minu of the squar of the euclidean distanc between x and the second landmark , that is what the enumer is and then divid by <num> sigma squar and similarli f3 is , you know , similar between x and l3 , which is equal to , again , similar formula .
and what thi similar function is , the mathemat term for thi , is that thi is go to be a kernel function .
and the specif kernel i'm us here , thi is actual call a gaussian kernel .
and so thi formula , thi particular choic of similar function is call a gaussian kernel .
but the wai the terminolog goe is that , you know , in the abstract these differ similar function ar call kernel and we can have differ similar function and the specif exampl i'm give here is call the gaussian kernel .
we'll see other exampl of other kernel .
but for now just think of these as similar function .
and so , instead of write similar between x and l , sometim we also write thi a kernel denot you know , lower case k between x and on of my landmark all right .
so let's see what a crimin actual do and why these sort of similar function , why these express might make sens .
so let's take my first landmark .
my landmark l1 , which is on of those point i chose on my figur just now .
so the similar of the kernel between x and l1 is given by thi express .
just to make sure , you know , we ar on the same page about what the numer term is , the numer can also be written as a sum from j equal <num> through n on sort of the distanc .
so thi is the compon wise distanc between the vector x and the vector l .
and again for the purpos of these slide i'm ignor x0 .
so just ignor the intercept term x0 , which is alwai equal to <num> .
so , you know , thi is how you comput the kernel with similar between x and a landmark .
so let's see what thi function doe .
suppos x is close to on of the landmark .
then thi euclidean distanc formula and the numer will be close to <num> , right .
so , that is thi term here , the distanc wa great , the distanc us x and <num> will be close to zero , and so f1 , thi is a simpl featur , will be approxim e to the minu <num> and then the numer squar over <num> is equal to squar so that e to the <num> , e to minu <num> , e to <num> is go to be close to on .
and i'll put the approxim symbol here becaus the distanc mai not be exactli <num> , but if x is closer to landmark thi term will be close to <num> and so f<num> would be close <num> .
convers , if x is far from <num> then thi first featur f1 will be e to the minu of some larg number squar , divid divid by two sigma squar and e to the minu of a larg number is go to be close to <num> .
so what these featur do is thei measur how similar x is from on of your landmark and the featur f is go to be close to on when x is close to your landmark and is go to be <num> or close to zero when x is far from your landmark .
each of these landmark .
on the previou line , i drew three landmark , l1 , l2 , l3 .
each of these landmark , defin a new featur f1 , f2 and f3 .
that is , given the the train exampl x , we can now comput three new featur f1 , f2 , and f3 , given , you know , the three landmark that i wrote just now .
but first , let's look at thi exponenti function , let's look at thi similar function and plot in some figur and just , you know , understand better what thi realli look like .
for thi exampl , let's sai i have two featur x1 and x2 .
and let's sai my first landmark , l1 is at a locat , <num> <num> .
so and let's sai i set sigma squar equal on for now .
if i plot what thi featur look like , what i get is thi figur .
so the vertic axi , the height of the surfac is the valu of f1 and down here on the horizont axi ar , if i have some train exampl , and there is x1 and there is x2 .
given a certain train exampl , the train exampl here which show the valu of x1 and x2 at a height abov the surfac , show the correspond valu of f1 and down below thi is the same figur i had show , us a quantifi plot , with x1 on horizont axi , x2 on horizont axi and so , thi figur on the bottom is just a contour plot of the 3d surfac .
you notic that when x is equal to <num> <num> exactli , then we the f1 take on the valu <num> , becaus that's at the maximum and x move awai as x goe further awai then thi featur take on valu that ar close to <num> .
and so , thi is realli a featur , f1 measur , you know , how close x is to the first landmark and if vari between <num> and on depend on how close x is to the first landmark l1 .
now the other wa due on thi slide is show the effect of vari thi paramet sigma squar .
so , sigma squar is the paramet of the gaussian kernel and as you vari it , you get slightli differ effect .
let's set sigma squar to be equal to <num> and see what we get .
we set sigma squar to <num> , what you find is that the kernel look similar , except for the width of the bump becom narrow .
the contour shrink a bit too .
so if sigma squar equal to <num> then as you start from x equal <num> <num> and as you move awai , then the featur f1 fall to zero much more rapidli and convers , if you ha increas sinc where three in that case and as i move awai from , you know l .
so thi point here is realli l , right , that's l1 is at locat <num> <num> , right .
so it's shown up here .
and if sigma squar is larg , then as you move awai from l1 , the valu of the featur fall awai much more slowli .
so , given thi definit of the featur , let's see what sourc of hypothesi we can learn .
given the train exampl x , we ar go to comput these featur f1 , f2 , f3 and a hypothesi is go to predict on when theta <num> plu theta <num> f<num> plu theta <num> f<num> , and so on is greater than or equal to <num> .
for thi particular exampl , let's sai that i've alreadi found a learn algorithm and let's sai that , you know , somehow i end up with these valu of the paramet .
so if theta <num> equal minu <num> , theta <num> equal <num> , theta <num> equal <num> , and theta <num> equal <num> and what i want to do is consid what happen if we have a train exampl that take ha locat at thi magenta dot , right where i just drew thi dot over here .
so let's sai i have a train exampl x , what would my hypothesi predict ?
well , if i look at thi formula .
becaus my train exampl x is close to l1 , we have that f1 is go to be close to <num> the becaus my train exampl x is far from l2 and l3 i have that , you know , f2 would be close to <num> and f3 will be close to <num> .
so , if i look at that formula , i have theta <num> plu theta <num> time <num> plu theta <num> time some valu .
not exactli <num> , but let's sai close to <num> .
then plu theta <num> time someth close to <num> .
and thi is go to be equal to plug in these valu now .
so , that give minu <num> plu <num> time <num> which is <num> , and so on .
which is equal to <num> which is greater than or equal to <num> .
so , at thi point , we're go to predict y equal <num> , becaus that's greater than or equal to zero .
now let's take a differ point .
now let' sai i take a differ point , i'm go to draw thi on in a differ color , in cyan sai , for a point out there , if that were my train exampl x , then if you make a similar comput , you find that f1 , f2 , ff3 ar all go to be close to <num> .
and so , we have theta <num> plu theta <num> , f<num> , plu so on and thi will be about equal to minu <num> , becaus theta <num> is minu <num> and f1 , f2 , f3 ar all zero .
so thi will be minu <num> , thi is less than zero .
and so , at thi point out there , we're go to predict y equal zero .
and if you do thi yourself for a rang of differ point , be sure to convinc yourself that if you have a train exampl that's close to l2 , sai , then at thi point we'll also predict y equal on .
and in fact , what you end up do is , you know , if you look around thi boundari , thi space , what we'll find is that for point near l1 and l2 we end up predict posit .
and for point far awai from l1 and l2 , that's for point far awai from these two landmark , we end up predict that the class is equal to <num> .
as so , what we end up do , is that the decis boundari of thi hypothesi would end up look someth like thi where insid thi red decis boundari would predict y equal <num> and outsid we predict y equal <num> .
and so thi is how with thi definit of the landmark and of the kernel function .
we can learn pretti complex non linear decis boundari , like what i just drew where we predict posit when we're close to either on of the two landmark .
and we predict neg when we're veri far awai from ani of the landmark .
and so thi is part of the idea of kernel of and how we us them with the support vector machin , which is that we defin these extra featur us landmark and similar function to learn more complex nonlinear classifi .
so hopefulli that give you a sens of the idea of kernel and how we could us it to defin new featur for the support vector machin .
but there ar a coupl of question that we haven't answer yet .
on is , how do we get these landmark ?
how do we choos these landmark ?
and anoth is , what other similar function , if ani , can we us other than the on we talk about , which is call the gaussian kernel .
in the next video we give answer to these question and put everyth togeth to show how support vector machin with kernel can be a power wai to learn complex nonlinear function .
in the last video , we start to talk about the kernel idea and how it can be us to defin new featur for the support vector machin .
in thi video , i'd like to throw in some of the miss detail and , also , sai a few word about how to us these idea in practic .
such as , how thei pertain to , for exampl , the bia varianc trade off in support vector machin .
in the last video , i talk about the process of pick a few landmark .
you know , l1 , l2 , l3 and that allow us to defin the similar function also call the kernel or in thi exampl if you have thi similar function thi is a gaussian kernel .
and that allow us to build thi form of a hypothesi function .
but where do we get these landmark from ?
where do we get l1 , l2 , l3 from ?
and it seem , also , that for complex learn problem , mayb we want a lot more landmark than just three of them that we might choos by hand .
so in practic thi is how the landmark ar chosen which is that given the machin learn problem .
we have some data set of some some posit and neg exampl .
so , thi is the idea here which is that we're gonna take the exampl and for everi train exampl that we have , we ar just go to call it .
we're just go to put landmark as exactli the same locat as the train exampl .
so if i have on train exampl if that is x1 , well then i'm go to choos thi is my first landmark to be at xactli the same locat as my first train exampl .
and if i have a differ train exampl x2 .
well we're go to set the second landmark to be the locat of my second train exampl .
on the figur on the right , i us red and blue dot just as illustr , the color of thi figur , the color of the dot on the figur on the right is not signific .
but what i'm go to end up with us thi method is i'm go to end up with m landmark of l1 , l2 down to l m if i have m train exampl with on landmark per locat of my per locat of each of my train exampl .
and thi is nice becaus it is sai that my featur ar basic go to measur how close an exampl is to on of the thing i saw in my train set .
so , just to write thi outlin a littl more concret , given m train exampl , i'm go to choos the the locat of my landmark to be exactli near the locat of my m train exampl .
when you ar given exampl x , and in thi exampl x can be someth in the train set , it can be someth in the cross valid set , or it can be someth in the test set .
given an exampl x we ar go to comput , you know , these featur as so f1 , f2 , and so on .
where l1 is actual equal to x1 and so on .
and these then give me a featur vector .
so let me write f as the featur vector .
i'm go to take these f1 , f2 and so on , and just group them into featur vector .
take those down to fm .
and , you know , just by convent .
if we want , we can add an extra featur f0 , which is alwai equal to <num> .
so thi plai a role similar to what we had previous .
for x0 , which wa our interceptor .
so , for exampl , if we have a train exampl x i , y i , the featur we would comput for thi train exampl will be as follow given x i , we will then map it to , you know , f1 i .
which is the similar .
i'm go to abbrevi as sim instead of write out the whole word similar , right ?
and f2 i equal the similar between x i and l2 , and so on , down to fm i equal the similar between x i and l m .
and somewher in the middl .
somewher in thi list , you know , at the i th compon , i will actual have on featur compon which is f subscript i i , which is go to be the similar between x and l i .
where l i is equal to x i , and so you know fi i is just go to be the similar between x and itself .
and if you're us the gaussian kernel thi is actual e to the minu <num> over <num> sigma squar and so , thi will be equal to <num> and that's okai .
so on of my featur for thi train exampl is go to be equal to <num> .
and then similar to what i have abov .
i can take all of these m featur and group them into a featur vector .
so instead of repres my exampl , us , you know , x i which is thi what r n plu r n on dimension vector .
depend on whether you can set term , is either r n or r n plu <num> .
we can now instead repres my train exampl us thi featur vector f .
i am go to write thi f superscript i .
which is go to be take all of these thing and stack them into a vector .
so , f1 i down to fm i and if you want and well , usual we'll also add thi f0 i , where f0 i is equal to <num> .
and so thi vector here give me my new featur vector with which to repres my train exampl .
so given these kernel and similar function , here's how we us a simpl vector machin .
if you alreadi have a learn set of paramet theta , then if you given a valu of x and you want to make a predict .
what we do is we comput the featur f , which is now an r m plu <num> dimension featur vector .
and we have m here becaus we have m train exampl and thu m landmark and what we do is we predict <num> if theta transpos f is greater than or equal to <num> .
right .
so , if theta transpos f , of cours , that's just equal to theta <num> , f<num> plu theta <num> , f1 plu dot dot dot , plu theta m f m .
and so my paramet vector theta is also now go to be an m plu <num> dimension vector .
and we have m here becaus where the number of landmark is equal to the train set size .
so m wa the train set size and now , the paramet vector theta is go to be m plu on dimension .
so that's how you make a predict if you alreadi have a set for the paramet's theta .
how do you get the paramet's theta ?
well you do that us the svm learn algorithm , and specif what you do is you would solv thi minim problem .
you've minim the paramet's theta of c time thi cost function which we had befor .
onli now , instead of look there instead of make predict us theta transpos x i us our origin featur , x i .
instead we've taken the featur x i and replac them with a new featur so we ar us theta transpos f i to make a predict on the i'f train exampl and we see that , you know , in both place here and it's by solv thi minim problem that you get the paramet for your support vector machin .
and on last detail is becaus thi optim problem we realli have n equal m featur .
that is here .
the number of featur we have .
realli , the effect number of featur we have is dimens of f .
so that n is actual go to be equal to m .
so , if you want to , you can think of thi as a sum , thi realli is a sum from j equal <num> through m .
and then on wai to think about thi , is you can think of it as n be equal to m , becaus if f isn't a new featur , then we have m plu <num> featur , with the plu <num> come from the interceptor .
and here , we still do sum from j equal <num> through n , becaus similar to our earlier video on regular , we still do not regular the paramet theta zero , which is why thi is a sum for j equal <num> through m instead of j equal zero though m .
so that's the support vector machin learn algorithm .
that's on sort of , mathemat detail asid that i should mention , which is that in the wai the support vector machin is implement , thi last term is actual done a littl bit differ .
so you don't realli need to know about thi last detail in order to us support vector machin , and in fact the equat that ar written down here should give you all the intuit that should need .
but in the wai the support vector machin is implement , you know , that term , the sum of j of theta j squar right ?
anoth wai to write thi is thi can be written as theta transpos theta if we ignor the paramet theta <num> .
so theta <num> down to theta m .
ignor theta <num> .
then thi sum of j of theta j squar that thi can also be written theta transpos theta .
and what most support vector machin implement do is actual replac thi theta transpos theta , will instead , theta transpos time some matrix insid , that depend on the kernel you us , time theta .
and so thi give us a slightli differ distanc metric .
we'll us a slightli differ measur instead of minim exactli the norm of theta squar mean that minim someth slightli similar to it .
that's like a rescal version of the paramet vector theta that depend on the kernel .
but thi is kind of a mathemat detail .
that allow the support vector machin softwar to run much more effici .
and the reason the support vector machin doe thi is with thi modif .
it allow it to scale to much bigger train set .
becaus for exampl , if you have a train set with <num> , <num> train exampl .
then , you know , the wai we defin landmark , we end up with <num> , <num> landmark .
and so theta becom <num> , <num> dimension .
and mayb that work , but when m becom realli , realli big then solv for all of these paramet , you know , if m were <num> , <num> or a <num> , <num> then solv for all of these paramet can becom expens for the support vector machin optim softwar , thu solv the minim problem that i drew here .
so kind of as mathemat detail , which again you realli don't need to know about .
it actual modifi that last term a littl bit to optim someth slightli differ than just minim the norm squar of theta squar , of theta .
but if you want , you can feel free to think of thi as an kind of a n implement detail that doe chang the object a bit , but is done primarili for reason of comput effici , so usual you don't realli have to worri about thi .
and by the wai , in case your wonder why we don't appli the kernel's idea to other algorithm as well like logist regress , it turn out that if you want , you can actual appli the kernel's idea and defin the sourc of featur us landmark and so on for logist regress .
but the comput trick that appli for support vector machin don't gener well to other algorithm like logist regress .
and so , us kernel with logist regress is go too veri slow , wherea , becaus of comput trick , like that embodi and how it modifi thi and the detail of how the support vector machin softwar is implement , support vector machin and kernel tend go particularli well togeth .
wherea , logist regress and kernel , you know , you can do it , but thi would run veri slowli .
and it won't be abl to take advantag of advanc optim techniqu that peopl have figur out for the particular case of run a support vector machin with a kernel .
but all thi pertain onli to how you actual implement softwar to minim the cost function .
i will sai more about that in the next video , but you realli don't need to know about how to write softwar to minim thi cost function becaus you can find veri good off the shelf softwar for do so .
and just as , you know , i wouldn't recommend write code to invert a matrix or to comput a squar root , i actual do not recommend write softwar to minim thi cost function yourself , but instead to us off the shelf softwar packag that peopl have develop and so those softwar packag alreadi embodi these numer optim trick , so you don't realli have to worri about them .
but on other thing that is worth know about is when you're appli a support vector machin , how do you choos the paramet of the support vector machin ?
and the last thing i want to do in thi video is sai a littl word about the bia and varianc trade off when us a support vector machin .
when us an svm , on of the thing you need to choos is the paramet c which wa in the optim object , and you recal that c plai a role similar to <num> over lambda , where lambda wa the regular paramet we had for logist regress .
so , if you have a larg valu of c , thi correspond to what we have back in logist regress , of a small valu of lambda mean of not us much regular .
and if you do that , you tend to have a hypothesi with lower bia and higher varianc .
wherea if you us a smaller valu of c then thi correspond to when we ar us logist regress with a larg valu of lambda and that correspond to a hypothesi with higher bia and lower varianc .
and so , hypothesi with larg c ha a higher varianc , and is more prone to overfit , wherea hypothesi with small c ha higher bia and is thu more prone to underfit .
so thi paramet c is on of the paramet we need to choos .
the other on is the paramet sigma squar , which appear in the gaussian kernel .
so if the gaussian kernel sigma squar is larg , then in the similar function , which wa thi you know e to the minu x minu landmark vari squar over <num> sigma squar .
in thi on of the exampl ; if i have onli on featur , x1 , if i have a landmark there at that locat , if sigma squar is larg , then , you know , the gaussian kernel would tend to fall off rel slowli and so thi would be my featur f i , and so thi would be smoother function that vari more smoothli , and so thi will give you a hypothesi with higher bia and lower varianc , becaus the gaussian kernel that fall off smoothli , you tend to get a hypothesi that vari slowli , or vari smoothli as you chang the input x .
wherea in contrast , if sigma squar wa small and if that's my landmark given my <num> featur x1 , you know , my gaussian kernel , my similar function , will vari more abruptli .
and in both case i'd pick out <num> , and so if sigma squar is small , then my featur vari less smoothli .
so if it's just higher slope or higher deriv here .
and us thi , you end up fit hypothes of lower bia and you can have higher varianc .
and if you look at thi week's point exercis , you actual get to plai around with some of these idea yourself and see these effect yourself .
so , that wa the support vector machin with kernel algorithm .
and hopefulli thi discuss of bia and varianc will give you some sens of how you can expect thi algorithm to behav as well .
so far we've been talk about svm in a fairli abstract level .
in thi video i'd like to talk about what you actual need to do in order to run or to us an svm .
the support vector machin algorithm pose a particular optim problem .
but as i briefli mention in an earlier video , i realli do not recommend write your own softwar to solv for the paramet's theta yourself .
so just as todai , veri few of us , or mayb almost essenti none of us would think of write code ourselv to invert a matrix or take a squar root of a number , and so on .
we just , you know , call some librari function to do that .
in the same wai , the softwar for solv the svm optim problem is veri complex , and there have been research that have been do essenti numer optim research for mani year .
so you come up with good softwar librari and good softwar packag to do thi .
and then strongli recommend just us on of the highli optim softwar librari rather than try to implement someth yourself .
and there ar lot of good softwar librari out there .
the two that i happen to us the most often ar the linear svm but there ar realli lot of good softwar librari for do thi that you know , you can link to mani of the major program languag that you mai be us to code up learn algorithm .
even though you shouldn't be write your own svm optim softwar , there ar a few thing you need to do , though .
first is to come up with with some choic of the paramet's c .
we talk a littl bit of the bia varianc properti of thi in the earlier video .
second , you also need to choos the kernel or the similar function that you want to us .
so on choic might be if we decid not to us ani kernel .
and the idea of no kernel is also call a linear kernel .
so if someon sai , i us an svm with a linear kernel , what that mean is you know , thei us an svm without us without us a kernel and it wa a version of the svm that just us theta transpos x , right , that predict <num> theta <num> plu theta <num> x<num> plu so on plu theta n , x n is greater than equal <num> .
thi term linear kernel , you can think of thi as you know thi is the version of the svm that just give you a standard linear classifi .
so that would be on reason choic for some problem , and you know , there would be mani softwar librari , like linear , wa on exampl , out of mani , on exampl of a softwar librari that can train an svm without us a kernel , also call a linear kernel .
so , why would you want to do thi ?
if you have a larg number of featur , if n is larg , and m the number of train exampl is small , then you know you have a huge number of featur that if x , thi is an x is an rn , rn <num> .
so if you have a huge number of featur alreadi , with a small train set , you know , mayb you want to just fit a linear decis boundari and not try to fit a veri complic nonlinear function , becaus might not have enough data .
and you might risk overfit , if you're try to fit a veri complic function in a veri high dimension featur space , but if your train set sampl is small .
so thi would be on reason set where you might decid to just not us a kernel , or equival to us what's call a linear kernel .
a second choic for the kernel that you might make , is thi gaussian kernel , and thi is what we had previous .
and if you do thi , then the other choic you need to make is to choos thi paramet sigma squar when we also talk a littl bit about the bia varianc tradeoff of how , if sigma squar is larg , then you tend to have a higher bia , lower varianc classifi , but if sigma squar is small , then you have a higher varianc , lower bia classifi .
so when would you choos a gaussian kernel ?
well , if your omiss of featur x , i mean rn , and if n is small , and , ideal , you know , if n is larg , right , so that's if , you know , we have sai , a two dimension train set , like the exampl i drew earlier .
so n is equal to <num> , but we have a pretti larg train set .
so , you know , i've drawn in a fairli larg number of train exampl , then mayb you want to us a kernel to fit a more complex nonlinear decis boundari , and the gaussian kernel would be a fine wai to do thi .
i'll sai more toward the end of the video , a littl bit more about when you might choos a linear kernel , a gaussian kernel and so on .
but if concret , if you decid to us a gaussian kernel , then here's what you need to do .
depend on what support vector machin softwar packag you us , it mai ask you to implement a kernel function , or to implement the similar function .
so if you're us an octav or matlab implement of an svm , it mai ask you to provid a function to comput a particular featur of the kernel .
so thi is realli comput f subscript i for on particular valu of i , where f here is just a singl real number , so mayb i should move thi better written f i , but what you need to do is to write a kernel function that take thi input , you know , a train exampl or a test exampl whatev it take in some vector x and take as input on of the landmark and but onli i've come down x1 and x2 here , becaus the landmark ar realli train exampl as well .
but what you need to do is write softwar that take thi input , you know , x1 , x2 and comput thi sort of similar function between them and return a real number .
and so what some support vector machin packag do is expect you to provid thi kernel function that take thi input you know , x1 , x2 and return a real number .
and then it will take it from there and it will automat gener all the featur , and so automat take x and map it to f1 , f2 , down to f m us thi function that you write , and gener all the featur and train the support vector machin from there .
but sometim you do need to provid thi function yourself .
other if you ar us the gaussian kernel , some svm implement will also includ the gaussian kernel and a few other kernel as well , sinc the gaussian kernel is probabl the most common kernel .
gaussian and linear kernel ar realli the two most popular kernel by far .
just on implement note .
if you have featur of veri differ scale , it is import to perform featur scale befor us the gaussian kernel .
and here's why .
if you imagin the comput the norm between x and l , right , so thi term here , and the numer term over there .
what thi is do , the norm between x and l , that's realli sai , you know , let's comput the vector v , which is equal to x minu l .
and then let's comput the norm doe vector v , which is the differ between x .
so the norm of v is realli equal to v1 squar plu v2 squar plu dot dot dot , plu vn squar .
becaus here x is in rn , or rn plu <num> , but i'm go to ignor , you know , x0 .
so , let's pretend x is an rn , squar on the left side is what make thi correct .
so thi is equal to that , right ?
and so written differ , thi is go to be x1 minu l1 squar , plu x2 minu l2 squar , plu dot dot dot plu xn minu ln squar .
and now if your featur take on veri differ rang of valu .
so take a hous predict , for exampl , if your data is some data about hous .
and if x is in the rang of thousand of squar feet , for the first featur , x1 .
but if your second featur , x2 is the number of bedroom .
so if thi is in the rang of on to five bedroom , then x1 minu l1 is go to be huge .
thi could be like a thousand squar , wherea x2 minu l2 is go to be much smaller and if that's the case , then in thi term , those distanc will be almost essenti domin by the size of the hous and the number of bathroom would be larg ignor .
as so as , to avoid thi in order to make a machin work well , do perform futur scale .
and that will sure that the svm give , you know , compar amount of attent to all of your differ featur , and not just to in thi exampl to size of hous were big movement here the featur .
when you try a support vector machin chanc ar by far the two most common kernel you us will be the linear kernel , mean no kernel , or the gaussian kernel that we talk about .
and just on note of warn which is that not all similar function you might come up with ar valid kernel .
and the gaussian kernel and the linear kernel and other kernel that you sometim other will us , all of them need to satisfi a technic condit .
it's call mercer's theorem and the reason you need to thi is becaus support vector machin algorithm or implement of the svm have lot of clever numer optim trick .
in order to solv for the paramet's theta effici and in the origin design envisag , those ar decis made to restrict our attent onli to kernel that satisfi thi technic condit call mercer's theorem .
and what that doe is , that make sure that all of these svm packag , all of these svm softwar packag can us the larg class of optim and get the paramet theta veri quickli .
so , what most peopl end up do is us either the linear or gaussian kernel , but there ar a few other kernel that also satisfi mercer's theorem and that you mai run across other peopl us , although i person end up us other kernel you know , veri , veri rare , if at all .
just to mention some of the other kernel that you mai run across .
on is the polynomi kernel .
and for that the similar between x and l is defin as , there ar a lot of option , you can take x transpos l squar .
so , here's on measur of how similar x and l ar .
if x and l ar veri close with each other , then the inner product will tend to be larg .
and so , you know , thi is a slightli unusu kernel .
that is not us that often , but you mai run across some peopl us it .
thi is on version of a polynomi kernel .
anoth is x transpos l cube .
these ar all exampl of the polynomi kernel .
x transpos l plu <num> cube .
x transpos l plu mayb a number differ then on <num> and , you know , to the power of <num> and so the polynomi kernel actual ha two paramet .
on is , what number do you add over here ?
it could be <num> .
thi is realli plu <num> over there , as well as what's the degre of the polynomi over there .
so the degre power and these number .
and the more gener form of the polynomi kernel is x transpos l , plu some constant and then to some degre in the x1 and so both of these ar paramet for the polynomi kernel .
so the polynomi kernel almost alwai or usual perform wors .
and the gaussian kernel doe not us that much , but thi is just someth that you mai run across .
usual it is us onli for data where x and l ar all strictli non neg , and so that ensur that these inner product ar never neg .
and thi captur the intuit that x and l ar veri similar to each other , then mayb the inter product between them will be larg .
thei have some other properti as well but peopl tend not to us it much .
and then , depend on what you're do , there ar other , sort of more esoter kernel as well , that you mai come across .
you know , there's a string kernel , thi is sometim us if your input data is text string or other type of string .
there ar thing like the chi squar kernel , the histogram intersect kernel , and so on .
there ar sort of more esoter kernel that you can us to measur similar between differ object .
so for exampl , if you're try to do some sort of text classif problem , where the input x is a string then mayb we want to find the similar between two string us the string kernel , but i person you know end up veri rare , if at all , us these more esoter kernel .
i think i might have us the chi squar kernel , mai be onc in my life and the histogram kernel , mai be onc or twice in my life .
i've actual never us the string kernel myself .
but in case you've run across thi in other applic .
you know , if you do a quick web search we do a quick googl search or quick bing search you should have found definit that these ar the kernel as well .
so just two last detail i want to talk about in thi video .
on in multiclass classif .
so , you have four class or more gener <num> class output some appropri decis boundai between your multipl class .
most svm , mani svm packag alreadi have built in multiclass classif function .
so if your us a pattern like that , you just us the both that function and that should work fine .
otherwis , on wai to do thi is to us the on versu all method that we talk about when we ar develop logist regress .
so what you do is you trade ksvm's if you have k class , on to distinguish each of the class from the rest .
and thi would give you k paramet vector , so thi will give you , upi lmpw .
theta <num> , which is try to distinguish class y equal on from all of the other class , then you get the second paramet , vector theta <num> , which is what you get when you , you know , have y equal <num> as the posit class and all the other as neg class and so on up to a paramet vector theta k , which is the paramet vector for distinguish the final class kei from anyth els , and then lastli , thi is exactli the same as the on versu all method we have for logist regress .
where we you just predict the class i with the largest theta transpos x .
so let's multiclass classif design .
for the more common case that there is a good chanc that whatev softwar packag you us , you know , there will be a reason chanc that ar alreadi have built in multiclass classif function , and so you don't need to worri about thi result .
final , we develop support vector machin start off with logist regress and then modifi the cost function a littl bit .
the last thing we want to do in thi video is , just sai a littl bit about .
when you will us on of these two algorithm , so let's sai n is the number of featur and m is the number of train exampl .
so , when should we us on algorithm versu the other ?
well , if n is larger rel to your train set size , so for exampl , if you take a busi with a number of featur thi is much larger than m and thi might be , for exampl , if you have a text classif problem , where you know , the dimens of the featur vector is i don't know , mayb , <num> thousand .
and if your train set size is mayb <num> you know , mayb , up to <num> .
so , imagin a spam classif problem , where email spam , where you have <num> , <num> featur correspond to <num> , <num> word but you have , you know , mayb <num> train exampl or mayb up to <num> , <num> exampl .
so if n is larg rel to m , then what i would usual do is us logist regress or us it as the m without a kernel or us it with a linear kernel .
becaus , if you have so mani featur with smaller train set , you know , a linear function will probabl do fine , and you don't have realli enough data to fit a veri complic nonlinear function .
now if is n is small and m is intermedi what i mean by thi is n is mayb anywher from <num> <num> , <num> would be veri small .
but mayb up to <num> featur and if the number of train exampl is mayb anywher from <num> , you know , <num> to mayb up to <num> , <num> exampl .
mayb up to <num> , <num> exampl .
if m is pretti big like mayb <num> , <num> but not a million .
right ?
so if m is an intermedi size then often an svm with a linear kernel will work well .
we talk about thi earli as well , with the on concret exampl , thi would be if you have a two dimension train set .
so , if n is equal to <num> where you have , you know , draw in a pretti larg number of train exampl .
so gaussian kernel will do a pretti good job separ posit and neg class .
on third set that's of interest is if n is small but m is larg .
so if n is you know , again mayb <num> to <num> , could be larger .
but if m wa , mayb <num> , <num> and greater to million .
so , <num> , <num> , a <num> , <num> , million , trillion .
you have veri veri larg train set size , right .
so if thi is the case , then a svm of the gaussian kernel will be somewhat slow to run .
todai's svm packag , if you're us a gaussian kernel , tend to struggl a bit .
if you have , you know , mayb <num> thousand okai , but if you have a million train exampl , mayb or even a <num> , <num> with a massiv valu of m .
todai's svm packag ar veri good , but thei can still struggl a littl bit when you have a massiv , massiv train that size when us a gaussian kernel .
so in that case , what i would usual do is try to just manual creat have more featur and then us logist regress or an svm without the kernel .
and in case you look at thi slide and you see logist regress or svm without a kernel .
in both of these place , i kind of pair them togeth .
there's a reason for that , is that logist regress and svm without the kernel , those ar realli pretti similar algorithm and , you know , either logist regress or svm without a kernel will usual do pretti similar thing and give pretti similar perform , but depend on your implement detail , on mai be more effici than the other .
but , where on of these algorithm appli , logist regress where svm without a kernel , the other on is to like to work pretti well as well .
but along with the power of the svm is when you us differ kernel to learn complex nonlinear function .
and thi regim , you know , when you have mayb up to <num> , <num> exampl , mayb up to <num> , <num> .
and your number of featur , thi is reason larg .
that's a veri common regim and mayb that's a regim where a support vector machin with a kernel kernel will shine .
you can do thing that ar much harder to do that will need logist regress .
and final , where do neural network fit in ?
well for all of these problem , for all of these differ regim , a well design neural network is like to work well as well .
the on disadvantag , or the on reason that might not sometim us the neural network is that , for some of these problem , the neural network might be slow to train .
but if you have a veri good svm implement packag , that could run faster , quit a bit faster than your neural network .
and , although we didn't show thi earlier , it turn out that the optim problem that the svm ha is a convex optim problem and so the good svm optim softwar packag will alwai find the global minimum or someth close to it .
and so for the svm you don't need to worri about local optima .
in practic local optima aren't a huge problem for neural network but thei all solv , so thi is on less thing to worri about if you're us an svm .
and depend on your problem , the neural network mai be slower , especi in thi sort of regim than the svm .
in case the guidelin thei gave here , seem a littl bit vagu and if you're look at some problem , you know , the guidelin ar a bit vagu , i'm still not entir sure , should i us thi algorithm or that algorithm , that's actual okai .
when i face a machin learn problem , you know , sometim it actual just not clear whether that's the best algorithm to us , but as you saw in the earlier video , realli , you know , the algorithm doe matter , but what often matter even more is thing like , how much data do you have .
and how skill ar you , how good ar you at do error analysi and debug learn algorithm , figur out how to design new featur and figur out what other featur to give you learn algorithm and so on .
and often those thing will matter more than what you ar us logist regress or an svm .
but have said that , the svm is still wide perceiv as on of the most power learn algorithm , and there is thi regim of when there's a veri effect wai to learn complex non linear function .
and so i actual , togeth with logist regress , neural network , svm's , us those to speed learn algorithm you're i think veri well posit to build state of the art you know , machin learn system for a wide region for applic and thi is anoth veri power tool to have in your arsen .
on that is us all over the place in silicon vallei , or in industri and in the academia , to build mani high perform machin learn system .
our first learn algorithm will be linear regress .
in thi video , you'll see what the model look like and more importantli you'll see what the overal process of supervis learn look like .
let's us some motiv exampl of predict hous price .
we're go to us a data set of hous price from the citi of portland , oregon .
and here i'm gonna plot my data set of a number of hous that were differ size that were sold for a rang of differ price .
let's sai that given thi data set , you have a friend that's try to sell a hous and let's see if friend's hous is size of <num> squar feet and you want to tell them how much thei might be abl to sell the hous for .
well on thing you could do is fit a model .
mayb fit a straight line to thi data .
look someth like that and base on that , mayb you could tell your friend that let's sai mayb he can sell the hous for around <num> , <num> .
so thi is an exampl of a supervis learn algorithm .
and it's supervis learn becaus we're given the , quot , right answer for each of our exampl .
name we're told what wa the actual hous , what wa the actual price of each of the hous in our data set were sold for and moreov , thi is an exampl of a regress problem where the term regress refer to the fact that we ar predict a real valu output name the price .
and just to remind you the other most common type of supervis learn problem is call the classif problem where we predict discret valu output such as if we ar look at cancer tumor and try to decid if a tumor is malign or benign .
so that's a zero on valu discret output .
more formal , in supervis learn , we have a data set and thi data set is call a train set .
so for hous price exampl , we have a train set of differ hous price and our job is to learn from thi data how to predict price of the hous .
let's defin some notat that we're us throughout thi cours .
we're go to defin quit a lot of symbol .
it's okai if you don't rememb all the symbol right now but as the cours progress it will be us conveni notat .
so i'm gonna us lower case m throughout thi cours to denot the number of train exampl .
so in thi data set , if i have , you know , let's sai <num> row in thi tabl .
then i have <num> train exampl and m equal <num> .
let me us lowercas x to denot the input variabl often also call the featur .
that would be the x is here , it would the input featur .
and i'm gonna us y to denot my output variabl or the target variabl which i'm go to predict and so that's the second column here .
notat , i'm go to us x , y to denot a singl train exampl .
so , a singl row in thi tabl correspond to a singl train exampl and to refer to a specif train exampl , i'm go to us thi notat x i comma give me y i and , we're go to us thi to refer to the ith train exampl .
so thi superscript i over here , thi is not exponenti right ?
thi x i , y i , the superscript i in parenthes that's just an index into my train set and refer to the ith row in thi tabl , okai ?
so thi is not x to the power of i , y to the power of i .
instead x i , y i just refer to the ith row of thi tabl .
so for exampl , x <num> refer to the input valu for the first train exampl so that's <num> .
that's thi x in the first row .
x <num> will be equal to <num> right ?
that's the second x and y <num> will be equal to <num> .
the first , the y valu for my first train exampl , that's what that <num> refer to .
so as mention , occasion i'll ask you a question to let you check your understand and a few second in thi video a multipl choic question will pop up in the video .
when it doe , pleas us your mous to select what you think is the right answer .
what defin by the train set is .
so here's how thi supervis learn algorithm work .
we saw that with the train set like our train set of hous price and we feed that to our learn algorithm .
is the job of a learn algorithm to then output a function which by convent is usual denot lowercas h and h stand for hypothesi and what the job of the hypothesi is , is , is a function that take as input the size of a hous like mayb the size of the new hous your friend's try to sell so it take in the valu of x and it tri to output the estim valu of y for the correspond hous .
so h is a function that map from x's to y's .
peopl often ask me , you know , why is thi function call hypothesi .
some of you mai know the mean of the term hypothesi , from the dictionari or from scienc or whatev .
it turn out that in machin learn , thi is a name that wa us in the earli dai of machin learn and it kinda stuck .
'caus mayb not a great name for thi sort of function , for map from size of hous to the predict , that you know . . . .
i think the term hypothesi , mayb isn't the best possibl name for thi , but thi is the standard terminolog that peopl us in machin learn .
so don't worri too much about why peopl call it that .
when design a learn algorithm , the next thing we need to decid is how do we repres thi hypothesi h .
for thi and the next few video , i'm go to choos our initi choic , for repres the hypothesi , will be the follow .
we're go to repres h as follow .
and we will write thi as h<u>theta x equal theta<u><num>< u>< u> plu theta<u><num> of x .
and as a shorthand , sometim instead of write , you< u> know , h subscript theta of x , sometim there's a shorthand , i'll just write as a h of x .
but more often i'll write it as a subscript theta over there .
and plot thi in the pictur , all thi mean is that , we ar go to predict that y is a linear function of x .
right , so that's the data set and what thi function is do , is predict that y is some straight line function of x .
that's h of x equal theta <num> plu theta <num> x , okai ?
and why a linear function ?
well , sometim we'll want to fit more complic , perhap non linear function as well .
but sinc thi linear case is the simpl build block , we will start with thi exampl first of fit linear function , and we will build on thi to eventu have more complex model , and more complex learn algorithm .
let me also give thi particular model a name .
thi model is call linear regress or thi , for exampl , is actual linear regress with on variabl , with the variabl be x .
predict all the price as function of on variabl x .
and anoth name for thi model is univari linear regress .
and univari is just a fanci wai of sai on variabl .
so , that's linear regress .
in the next video we'll start to talk about just how we go about implement thi model .
in thi video we'll defin someth call the cost function .
thi will let us figur out how to fit the best possibl straight line to our data .
in linear regress we have a train set like that shown here .
rememb our notat m wa the number of train exampl .
so mayb m <num> .
and the form of the hypothesi , which we us to make predict , is thi linear function .
to introduc a littl bit more terminolog , these theta zero and theta on , right , these theta i's ar what i call the paramet of the model .
what we're go to do in thi video is talk about how to go about choos these two paramet valu , theta zero and theta on .
with differ choic of paramet theta zero and theta on we get differ hypothes , differ hypothesi function .
i know some of you will probabl be alreadi familiar with what i'm go to do on thi slide , but just to review here ar a few exampl .
if theta zero is <num> and theta on is <num> , then the hypothesi function will look like thi .
right , becaus your hypothesi function will be h x equal <num> plu <num> time x which is thi constant valu function , thi is flat at <num> .
if theta zero equal <num> and theta on equal <num> , then the hypothesi will look like thi .
and it should pass through thi point <num> , <num> , sai you now have h x or realli some h<u>theta x but sometim i'll just omit theta for< u> breviti .
so , h x will be equal to just <num> time x which look like that .
and final if theta zero equal <num> and theta on equal <num> then we end up with the hypothesi that look like thi .
let's see , it should pass through the <num> , <num> point like so .
and thi is my new h x or my new h<u>theta x .
all right ?
well< u> you rememb that thi is h<u>theta x but as a shorthand< u> sometim i just write thi as h x .
in linear regress we have a train set , like mayb the on i've plot here .
what we want to do is come up with valu for the paramet theta zero and theta on .
so that the straight line we get out of thi correspond to a straight line that somehow fit the data well .
like mayb that line over there .
so how do we come up with valu theta zero , theta on that correspond to a good fit to the data ?
the idea is we're go to choos our paramet theta zero , theta on so that h x , mean the valu we predict on input x , that thi at least close to the valu y for the exampl in our train set , for our train exampl .
so , in our train set we're given a number of exampl where we know x decid the hous and we know the actual price of what it's sold for .
so let's try to choos valu for the paramet so that at least in the train set , given the x's in the train set , we make reason accur predict for the y valu .
let's formal thi .
so linear regress , what we're go to do is that i'm go to want to solv a minim problem .
so i'm go to write minim over theta zero , theta on .
and , i want thi to be small , right , i want the differ between h x and y to be small .
and on thing i'm gonna do is try to minim the squar differ between the output of the hypothesi and the actual price of the hous .
okai ?
so let's fill in some detail .
rememb that i wa us the notat x i , y i to repres the ith train exampl .
so what i want realli is to sum over my train set .
sum from i equal <num> to m of the squar differ between thi is the predict of my hypothesi when it is input the size of hous number i , right , minu the actual price that hous number i will sell for and i want to minim the sum of my train set sum from i equal <num> through m of the differ of thi squar error , squar differ between the predict price of the hous and the price that it will actual sell for .
and just remind you of your notat m here wa the , the size of my train set , right , so the m there is my number of train exampl .
right ?
that hash sign is the abbrevi for number of train exampl .
okai ?
and to make some of our , make the math a littl bit easier , i'm go to actual look at , you know , <num> over m time that .
so we're go to try to minim my averag error , which we're go to minim on by 2m .
put the <num> , the constant on half , in front it just make some of the math a littl easier .
so minim on half of someth , right , should give you the same valu of the paramet theta zero , theta on as minim that function .
and just make sure thi , thi , thi equat is clear , right ?
thi express in here , h<u>theta x , thi is my , thi is< u> our usual , right ?
that's equal to thi plu theta on x i .
and , thi notat , minim over theta zero and theta on , thi mean find me the valu of theta zero and theta on that caus thi express to be minim .
and thi express depend on theta zero and theta on .
okai ?
so just to recap , we're pose thi problem as find me the valu of theta zero and theta on so that the averag alreadi on over two m time the sum of squar error between my predict on the train set minu the actual valu of the hous on the train set is minim .
so thi is go to be my overal object function for linear regress .
and just to , you know rewrit thi out a littl bit more cleanli what i'm go to do by convent is we usual defin a cost function .
which is go to be exactli thi .
that formula that i have up here .
and what i want to do is minim over theta zero and theta on my function j of theta zero comma theta on .
just write thi out , thi is my cost function .
so , thi cost function is also call the squar error function or sometim call the squar error cost function and it turn out that why , why do we , you know , take the squar of the error ?
it turn out that the squar error cost function is a reason choic and will work well for most problem , for most regress problem .
there ar other cost function that will work pretti well , but the squar error cost function is probabl the most commonli us on for regress problem .
later in thi class we'll also talk about altern cost function as well , but thi , thi choic that we just had , should be a pret , pretti reason thing to try for most linear regress problem .
okai .
so that's the cost function .
so far we've just seen a mathemat definit of you know thi cost function and in case thi function j of theta zero theta on in case thi function seem a littl bit abstract and you still don't have a good sens of what it do in the next video , in the next coupl video we're actual go to go a littl bit deeper into what the cost function j is do and try to give you better intuit about what it comput and why we want to us it .
in the previou video , we gave the mathemat definit of the cost function .
in thi video , let's look at some exampl , to get back to intuit about what the cost function is do , and why we want to us it .
to recap , here's what we had last time .
we want to fit a straight line to our data , so we had thi form as a hypothesi with these paramet theta zero and theta on , and with differ choic of the paramet we end up with differ straight line fit .
so the data which ar fit like so , and there's a cost function , and that wa our optim object .
so thi video , in order to better visual the cost function j , i'm go to work with a simplifi hypothesi function , like that shown on the right .
so i'm gonna us my simplifi hypothesi , which is just theta on time x .
we can , if you want , think of thi as set the paramet theta zero equal to <num> .
so i have onli on paramet theta on and my cost function is similar to befor except that now h of x that is now equal to just theta on time x .
and i have onli on paramet theta on and so my optim object is to minim j of theta on .
in pictur what thi mean is that if theta zero equal zero that correspond to choos onli hypothesi function that pass through the origin , that pass through the point <num> , <num> .
us thi simplifi definit of a hypothes cost function let's try to understand the cost function concept better .
it turn out that two kei function we want to understand .
the first is the hypothesi function , and the second is a cost function .
so , notic that the hypothesi , right , h of x .
for a face valu of theta on , thi is a function of x .
so the hypothesi is a function of , what is the size of the hous x .
in contrast , the cost function , j , that's a function of the paramet , theta on , which control the slope of the straight line .
let's plot these function and try to understand them both better .
let's start with the hypothesi .
on the left , let's sai here's my train set with three point at <num> , <num> , <num> , <num> , and <num> , <num> .
let's pick a valu theta on , so when theta on equal on , and if that's my choic for theta on , then my hypothesi is go to look like thi straight line over here .
and i'm gonna point out , when i'm plot my hypothesi function .
x axi , my horizont axi is label x , is label you know , size of the hous over here .
now , of temporari , set theta on equal on , what i want to do is figur out what is j of theta on , when theta on equal on .
so let's go ahead and comput what the cost function ha for .
you'll devalu on .
well , as usual , my cost function is defin as follow , right ?
some from , some of 'em ar train set of thi usual squar error term .
and , thi is therefor equal to .
and thi .
of theta on x i minu y i and if you simplifi thi turn out to be .
that .
zero squar to zero squar to zero squar which is of cours , just equal to zero .
now , insid the cost function .
it turn out each of these term here is equal to zero .
becaus for the specif train set i have or my <num> train exampl ar <num> , <num> , <num> , <num> , <num> , <num> .
if theta on is equal to on .
then h of x .
h of x i .
is equal to y i exactli , let me write thi better .
right ?
and so , h of x minu y , each of these term is equal to zero , which is why i find that j of on is equal to zero .
so , we now know that j of on is equal to zero .
let's plot that .
what i'm gonna do on the right is plot my cost function j .
and notic , becaus my cost function is a function of my paramet theta on , when i plot my cost function , the horizont axi is now label with theta on .
so i have j of on zero zero so let's go ahead and plot that .
end up with .
an x over there .
now let look at some other exampl .
theta <num> can take on a rang of differ valu .
right ?
so theta <num> can take on the neg valu , zero , posit valu .
so what if theta <num> is equal to <num> .
what happen then ?
let's go ahead and plot that .
i'm now go to set theta <num> equal <num> , and in that case my hypothesi now look like thi .
as a line with slope equal to <num> , and , let comput j , of <num> .
so that is go to be on over 2m of , my usual cost function .
it turn out that the cost function is go to be the sum of squar valu of the height of thi line .
plu the sum of squar of the height of that line , plu the sum of squar of the height of that line , right ?
? caus just thi vertic distanc , that's the differ between , you know , y .
i .
and the predict valu , h of xi , right ?
so the first exampl is go to be <num> minu on squar .
becaus my hypothesi predict <num> .
wherea , the actual valu wa on .
for my second exampl , i get , on minu two squar , becaus my hypothesi predict on , but the actual hous price wa two .
and then final , plu .
<num> minu three squar .
and so that's equal to on over two time three .
becaus , m when trade set size , right , have three train exampl .
in that , that's time simplifi for the parenthes it's <num> .
so that's <num> over six which is about <num> . <num> .
so now we know that j of <num> is about <num> . <num> .
let go and plot that .
oh excus me , math error , it's actual <num> . <num> .
so we plot that which is mayb about over there .
okai ?
now , let's do on more .
how about if theta on is equal to zero , what is j of zero equal to ?
it turn out that if theta on is equal to zero , then h of x is just equal to , you know , thi flat line , right , that just goe horizont like thi .
and so , measur the error .
we have that j of zero is equal to on over two m , time on squar plu two squar plu three squar , which is , on six time fourteen which is about <num> .
so let's go ahead and plot as well .
so it end up with a valu around <num> and of cours we can keep on do thi for other valu of theta on .
it turn out that you can have you know neg valu of theta on as well so if theta on is neg then h of x would be equal to sai minu <num> time x then theta on is minu <num> and so that correspond to a hypothesi with a slope of neg <num> .
and you can actual keep on comput these error .
thi turn out to be , you know , for <num> , it turn out to have realli high error .
it work out to be someth , like , <num> . <num> .
and so on , and the differ valu of theta on , you can comput these thing , right ?
and it turn out that you , your comput rang of valu , you get someth like that .
and by comput the rang of valu , you can actual slowli creat out .
what doe function j of theta sai and that's what j of theta is .
to recap , for each valu of theta on , right ?
each valu of theta on correspond to a differ hypothesi , or to a differ straight line fit on the left .
and for each valu of theta on , we could then deriv a differ valu of j of theta on .
and for exampl , you know , theta on <num> , correspond to thi straight line straight through the data .
wherea theta on <num> .
and thi point shown in magenta correspond to mayb that line , and theta on zero which is shown in blue that correspond to thi horizont line .
right , so for each valu of theta on we wound up with a differ valu of j of theta on and we could then us thi to trace out thi plot on the right .
now you rememb , the optim object for our learn algorithm is we want to choos the valu of theta on .
that minim j of theta on .
right ?
thi wa our object function for the linear regress .
well , look at thi curv , the valu that minim j of theta on is , you know , theta on equal to on .
and low and behold , that is inde the best possibl straight line fit through our data , by set theta on equal on .
and just , for thi particular train set , we actual end up fit it perfectli .
and that's why minim j of theta on correspond to find a straight line that fit the data well .
so , to wrap up .
in thi video , we look up some plot .
to understand the cost function .
to do so , we simplifi the algorithm .
so that it onli had on paramet theta on .
and we set the paramet theta zero to be onli zero .
in the next video .
we'll go back to the origin problem formul and look at some visual involv both theta zero and theta on .
that is without set theta zero to zero .
and hopefulli that will give you , an even better sens of what the cost function j is do in the origin linear regress formul .
in thi video , let delv deeper and get even better intuit about what the cost function is do .
thi video assum that you're familiar with contour plot .
if you ar not familiar with contour plot or contour figur some of the illustr in thi video mai or mai not make sens to you but is okai and if you end up skip thi video or some of it doe not quit make sens becaus you haven't seen contour plot befor .
that's okai and you will still understand the rest of thi cours without those part of thi .
here's our problem formul as usual , with the hypothesi paramet , cost function , and our optim object .
unlik befor , unlik the last video , i'm go to keep both of my paramet , theta zero , and theta on , as we gener our visual for the cost function .
so , same as last time , we want to understand the hypothesi h and the cost function j .
so , here's my train set of hous price and let's make some hypothesi .
you know , like that on , thi is not a particularli good hypothesi .
but , if i set theta zero <num> and theta on <num> . <num> , then i end up with thi hypothesi down here and that correspond to that straight line .
now given these valu of theta zero and theta on , we want to plot the correspond , you know , cost function on the right .
what we did last time wa , right , when we onli had theta on .
in other word , draw plot that look like thi as a function of theta on .
but now we have two paramet , theta zero , and theta on , and so the plot get a littl more complic .
it turn out that when we have onli on paramet , that the part we drew had thi sort of bow shape function .
now , when we have two paramet , it turn out the cost function also ha a similar sort of bow shape .
and , in fact , depend on your train set , you might get a cost function that mayb look someth like thi .
so , thi is a <num> d surfac plot , where the ax ar label theta zero and theta on .
so as you vari theta zero and theta on , the two paramet , you get differ valu of the cost function j theta zero , theta on and the height of thi surfac abov a particular point of theta zero , theta on .
right , that's , that's the vertic axi .
the height of the surfac of the point indic the valu of j of theta zero , j of theta on .
and you can see it sort of ha thi bow like shape .
let me show you the same plot in 3d .
so here's the same figur in 3d , horizont axi theta on and vertic axi j theta zero , theta on , and if i rotat thi plot around .
you kinda of a get a sens , i hope , of thi bowl shape surfac as that's what the cost function j look like .
now for the purpos of illustr in the rest of thi video i'm not actual go to us these sort of 3d surfac to show you the cost function j , instead i'm go to us contour plot .
or what i also call contour figur .
i guess thei mean the same thing .
to show you these surfac .
so here's an exampl of a contour figur , shown on the right , where the axi ar theta zero and theta on .
and what each of these oval , what each of these ellipsi show is a set of point that take on the same valu for j theta zero , theta on .
so concret , for exampl thi , you'll take that point and that point and that point .
all three of these point that i just drew in magenta , thei have the same valu for j theta zero , theta on .
okai .
where , right , these , thi is the theta zero , theta on axi but those three have the same valu for j theta zero , theta on and if you haven't seen contour plot much befor think of , imagin if you will .
a bow shape function that's come out of my screen .
so that the minimum , so the bottom of the bow is thi point right there , right ?
thi middl , the middl of these concentr ellips .
and imagin a bow shape that sort of grow out of my screen like thi , so that each of these ellips , you know , ha the same height abov my screen .
and the minimum with the bow , right , is right down there .
and so the contour figur is a , is wai to , is mayb a more conveni wai to visual my function j .
so , let's look at some exampl .
over here , i have a particular point , right ?
and so thi is , with , you know , theta zero equal mayb about <num> , and theta on equal mayb a <num> . <num> .
and so thi point , right , thi point in red correspond to on set of pair valu of theta zero , theta on and the correspond , in fact , to that hypothesi , right , theta zero is about <num> , that is , where it intersect the vertic axi is around <num> , and thi is slope of about <num> . <num> .
now thi line is realli not such a good fit to the data , right .
thi hypothesi , h x , with these valu of theta zero , theta on , it's realli not such a good fit to the data .
and so you find that , it's cost .
is a valu that's out here that's you know pretti far from the minimum right it's pretti far thi is a pretti high cost becaus thi is just not that good a fit to the data .
let's look at some more exampl .
now here's a differ hypothesi that's you know still not a great fit for the data but mai be slightli better so here right that's my point that those ar my paramet theta zero theta on and so my theta zero valu .
right ?
that's bout <num> and my valu for theta on .
is equal to zero .
so , you know , let's break it out .
let's take theta zero equal <num> theta on equal zero .
and thi pair of paramet correspond to that hypothesi , correspond to flat line , that is , h x equal <num> plu zero time x .
so that's the hypothesi .
and thi hypothesi again ha some cost , and that cost is , you know , plot as the height of the j function at that point .
let's look at just a coupl of exampl .
here's on more , you know , at thi valu of theta zero , and at that valu of theta on , we end up with thi hypothesi , h x and again , not a great fit to the data , and is actual further awai from the minimum .
last exampl , thi is actual not quit at the minimum , but it's pretti close to the minimum .
so thi is not such a bad fit to the , to the data , where , for a particular valu , of , theta zero .
which , on of them ha valu , as in for a particular valu for theta on .
we get a particular h x .
and thi is , thi is not quit at the minimum , but it's pretti close .
and so the sum of squar error is sum of squar distanc between my , train sampl and my hypothesi .
realli , that's a sum of squar distanc , right ?
of all of these error .
thi is pretti close to the minimum even though it's not quit the minimum .
so with these figur i hope that give you a better understand of what valu of the cost function j , how thei ar and how that correspond to differ hypothesi and so as how better hypothes mai correspond to point that ar closer to the minimum of thi cost function j .
now of cours what we realli want is an effici algorithm , right , a effici piec of softwar for automat find the valu of theta zero and theta on , that minim the cost function j , right ?
and what we , what we don't wanna do is to , you know , how to write softwar , to plot out thi point , and then try to manual read off the number , that thi is not a good wai to do it .
and , in fact , we'll see it later , that when we look at more complic exampl , we'll have high dimension figur with more paramet , that , it turn out , we'll see in a few , we'll see later in thi cours , exampl where thi figur , you know , cannot realli be plot , and thi becom much harder to visual .
and so , what we want is to have softwar to find the valu of theta zero , theta on that minim thi function and in the next video we start to talk about an algorithm for automat find that valu of theta zero and theta on that minim the cost function j .
we've previous defin the cost function j .
in thi video i want to tell you about an algorithm call gradient descent for minim the cost function j .
it turn out gradient descent is a more gener algorithm and is us not onli in linear regress .
it's actual us all over the place in machin learn .
and later in the class we'll us gradient descent to minim other function as well , not just the cost function j , for linear regress .
so in thi video , i'm go to talk about gradient descent for minim some arbitrari function j .
and then in later video , we'll take those algorithm and appli it specif to the cost function j that we had to find for linear regress .
so here's the problem setup .
we're go to see that we have some function j of theta0 , theta1 .
mayb it's a cost function from linear regress .
mayb it's some other function we want to minim .
and we want to come up with an algorithm for minim that as a function of j of theta0 , theta1 .
just as an asid , it turn out that gradient descent actual appli to more gener function .
so imagin if you have a function that's a function of j of theta0 , theta1 , theta2 , up to some theta n .
and you want to minim over theta0 up to theta n of thi j of theta0 up to theta n .
it turn out gradient descent is an algorithm for solv thi more gener problem , but for the sake of breviti , for the sake of your succinct of notat , i'm just go to present onli two paramet throughout the rest of thi video .
here's the idea for gradient descent .
what we're go to do is we're go to start off with some initi guess for theta0 and theta1 .
doesn't realli matter what thei ar , but a common choic would be if we set theta<num> to <num> , and set theta1 to <num> .
just initi them to <num> .
what we're go to do in gradient descent is we'll keep chang theta0 and theta1 a littl bit to try to reduc j of theta0 , theta1 until hopefulli we wind up at a minimum or mayb a local minimum .
so , let's see see pictur of what gradient descent doe .
let's sai i try to minim thi function .
so notic the ax .
thi is , theta0 , theta1 on the horizont ax , and j is a vertic axi .
and so the height of the surfac show j , and we want to minim thi function .
so , we're go to start off with theta0 , theta1 at some point .
so imagin pick some valu for theta0 , theta1 , and that correspond to start at some point on the surfac of thi function .
okai ?
so whatev valu of theta0 , theta1 give you some point here .
i did initi them to <num> , but sometim you initi it to other valu as well .
now .
i want us to imagin that thi figur show a hill .
imagin thi is like a landscap of some grassi park with two hill like so .
and i want you to imagin that you ar physic stand at that point on the hill on thi littl red hill in your park .
in gradient descent , what we're go to do is spin <num> degre around and just look all around us and ask , if i were to take a littl babi step in some direct , and i want to go downhil as quickli as possibl , what direct do i take that littl babi step in if i want to go down , if i sort of want to physic walk down thi hill as rapidli as possibl ? turn out that if we're stand at that point on the hill , you look all around , you find that the best direct to take a littl step downhil is roughli that direct .
okai .
and now you're at thi new point on your hill .
you're go to , again , look all around , and then sai , what direct should i step in order to take a littl babi step downhil ? and if you do that and take anoth step , you take a step in that direct , and then you keep go .
you know , from thi new point , you look around , decid what direct will take you downhil most quickli , take anoth step , anoth step , and so on , until you converg to thi , local minimum down here .
further descent ha an interest properti .
thi first time we ran gradient descent , we were start at thi point over here , right ?
start at that point over here .
now imagin , we initi gradient descent just a coupl step to the right .
imagin we initi gradient descent with that point on the upper right .
if you were to repeat thi process , and stop at the point , and look all around .
take a littl step in the direct of steepest descent .
you would do that .
then look around , take anoth step , and so on .
and if you start it just a coupl step to the right , the gradient descent will have taken you to thi second local optimum over on the right .
so if you had start at thi first point , you would have wound up at thi local optimum .
but if you start just a littl bit , a slightli differ locat , you would have wound up at a veri differ local optimum .
and thi is a properti of gradient descent that we'll sai a littl bit more about later .
so , that's the intuit in pictur .
let's look at the map .
thi is the definit of the gradient descent algorithm .
we're go to just repeatedli do thi .
on to converg .
we're go to updat my paramet theta j by , you know , take theta j and subtract from it alpha time thi term over here .
so , let's see .
there ar a lot of detail in thi equat , so let me unpack some of it .
first , thi notat here , colon equal .
we're go to us to denot assign , so it's the assign oper .
so concret , if i write a b , what thi mean in a comput , thi mean take the valu in b and us it to overwrit whatev the valu of a .
so thi mean we will set a to be equal to the valu of b .
okai , it's assign .
i can also do a a <num> .
thi mean take a and increas it valu by on .
wherea in contrast , if i us the equal sign and i write a b , then thi is a truth assert .
so if i write a b , then i'm assert that the valu of a equal to the valu of b .
so the left hand side , that's a comput oper , where you set the valu of a to be a valu .
the right hand side , thi is assert , i'm just make a claim that the valu of a and b ar the same .
and so , wherea i can write a a <num> , that mean increment a by <num> .
hopefulli , i won't ever write a a <num> .
becaus that's just wrong .
a and a <num> can never be equal to the same valu .
so that's the first part of the definit .
thi alpha here is a number that is call the learn rate .
and what alpha doe is , it basic control how big a step we take downhil with gradient descent .
so if alpha is veri larg , then that correspond to a veri aggress gradient descent procedur , where we're try to take huge step downhil .
and if alpha is veri small , then we're take littl , littl babi step downhil .
and , i'll come back and sai more about thi later .
about how to set alpha and so on .
and final , thi term here .
that's the deriv term , i don't want to talk about it right now , but i will deriv thi deriv term and tell you exactli what thi is base on .
and some of you will be more familiar with calculu than other , but even if you aren't familiar with calculu don't worri about it , i'll tell you what you need to know about thi term here .
now there's on more subtleti about gradient descent which is , in gradient descent , we're go to updat theta0 and theta1 .
so thi updat take place where j <num> , and j <num> .
so you're go to updat j , theta0 , and updat theta1 .
and the subtleti of how you implement gradient descent is , for thi express , for thi updat equat , you want to simultan updat theta0 and theta1 .
what i mean by that is that in thi equat , we're go to updat theta0 theta0 someth , and updat theta1 theta1 someth .
and the wai to implement thi is , you should comput the right hand side .
comput that thing for both theta0 and theta1 , and then simultan at the same time updat theta0 and theta1 .
so let me sai what i mean by that .
thi is a correct implement of gradient descent mean simultan updat .
i'm go to set temp0 equal that , set temp1 equal that .
so basic comput the right hand side .
and then have comput the right hand side and store them togeth in temp0 and temp1 , i'm go to updat theta0 and theta1 simultan , becaus that's the correct implement .
in contrast , here's an incorrect implement that doe not do a simultan updat .
so in thi incorrect implement , we comput temp0 , and then we updat theta0 and then we comput temp1 .
then we updat temp1 .
and the differ between the right hand side and the left hand side implement is that if we look down here , you look at thi step , if by thi time you've alreadi updat theta0 then you would be us the new valu of theta0 to comput thi deriv term and so thi give you a differ valu of temp1 than the left hand side , becaus you've now plug in the new valu of theta0 into thi equat .
and so thi on right hand side is not a correct implement of gradient descent .
so i don't want to sai why you need to do the simultan updat , it turn out that the wai gradient descent is usual implement , we'll sai more about it later , it actual turn out to be more natur to implement the simultan updat .
and when peopl talk about gradient descent , thei alwai mean simultan updat .
if you implement the non simultan updat , it turn out it will probabl work anywai , but thi algorithm on the right is not what peopl peopl refer to as gradient descent and thi is some other algorithm with differ properti .
and for variou reason , thi can behav in slightli stranger wai .
and what you should do is to realli implement the simultan updat of gradient descent .
so , that's the outlin of the gradient descent algorithm .
in the next video , we're go to go into the detail of the deriv term , which i wrote out but didn't realli defin .
and if you've taken a calculu class befor and if you're familiar with partial deriv and deriv , it turn out that's exactli what that deriv term is .
but in case you aren't familiar with calculu , don't worri about it .
the next video will give you all the intuit and will tell you everyth you need to know to comput that deriv term , even if you haven't seen calculu , or even if you haven't seen partial deriv befor .
and with that , with the next video , hopefulli , we'll be abl to give all the intuit you need to appli gradient descent .
in the previou video , we gave a mathemat definit of gradient descent .
let's delv deeper , and in thi video , get better intuit about what the algorithm is do , and why the step of the gradient descent algorithm might make sens .
here's the gradient descent algorithm that we saw last time .
and , just to remind you , thi paramet , or thi term , alpha , is call the learn rate .
and it control how big a step we take when updat my paramet theta j .
and thi second term here is the deriv term .
and what i want to do in thi video is give you better intuit about what each of these two term is do and why , when put togeth , thi entir updat make sens .
in order to convei these intuit , what i want to do is us a slightli simpler exampl where we want to minim the function of just on paramet .
so , so we have a , sai we have a cost function j of just on paramet , theta on , like we did , you know , a few video back .
where theta on is a real number , okai ?
just so we can have 1d plot , which ar a littl bit simpler to look at .
and let's try to understand why gradient descent would do on thi function .
so , let's sai here's my function .
j of theta on , and so that's my , and where theta on is a real number .
right , now let's sai i've initi gradient descent with theta on at thi locat .
so imag that we start off at that point on my function .
what gradient descent will do , is it will updat .
theta on get updat as theta on minu alpha time dd theta on j of theta on , right ?
and oh an just as an asid you know thi , thi deriv term , right ?
if you're wonder why i chang the notat from these partial deriv symbol .
if you don't know what the differ is between these partial deriv symbol and the dd theta don't worri about it .
technic in mathemat we call thi a partial deriv , we call thi a deriv , depend on the number of , of paramet in the function j , but that's a mathemat technic , so , you know for the purpos of thi lectur , think of these partial symbol , and dd theta on as exactli the same thing .
and , don't worri about whether there ar ani differ .
i'm gonna try to us the mathemat precis notat .
but for our purpos , these notat ar realli the same thing .
so , let's see what thi , thi equat will do .
and so we're go to comput thi deriv of , i'm not sure if you've seen deriv in calculu befor .
but what a deriv , at thi point , doe , is basic sai , you know , let's .
take the tangent to that point , like that straight line , the red line , just , just touch thi function and let's look at the slope of thi red line .
that's where the deriv is .
it sai what's the slope of the line that is just tangent to the function , okai , and the slope of the line is of cours is just right , you know just the height divid by thi horizont thing .
now .
thi line ha a posit slope , so it ha a posit deriv .
and so , my updat to theta is go to be , theta on give the updat that theta on minu alpha time some posit number .
okai ?
alpha , the learn rate is alwai a posit number .
and so i'm gonna to take theta on , thi updat as theta on minu someth .
so i'm gonna end up move theta on to the left .
i'm gonna decreas theta on and we can see thi is the right thing to do becaus i actual went ahead in thi direct you know to get me closer to the minimum over there .
so , gradient descent so far seem to be do the right thing .
let's look at anoth exampl .
so let's take my same function j .
just try to draw the same function j of theta on .
and now let's sai i had instead initi my paramet over there on the left .
so theta on is here .
i'm gonna add that point on the surfac .
now , my deriv term , d , d theta on j of theta on , when evalu at thi point , gonna look at right .
the slope of that line .
so thi deriv term is a slope of thi line .
but thi line is slant down , so thi line ha neg slope .
right ?
or altern i sai that thi function ha neg deriv , just mean neg slope at that point .
so thi is less than equal to zero .
so when i updat theta , then if theta is updat as theta minu alpha time a neg number .
and so i have theta on minu a neg number which mean i'm actual go to increas theta , right ?
becaus thi is minu of a neg number mean i'm ad someth to theta and what that mean is that i'm go to end up increas theta .
and so we'll start here and increas theta , which again seem like the thing i want to do to try to get me closer to the minimum .
so , thi hopefulli explain the intuit behind what the deriv term is do .
let's next take a look at the learn rate term alpha , and try to figur out what that's do .
so , here's my gradient descent updat rule .
right , there's thi equat and let's look at what can happen , if alpha is either too small , or if alpha is too larg .
so thi first exampl , what happen if alpha is too small .
so here's my function j .
j of theta .
let just start here .
if alpha is too small then what i'm go to do is gonna multipli the updat by some small number .
so end up take , you know , it's like a babi step like that .
okai , so that's on step then from thi new point we're gonna take anoth step .
but if the alpha is too small let take anoth littl babi step .
and so if and so if my learn rate is too small .
i'm gonna end up , you know , take these tini , tini babi step to try to get to the minimum and i'm gonna need a lot of step to get to the minimum and so .
if alpha's too small , can be slow becaus it's gonna take these tini , tini babi step .
and it's gonna need a lot of step befor it get anywai close to the global minimum .
now , how about if the alpha is too larg .
so here's my function j of theta .
turn out if alpha is too larg , then grade descent can overshoot a minimum and mai even fail to converg or even diverg .
so here is what i mean .
let's sai ir minimum so the deriv council it's actual close to the minimum .
so the deriv point to the right , but if alpha is too big , i'm gonna take a huge step .
mayb i'm gonna take a huge step like that .
right ?
so i end up take a huge step .
now , my cost function ha got wors .
caus it start off from thi valu then now my valu ha gotten wors .
now my deriv , you know , point to the left , it's actual decreas theta .
but look , if my learn rate is too big , i mai take a huge step go from here all the wai out there so i end up .
go all there .
right ?
and if my learn rate wa too big i can take anoth huge step on the next acceler and kind of overshoot and overshoot and so on until you notic i'm actual get further and further awai from the minimum .
and so if alpha is too larg it can fail to converg or even diverg .
now , i have anoth question for you .
so , thi is a tricki on .
and when i wa first learn thi stuff , it actual took me a long time to figur thi out .
what if your pre emptiv theta on is alreadi at a local minimum ?
what do you think on step of gradient descent will do ?
so let's suppos you initi theta on at a local minimum .
so you know suppos thi is your initi valu of theta on over here and it's alreadi at a local optimum or the local minimum .
it send out that at local optimum your deriv would be equal to zero .
sinc it's that slope where it's that tangent point so the slope of thi line will be equal to zero and thu thi deriv term .
is equal to zero .
and so , in your gradient descent updat , you have theta on , give updat that theta on , minu alpha time zero .
and so , what thi mean is that , if you're alreadi at a local optimum , it leav theta on unchang 'caus thi , you know , get the updat's theta on equal theta on .
so if your paramet is alreadi at a local minimum , on step of gradient descent doe absolut noth .
it doesn't chang the paramet , which is , which is what you want .
cuz it keep your solut at the local optimum .
thi also explain why gradient descent can converg the local minimum , even with the learn rate alpha fix .
here's what i mean by that .
let's look at an exampl .
so here's a cost function j with theta .
that mayb i want to minim and let's sai i initi my algorithm my gradient descent algorithm , you know , out there at that magenta point .
if i take on step of gradient descent you know , mayb it'll take me to that point cuz my deriv's pretti steep out there , right ?
now i'm at thi green point and if i take anoth step of gradient descent , you notic that my deriv , mean the slope , is less steep at the green point when compar to at the magenta point out there , right ?
becaus as i approach the minimum my deriv get closer and closer to zero as i approach the minimum .
so , after on step of gradient descent , my new deriv is a littl bit smaller .
so i wanna take anoth step of gradient descent .
i will natur take a somewhat smaller step from thi green point than i did from the magenta point .
now i'm at the new point , the red point , and then now even closer to global minimum , so the deriv here will be even smaller than it wa at the green point .
so when i take anoth step of gradient descent , you know , now my deriv term is even smaller , and so the magnitud of the updat to theta on is even smaller , so you can take small step like so , and as gradient descent run .
you will automat take smaller and smaller step until eventu you ar take veri small step , you know , and you find the converg to the to the local minimum .
so , just to recap .
in gradient descent as we approach the local minimum , grade descent will automat take smaller step and that's becaus as we approach the local minimum , by definit , local minimum is when you have thi deriv equal to zero .
so as we approach the local minimum thi deriv term will automat get smaller and so gradient descent will automat take smaller step .
so , thi is what gradient descent look like , and so actual there is no need to decreas alpha overtim .
so , that's the gradient descent algorithm , and you can us it to minim , to try to minim ani cost function j .
not the cost function j to be defin for linear regress .
in the next video , we're go to take the function j , and set that back to be exactli linear regress's cost function .
the , the squar cost function that we came up with earlier .
and take gradient descent , and the squar cost function , and put them togeth .
that will give us our first learn algorithm , that'll give us our linear regress algorithm .
in previou video , we talk about the gradient descent algorithm and talk about the linear regress model and the squar error cost function .
in thi video , we're go to put togeth gradient descent with our cost function , and that will give us an algorithm for linear regress for fit a straight line to our data .
so , thi is what we work out in the previou video .
that's our gradient descent algorithm , which should be familiar , and you see the linear linear regress model with our linear hypothesi and our squar error cost function .
what we're go to do is appli gradient descent to minim our squar error cost function .
now , in order to appli gradient descent , in order to write thi piec of code , the kei term we need is thi deriv term over here .
so , we need to figur out what is thi partial deriv term , and plug in the definit of the cost function j , thi turn out to be thi inaud equal sum <num> through m of thi squar error cost function term , and all i did here wa i just you know plug in the definit of the cost function there , and simplifi littl bit more , thi turn out to be equal to , thi inaud equal sum <num> through m of tetha zero plu tetha on , xi minu yi squar .
and all i did there wa took the definit for my hypothesi and plug that in there .
and it turn out we need to figur out what is the partial deriv of two case for j equal <num> and for j equal <num> want to figur out what is thi partial deriv for both the theta <num> case and the theta <num> case .
and i'm just go to write out the answer .
it turn out thi first term simplifi to <num> m , sum over my train set of just that , x i y i .
and for thi term , partial deriv with respect to theta <num> , it turn out i get thi term y i <i>x i . < i> okai .
and comput these partial deriv , so go from thi equat to either of these equat down there , comput those partial deriv term requir some multivari calculu .
if you know calculu , feel free to work through the deriv yourself and check take the deriv you actual get the answer that i got .
but if you ar less familiar with calculu you don't worri about it , and it is fine to just take these equat work out , and you won't need to know calculu or anyth like that in order to do the homework , so to implement gradient descent you'd get that to work .
but so , after these definit , or after what we've work out to be the deriv , which is realli just the slope of the cost function j .
we can now plug them back into our gradient descent algorithm .
so here's gradient descent , or the regress , which is go to repeat until converg , theta <num> and theta on get updat as , you know , the same minu alpha time the deriv term .
so , thi term here .
so , here's our linear regress algorithm .
thi first term here that term is , of cours , just a partial deriv of respect theta zero , that we work on in the previou slide .
and thi second term here , that term is just a partial deriv with respect to theta on that we work out on the previou line .
and just as a quick remind , you must , when implement gradient descent , there's actual there's detail that , you know , you should be implement it so the updat theta zero and theta on simultan .
so , let's see how gradient descent work .
on of the issu we solv gradient descent is that it can be suscept to local optima .
so , when i first explain gradient descent , i show you thi pictur of it , you know , go downhil on the surfac and we saw how , depend on where you're initi , you can end up with differ local optima .
you know , you can end up here or here .
but , it turn out that the cost function for gradient of cost function for linear regress is alwai go to be a bow shape function like thi .
the technic term for thi is that thi is call a convex function .
and i'm not go to give the formal definit for what is a convex function , c o n v e x , but inform a convex function mean a bow shape function , you know , kind of like a bow shape .
and so , thi function doesn't have ani local optima , except for the on global optimum .
and doe gradient descent on thi type of cost function which you get whenev you're us linear regress , it will alwai convert to the global optimum , becaus there ar no other local optima other than global optimum .
so now , let's see thi algorithm in action .
as usual , here ar plot of the hypothesi function and of my cost function j .
and so , let's see how to initi my paramet at thi valu .
you know , let's sai , usual you initi your paramet at zero for zero , theta zero and zero .
for illustr in thi specif present , i have initialis theta zero at about <num> , and theta on at about minu <num> , okai ?
and so , thi correspond to h over x , equal , you know , minu <num> minu <num> x is thi line , so out here on the cost function .
now if we take on step of gradient descent , we end up go from thi point out here , a littl bit to the down left to that second point over there .
and , you notic that my line chang a littl bit .
and , as i take anoth step at gradient descent , my line on the left will chang .
right .
and i have also move to a new point on my cost function .
and as i think further step is gradient descent , i'm go down in cost , right , so my paramet is follow thi trajectori , and if you look on the left , thi correspond to hypothes that seem to be get to be better and better fit for the data until eventu , i have now wound up at the global minimum .
and thi global minimum correspond to thi hypothesi , which give me a good fit to the data .
and so that's gradient descent , and we've just run it and gotten a good fit to my data set of hous price .
and you can now us it to predict .
you know , if your friend ha a hous with a size <num> squar feet , you can now read off the valu and tell them that , i don't know , mayb thei can get <num> , <num> for their hous .
final , just to give thi anoth name , it turn out that the algorithm that we just went over is sometim call batch gradient descent .
and it turn out in machin learn , i feel like us machin learn peopl , we're not alwai creat ha given me some algorithm .
but the term batch gradient descent mean that refer to the fact that , in everi step of gradient descent we're look at all of the train exampl .
so , in gradient descent , you know , when comput deriv , we're comput these sum , thi sum of .
so , in everi separ gradient descent , we end up comput someth like thi , that sum over our m train exampl .
and so the term batch gradient descent refer to the fact when look at the entir batch of train exampl , and again , thi is realli , realli not a great name , but thi is what machin learn peopl call it .
and it turn out there ar sometim other version of gradient descent that ar not batch version but instead do not look at the entir trane set but look at small subset of the train set at the time , and we'll talk about those version later in thi cours as well .
but for now , us the algorithm you just learn , now we're us batch gradient descent , you now know how to implement gradient descent , or linear regress .
so that's linear regress with gradient descent .
if you've seen advanc linear algebra befor so some you mai have taken a class with advanc linear algebra , you might know that there exist a solut for numer solv for the minimum of the cost function j , without need to us and iter algorithm like gradient descent .
later in thi cours we will talk about that method as well that just solv for the minimum cost function j without need thi multipl step of gradient descent .
that other method is call normal equat method .
and , but in case you have heard of that method , it turn out gradient descent will scale better to larger data set than that normal equal method and , now that we know about gradient descent , we'll be abl to us it in lot of differ context , and we'll us it in lot of differ machin learn problem as well .
so , congrat on learn about your first machin learn algorithm .
we'll later have exercis in which we'll ask you to implement gradient descent and hopefulli see these algorithm work for yourselv .
but befor that i first want to tell you in the next set of video , the first want to tell you about a gener of the gradient descent algorithm that will make it much more power and i guess i will tell you about that in the next video .
you now know about linear regress and gradient descent .
the plan from here on out is to tell you about a coupl of import extens of these idea .
concret here thei ar .
first it turn out that in order to solv thi minim problem , turn out there's an algorithm for solv for theta zero and theta on exactli without need an iter algorithm .
without need thi algorithm like gradient descent that we had to iter , you know , multipl time over .
so it turn out there ar advantag and disadvantag of thi algorithm that let you just solv for theta zero and theta on , basic in just on shot .
on advantag is that there is no longer a learn rate alpha that you need to worri about and set .
and so it can be much faster for some problem .
we'll talk about it advantag and disadvantag later .
second , we'll also talk about algorithm for learn with a larger number of featur .
so , so far we've been learn with just on featur , the size of the hous and us that to predict the price , so we're try to take x and us that to predict y .
but for other learn problem we mai have a larger number of featur .
so for exampl let's sai that you know not onli the size , but also the number of bedroom , the number of floor , and the ag of these hous .
and you want to us that to predict the price of the hous .
in that case mayb we'll call these featur x1 , x2 , x3 , and x4 .
so now we have , you know , four featur .
we want to us these four featur to predict why the price of the hous .
it turn out with all of these featur , four of them in thi case , it turn out that with multipl featur it becom harder to plot or visual the data .
so for exampl here we try to plot thi type of data set .
mayb we will have the vertic axi be the price and mayb we can have on axi here , and anoth on here where thi axi is the size of the hous , and that axi is the number of bedroom .
you know , but thi is just plot , right my first two featur size and number of bedroom .
and when we have these addit featur i don't know , i just don't know how to plot all of these data , right cuz i need like a <num> dimension or <num> dimension figur .
i don't realli know how to plot you know someth more than like a <num> dimension figur , like , like what i have over here .
also as you can tell , the notat start to get a littl more complic , right .
so rather than just have x our featur we now have x1 through x4 .
and we're us these subscript to denot my four differ featur .
it turn out the best notat to keep all of thi straight and to understand what's go on with the data even when we don't quit know how to plot it .
it turn out that the best notat is the notat of linear algebra .
linear algebra give us a notat and a set of thing or a set of oper that we can do with matric and vector .
for exampl .
here's a matrix where the column of thi matrix ar the first column is the size of the four hous , the second column wa the number of bedroom , that's the number of floor and that wa the ag of the home .
and so a matrix is a block of number that let me take all of my data , all of my x's .
all of my featur and organ them effici into sort of on big block of number like that .
and here is what we call a vector in linear algebra where the four number here ar the price of the four hous that we saw on the previou slide .
so .
in the next set of video what i'm go to do is do a quick review of linear algebra .
if you haven't seen matric and vector befor , so if all of thi , everyth on thi slide is brand new to you or if you've seen linear algebra befor , but it's been a while so you aren't complet familiar with it anymor , then pleas watch the next set of video .
and i'll quickli review the linear algebra you need in order to implement and us the more power version of linear regress .
it turn out linear algebra isn't just us for linear regress model but these idea of matric and vector will be us for help us to implement and actual get computation effici implement for mani later machin learn model as well .
and as you can tell these sort of matric and vector will give us an effici wai to start to organ larg amount of data , when we work with larger train set .
so , in case , in case you're not familiar with linear algebra or in case linear algebra seem like a complic , scari concept for those of you who've never seen it befor , don't worri about it .
it turn out in order to implement machin learn algorithm we need onli the veri , veri basic of linear algebra and you'll be abl to veri quickli pick up everyth you need to know in the next few video .
concret , to decid if you should watch the next set of video , here ar the topic i'm go to cover .
talk about what ar matric and vector .
talk about how to add , subtract , multipli matric and vector .
talk about the idea of matrix invers and transpos .
and so , if you ar not sure if you should watch the next set of video take a look at these two thing .
so if you think you know how to comput thi quantiti , thi matrix transpos time anoth matrix .
if you think you know , if you have seen thi stuff befor , if you know how to comput the invers of matrix time a vector , minu a number , time anoth vector .
if these two thing look complet familiar to you then you can safe skip the option set of video on linear algebra .
but if these , concept , if you're slightli uncertain what these block of number or these matric of number mean , then pleas take a look of the next set of video and , it'll veri quickli teach you what you need to know about linear algebra in order to program machin learn algorithm and deal with larg amount of data .
let's get start with our linear algebra review .
in thi video i want to tell you what ar matric and what ar vector .
a matrix is a rectangular arrai of number written between squar bracket .
so , for exampl , here is a matrix on the right , a left squar bracket .
and then , write in a bunch of number .
these could be featur from a learn problem or it could be data from somewher els , but the specif valu don't matter , and then i'm go to close it with anoth right bracket on the right .
and so that's on matrix .
and , here's anoth exampl of the matrix , let's write <num> , <num> , <num> , <num> .
so matrix is just anoth wai for sai , is a 2d or a two dimension arrai .
and the other piec of knowledg that we need is that the dimens of the matrix is go to be written as the number of row time the number of column in the matrix .
so , concret , thi exampl on the left , thi ha <num> , <num> , <num> , <num> row and ha <num> column , and so thi exampl on the left is a <num> by <num> matrix number of row by number of column .
so , four row , two column .
thi on on the right , thi matrix ha two row .
that's the first row , that's the second row , and it ha three column .
that's the first column , that's the second column , that's the third column so , thi second matrix we sai it is a <num> by <num> matrix .
so we sai that the dimens of thi matrix is <num> by <num> .
sometim you also see thi written out , in the case of left , you will see thi written out as r4 by <num> or concret what peopl will sometim sai thi matrix is an element of the set r <num> by <num> .
so , thi thing here , thi just mean the set of all matric that of dimens <num> by <num> and thi thing on the right , sometim thi is written out as a matrix that is an r <num> by <num> .
so if you ever see , <num> by <num> .
so if you ever see someth like thi ar <num> by <num> or ar <num> by <num> , peopl ar just refer to matric of a specif dimens .
next , let's talk about how to refer to specif element of the matrix .
and by matrix element , other than the matrix i just mean the entri , so the number insid the matrix .
so , in the standard notat , if a is thi matrix here , then a sub strip ij is go to refer to the i , j entri , mean the entri in the matrix in the ith row and jth column .
so for exampl a<num> <num> is go to refer to the entri in the 1st row and the 1st column , so that's the first row and the first column and so a<num> <num> is go to be equal to <num> , <num> , <num> , <num> .
anoth exampl , <num> <num> <num> is go to refer to the entri in the first row and the second column and so a <num> <num> is go to be equal to on nine on .
thi come from a quick exampl .
let's see , a , oh let's sai a <num> <num> , is go to refer to the entri in the 3rd row , and second column , right , becaus that's <num> <num> so that's equal to <num> <num> <num> <num> .
and final , <num> <num> <num> is go to refer to thi on right , fourth row , first column is equal to <num> <num> <num> and if , hopefulli you won't , but if you were to write and sai well thi a <num> <num> , well , that refer to the fourth row , and the third column that , you know , thi matrix ha no third column so thi is undefin , you know , or you can think of thi as an error .
there's no such element as <num> <num> <num> , so , you know , you shouldn't be refer to <num> <num> <num> .
so , the matrix get you a wai of let you quickli organ , index and access lot of data .
in case i seem to be toss up a lot of concept , a lot of new notat veri rapidli , you don't need to memor all of thi , but on the cours websit where we have post the lectur note , we also have all of these definit written down .
so you can alwai refer back , you know , either to these slide , possibl coursework , so audibl lectur note if you forget well , a41 wa that ?
which row , which column wa that ?
don't worri about memor everyth now .
you can alwai refer back to the written materi on the cours websit , and us that as a refer .
so that's what a matrix is .
next , let's talk about what is a vector .
a vector turn out to be a special case of a matrix .
a vector is a matrix that ha onli <num> column so you have an n x <num> matrix , then that's a rememb , right ?
n is the number of row , and <num> here is the number of column , so , so matrix with just on column is what we call a vector .
so here's an exampl of a vector , with i guess i have n equal four element here .
so we also call thi thing , anoth term for thi is a four dmension vector , just mean that thi is a vector with four element , with four number in it .
and , just as earlier for matric you saw thi notat r3 by <num> to refer to <num> by <num> matric , for thi vector we ar go to refer to thi as a vector in the set r4 .
so thi r4 mean a set of four dimension vector .
next let's talk about how to refer to the element of the vector .
we ar go to us the notat yi to refer to the ith element of the vector y .
so if y is thi vector , y subscript i is the ith element .
so y1 is the first element , four sixti , y2 is equal to the second element , two thirti two there's the first .
there's the second .
y3 is equal to <num> and so on , and onli y1 through y4 ar defin consist <num> dimension vector .
also it turn out that there ar actual <num> convent for how to index into a vector and here thei ar .
sometim , peopl will us on index and sometim zero index factor .
so thi exampl on the left is a on in that specter where the element we write is y1 , y2 , y3 , y4 .
and thi exampl in the right is an exampl of a zero index factor where we start the index of the element from zero .
so the element go from a zero up to y three .
and thi is a bit like the arrai of some primari languag where the arrai can either be index start from on .
the first element of an arrai is sometim a y1 , thi is sequenc notat i guess , and sometim it's zero index depend on what program languag you us .
so it turn out that in most of math , the on index version is more common for a lot of machin learn applic , zero index vector give us a more conveni notat .
so what you should usual do is , unless otherwis specifi , you should assum we ar us on index vector .
in fact , throughout the rest of these video on linear algebra review , i will be us on index vector .
but just be awar that when we ar talk about machin learn applic , sometim i will explicitli sai when we need to switch to , when we need to us the zero index vector as well .
final , by convent , usual when write matric and vector , most peopl will us upper case to refer to matric .
so we're go to us capit letter like a , b , c , you know , x , to refer to matric , and usual we'll us lowercas , like a , b , x , y , to refer to either number , or just raw number or scalar or to vector .
thi isn't alwai true but thi is the more common notat where we us lower case y for refer to vector and we usual us upper case to refer to a matrix .
so , you now know what ar matric and vector .
in thi video we'll talk about matrix addit and subtract , as well as how to multipli a matrix by a number , also call scalar multipl .
let's start an exampl .
given two matric like these , let's sai i want to add them togeth .
how do i do that ?
and so , what doe addit of matric mean ?
it turn out that if you want to add two matric , what you do is you just add up the element of these matric on at a time .
so , my result of ad two matric is go to be itself anoth matrix and the first element again just by take on and four and multipli them and ad them togeth , so i get five .
the second element i get by take two and two and ad them , so i get four ; three plu three plu zero is three , and so on .
i'm go to stop chang color , i guess .
and , on the right is open five , ten and two .
and it turn out you can add onli two matric that ar of the same dimens .
so thi exampl is a three by two matrix , becaus thi ha <num> row and <num> column , so it's <num> by <num> .
thi is also a <num> by <num> matrix , and the result of ad these two matric is a <num> by <num> matrix again .
so you can onli add matric of the same dimens , and the result will be anoth matrix that's of the same dimens as the on you just ad .
where as in contrast , if you were to take these two matric , so thi on is a <num> by <num> matrix , okai , <num> row , <num> column .
thi here is a <num> by <num> matrix .
and becaus these two matric ar not of the same dimens , you know , thi is an error , so you cannot add these two matric and , you know , their sum is not well defin .
so that's matrix addit .
next , let's talk about multipli matric by a scalar number .
and the scalar is just a , mayb a overli fanci term for , you know , a number or a real number .
all right , thi mean real number .
so let's take the number <num> and multipli it by thi matrix .
and if you do that , the result is pretti much what you'll expect .
you just take your element of the matrix and multipli them by <num> , on at a time .
so , you know , on time three is three .
what , two time three is six , <num> time <num> is <num> , and let's see , i'm go to stop chang color again .
zero time <num> is zero .
three time <num> is <num> , and <num> time <num> is three .
and so thi matrix is the result of multipli that matrix on the left by <num> .
and you notic , again , thi is a <num> by <num> matrix and the result is a matrix of the same dimens .
thi is a <num> by <num> , both of these ar <num> by <num> dimension matric .
and by the wai , you can write multipl , you know , either wai .
so , i have three time thi matrix .
i could also have written thi matrix and <num> , <num> , <num> , <num> , <num> , right .
i just copi thi matrix over to the right .
i can also take thi matrix and multipli thi by three .
so whether it's you know , <num> time the matrix or the matrix time three is the same thing and thi thing here in the middl is the result .
you can also take a matrix and divid it by a number .
so , turn out take thi matrix and divid it by four , thi is actual the same as take the number on quarter , and multipli it by thi matrix .
<num> , <num> , <num> , <num> and so , you can figur the answer , the result of thi product is , on quarter time four is on , on quarter time zero is zero .
on quarter time six is , what , three halv , about six over four is three halv , and on quarter time three is three quarter .
and so that's the result of comput thi matrix divid by four .
vector give you the result .
final , for a slightli more complic exampl , you can also take these oper and combin them togeth .
so in thi calcul , i have three time a vector plu a vector minu anoth vector divid by three .
so just make sure we know where these ar , right .
thi multipl .
thi is an exampl of scalar multipl becaus i am take three and multipli it .
and thi is , you know , anoth scalar multipl .
or more like scalar divis , i guess .
it realli just mean on zero time thi .
and so if we evalu these two oper first , then what we get is thi thing is equal to , let's see , so three time that vector is three , twelv , six , plu my vector in the middl which is a <num> minu on , zero , two third , right ?
and again , just to make sure we understand what is go on here , thi plu symbol , that is matrix addit , right ?
i realli , sinc these ar vector , rememb , vector ar special case of matric , right ?
thi , you can also call thi vector addit thi minu sign here , thi is again a matrix subtract , but becaus thi is an n by <num> , realli a three by on matrix , that thi is actual a vector , so thi is also vector , thi column .
we call thi matrix a vector subtract , as well .
ok ?
and final to wrap thi up .
thi therefor give me a vector , whose first element is go to be <num> <num> <num> , so that's <num> <num> , which is <num> .
the second element is <num> <num> <num> , which is <num> .
and the third element of thi is , what , <num> <num> <num> <num> , which is <num> <num> <num> , so that's <num> and on third and see , you close thi squar bracket .
and so thi give me a <num> by <num> matrix , which is also just call a <num> dimension vector , which is the outcom of thi calcul over here .
so that's how you add and subtract matric and vector and multipli them by scalar or by row number .
so far i have onli talk about how to multipli matric and vector by scalar , by row number .
in the next video we will talk about a much more interest step , of take <num> matric and multipli <num> matric togeth .
in thi video , i'd like to start talk about how to multipli togeth two matric .
we'll start with a special case of that , of matrix vector multipl multipli a matrix togeth with a vector .
let's start with an exampl .
here is a matrix , and here is a vector , and let's sai we want to multipli togeth thi matrix with thi vector , what's the result ?
let me just work through thi exampl and then we can step back and look at just what the step were .
it turn out the result of thi multipl process is go to be , itself , a vector .
and i'm just go work with thi first and later we'll come back and see just what i did here .
to get the first element of thi vector i am go to take these two number and multipli them with the first row of the matrix and add up the correspond number .
take on multipli by on , and take three and multipli it by five , and that's what , that's on plu fifteen so that give me sixteen .
i'm go to write sixteen here .
then for the second row , second element , i am go to take the second row and multipli it by thi vector , so i have four time on , plu zero time five , which is equal to four , so you'll have four there .
and final for the last on i have two on time on five , so two by on , plu on by <num> , which is equal to a <num> , and so i get a <num> over there .
it turn out that the result of multipli that's a 3x2 matrix by a 2x1 matrix is also just a two dimension vector .
the result of thi is go to be a 3x1 matrix , so that's why three by on 3x1 matrix , in other word a 3x1 matrix is just a three dimension vector .
so i realiz that i did that pretti quickli , and you're probabl not sure that you can repeat thi process yourself , but let's look in more detail at what just happen and what thi process of multipli a matrix by a vector look like .
here's the detail of how to multipli a matrix by a vector .
let's sai i have a matrix a and want to multipli it by a vector x .
the result is go to be some vector y .
so the matrix a is a m by n dimension matrix , so m row and n column and we ar go to multipli that by a n by <num> matrix , in other word an n dimension vector .
it turn out thi n here ha to match thi n here .
in other word , the number of column in thi matrix , so it's the number of n column .
the number of column here ha to match the number of row here .
it ha to match the dimens of thi vector .
and the result of thi product is go to be an n dimension vector y .
row here .
m is go to be equal to the number of row in thi matrix a .
so how do you actual comput thi vector y ?
well it turn out to comput thi vector y , the process is to get y i , multipli a's i'th row with the element of the vector x and add them up .
so here's what i mean .
in order to get the first element of y , that first number whatev that turn out to be we're gonna take the first row of the matrix a and multipli them on at a time with the element of thi vector x .
so i take thi first number multipli it by thi first number .
then take the second number multipli it by thi second number .
take thi third number whatev that is , multipli it the third number and so on until you get to the end .
and i'm gonna add up the result of these product and the result of pai that out is go to give us thi first element of y .
then when we want to get the second element of y , let's sai thi element .
the wai we do that is we take the second row of a and we repeat the whole thing .
so we take the second row of a , and multipli it element wise , so the element of x and add up the result of the product and that would give me the second element of y .
and you keep go to get and we go to take the third row of a , multipli element ys with the vector x , sum up the result and then i get the third element and so on , until i get down to the last row like so , okai ?
so that's the procedur .
let's do on more exampl .
here's the exampl so let's look at the dimens .
here , thi is a three by four dimension matrix .
thi is a four dimension vector , or a <num> x <num> matrix , and so the result of thi , the result of thi product is go to be a three dimension vector .
write , you know , the vector , with room for three element .
let's do the , let's carri out the product .
so for the first element , i'm go to take these four number and multipli them with the vector x .
so i have 1x1 , plu 2x3 , plu 1x2 , plu 5x1 , which is equal to that's <num> <num> , plu <num> <num> , which give me <num> .
and then for the second element , i'm go to take thi row now and multipli it with thi vector 0x1 <num> .
all right , so 0x1 3x3 plu 0x2 plu 4x1 , which is equal to , let's see that's <num> <num> , which is <num> .
and final , for the last element , i'm go to take thi last row , so i have minu on time on .
you have minu two , or realli there's a plu next to a two i guess .
time three plu zero time two plu zero time on , and so that's go to be minu on minu six , which is go to make thi seven , and so that's vector seven .
okai ?
so my final answer is thi vector fourteen , just to write to that without the color , fourteen , thirteen , neg seven .
and as promis , the result here is a three by on matrix .
so that's how you multipli a matrix and a vector .
i know that a lot just happen on thi slide , so if you're not quit sure where all these number went , you know , feel free to paus the video you know , and so take a slow care look at thi big calcul that we just did and try to make sure that you understand the step of what just happen to get us these number , fourteen , thirteen and eleven .
final , let me show you a neat trick .
let's sai we have a set of four hous so <num> hous with <num> size like these .
and let's sai i have a hypothes for predict what is the price of a hous , and let's sai i want to comput , you know , h of x for each of my <num> hous here .
it turn out there's neat wai of pose thi , appli thi hypothesi to all of my hous at the same time .
it turn out there's a neat wai to pose thi as a matrix vector multipl .
so , here's how i'm go to do it .
i am go to construct a matrix as follow .
my matrix is go to be <num> time , and i'm go to write down the size of my four hous here and i'm go to construct a vector as well , and my vector is go to thi vector of two element , that's minu <num> and <num> . <num> .
that's these two co effici ; data <num> and data <num> .
and what i am go to do is to take matrix and that vector and multipli them togeth , that time is that multipl symbol .
so what do i get ?
well thi is a four by two matrix .
thi is a two by on matrix .
so the outcom is go to be a four by on vector , all right .
so , let me , so thi is go to be a <num> by <num> matrix is the outcom or realli a four diminson vector , so let me write it as on of my four element in my four real number here .
now it turn out and so thi first element of thi result , the wai i am go to get that is , i am go to take thi and multipli it by the vector .
and so thi is go to be <num> x <num> <num> . <num> x <num> .
by the wai , on the earlier slide i wa write <num> x <num> and <num> x <num> . <num> , but the order doesn't matter , right ?
<num> x <num> is the same as <num> x <num> .
and thi first element , of cours , is h appli to <num> .
so it's realli the predict price of my first hous .
well , how about the second element ?
hope you can see where i am go to get the second element .
right ?
i'm gonna take thi and multipli it by my vector .
and so that's gonna be <num> x <num> <num> . <num> x <num> .
and so thi is go be h of <num> .
right ?
and so on for the third and the fourth element of thi <num> x <num> vector .
and just there , right ?
thi thing here that i just drew the green box around , that's a real number , ok ?
that's a singl real number , and thi thing here that i drew the magenta box around the purpl , magenta color box around that's a real number , right ?
and so thi thing on the right thi thing on the right overal , thi is a <num> by <num> dimension matrix , wa a <num> dimension vector .
and , the neat thing about thi is that when you're actual implement thi in softwar so when you have four hous and when you want to us your hypothesi to predict the price , predict the price y of all of these four hous .
what thi mean is that , you know , you can write thi in on line of code .
when we talk about octav and program languag later , you can actual , you'll actual write thi in on line of code .
you write predict equal my , you know , data matrix time paramet , right ?
where data matrix is thi thing here , and paramet is thi thing here , and thi time is a matrix vector multipl .
and if you just do thi then thi variabl predict sorri for my bad handwrit then just implement thi on line of code assum you have an appropri librari to do matrix vector multipl .
if you just do thi , then predict becom thi <num> by <num> dimension vector , on the right , that just give you all the predict price .
and your altern to do thi as a matrix vector multipl would be to write eometh like , you know , for i equal <num> to <num> , right ?
and you have sai a thousand hous it would be for i equal <num> to a thousand or whatev .
and then you have to write a predict , you know , if i equal .
and then do a bunch more work over there and it turn out that when you have a larg number of hous , if you're try to predict the price of not just four but mayb of a thousand hous then it turn out that when you implement thi in the comput , implement it like thi , in ani of the variou languag .
thi is not onli true for octav , but for supra server java or python , other high level , other languag as well .
it turn out , that , by write code in thi style on the left , it allow you to not onli simplifi the code , becaus , now , you're just write on line of code rather than the form of a bunch of thing insid .
but , for subtl reason , that we will see later , it turn out to be much more computation effici to make predict on all of the price of all of your hous do it the wai on the left than the wai on the right than if you were to write your own formula .
i'll sai more about thi later when we talk about vector , but , so , by pose a predict thi wai , you get not onli a simpler piec of code , but a more effici on .
so , that's it for matrix vector multipl and we'll make good us of these sort of oper as we develop the live regress in other model further .
but , in the next video we're go to take thi and gener thi to the case of matrix matrix multipl .
in thi video we talk about matrix , matrix multipl or how to multipli two matric togeth .
when we talk about the method in linear regress for how to solv for the paramet , theta zero and theta on , all in on shot .
so , without need an iter algorithm like gradient descent .
when we talk about that algorithm , it turn out that matrix , matrix multipl is on of the kei step that you need to know .
so , let's , as usual , start with an exampl .
let's sai i have two matric and i want to multipli them togeth .
let me again just refer thi exampl and then i'll tell you in a littl bit what happen .
so , the first thing i'm gonna do is , i'm go to pull out the first column of thi matrix on the right .
and i'm go to take thi matrix on the left and multipli it by , you know , a vector .
that's just thi first column , ok ?
and it turn out if i do that i am go to get the vector <num> , <num> .
so , thi is the same matrix vector multipl as you saw in the last video .
i work thi out in advanc so , i know it's <num> , <num> .
and , then , the second thing i'm go to do is , i'm go to pull out the second column , thi matrix on the right and i am then go to take thi matrix on the left , right , so , it will be that matrix , and multipli it by that second column on the right .
so , again , thi is a matrix vector multipl set , which you saw from the previou video , and it turn out that if you multipli thi matrix and thi vector , you get <num> , <num> and by the wai , if you want to practic your matrix vector multipl , feel free to paus the video and check thi product yourself .
then , i'm just go to take these two result and put them togeth , and that will be my answer .
so , turn out the outcom of thi product is go to be a <num> by <num> matrix , and the wai i am go to fill in thi matrix is just by take my element <num> , <num> and plug them here , and take <num> , <num> and plug them into the second column .
okai ?
so , that wa the mechan of how to multipli a matrix by anoth matrix .
you basic look at the second matrix on column at a time , and you assembl the answer .
and again , we will step through thi much more carefulli in a second , but i just want to point out also , thi first exampl is a 2x3 matrix matrix .
multipli that by a 3x2 matrix , and the outcom of thi product , it turn out to be a 2x2 matrix .
and again , we'll see in a second why thi wa the case .
all right .
that wa the mechan of the calcul .
let's actual look at the detail and look at what exactli happen .
here ar detail .
i have a matrix a and i want to multipli that with a matrix b , and the result will be some new matrix c .
and it turn out you can onli multipli togeth matric whose dimens match so a is an m by n matrix , so m column , n column and i am go to multipli that with an n by o and it turn out thi n here must match thi n here , so the number of column in first matrix must equal to the number of row in second matrix .
and the result of thi product will be an m by o matrix , like the the matrix c here .
and , in the previou video , everyth we did correspond to thi special case of ob equal to <num> .
okai ?
that wa , that wa in case of b be a vector .
but now , we ar go to view of the case of valu of o larger than <num> .
so , here's how you multipli togeth the two matric .
in order to get , what i am go to do is i am go to take the first column of b and treat that as a vector , and multipli the matrix a , with the first column of b , and the result of that will be a m by <num> vector , and we're go to put that over here .
then , i'm go to take the second column of b , right , so , thi is anoth n by on vector , so , thi column here , thi is right , n by on , those ar n dimension vector , gonna multipli thi matrix with thi n by on vector .
the result will be a m dimension vector , which we'll put there .
and , so on .
okai ?
and , so , you know , and then i'm go to take the third column , multipli it by thi matrix , i get a m dimension vector .
and so on , until you get to the last column time , the matrix time the lost column give you the lost column of c .
just to sai that again .
the ith column of the matrix c is attain by take the matrix a and multipli the matrix a with the ith column of the matrix b for the valu of i equal <num> , <num> up through o .
okai ?
so , thi is just a summari of what we did up there in order to comput the matrix c .
let's look at just on more exampl .
let 's sai , i want to multipli togeth these two matric .
so , what i'm go to do is , first pull out the first column of my second matrix , that wa matrix b , that wa my matrix b on the previou slide .
and , i therefor , have thi matrix time my vector and so , oh , let's do thi calcul quickli .
there's go to be equal to , right , <num> , <num> time <num> , <num> so that give <num> time <num> , plu <num> time <num> .
and , the second element is go to be <num> , <num> time <num> , <num> so , that's go to be two time <num> plu <num> time <num> and that is <num> , <num> , actual didn't write that in green , so thi is nine fifteen , and then mix .
i am go to pull out the second column of thi , and do the correspond calcul so there's thi matrix time thi vector <num> , <num> .
let's also do thi quickli , so that's on time on plu three time two .
so that deal with that row , let's do the other on , so let's see , that give me two time on plu time two , so that is go to be equal to , let's see , on time on plu three time on is four and two time on plu five time two is twelv .
so now i have these two you , and so my outcom , so the product of these two matric is go to be , thi goe here and thi goe here , so i get nine fifteen and four twelv and you mai notic also that the result of multipli a 2x2 matrix with anoth 2x2 matrix .
the result dimens is go to be that first two time that second two , so the result is itself also a two by two matrix .
final let me show you on more neat trick you can do with matrix matrix multipl .
let's sai as befor that we have four hous whose price we want to predict , onli now we have three compet hypothesi shown here on the right , so if you want to so appli all <num> compet hypothes to all four of the hous , it turn out you can do that veri effici us a matrix matrix multipl so here on the left is my usual matrix , same as from the last video where these valu ar my hous price and i put on there on the left as well .
and , what i'm go to do is construct anoth matrix , where here these , the first column , is thi minu <num> and two five and the second column is thi two hundr open on and so on and it turn out that if you multipli these two matric what you find is that , thi first column , you know , oh , well how do you get thi first column , right ?
a procedur from matrix matrix multipl is the wai you get thi first column , is you take thi matrix and you multipli it by thi first column , and we saw in the previou video that thi is exactli the predict hous price of the first hypothesi , right ?
of thi first hypothesi here .
and , how about a second column ?
well , how do setup the second column ?
the wai you get the second column is , well , you take thi matrix and you multipli by thi second column .
and so thi second column turn out to be the predict of the second hypothesi of the second hypothesi up there , and similarli for the third column .
and so , i didn't step through all the detail but hopefulli you just , feel free to paus the video and check the math yourself and check that what i just claim realli is true .
but it turn out that by construct these two matric , what you can therefor do is veri quickli appli all three hypothes to all four hous size to get , you know , all twelv predict price output by your three hypothes on your four hous .
so on matrix multipl that you manag to make <num> predict and , even better , it turn out that in order to do that matrix multipl and there ar lot of good linear algebra librari in order to do thi multipl step for you , and no matter so pretti much ani reason program languag that you might be us .
certainli all the top ten most popular program languag will have great linear algebra librari .
and thei'll be good thing ar highli optim in order to do that , matrix matrix multipl veri effici , includ take , take advantag of ani parallel comput that your comput mai be capabl of , when your comput ha multipl call or lot of multipl processor , within a processor sometim there's there's parallel as well call symdiparallel the comput take care of and you should , there ar veri good free librari that you can us to do thi matrix matrix multipl veri effici so that you can veri effici , you know , make lot of predict of lot of hypothes .
matrix multipl is realli us sinc you can pack a lot of comput into just on matrix multipl oper .
but you should be care of how you us them .
in thi video i want to tell you about a few properti of matrix multipl .
when work with just raw number or when work with scalar , multipl is commut .
and what i mean by that is if you take three time five , that is equal to five time three and the order of thi multipl doesn't matter .
and thi is call the commut properti of multipl of real number .
it turn out thi properti that you can , you know , revers the order in which you multipli thing , thi is not true for matrix multipl . so concret , if a and b ar matric , then in gener , a time b is not equal to b time a .
so just be care of that .
it's not okai to arbitrarili revers the order in which you ar multipli matric .
so , we sai that matrix multipl is not commut , it's a fanci wai of sai it .
as a concret exampl , here ar two matric , matrix <num> time <num> , and if you multipli these two matric , you get thi result on the right .
now , let's swap around the order of these two matric .
so , i'm go to take these two matric and just revers them .
it turn out if you multipli these two matric , you get the second answer on the right and , you know , real clearli , these two matric ar not equal to each other .
so , in fact , in gener , if you have a matrix oper like a time b .
if a is an m by n matrix and b is an by m matrix , just as an exampl .
then , it turn out that the matrix a time b right , is go to be an m by m matrix , where as the matrix b x a is go to be an n by n matrix so the dimens don't even match , right , so a time b and b time a mai not even be the same dimens .
in the exampl on the left , i have all two by two matric , so the dimens were the same , but in gener revers the order of the matric can even chang the dimens of the outcom so matrix multipl is not commut .
here's the next i want to talk about .
so , when talk about real number , or scalar , let's see , i have <num> time <num> time <num> .
i can either multipli <num> time <num> first , and i can comput thi as <num> time <num> .
or , i can multipli three time five for us and i can comput thi as , you know fifteen time two and both of these give you the same answer , right ?
each , both of these is equal to thirti so whether i multipli five time two first or whether i multipli three time five first becaus well , three time five time two is equal to three time five time two .
and thi is call the associ properti of role number multipl .
it turn out that matrix multipl is associ .
so concret , let's sai i have a product of three matric , a time b time c .
then i can comput thi either as a time , b time c or i can comput thi as a time b , time c and these will actual give me the same answer .
i'm not go to prove thi , but you can just take my word for it , i guess .
so just be clear what i mean by these two case , let's look at first on first case .
what i mean by that is if you actual want to comput a time b time c , what you can do is you can first comput b time c .
so that d equal b time c , then comput a time d .
and so thi is realli comput a time b time c .
or , for thi second case , you can comput thi as , you can set e equal a time b .
then comput e time c .
and thi is then the same as a time b time c and it turn out that both of these option will give you , is guarante to give you the same answer .
and so we sai that matrix multipl doe enjoi the associ properti .
okai ?
and don't worri about the terminolog associ and commut that's why there's not realli go to us thi terminolog later in these class , so don't worri about memor those term .
final , i want to tell you about the ident matrix , which is special matrix .
so let's again make the analog to what we know of raw number , so when deal with raw number or scalar number , the number on , is you can think of it as the ident of multipl , and what i mean by that is for ani number z , the number <num> time z is equal to z time on , and that's just equal to the number z , right , for ani raw number .
z .
so <num> is the ident oper and so it satisfi thi equat .
so it turn out that in the space of matric as an ident matrix as well .
and it's unusu denot i , or sometim we write it as i of n by n we want to make explicit the dimens .
so i subscript n by n is the n by n ident matrix .
and so there's a differ ident matrix for each dimens n and ar a few exampl .
here's the two by two ident matrix , here's the three by three ident matrix , here's the four by four ident matrix .
so the ident matrix , ha the properti that it ha on along the diagon , right , and so on and is zero everywher els , and so , by the wai the on by on ident matrix is just a number on .
thi is on by on matrix just and it's not a veri interest ident matrix and inform when i or other ar be sloppi , veri often , we will write the ident matrix us fine notat .
i draw , you know , let's go back to it and just write <num> , dot , dot , dot , <num> and then we'll , mayb , somewhat sloppili write a bunch of zero there .
and these zero , thi big zero , thi big zero that's meant to denot that thi matrix is zero everywher except for the diagon , so thi is just how i might sloppili write thi ident matrix she sai properti that for ani matrix a , a time ident i time a a .
so that's a lot like thi equat that we have up here .
on time z equal z time on , equal z itself so i time a equal a time i equal a .
just make sure we have the dimens right , so if a is a n by n matrix , then thi ident matrix that's an m by n ident matrix .
and if a is m by n then thi ident matrix , right , for matrix multipl make sens that ha a m by n matrix becaus thi m ha a match up that m and in either case the outcom of thi process is you get back to matrix a , which is m by n .
so whenev we write the ident matrix i , you know , veri often the dimens rightwil be implicit from the context .
so these two i's thei' re actual differ dimens matric , on mai be n by n , the other is m by m but when we want to make the dimens of the matrix explicit , then sometim we'll write to thi i subscript n by n , kind of like we have up here .
but veri often the dimens will be implicit .
final , just want to point out that earlier i said that a time b is not in gener equal to b time a , right ?
that for most matric a and b , thi is not true .
but when b is the ident matrix , thi doe hold true .
that a time the ident matrix doe inde equal to ident time a , it's just that thi is not true for other matric , b in gener .
so that's it for the properti of matrix multipl .
and the special matric , like the ident matrix i want to tell you about , in the next and final video now linear algebra review .
in thi video , i want to tell you about a coupl of special matrix oper , call the matrix invers and the matrix transpos oper .
let's start by talk about matrix invers , and as usual we'll start by think about how it relat to real number .
in the last video , i said that the number on plai the role of the ident in the space of real number becaus on time anyth is equal to itself .
it turn out that real number have thi properti that veri number have an , that each number ha an invers , for exampl , given the number three , there exist some number , which happen to be three invers so that that number time give you back the ident element on .
and so to me , invers of cours thi is just on third .
and given some other number , mayb twelv there is some number which is the invers of twelv written as twelv to the minu on , or realli thi is just on twelv .
so that when you multipli these two thing togeth .
the product is equal to the ident element on again .
now it turn out that in the space of real number , not everyth ha an invers .
for exampl the number zero doe not have an invers , right ?
becaus zero's a zero invers , on over zero that's undefin .
like thi on over zero is not well defin .
and what we want to do , in the rest of thi slide , is figur out what doe it mean to comput the invers of a matrix .
here's the idea if a is a n by n matrix , and it ha an invers , i will sai a bit more about that later , then the invers is go to be written a to the minu on and a time thi invers , a to the minu on , is go to equal to a invers time a , is go to give us back the ident matrix .
okai ?
onli matric that ar m by m for some the idea of m have invers .
so , a matrix is m by m , thi is also call a squar matrix and it's call squar becaus the number of row is equal to the number of column .
right and it turn out onli squar matric have invers , so a is a squar matrix , is m by m , on invers thi equat over here .
let's look at a concret exampl , so let's sai i have a matrix , three , four , two , sixteen .
so thi is a two by two matrix , so it's a squar matrix and so thi mai just could have an and it turn out that i happen to know the invers of thi matrix is zero point four , minu zero point on , minu zero point zero five , zero zero seven five .
and if i take thi matrix and multipli these togeth it turn out what i get is the two by two ident matrix , i , thi is i two by two .
okai ?
and so on thi slide , you know thi matrix is the matrix a , and thi matrix is the matrix a invers .
and it turn out if that you ar comput a time a invers , it turn out if you comput a invers time a you also get back the ident matrix .
so how did i find thi invers or how did i come up with thi invers over here ?
it turn out that sometim you can comput invers by hand but almost no on doe that these dai .
and it turn out there is veri good numer softwar for take a matrix and comput it invers .
so again , thi is on of those thing where there ar lot of open sourc librari that you can link to from ani of the popular program languag to comput invers of matric .
let me show you a quick exampl .
how i actual comput thi invers , and what i did wa i us softwar call optiv .
so let me bring that up .
we will see a lot about optiv later .
let me just quickli show you an exampl .
set my matrix a to be equal to that matrix on the left , type three four two sixteen , so that's my matrix a right .
thi is matrix <num> , <num> that i have down here on the left .
and , the softwar let me comput the invers of a veri easili .
it's like p over a equal thi .
and so , thi is right , thi matrix here on my four minu , on my on , and so on .
thi given the numer solut to what is the invers of a .
so let me just write , invers of a equal p invers of a over that i can now just verifi that a time a invers the ident is , type a time the invers of a and the result of that is thi matrix and thi is on on on the diagon and essenti ten to the minu seventeen , ten to the minu sixteen , so up to numer precis , up to a littl bit of round off error that my comput had in find optim matric and these number off the diagon ar essenti zero so a time the invers is essenti the ident matrix .
can also verifi the invers of a time a is also equal to the ident , on on the diagon and valu that ar essenti zero except for a littl bit of round dot error on the off diagon .
if a definit that the invers of a matrix is , i had thi caveat first it must alwai be a squar matrix , it had thi caveat , that if a ha an invers , exactli what matric have an invers is beyond the scope of thi linear algebra for review that on intuit you might take awai that just as the number zero doesn't have an invers , it turn out that if a is sai the matrix of all zero , then thi matrix a also doe not have an invers becaus there's no matrix there's no a invers matrix so that thi matrix time some other matrix will give you the ident matrix so thi matrix of all zero , and there ar a few other matric with properti similar to thi .
that also don't have an invers .
but it turn out that in thi review i don't want to go too deepli into what it mean matrix have an invers but it turn out for our machin learn applic thi shouldn't be an issu or more precis for the learn algorithm where thi mai be an to name whether or not an invers matrix appear and i will tell when we get to those learn algorithm just what it mean for an algorithm to have or not have an invers and how to fix it in case .
work with matric that don't have invers .
but the intuit if you want is that you can think of matric as not have an invers that is somehow too close to zero in some sens .
so , just to wrap up the terminolog , matrix that don't have an invers sometim call a singular matrix or degener matrix and so thi matrix over here is an exampl zero zero zero matrix .
is an exampl of a matrix that is singular , or a matrix that is degener .
final , the last special matrix oper i want to tell you about is to do matrix transpos .
so suppos i have matrix a , if i comput the transpos of a , that's what i get here on the right .
thi is a transpos which is written and a superscript t , and the wai you comput the transpos of a matrix is as follow .
to get a transpos i am go to first take the first row of a on to zero .
that becom thi first column of thi transpos .
and then i'm go to take the second row of a , <num> <num> <num> , and that becom the second column .
of the matrix a transpos .
and anoth wai of think about how the comput transpos is as if you're take thi sort of <num> degre axi and you ar mirror or you ar flip the matrix along that <num> degre axi .
so here's the more formal definit of a matrix transpos .
let's sai a is a m by n matrix .
and let's let b equal a transpos and so ba transpos like so .
then b is go to be a n by m matrix with the dimens revers so here we have a 2x3 matrix .
and so the transpos becom a 3x2 matrix , and moreov , the bij is equal to aji .
so the ij element of thi matrix b is go to be the ji element of that earlier matrix a .
so for exampl , b <num> <num> is go to be equal to , look at thi matrix , b <num> <num> is go to be equal to thi element <num> 1st row , 2nd column .
and that equal to thi , which is a two on , second row first column , right , which is equal to two and some of the exampl b <num> <num> , right , that's b <num> <num> is thi element <num> , and that's equal to a two three which is thi element up here , nine .
and so that wrap up the definit of what it mean to take the transpos of a matrix and that in fact conclud our linear algebra review .
so by now hopefulli you know how to add and subtract matric as well as multipli them and you also know how , what ar the definit of the invers and transpos of a matrix and these ar the main oper us in linear algebra for thi cours .
in case thi is the first time you ar see thi materi .
i know thi wa a lot of linear algebra materi all present veri quickli and it's a lot to absorb but if you there's no need to memor all the definit we just went through and if you download the copi of either these slide or of the lectur note from the cours websit .
and us either the slide or the lectur note as a refer then you can alwai refer back to the definit and to figur out what ar these matrix multipl , transpos and so on definit .
and the lectur note on the cours websit also ha pointer to addit resourc linear algebra which you can us to learn more about linear algebra by yourself .
and next with these new tool .
in thi video we will start to talk about a new version of linear regress that's more power .
on that work with multipl variabl or with multipl featur .
here's what i mean .
in the origin version of linear regress that we develop , we have a singl featur x , the size of the hous , and we want to us that to predict why the price of the hous and thi wa our form of our hypothesi .
but now imagin , what if we had not onli the size of the hous as a featur or as a variabl of which to try to predict the price , but that we also knew the number of bedroom , the number of hous and the ag of the home and year .
it seem like thi would give us a lot more inform with which to predict the price .
to introduc a littl bit of notat , we sort of start to talk about thi earlier , i'm go to us the variabl x subscript <num> x subscript <num> and so on to denot my , in thi case , four featur and i'm go to continu to us y to denot the variabl , the output variabl price that we're try to predict .
let's introduc a littl bit more notat .
now that we have four featur i'm go to us lowercas n to denot the number of featur .
so in thi exampl we have n4 becaus we have , you know , on , two , three , four featur .
and n is differ from our earlier notat where we were us n to denot the number of exampl .
so if you have <num> row m is the number of row on thi tabl or the number of train exampl .
so i'm also go to us x superscript i to denot the input featur of the i train exampl .
as a concret exampl let sai x2 is go to be a vector of the featur for my second train exampl .
and so x2 here is go to be a vector <num> , <num> , <num> , <num> sinc those ar my four featur that i have to try to predict the price of the second hous .
so , in thi notat , the superscript <num> here .
that's an index into my train set .
thi is not x to the power of <num> .
instead , thi is , you know , an index that sai look at the second row of thi tabl .
thi refer to my second train exampl .
with thi notat x2 is a four dimension vector .
in fact , more gener , thi is an in dimension featur back there .
with thi notat , x2 is now a vector and so , i'm go to us also xi subscript j to denot the valu of the j , of featur number j and the train exampl .
so concret x2 subscript <num> , will refer to featur number three in the x factor which is equal to <num> , right ?
that wa a <num> over there , just fix my handwrit .
so x<num> subscript <num> is go to be equal to <num> .
now that we have multipl featur , let's talk about what the form of our hypothesi should be .
previous thi wa the form of our hypothesi , where x wa our singl featur , but now that we have multipl featur , we aren't go to us the simpl represent ani more .
instead , a form of the hypothesi in linear regress is go to be thi , can be theta <num> plu theta <num> x<num> plu theta <num> x2 plu theta <num> x<num> plu theta <num> x<num> .
and if we have n featur then rather than sum up over our four featur , we would have a sum over our n featur .
concret for a particular set of our paramet we mai have h of x <num> <num> x1 <num> . <num>1x2 3x3 2x4 .
thi would be on exampl of a hypothesi and you rememb a hypothesi is try to predict the price of the hous in thousand of dollar , just sai that , you know , the base price of a hous is mayb <num> , <num> plu anoth open <num> , so that's an extra , what , hundr dollar per squar feet , yeah , plu the price goe up a littl bit for each addit floor that the hous ha .
x two is the number of floor , and it goe up further for each addit bedroom the hous ha , becaus x three wa the number of bedroom , and the price goe down a littl bit with each addit ag of the hous .
with each addit year of the ag of the hous .
here's the form of a hypothesi rewritten on the slide .
and what i'm gonna do is introduc a littl bit of notat to simplifi thi equat .
for conveni of notat , let me defin x subscript <num> to be equal on .
concret , thi mean that for everi exampl i i have a featur vector x superscript i and x superscript i subscript <num> is go to be equal to <num> .
you can think of thi as defin an addit zero featur .
so wherea previous i had n featur becaus x1 , x2 through xn , i'm now defin an addit sort of zero featur vector that alwai take on the valu of on .
so now my featur vector x becom thi n <num> dimension vector that is zero index .
so thi is now a n <num> dimension featur vector , but i'm gonna index it from <num> and i'm also go to think of my paramet as a vector .
so , our paramet here , right that would be our theta zero , theta on , theta two , and so on all the wai up to theta n , we're go to gather them up into a paramet vector written theta <num> , theta <num> , theta <num> , and so on , down to theta n .
thi is anoth zero index vector .
it's of index sign from zero .
that is anoth n plu <num> dimension vector .
so , my hypothesi cannot be written theta 0x0 plu theta 1x1 up to theta n xn .
and thi equat is the same as thi on top becaus , you know , eight zero is equal to on .
underneath and i now take thi form of the hypothesi and write thi as either transpos x , depend on how familiar you ar with inner product of vector if you write what theta transfer x is what theta transfer and thi is theta zero , theta on , up to theta n .
so thi thing here is theta transpos and thi is actual a n plu on by on matrix .
it's also call a row vector and you take that and multipli it with the vector x which is x zero , x on , and so on , down to x n .
and so , the inner product that is theta transpos x is just equal to thi .
thi give us a conveni wai to write the form of the hypothesi as just the inner product between our paramet vector theta and our theta vector x .
and it is thi littl bit of notat , thi littl excerpt of the notat convent that let us write thi in thi compact form .
so that's the form of a hypthesi when we have multipl featur .
and , just to give thi anoth name , thi is also call multivari linear regress .
and the term multivari that's just mayb a fanci term for sai we have multipl featur , or multivari with which to try to predict the valu y .
in the previou video , we talk about the form of the hypothesi for linear regress with multipl featur or with multipl variabl .
in thi video , let's talk about how to fit the paramet of that hypothesi .
in particular let's talk about how to us gradient descent for linear regress with multipl featur .
to quickli summar our notat , thi is our formal hypothesi in multivari linear regress where we've adopt the convent that x0 <num> .
the paramet of thi model ar theta0 through theta n , but instead of think of thi as n separ paramet , which is valid , i'm instead go to think of the paramet as theta where theta here is a n <num> dimension vector .
so i'm just go to think of the paramet of thi model as itself be a vector .
our cost function is j of theta0 through theta n which is given by thi usual sum of squar of error term .
but again instead of think of j as a function of these n <num> number , i'm go to more commonli write j as just a function of the paramet vector theta so that theta here is a vector .
here's what gradient descent look like .
we're go to repeatedli updat each paramet theta j accord to theta j minu alpha time thi deriv term .
and onc again we just write thi as j of theta , so theta j is updat as theta j minu the learn rate alpha time the deriv , a partial deriv of the cost function with respect to the paramet theta j .
let's see what thi look like when we implement gradient descent and , in particular , let's go see what that partial deriv term look like .
here's what we have for gradient descent for the case of when we had n <num> featur .
we had two separ updat rule for the paramet theta0 and theta1 , and hopefulli these look familiar to you .
and thi term here wa of cours the partial deriv of the cost function with respect to the paramet of theta0 , and similarli we had a differ updat rule for the paramet theta1 .
there's on littl differ which is that when we previous had onli on featur , we would call that featur x i but now in our new notat we would of cours call thi x i <u><num> to denot our on featur . < u> so that wa for when we had onli on featur .
let's look at the new algorithm for we have more than on featur , where the number of featur n mai be much larger than on .
we get thi updat rule for gradient descent and , mayb for those of you that know calculu , if you take the definit of the cost function and take the partial deriv of the cost function j with respect to the paramet theta j , you'll find that that partial deriv is exactli that term that i've drawn the blue box around .
and if you implement thi you will get a work implement of gradient descent for multivari linear regress .
the last thing i want to do on thi slide is give you a sens of why these new and old algorithm ar sort of the same thing or why thei're both similar algorithm or why thei're both gradient descent algorithm .
let's consid a case where we have two featur or mayb more than two featur , so we have three updat rule for the paramet theta0 , theta1 , theta2 and mayb other valu of theta as well .
if you look at the updat rule for theta0 , what you find is that thi updat rule here is the same as the updat rule that we had previous for the case of n <num> .
and the reason that thei ar equival is , of cours , becaus in our notat convent we had thi x i <u><num> <num> convent , which is< u> why these two term that i've drawn the magenta box around ar equival .
similarli , if you look the updat rule for theta1 , you find that thi term here is equival to the term we previous had , or the equat or the updat rule we previous had for theta1 , where of cours we're just us thi new notat x i <u><num> to denot< u> our first featur , and now that we have more than on featur we can have similar updat rule for the other paramet like theta2 and so on .
there's a lot go on on thi slide so i definit encourag you if you need to to paus the video and look at all the math on thi slide slowli to make sure you understand everyth that's go on here .
but if you implement the algorithm written up here then you have a work implement of linear regress with multipl featur .
in thi video and in the video after thi on , i wanna tell you about some of the practic trick for make gradient descent work well .
in thi video , i want to tell you about an idea call featur skill .
here's the idea .
if you have a problem where you have multipl featur , if you make sure that the featur ar on a similar scale , by which i mean make sure that the differ featur take on similar rang of valu , then gradient descent can converg more quickli .
concret let's sai you have a problem with two featur where x1 is the size of hous and take on valu between sai zero to two thousand and two is the number of bedroom , and mayb that take on valu between on and five .
if you plot the contour of the co function j of theta , then the contour mai look like thi , where , let's see , j of theta is a function of paramet theta zero , theta on and theta two .
i'm go to ignor theta zero , so let's about theta <num> and pretend as a function of onli theta <num> and theta <num> , but if x1 can take on them , you know , much larger rang of valu and x2 it turn out that the contour of the caus function j of theta can take on thi veri veri skew ellipt shape , except that with the so <num> to <num> ratio , it can be even more secur .
so , thi is veri , veri tall and skinni ellips , or these veri tall skinni oval , can form the contour of the caus function j of theta .
and if you run gradient descent on thi co function , your gradient mai end up take a long time and can oscil back and forth and take a long time befor it can final find it wai to the global minimum .
in fact , you can imagin if these contour ar exagger even more when you draw incred skinni , tall skinni contour , and it can be even more extrem than , then , gradient descent just have a much harder time take it's wai , meander around , it can take a long time to find thi wai to the global minimum .
in these set , a us thing to do is to scale the featur .
concret if you instead defin the featur x on to be the size of the hous divid by two thousand , and defin x two to be mayb the number of bedroom divid by five , then the count well as of the cost function j can becom much more , much less skew so the contour mai look more like circl .
and if you run gradient descent on a cost function like thi , then gradient descent , you can show mathemat , you can find a much more direct path to the global minimum rather than take a much more convolut path where you're sort of try to follow a much more complic trajectori to get to the global minimum .
so , by scale the featur so that there ar , the consum rang of valu .
in thi exampl , we end up with both featur , x on and x two , between zero and on .
you can wind up with an implement of gradient descent .
thei can convert much faster .
more gener , when we're perform featur scale , what we often want to do is get everi featur into approxim a <num> to <num> rang and concret , your featur x0 is alwai equal to <num> .
so , that's alreadi in that rang , but you mai end up divid other featur by differ number to get them to thi rang .
the number <num> and <num> aren't too import .
so , if you have a featur , x1 that wind up be between zero and three , that's not a problem .
if you end up have a differ featur that wind be between <num> and <num> , again , thi is close enough to minu on and plu on that , you know , that's fine , and that's fine .
it's onli if you have a differ featur , sai x <num> that is between , that rang from <num> tp <num> , then , thi is a veri differ valu than minu <num> and plu <num> .
so , thi might be a less well skill featur and similarli , if your featur take on a veri , veri small rang of valu so if x <num> take on valu between minu <num> . <num> and posit <num> . <num> , then again thi take on a much smaller rang of valu than the minu on to plu on rang .
and again i would consid thi featur poorli scale .
so you want the rang of valu , you know , can be bigger than plu or smaller than plu on , but just not much bigger , like plu <num> here , or too much smaller like <num> . <num> on over there .
differ peopl have differ rule of thumb .
but the on that i us is that if a featur take on the rang of valu from sai minu three the plu <num> how you should think that should be just fine , but mayb it take on much larger valu than plu <num> or minu <num> unless not to worri and if it take on valu from sai minu on third to on third .
you know , i think that's fine too or <num> to on third or minu on third to <num> .
i guess that's typic rang of valu sector <num> okai .
but it will take on a much tinier rang of valu like x4 here than gain on mine not to worri .
so , the take home messag is don't worri if your featur ar not exactli on the same scale or exactli in the same rang of valu .
but so long as thei're all close enough to thi gradient descent it should work okai .
in addit to divid by so that the maximum valu when perform featur scale sometim peopl will also do what's call mean normal .
and what i mean by that is that you want to take a featur xi and replac it with xi minu new i to make your featur have approxim <num> mean .
and obvious we want to appli thi to the futur x zero , becaus the futur x zero is alwai equal to on , so it cannot have an averag valu of zero .
but it concret for other featur if the rang of size of the hous take on valu between <num> to <num> and if you know , the averag size of a hous is equal to <num> then you might us thi formula .
size , set the featur x1 to the size minu the averag valu divid by <num> and similarli , on averag if your hous have on to five bedroom and if on averag a hous ha two bedroom then you might us thi formula to mean normal your second featur x2 .
in both of these case , you therefor wind up with featur x1 and x2 .
thei can take on valu roughli between minu . <num> and posit . <num> .
exactli not true x2 can actual be slightli larger than . <num> but , close enough .
and the more gener rule is that you might take a featur x1 and replac it with x1 minu mu1 over s1 where to defin these term mu1 is the averag valu of x1 in the train set and s1 is the rang of valu of that featur and by rang , i mean let's sai the maximum valu minu the minimum valu or for those of you that understand the deviat of the variabl is set s1 to be the standard deviat of the variabl would be fine , too .
but take , you know , thi max minu min would be fine .
and similarli for the second featur , x2 , you replac x2 with thi sort of subtract the mean of the featur and divid it by the rang of valu mean the max minu min .
and thi sort of formula will get your featur , you know , mayb not exactli , but mayb roughli into these sort of rang , and by the wai , for those of you that ar be super care technic if we're take the rang as max minu min thi five here will actual becom a four .
so if max is <num> minu <num> then the rang of their own valu is actual equal to <num> , but all of these ar approxim and ani valu that get the featur into anyth close to these sort of rang will do fine .
and the featur scale doesn't have to be too exact , in order to get gradient descent to run quit a lot faster .
so , now you know about featur scale and if you appli thi simpl trick , it and make gradient descent run much faster and converg in a lot fewer other iter .
that wa featur scale .
in the next video , i'll tell you about anoth trick to make gradient descent work well in practic .
in thi video , i wanna give you more practic tip for get gradient descent to work .
the idea in thi video will center around the learn rate alpha .
concret , here's the gradient descent updat rule and what i want to do in thi video is tell you about what i think of as debug and some tip for make sure that gradient descent is work correctli and second , i want to tell you how to choos the rate out for , but thi is how i go about choos it .
here's someth that i often do to make sure gradient descent is work correctli .
the job of gradient descent is to find a valu of theta for you that , you know , hopefulli minim the cost function j of theta .
what i often do is therefor pluck the cost function j of theta as gradient descent run .
so , the x axi here is the number of iter of gradient descent and as gradient descent run , you'll hopefulli get a plot that mayb look like thi .
notic that the x axi is a number of iter previous we were look at plot of j of theta where the x axi , where the horizont axi , wa the paramet vector theta but thi is not where thi is .
concret , what thi point is is i'm go to rank gradient descent for hundr iter .
and whatev valu i get for theta after a hundr of the ration and get , you know , some valu of theta after a hundr iter and i'm go to evalu the cost function j of theta for the valu of theta i get after a hundr iter and thi vertic height is the valu of j of theta for the valu of theta i got after a hundr other ratio of gradient descent and thi point here , that correspond to the valu of j of theta for the theta that i get after i've run grade and descent for two hundr iter .
so what thi plot is show , is it's show the valu of your cost function after iter of gradient descent .
and , if gradient descent is work properli , then j of theta should decreas .
after everi iter .
and on us thing that thi sort of plot can tell you also is that if you look at the specif figur that i've drawn , it look like by the time you've gotten out to three hundr iter , between three and four hundr iter , in thi segment , it look like j of theta hasn't gone down much more .
so by the time you get to four hundr iter , it look like thi curv ha flatten out here .
and so , wai out here at four hundr iter , it look like grade and descend ha more or less converg becaus your cost function isn't go down much more .
so look at thi figur can also help you judg whether or not gradient descent ha converg .
by the wai , the number of iter that gradient descent take to converg for a physic applic can vari a lot .
so mayb for on applic gradient descent mai converg after just thirti iter , for a differ applic gradient descent made the <num> , <num> iter .
for anoth learn algorithm it mai take three million iter .
it turn out to be veri difficult to tell in advanc how mani iter gradient descent need to converg , and is usual by plot thi sort of plot .
plot the caus function as we increas the number of iter .
it's usual by look at these plot that i tri to tell if gradient descent ha converg .
it is also possibl to come up with automat converg test ; name to have an algorithm to try to tell you if gradient descent ha converg and here's mayb a pretti typic exampl of an automat converg test and so , you test the clear converg if your caus function jf theta decreas by less than some small valu epsilon , some small valu ten to the minu three in on iter , but i find that usual choos what thi threshold is is pretti difficult .
so , in order to check your gradient descent ha converg , i actual tend to look at plot like like thi figur on the left rather than reli on an automat converg test .
look at thi sort of figur can also tell you or give you an advanc warn if mayb gradient descent is not work correctli .
concret , if you plug jf theta as a function of number of iter , then , if you see a figur like thi , where j of theta is actual increas , then that give you a clear sign that gradient descent is not work .
and a figur like thi usual mean that you should be us smaller learn rate alpha .
if j of theta is actual increas , the most common caus for that is if you're try to minim the function that mayb look like thi .
that's if your learn rate is too big then if you start off there , gradient descent mai overshoot the minimum , send you there , then if onli there's too big , you mai overshoot again , it will send you there and so on so that what you realli want wa realli start here and for to slowli go downhil .
but if the learn is too big then gradient descent can instead keep on over shoot the minimum so that you actual end up get wors and wors instead of get the higher valu of the cost function j of theta so do you end up with a plot like and if you see a plot like thi the fix usual is to just us a smaller valu of alpha .
oh , and also of cours make sure that your code doe not have a bug in it .
but usual to watch it out of the firm is the most common , could be a common problem .
similarli , sometim , you mai also see j of theta do someth like thi and it go down for a while then go up then go down for a while then go up .
go down for a while , it goe up and so on and and to fix for someth like thi is also to us a smaller valu of alpha .
i'm not go to prove it here , but undeni assumpt about the cost function , which doe proof of linear regress .
you can show of mathematician have shown that if your learn rate offer is small enough then j of theta should decreas on everi singl iter .
so , if thi doesn't happen , probabl mean algorithm is too big then you should send a smaller , but of cours , you all so you don't want your learn rate to be too small becaus if you do that , if you were to do that , then gradient descent can be slow to converg .
and if alpha were too small , you might end up start out here , sai , and , you know , end up take just minuscul , minuscul babi step .
right ?
and just take a lot of iter befor you final get to the minimum .
and so , if alpha is too small , gradient descent can make veri slow progress and be slow to converg .
to summar , if the learn rate is too small , you can have a slow converg problem , and if the learn rate is too larg , j of theta mai not decreas on everi iter and mai not even converg .
in some case , if the learn rate is too larg , slow converg is also possibl , but the more common problem you see is that just that j of theta mai not decreas on everi iter .
and in order to debug all of these thing , often plot that j of theta as a function of the number of iter can help you figur out what's go on .
concret , what i actual do when i run gradient descent is i would try a rang of valu .
so just try run gradient descent with a rang of valu for alpha , like <num> . <num> , <num> . <num> , so these ar a factor of <num> differ , and for these differ of thi of alpha , just plot j of theta as a function of number of iter and then pick the valu of alpha that , you know , seem to be caus j of theta to decreas rapidli .
in fact , what i do actual isn't these step of ten .
so , you know , thi is a scale factor of ten if you reach the top .
what i'll actual do is try thi rang of valu and so on where thi is , you know , <num> . <num> then increas the linear rate to <num> to get <num> . <num> and then to step up thi is anoth roughli <num> fold increas point of <num> . <num> to <num> . <num>1s and so these ar roughli , you know , try out gradient descent with each valu i try be about 3x bigger than the previou valu .
so what i'll do is a rang of valu until i've made sure that i've found on valu that is too small and made sure i found on valu that is too larg , and then i sort of try to pick the largest possibl valu or just someth slightli smaller than the largest reason valu that i found .
and when i do that usual it just give me a good learn rate for my problem .
and if you do thi too , hopefulli you will be abl to choos a good learn rate for your implement of gradient descent .
you now know about linear regress with multipl variabl .
in thi video , i wanna tell you a bit about the choic of featur that you have and how you can get differ learn algorithm , sometim veri power on by choos appropri featur .
and in particular i also want to tell you about polynomi regress allow you to us the machineri of linear regress to fit veri complic , even veri non linear function .
let's take the exampl of predict the price of the hous .
suppos you have two featur , the frontag of hous and the depth of the hous .
so , here's the pictur of the hous we're try to sell .
so , the frontag is defin as thi distanc is basic the width or the length of how wide your lot is if thi that you own , and the depth of the hous is how deep your properti is , so there's a frontag , there's a depth .
call frontag and depth .
you might build a linear regress model like thi where frontag is your first featur x1 and and depth is your second featur x2 , but when you're appli linear regress , you don't necessarili have to us just the featur x1 and x2 that you're given .
what you can do is actual creat new featur by yourself .
so , if i want to predict the price of a hous , what i might do instead is decid that what realli determin the size of the hous is the area or the land area that i own .
so , i might creat a new featur .
i'm just gonna call thi featur x which is frontag , time depth .
thi is a multipl symbol .
it's a frontag x depth becaus thi is the land area that i own and i might then select my hypothesi as that us just on featur which is my land area , right ?
becaus the area of a rectangl is you know , the product of the length of the size so , depend on what insight you might have into a particular problem , rather than just take the featur that we happen to have start off with , sometim by defin new featur you might actual get a better model .
close relat to the idea of choos your featur is thi idea call polynomi regress .
let's sai you have a hous price data set that look like thi .
then there ar a few differ model you might fit to thi .
on thing you could do is fit a quadrat model like thi .
it doesn't look like a straight line fit thi data veri well .
so mayb you want to fit a quadrat model like thi where you think the size , where you think the price is a quadrat function and mayb that'll give you , you know , a fit to the data that look like that .
but then you mai decid that your quadrat model doesn't make sens becaus of a quadrat function , eventu thi function come back down and well , we don't think hous price should go down when the size goe up too high .
so then mayb we might choos a differ polynomi model and choos to us instead a cubic function , and where we have now a third order term and we fit that , mayb we get thi sort of model , and mayb the green line is a somewhat better fit to the data caus it doesn't eventu come back down .
so how do we actual fit a model like thi to our data ?
us the machineri of multivari linear regress , we can do thi with a pretti simpl modif to our algorithm .
the form of the hypothesi we , we know how the fit look like thi , where we sai h of x is theta zero plu theta on x on plu x two theta x3 .
and if we want to fit thi cubic model that i have box in green , what we're sai is that to predict the price of a hous , it's theta <num> plu theta <num> time the size of the hous plu theta <num> time the squar size of the hous .
so thi term is equal to that term .
and then plu theta <num> time the cube of the size of the hous rais that third term .
in order to map these two definit to each other , well , the natur wai to do that is to set the first featur x on to be the size of the hous , and set the second featur x two to be the squar of the size of the hous , and set the third featur x three to be the cube of the size of the hous .
and , just by choos my three featur thi wai and appli the machineri of linear regress , i can fit thi model and end up with a cubic fit to my data .
i just want to point out on more thing , which is that if you choos your featur like thi , then featur scale becom increasingli import .
so if the size of the hous rang from on to a thousand , so , you know , from on to a thousand squar feet , sai , then the size squar of the hous will rang from on to on million , the squar of a thousand , and your third featur x cube , excus me you , your third featur x three , which is the size cube of the hous , will rang from on two ten to the nine , and so these three featur take on veri differ rang of valu , and it's import to appli featur scale if you're us gradient descent to get them into compar rang of valu .
final , here's on last exampl of how you realli have broad choic in the featur you us .
earlier we talk about how a quadrat model like thi might not be ideal becaus , you know , mayb a quadrat model fit the data okai , but the quadrat function goe back down and we realli don't want , right , hous price that go down , to predict that , as the size of hous freez .
but rather than go to a cubic model there , you have , mayb , other choic of featur and there ar mani possibl choic .
but just to give you anoth exampl of a reason choic , anoth reason choic might be to sai that the price of a hous is theta zero plu theta on time the size , and then plu theta two time the squar root of the size , right ?
so the squar root function is thi sort of function , and mayb there will be some valu of theta on , theta two , theta three , that will let you take thi model and , for the curv that look like that , and , you know , goe up , but sort of flatten out a bit and doesn't ever come back down .
and , so , by have insight into , in thi case , the shape of a squar root function , and , into the shape of the data , by choos differ featur , you can sometim get better model .
in thi video , we talk about polynomi regress .
that is , how to fit a polynomi , like a quadrat function , or a cubic function , to your data .
wa also throw out thi idea , that you have a choic in what featur to us , such as that instead of us the frontish and the depth of the hous , mayb , you can multipli them togeth to get a featur that captur the land area of a hous .
in case thi seem a littl bit bewild , that with all these differ featur choic , so how do i decid what featur to us .
later in thi class , we'll talk about some algorithm were automat choos what featur ar us , so you can have an algorithm look at the data and automat choos for you whether you want to fit a quadrat function , or a cubic function , or someth els .
but , until we get to those algorithm now i just want you to be awar that you have a choic in what featur to us , and by design differ featur you can fit more complex function your data then just fit a straight line to the data and in particular you can put polynomi function as well and sometim by appropri insight into the featur simpli get a much better model for your data .
in thi video , we'll talk about the normal equat , which for some linear regress problem , will give us a much better wai to solv for the optim valu of the paramet theta .
concret , so far the algorithm that we've been us for linear regress is gradient descent where in order to minim the cost function j of theta , we would take thi iter algorithm that take mani step , multipl iter of gradient descent to converg to the global minimum .
in contrast , the normal equat would give us a method to solv for theta analyt , so that rather than need to run thi iter algorithm , we can instead just solv for the optim valu for theta all at on go , so that in basic on step you get to the optim valu right there .
it turn out the normal equat that ha some advantag and some disadvantag , but befor we get to that and talk about when you should us it , let's get some intuit about what thi method doe .
for thi week's planetari exampl , let's imagin , let's take a veri simplifi cost function j of theta , that's just the function of a real number theta .
so , for now , imagin that theta is just a scalar valu or that theta is just a row valu .
it's just a number , rather than a vector .
imagin that we have a cost function j that's a quadrat function of thi real valu paramet theta , so j of theta look like that .
well , how do you minim a quadrat function ?
for those of you that know a littl bit of calculu , you mai know that the wai to minim a function is to take deriv and to set deriv equal to zero .
so , you take the deriv of j with respect to the paramet of theta .
you get some formula which i am not go to deriv , you set that deriv equal to zero , and thi allow you to solv for the valu of theda that minim j of theta .
that wa a simpler case of when data wa just real number .
in the problem that we ar interest in , theta is no longer just a real number , but , instead , is thi n <num> dimension paramet vector , and , a cost function j is a function of thi vector valu or theta <num> through theta m .
and , a cost function look like thi , some squar cost function on the right .
how do we minim thi cost function j ?
calculu actual tell us that , if you , that on wai to do so , is to take the partial deriv of j , with respect to everi paramet of theta j in turn , and then , to set all of these to <num> .
if you do that , and you solv for the valu of theta <num> , theta <num> , up to theta n , then , thi would give you that valu of theta to minim the cost function j .
where , if you actual work through the calculu and work through the solut to the paramet theta <num> through theta n , the deriv end up be somewhat involv .
and , what i am go to do in thi video , is actual to not go through the deriv , which is kind of long and kind of involv , but what i want to do is just tell you what you need to know in order to implement thi process so you can solv for the valu of the theta that correspond to where the partial deriv is equal to zero .
or altern , or equival , the valu of theta is that minim the cost function j of theta .
i realiz that some of the comment i made that made more sens onli to those of you that ar normal familiar with calculu .
so , but if you don't know , if you're less familiar with calculu , don't worri about it .
i'm just go to tell you what you need to know in order to implement thi algorithm and get it to work .
for the exampl that i want to us as a run exampl let's sai that i have m <num> train exampl .
in order to implement thi normal equat at big , what i'm go to do is the follow .
i'm go to take my data set , so here ar my four train exampl .
in thi case let's assum that , you know , these four exampl is all the data i have .
what i am go to do is take my data set and add an extra column that correspond to my extra featur , x0 , that is alwai take on thi valu of <num> .
what i'm go to do is i'm then go to construct a matrix call x that's a matrix ar basic contain all of the featur from my train data , so complet here is my here ar all my featur and we're go to take all those number and put them into thi matrix x , okai ?
so just , you know , copi the data over on column at a time and then i am go to do someth similar for y's .
i am go to take the valu that i'm try to predict and construct now a vector , like so and call that a vector y .
so x is go to be a m by n <num> dimension matrix , and y is go to be a m dimension vector where m is the number of train exampl and n is , n is a number of featur , n <num> , becaus of thi extra featur x0 that i had .
final if you take your matrix x and you take your vector y , and if you just comput thi , and set theta to be equal to x transpos x invers time x transpos y , thi would give you the valu of theta that minim your cost function .
there wa a lot that happen on the slide and i work through it us on specif exampl of on dataset .
let me just write thi out in a slightli more gener form and then let me just , and later on in thi video let me explain thi equat a littl bit more .
it is not yet entir clear how to do thi .
in a gener case , let us sai we have m train exampl so x1 , y1 up to xn , yn and n featur .
so , each of the train exampl x i mai look like a vector like thi , that is a n <num> dimension featur vector .
the wai i'm go to construct the matrix x , thi is also call the design matrix is as follow .
each train exampl give me a featur vector like thi .
sai , sort of n <num> dimension vector .
the wai i am go to construct my design matrix x is onli construct the matrix like thi .
and what i'm go to do is take the first train exampl , so that's a vector , take it transpos so it end up be thi , you know , long flat thing and make x1 transpos the first row of my design matrix .
then i am go to take my second train exampl , x2 , take the transpos of that and put that as the second row of x and so on , down until my last train exampl .
take the transpos of that , and that's my last row of my matrix x .
and , so , that make my matrix x , an m by n <num> dimension matrix .
as a concret exampl , let's sai i have onli on featur , realli , onli on featur other than x zero , which is alwai equal to <num> .
so if my featur vector x i ar equal to thi <num> , which is x <num> , then some real featur , like mayb the size of the hous , then my design matrix , x , would be equal to thi .
for the first row , i'm go to basic take thi and take it transpos .
so , i'm go to end up with <num> , and then x <num> <num> .
for the second row , we're go to end up with <num> and then x <num> <num> and so on down to <num> , and then x <num> m .
and thu , thi will be a m by <num> dimension matrix .
so , that's how to construct the matrix x .
and , the vector y sometim i might write an arrow on top to denot that it is a vector , but veri often i'll just write thi as y , either wai .
the vector y is obtain by take all all the label , all the correct price of hous in my train set , and just stack them up into an m dimension vector , and that's y .
final , have construct the matrix x and the vector y , we then just comput theta as x' <num> x x x'y .
i just want to make i just want to make sure that thi equat make sens to you and that you know how to implement it .
so , you know , concret , what is thi x' <num> x ?
well , x' <num> x is the invers of the matrix x'x .
concret , if you were to sai set a to be equal to x' x x , so x' is a matrix , x' x x give you anoth matrix , and we call that matrix a .
then , you know , x' <num> x is just you take thi matrix a and you invert it , right !
thi give , let's sai <num> a .
and so that's how you comput thi thing .
you comput x'x and then you comput it invers .
we haven't yet talk about octav .
we'll do so in the later set of video , but in the octav program languag or a similar view , and also the matlab program languag is veri similar .
the command to comput thi quantiti , x transpos x invers time x transpos y , is as follow .
in octav x prime is the notat that you us to denot x transpos .
and so , thi express that's box in red , that's comput x transpos time x .
pinv is a function for comput the invers of a matrix , so thi comput x transpos x invers , and then you multipli that by x transpos , and you multipli that by y .
so you end comput that formula which i didn't prove , but it is possibl to show mathemat even though i'm not go to do so here , that thi formula give you the optim valu of theta in the sens that if you set theta equal to thi , that's the valu of theta that minim the cost function j of theta for the new regress .
on last detail in the earlier video .
i talk about the featur skill and the idea of get featur to be on similar rang of scale of similar rang of valu of each other .
if you ar us thi normal equat method then featur scale isn't actual necessari and is actual okai if , sai , some featur x on is between zero and on , and some featur x two is between rang from zero to on thousand and some featur x three rang from zero to ten to the minu five and if you ar us the normal equat method thi is okai and there is no need to do featur scale , although of cours if you ar us gradient descent , then , featur scale is still import .
final , where should you us the gradient descent and when should you us the normal equat method .
here ar some of the their advantag and disadvantag .
let's sai you have m train exampl and n featur .
on disadvantag of gradient descent is that , you need to choos the learn rate alpha .
and , often , thi mean run it few time with differ learn rate alpha and then see what work best .
and so that is sort of extra work and extra hassl .
anoth disadvantag with gradient descent is it need mani more iter .
so , depend on the detail , that could make it slower , although there's more to the stori as we'll see in a second .
as for the normal equat , you don't need to choos ani learn rate alpha .
so that , you know , make it realli conveni , make it simpl to implement .
you just run it and it usual just work .
and you don't need to iter , so , you don't need to plot j of theta or check the converg or take all those extra step .
so far , the balanc seem to favor normal the normal equat .
here ar some disadvantag of the normal equat , and some advantag of gradient descent .
gradient descent work pretti well , even when you have a veri larg number of featur .
so , even if you have million of featur you can run gradient descent and it will be reason effici .
it will do someth reason .
in contrast to normal equat , in , in order to solv for the paramet data , we need to solv for thi term .
we need to comput thi term , x transpos , x invers .
thi matrix x transpos x .
that's an n by n matrix , if you have n featur .
becaus , if you look at the dimens of x transpos the dimens of x , you multipli , figur out what the dimens of the product is , the matrix x transpos x is an n by n matrix where n is the number of featur , and for almost comput implement the cost of invert the matrix , rose roughli as the cube of the dimens of the matrix .
so , comput thi invers cost , roughli order , and cube time .
sometim , it's slightli faster than n cube but , it's , you know , close enough for our purpos .
so if n the number of featur is veri larg , then comput thi quantiti can be slow and the normal equat method can actual be much slower .
so if n is larg then i might usual us gradient descent becaus we don't want to pai thi all in q time .
but , if n is rel small , then the normal equat might give you a better wai to solv the paramet .
what doe small and larg mean ?
well , if n is on the order of a hundr , then invert a hundr by hundr matrix is no problem by modern comput standard .
if n is a thousand , i would still us the normal equat method .
invert a thousand by thousand matrix is actual realli fast on a modern comput .
if n is ten thousand , then i might start to wonder .
invert a ten thousand by ten thousand matrix start to get kind of slow , and i might then start to mayb lean in the direct of gradient descent , but mayb not quit .
n equal ten thousand , you can sort of convert a ten thousand by ten thousand matrix .
but if it get much bigger than that , then , i would probabl us gradient descent .
so , if n equal ten to the sixth with a million featur , then invert a million by million matrix is go to be veri expens , and i would definit favor gradient descent if you have that mani featur .
so exactli how larg set of featur ha to be befor you convert a gradient descent , it's hard to give a strict number .
but , for me , it is usual around ten thousand that i might start to consid switch over to gradient descent or mayb , some other algorithm that we'll talk about later in thi class .
to summar , so long as the number of featur is not too larg , the normal equat give us a great altern method to solv for the paramet theta .
concret , so long as the number of featur is less than <num> , you know , i would us , i would usual is us in normal equat method rather than , gradient descent .
to preview some idea that we'll talk about later in thi cours , as we get to the more complex learn algorithm , for exampl , when we talk about classif algorithm , like a logist regress algorithm , we'll see that those algorithm actual . . .
the normal equat method actual do not work for those more sophist learn algorithm , and , we will have to resort to gradient descent for those algorithm .
so , gradient descent is a veri us algorithm to know .
the linear regress will have a larg number of featur and for some of the other algorithm that we'll see in thi cours , becaus , for them , the normal equat method just doesn't appli and doesn't work .
but for thi specif model of linear regress , the normal equat can give you a altern that can be much faster , than gradient descent .
so , depend on the detail of your algortithm , depend of the detail of the problem and how mani featur that you have , both of these algorithm ar well worth know about .
in thi video , i want to talk about the normal equat and non invert .
thi is a somewhat more advanc concept , but it is someth that i've often been ask about .
and so i want to talk about it here .
but thi is a somewhat more advanc concept , so feel free to consid thi option materi there's a phenomenon that you mai run into that's mayb for some of you us to understand .
but even if you don't understand it , the normal equat and linear regress , you should realli get that to work okai .
here's the issu for those of you that ar mayb somewhat more familar with linear algebra , what some student have ask me is , when comput thi theta equal x<u>transpos x <u>invers x<u>transpos y< u>< u>< u> what if the matrix x<u>transpos x is non invert ? < u> so , for those of you that know a bit more linear algebra you mai know that onli some matric ar invert and some matric do not have an invers we call those non invert matric , singular or degener matric .
the issu or the problem of x<u>tranpos x be non invert< u> should happen pretti rare .
and in octav , if you implement thi to comput theta , it turn out that thi will actual do the right thing .
i'm get a littl bit technic now and i don't want to go into detail , but octav ha two function for invert matric on is call pinv , and the other is call inv .
the differ between these two ar somewhat technic .
on's call the pseudo invers , on's call the invers .
you can show mathem so as long as you us the pinv function , then thi will actual comput the valu of theta that you want , even if x<u>transpos x is non invert . < u> the specif detail between what is the differ between pinv and what is inv that is somewhat advanc numer comput concept , that i don't realli want to get into .
but i thought in thi option video i try to give you a littl bit of intuit about what it mean that x<u>transpos x to be non invert . < u> for those of you that know a bit more linear algebra and might be interest .
i'm not go to proov thi mathemat , but if x<u>transpos x is non invert , < u> there ar usual two most common caus the first caus is if somehow , in your learn problem , you have redund featur , concret , if you try to predict hous price and if x<u><num> is the size of a hous in squar feet , < u> and x<u><num> is the size of the hous in squar meter , < u> then , you know , <num> meter is equal to <num> . <num> feet , round to two decim , and so your two featur will alwai satisfi the constraint that x<u><num> equal <num> . <num> <num> time x<u><num> . < u>< u> and you can show , for those of you thi is somehwat advanc linear algebra now , but if you're an expert in linear algebra , you can actual show that if your two featur ar relat via a linear equat like thi , then matrix x<u>transpos x will be non invert . < u> the second thing that can caus x<u>transpos x to be non invert< u> is if you're try to run a learn algorithm with a <i>lot< i> of a featur .
concret , if m is less than or equal to n .
for exampl , if you imagin that you have m equal <num> train exampl and that you have n equal <num> featur , then you're try to fit a paramet vector theta , which is n <num> dimension , so it's a <num> dimension you're try to fit a <num> paramet from just <num> train exampl .
and thi turn out to sometim work , but to not alwai be a good idea .
becaus , as we see later , you might not have enough data if you onli have <num> exampl to fit <num> or <num> paramet .
we'll see later in thi cours , why thi might be too littl data to fit thi mani paramet .
but commonli , what we do then if m is less than n , is to see if we can either delet some featur or to us a techniqu call regular , which is someth that we will talk about a bit later in thi cours as well , that will kind of let you fit a <i>lot< i> of paramet us a <i>lot< i> of featur even if you have a rel small train set .
but thi regular will be a later topic in thi cours .
but to summar , if ever you find that x<u>transpos x is singular< u> or altern find is non invert , what i would recommend you do is first look at your featur and see if you have redund featur like these x<u><num> and x<u><num> be linearli depend , < u>< u> or be a linear function of each other , like so and if you do have redund featur and if you just delet on of these featur you realli don't need both of these featur , so if you just delet on of these featur that will solv your non invert problem and , so first think through my featur and check if ani ar redund and if so , then , you know , keep delet the redund featur until thei ar no longer redund .
and if your featur ar non redund , i would check if i might have too mani featur , and if that's the case i would either delet some featur if i can bare to us fewer featur , or els i would consid us regular , which is thi topic that we will talk about later .
so , that's it for the normal equat and what it mean if the matrix x<u>transpos x is non invert . < u> but thi is a problem that hopefulli you run into pretti rare .
and if you just implement it in octav us the pinv function which is call the pseudo invers function so you us a differ linear algebra librari , that is call pseudo invers but that implement should just do the right thing even if x<u>transpos x is non invert< u> which should happen pretti rarili anywai so thi should not be a problem for most implement of linear regress .
you now know a bunch about machin learn .
in thi video , i like to teach you a program languag , octav , in which you'll be abl to veri quickli implement the the learn algorithm we've seen alreadi , and the learn algorithm we'll see later in thi cours .
in the past , i've tri to teach machin learn us a larg varieti of differ program languag includ c java , python , numpi , and also octav , and what i found wa that student were abl to learn the most product learn the most quickli and prototyp your algorithm most quickli us a rel high level languag like octav .
in fact , what i often see in silicon vallei is that if even if you need to build .
if you want to build a larg scale deploy of a learn algorithm , what peopl will often do is prototyp and the languag is octav .
which is a great prototyp languag .
so you can sort of get your learn algorithm work quickli .
and then onli if you need to a veri larg scale deploy of it .
onli then spend your time re implement the algorithm to c java or some of the languag like that .
becaus all the lesson we've learn is that a time or develop a time .
that is your time .
the machin learn's time is incred valuabl .
and if you can get your learn algorithm to work more quickli in octav .
then overal you have a huge time save by first develop the algorithm in octav , and then implement and mayb c java , onli after we have the idea work .
the most common prototyp languag i see peopl us for machin learn ar octav , matlab , python , numpi , and r .
octav is nice becaus open sourc .
and matlab work well too , but it is expens for to mani peopl .
but if you have access to a copi of matlab .
you can also us matlab with thi class .
if you know python , numpi , or if you know r .
i do see some peopl us it .
but , what i see is that peopl usual end up develop somewhat more slowli , and you know , these languag .
becaus the python , numpi syntax is just slightli clunkier than the octav syntax .
and so becaus of that , and becaus we ar releas starter code in octav .
i strongli recommend that you not try to do the follow exercis in thi class in numpi and r .
but that i do recommend that you instead do the program exercis for thi class in octav instead .
what i'm go to do in thi video is go through a list of command veri , veri quickli , and it goal is to quickli show you the rang of command and the rang of thing you can do in octav .
the cours websit will have a transcript of everyth i do , and so after watch thi video you can refer to the transcript post on the cours websit when you want find a command .
concret , what i recommend you do is first watch the tutori video .
and after watch to the end , then instal octav on your comput .
and final , it goe to the cours websit , download the transcript of the thing you see in the session , and type in whatev command seem interest to you into octav , so that it's run on your own comput , so you can see it run for yourself .
and with that let's get start .
here's my window desktop , and i'm go to start up octav .
and i'm now in octav .
and that's my octav prompt .
let me first show the elementari oper you can do in octav .
so you type in <num> <num> .
that give you the answer of <num> .
<num> <num> .
<num> x <num> , <num> <num> , <num> <num> is <num> .
so those ar the elementari math oper .
you can also do logic oper .
so on equal two .
thi evalu to fals .
the percent command here mean a comment .
so , on equal two , evalu to fals .
which is repres by zero .
on not equal to two .
thi is true .
so that return on .
note that a not equal sign is thi tild equal symbol .
and not bang equal .
which is what some other program languag us .
let see logic oper on and zero us a doubl ampersand sign to the logic and .
and that evalu fals .
on or zero is the or oper .
and that evalu to true .
and i can xor on and zero , and that evalu to on .
thi thing over on the left , thi octav <num> . x equal <num> , thi is the default octav prompt .
it show the , what , the version in octav and so on .
if you don't want that prompt , there's a somewhat cryptic command pf quot , greater than , greater than and so on , that you can us to chang the prompt .
and i guess thi quot a string in the middl .
your quot , greater than , greater than , space .
that's what i prefer my octav prompt to look like .
so if i hit enter .
oop , excus me .
like so .
ps1 like so .
now my octav prompt ha chang to the greater than , greater than sign . which , you know , look quit a bit better .
next let's talk about octav variabl .
i can take the variabl a and assign it to <num> .
and hit enter .
and now a is equal to <num> .
you want to assign a variabl , but you don't want to print out the result .
if you put a semicolon , the semicolon suppress the print output .
so to do that , enter , it doesn't print anyth .
wherea a equal <num> .
mix it , print it out , where a equal , <num> semicolon doesn't print anyth .
i can do string assign .
b equal hi now if i just enter b it print out the variabl b .
so b is the string hi c equal <num> greater than colon <num> .
so , now c evalu the true .
if you want to print out or displai a variabl , here's how you go about it .
let me set a equal pi  .
and if i want to print a i can just type a like so , and it will print it out .
for more complex print there is also the disp command which stand for displai .
displai a just print out a like so .
you can also displai string so disp , sprintf , two decim , percent <num> , f , comma , a .
like so .
and thi will print out the string .
two decim , colon , <num> . <num> .
thi is kind of an old style c syntax .
for those of you that have program c befor , thi is essenti the syntax you us to print screen .
so the sprintf gener a string that is less than the <num> decim , <num> plu string .
thi percent <num> f mean substitut a into here , show the two digit after the decim point .
and disp take the string disp gener it by the sprintf command .
sprintf .
the sprintf command .
and disp actual displai the string .
and to show you anoth exampl , sprintf six decim percent <num> f comma a .
and , thi should print pi  with six decim place .
final , i wa sai , a like so , look like thi .
there ar us shortcut that type type format long .
it caus string by default .
be displai to a lot more decim place .
and format short is a command that restor the default of just print a small number of digit .
okai , that's how you work with variabl .
now let's look at vector and matric .
let's sai i want to assign mat a to the matrix .
let me show you an exampl <num> , <num> , semicolon , <num> , <num> , semicolon , <num> , <num> .
thi gener a three by two matrix a whose first row is <num> , <num> .
second row <num> , <num> .
third row is <num> , <num> .
what the semicolon doe is essenti sai , go to the next row of the matrix .
there ar other wai to type thi in .
type a <num> , <num> semicolon <num> , <num> , semicolon , <num> , <num> , like so .
and that's anoth equival wai of assign a to be the valu of thi three by two matrix .
similarli you can assign vector .
so v equal <num> , <num> , <num> .
thi is actual a row vector .
or thi is a <num> by <num> vector .
where that is a fat y vector , excus me , not , thi is a <num> by <num> matrix , right .
not <num> by <num> .
if i want to assign thi to a column vector , what i would do instead is do v <num> ; <num> ; <num> .
and thi will give me a <num> by <num> .
there's a <num> by <num> vector .
so thi will be a column vector .
here's some more us notat .
v equal <num> <num> <num> .
what thi doe is it set v to the bunch of element that start from <num> .
and increment and step of <num> until you get up to <num> .
so if i do thi , v is go to be thi , you know , row vector .
thi is what on by eleven matrix realli .
that's <num> , <num> , <num> , <num> and so on until we get up to two .
now , and i can also set v equal on colon six , and that set v to be these number .
<num> through <num> , okai .
now here ar some other wai to gener matric .
on <num> is a command that gener a matrix that is a two by three matrix that is the matrix of all on .
so if i set that c2 time on two by three thi gener a two by three matrix that is all two's .
you can think of thi as a shorter wai of write thi and c<num> , <num> , <num>'s and you can call them <num> , <num> , <num> , which would also give you the same result .
let's sai w equal on's , on by three , so thi is go to be a row vector or a row of three on's and similarli you can also sai w equal zero , on by three , and thi gener a matrix .
a on by three matrix of all zero .
just a coupl more wai to gener matric .
if i do w equal rand on by three , thi give me a on by three matrix of all random number .
if i do rand three by three .
thi give me a three by three matrix of all random number drawn from the uniform distribut between zero and on .
so everi time i do thi , i get a differ set of random number drawn uniformli between zero and on .
for those of you that know what a gaussian random variabl is or for those of you that know what a normal random variabl is , you can also set w equal rand n , on by three .
and so these ar go to be three valu drawn from a gaussian distribut with mean zero and varianc or standard deviat equal to on .
and you can set more complex thing like w equal minu six , plu the squar root ten , time , let sai rand n , on by ten thousand .
and i'm go to put a semicolon at the end becaus i don't realli want thi print out .
thi is go to be a what ?
well , it's go to be a vector of , with a hundr thousand , excus me , ten thousand element .
so , well , actual , you know what ?
let's print it out .
so thi will gener a matrix like thi .
right ?
with <num> , <num> element .
so that's what w is .
and if i now plot a histogram of w with a hist command , i can now .
and octav's print hist command , you know , take a coupl second to bring thi up , but thi is a histogram of my random variabl for w .
there wa minu <num> plu zero ten time thi gaussian random variabl .
and i can plot a histogram with more bucket , with more bin , with sai , <num> bin .
and thi is my histogram of a gaussian with mean minu <num> .
becaus i have a minu <num> there plu squar root <num> time thi .
so the varianc of thi gaussian random variabl is <num> on the standard deviat is squar root of <num> , which is about what ?
three point on .
final , on special command for gener matrix , which is the i command .
so i stand for thi is mayb a pun on the word ident .
it's server set ey <num> .
thi is the <num> by <num> ident matrix .
so i equal ey <num> .
thi give me a <num> by <num> ident matrix .
and i equal ey <num> , ey <num> .
that give me a <num> by <num> ident matrix , i3 is the <num> by <num> ident matrix .
lastli , to wrap up thi video , there's on more us command .
which is the help command .
so you can type help i and thi bring up the help function for the ident matrix .
hit q to quit .
and you can also type help rand .
bring up document for the rand or the random number gener function .
or even help help , which show you , you know help on the help function .
so , those ar the basic oper in octav .
and with thi you should be abl to gener a few matric , multipli , add thing .
and us the basic oper in octav .
in the next video , i'd like to start talk about more sophist command and how to us data around and start to process data in octav .
in thi second tutori video on octav , i'd like to start to tell you how to move data around in octav .
so , if you have data for a machin learn problem , how do you load that data in octav ?
how do you put it into matrix ?
how do you manipul these matric ?
how do you save the result ?
how do you move data around and oper with data ?
here's my octav window as befor , pick up from where we left off in the last video .
if i type a , that's the matrix so we gener it , right , with thi command equal on , two , three , four , five , six , and thi is a three by two matrix .
the size command in octav let you , tell you what is the size of a matrix .
so size a return three , two .
it turn out that thi size command itself is actual return a on by two matrix .
so you can actual set sz equal size of a and sz is now a on by two matrix where the first element of thi is three , and the second element of thi is two .
so , if you just type size of sz .
doe sz is a on by two matrix whose two element contain the dimens of the matrix a .
you can also type size a on to give you back the first dimens of a , size of the first dimens of a .
so that's the number of row and size a two to give you back two , which is the number of column in the matrix a .
if you have a vector v , so let's sai v equal on , two , three , four , and you type length v .
what thi doe is it give you the size of the longest dimens .
so you can also type length a and becaus a is a three by two matrix , the longer dimens is of size three , so thi should print out three .
but usual we appli length onli to vector .
so you know , length on , two , three , four , five , rather than appli length to matric becaus that's a littl more confus .
now , let's look at how the load data and find data on the file system .
when we start an octav we're usual , we're often in a path that is , you know , the locat of where the octav locat is .
so the pwd command show the current directori , or the current path that octav is in .
so right now we're in thi mayb somewhat off scale directori .
the cd command stand for chang directori , so i can go to c user ang desktop , and now i'm in , you know , in my desktop and if i type ls , ls is , it come from a unix or a linux command .
but , ls will list the directori on my desktop and so these ar the file that ar on my desktop right now .
in fact , on my desktop ar two file featur x and price y that's mayb come from a machin learn problem i want to solv .
so , here's my desktop .
here's featur x , and featur x is thi window , excus me , is thi file with two column of data .
thi is actual my hous price data .
so i think , you know , i think i have forti seven row in thi data set .
and so the first hous ha size two hundr four squar feet , ha three bedroom ; second hous ha sixteen hundr squar feet , ha three bedroom ; and so on .
and price y is thi file that ha the price of the data in my train set .
so , featur x and price y ar just text file with my data .
how do i load thi data into octav ?
well , i just type the command load featur x dot dat and if i do that , i load the featur x and can load price y dot dat .
and by the wai , there ar multipl wai to do thi .
thi command if you put featur x dot dat on that in string and load it like so .
thi is a typo there .
thi is an equival command .
so you can , thi wai i'm just put the file name of the string in the found in a string and in an octav us singl quot to repres string , like so .
so that's a string , and we can load the file whose name is given by that string .
now the who command now show me what variabl i have in my octav workspac .
so who show me whether the variabl that octav ha in memori current .
featur x and price y ar among them , as well as the variabl that , you know , we creat earlier in thi session .
so i can type featur x to displai featur x .
and there's my data .
and i can type size featur x and that's my <num> by two matrix .
and some of these size , press y , that give me my <num> by on vector .
thi is a <num> dimension vector .
thi is all common vector that ha all the price y in my train set .
now the who function show you on of the variabl that , in the current workspac .
there's also the who s variabl that give you the detail view .
and so thi also , with an s at the end thi also list my variabl except that it now list the size as well .
so a is a three by two matrix and featur x as a <num> by <num> matrix .
price y is a <num> by on matrix .
mean thi is just a vector .
and it show , you know , how mani byte of memori it's take up .
as well as what type of data thi is .
doubl mean doubl posit float point so that just mean that these ar real valu , the float point number .
now if you want to get rid of a variabl you can us the clear command .
so clear featur x and type whose again .
you notic that the featur x variabl ha now disappear .
and how do we save data ?
let's see .
let's take the variabl v and sai that it's a price y <num> colon <num> .
thi set v to be the first <num> element of vector y .
so let's type who or whose .
wherea y wa a <num> by <num> vector .
v is now <num> by <num> .
b equal price y , on column ten that set it to the just the first ten element of y .
let's sai i wanna save thi to date to disc the command save , hello . mat v .
thi will save the variabl v into a file call hello . mat .
so let's do that .
and now a file ha appear on my desktop , you know , call hello . mat .
i happen to have matlab instal in thi window , which is why , you know , thi icon look like thi becaus window is recogn as it's a matlab file , but don't worri about it if thi file look like it ha a differ icon on your machin and let's sai i clear all my variabl .
so , if you type clear without anyth then thi actual delet all of the variabl in your workspac .
so there's now noth left in the workspac .
and if i load hello . mat , i can now load back my variabl v , which is the data that i previous save into the hello . mat file .
so , hello . mat , what we did just now to save hello . mat to view , thi save the data in a binari format , a somewhat more compress binari format .
so if v is a lot of data , thi , you know , will be somewhat more compress .
will take off less the space .
if you want to save your data in a human readabl format then you type save hello . text the variabl v and then ascii .
so , thi will save it as a text or as ascii format of text .
and now , onc i've done that , i have thi file .
hello . text ha just appear on my desktop , and if i open thi up , we see that thi is a text file with my data save awai .
so that's how you load and save data .
now let's talk a bit about how to manipul data .
let's set a equal to that matrix again so is my three by two matrix .
so as index .
so type a <num> , <num> .
thi index into the <num> , <num> element of the matrix a .
so , thi is what , you know , in normal , we will write thi as a subscript <num> , <num> or a subscript , you know , <num> , <num> and so that's the element and third row and second column of a which is the element of six .
i can also type a to comma colon to fetch everyth in the second row .
so , the colon mean everi element along that row or column .
so , a of <num> comma colon is thi second row of a .
right .
and similarli , if i do a colon comma <num> then thi mean get everyth in the second column of a .
so , thi give me <num> <num> <num> .
right thi mean of a .
everyth , second column .
so , thi is my second column a , which is <num> <num> <num> .
now , you can also us somewhat most of the sophist index in the oper .
so so , we just click each of an exampl .
you do thi mayb less often , but let me do thi a <num> <num> comma colon .
thi mean get all of the element of a who's first index on or three .
thi mean i get everyth from the first and third row of a and from all column .
so , thi wa the matrix a and so a <num> <num> comma colon mean get everyth from the first row and from the second row and from the third row and the colon mean , you know , on both of first and the second column and so thi give me thi <num> <num> <num> <num> .
although , you us the sourc of more subscript index oper mayb somewhat less often .
to show you what els we can do .
here's the a matrix and thi sourc a colon , to give me the second column .
you can also us thi to do assign .
so i can take the second column of a and assign that to <num> , <num> , <num> , and if i do that i'm now , you know , take the second column of a and i'm assign thi column vector <num> , <num> , <num> to it .
so , now a is thi matrix that's <num> , <num> , <num> .
and the second column ha been replac by <num> , <num> , <num> .
and here's anoth oper .
let's set a to be equal to a comma <num> , <num> , <num> like so and what thi will do is depend anoth column vector to the right .
so , now , oop .
i think i made a littl mistak .
should have put semicolon there and now a is equal to thi .
okai ?
i hope that make sens .
so thi <num> , <num> , <num> .
thi is a column vector and what we did wa we set a , take a and set it to the origin definit .
and then we put that column vector to the right and so , we end up take the matrix a and which wa these six element on the left .
so we took matrix a and we append anoth column vector to the right ; which is now why a is a three by three matrix that look like that .
and final , on neat trick that i sometim us if you do just a and just a colon like so .
thi is a somewhat special case syntax .
what thi mean is that put all element with a into a singl column vector and thi give me a <num> by <num> vector .
thei adjust the other on ar combin togeth .
just a coupl more exampl .
let's see .
let's sai i set a to be equal to <num> , okai ?
and let's sai i set a b to b equal to <num> , <num> , <num> , <num> , <num> , <num> .
i can creat a new matrix c as a b .
thi just mean my matrix a .
here's my matrix b and i've set c to be equal to ab .
what i'm do is i'm take these two matric and just concaten onto each other .
so the left , matrix a on the left .
and i have the matrix b on the right .
and that's how i form thi matrix c by put them togeth .
i can also do c equal a semicolon b .
the semi colon notat mean that i go put the next thing at the bottom .
so , i'll do is a equal semicolon b .
it also put the matric a and b togeth except that it now put them on top of each other .
so now i have a on top and b at the bottom and c here is now in <num> by <num> matrix .
so , just sai the semicolon thing usual mean , you know , go to the next line .
so , c is compris by a and then go to the bottom of that and then put b in the bottom and by the wai , thi a b is the same as a , b and so you know , either of these give you the same result .
so , with that , hopefulli you now know how to construct matric and hopefulli start to show you some of the command that you us to quickli put togeth matric and take matric and , you know , slam them togeth to form bigger matric , and with just a few line of code , octav is veri conveni in term of how quickli we can assembl complex matric and move data around .
so that's it for move data around .
in the next video we'll start to talk about how to actual do complex comput on thi , on our data .
so , hopefulli that give you a sens of how , with just a few command , you can veri quickli move data around in octav .
you know , you load and save vector and matric , load and save data , put togeth matric to creat bigger matric , index into or select specif element on the matric .
i know i went through a lot of command , so i think the best thing for you to do is afterward , to look at the transcript of the thing i wa type .
you know , look at it .
look at the coursework site and download the transcript of the session from there and look through the transcript and type some of those command into octav yourself and start to plai with these command and get it to work .
and obvious , you know , there's no point at all to try to memor all these command .
it's just , but what you should do is , hopefulli from thi video you have gotten a sens of the sort of thing you can do .
so that when later on when you ar try to program a learn algorithm yourself , if you ar try to find a specif command that mayb you think octav can do becaus you think you might have seen it here , you should refer to the transcript of the session and look through that in order to find the command you wanna us .
so , that's it for move data around and in the next video what i'd like to do is start to tell you how to actual do complex comput on our data , and how to comput on the data , and actual start to implement learn algorithm .
now that you know how to load and save data in octav , put your data into matric and so on .
in thi video i'd like to show you how to do comput oper on data and later on we'll be us thi sort of comput oper to implement our learn algorithm .
let's get start .
here's my octav window .
let me just quickli initi some variabl to us for exampl and set a to be a <num> by <num> matrix .
and set b to a <num> by <num> matrix and let's set c to a <num> by <num> matrix , like so .
now , let's sai i want to multipli <num> of my matric .
so , let's sai i wanna comput axc .
i just type axc .
so , it's a <num> by <num> matrix time a <num> by <num> matrix .
thi give me thi <num> by <num> matrix .
you can also do element wise oper and do a . xb and what thi would do is thei'll take each element of a and multipli it by the correspond element of b .
so , that's a , that's b , that's a . xb .
so , for exampl , the first element give <num> time <num> which give <num> .
the second element give <num> x <num> which give <num> and so on .
so it is the element wise multipl of two matric , and in gener the p rand tend to , it's usual us , to denot element wise oper in octav .
so , here's a matrix a and i'll do a dot carri <num> .
thi give me the multi , the element wise squar of a , so <num> squar is <num> , <num> squar is <num> and so on .
let's set v to a vector , we'll set v as <num> as a column vector .
you can also do <num> .
over v to do the element wise reciproc of v so thi give me on over on , on over two and on over three .
thi work too for matric so on dot over a , give me that element wise invers of a .
and onc again the p radian give us a clue that thi is an element wise oper .
to also do thing like log v thi is an element wise logarithm of , the v , e to the v , is the base e exponenti of these element of thi is e , thi is e squar eq , thi is v .
and i can also do app v to take the element wise absolut valu of v .
so here , v wa all posit , ab , sai minu <num> to minu <num> , the element wise absolut valu give me back these non neg valu and neg v give me the minu of v .
thi is the same as 1xv but usual you just write neg v and so that neg 1xv and what els can you do ?
here's anoth neat trick .
so let's see .
let's sai i want to take v and increment each of these element by <num> .
well , on wai to do it is by construct a <num> by <num> vector thi all on and ad that to v .
so , thei do that .
thi increment v by for <num> to <num> .
the wai i did that wa length of v , is three .
so on , length of v by on , thi is on of three by on .
so that's on , three by on .
on the right and what i did wa b plu on , v by on , which is ad thi vector of all on to b .
and so thi increment v by on .
and you , anoth simpler wai to do that is to type v on , right ?
so that's v and v on also mean to add on element wise to each of my element of v .
now , let's talk about more oper .
so , here's my matrix a .
if you want to write a transpos .
the wai to do that is to write a prime .
that's the apostroph symbol .
it's the left quot .
so , on your keyboard you probabl have a left quot and a right quot .
so thi is a at the standard quotat mark is a , what to sai , a transpos to excus me the , you know , a transpos of my major and of cours a transpos if i transpos that again then i should get back my matrix a .
some more us function .
let's sai locat a is <num> <num> to <num> .
so , it's a , you know , <num> by <num> matrix .
let's sai set val equal max of a .
thi return the maximum valu of a , which in thi case is <num> and i can do val ind max a .
and thi return val of int which ar the maximum valu of a which is <num> as wa the index .
so the element number two of a that <num> .
so , in is my index into thi .
just as a warn if you do max a where a is a matrix .
what thi doe is thi actual doe the column wise maximum , but sai a littl bit more about thi in a second .
so , us thi exampl of the variabl lowercas a .
if i do a less than three .
thi doe the element wise oper .
element wise comparison .
so , the first element of a is less than three equal to on .
second element of a is not less than three , so thi valu is zero , becaus it is also .
the third and fourth number of a ar the lesson , i meant less than three , third and fourth element ar less than three .
so thi is on , on , so thi is just the element wide comparison of all four element variabl lower case three and it return true or fals depend on whether or not it's less than three .
now , if i do find a less than three , thi would tell me which ar the element of a that the variabl a of less than three and in thi case the 1st , 3rd and 4th element ar lesson three .
for my next exampl oh , let me set eight be code to magic three .
the magic function return .
let's type help magic .
function call the magic function return .
return thi matric call magic squar .
thei have thi , you know , mathemat properti that all of their row and column and diagon sum up to the same thing .
so , you know , it's not actual us for machin learn as far as i know , but i'm just us thi as a conveni wai , you know , to gener a <num> by <num> matrix and thi magic squar screen .
we have the power of <num> at each row , each column and the diagon all add up to the same thing , so it's kind of a mathemat construct .
i us magic , i us thi magic function onli when i'm do demo , or when i'm teach octav like thi and i don't actual us it for ani , you know , us machin learn applic .
but , let's see , if i type rc equal find a greater than or equal <num> .
thi find all the element of a that ar greater than and equal to <num> and so , rc sens a row and column .
so , the <num> element is greater than <num> .
the three two element is greater than <num> and the two <num> element is greater than <num> .
so let's see , the two , three element for exampl , is a two , three .
is seven , is thi element out here , and that is inde greater than or equal seven .
by the wai , i actual don't even memor myself what these find function do in the all these thing do myself and whenev i us a find function , sometim i forget myself exactli what doe , and you know , type help find to look up the document .
okai , just two more thing , if it's okai , to show you .
on is the sum function .
so here's my a and i type sum a .
thi add up all the element of a .
and if i want to multipli them togeth , i type prod a .
prod sens of product , and it return the product of these four element of a .
floor a round down , these element of a , so zero o point five get round down to zero .
and ceil , or ceil a , get round up , so zero point five , round up to the nearest integ , so zero point five get round up to on .
you can also .
let's see .
let me type rand <num> .
thi gener set a <num> by <num> matrix .
if i type max randd <num> , rand <num> .
what thi doe is it take the element wise maximum of <num> random <num> by <num> matric .
so , you'll notic all these number tend to be a bit on the larg side becaus each of these is actual the max of a randomli , of element y's max of two randomli gener matric .
thi is my magic number .
thi wa my magic squar 3x3a .
let's sai i type max a and then thi will be it .
open , close , squar bracket comma <num> .
what thi doe is thi take the column wise maximum .
so , the maximum of the first column is eight , max of the second column is nine , the max of the third column is seven .
thi <num> mean to take the max along the first dimens of a .
in contrast , if i were to type max a , thi funni notat <num> then thi take the per row maximum .
so , the maximum for the first row is <num> , max of second row is <num> , max of the third row is <num> and so thi allow you to take max .
you know , per row or per column .
and if you want to , and rememb it default to column mark wise element on thi , so if you want to find the maximum element in the entir matrix a , you can type max of max of a , like so , which is nine .
or you can turn a into a vector and type max of a colon , like so , thi treat thi as a vector and take the max element of vector .
final , let's set a to be a nine by nine magic squar .
so rememb , the magic squar ha thi properti that everi column in everi row sum the same thing and also the diagon .
so here is 9x9 magic squar .
so let me just sum a on so thi doe a per column sum .
and so i'm go to take each column of a and add them up and thi , you know , let us verifi that inde for <num> by <num> magic squar .
everi column add up to <num> as of the same thing .
now , let's do the row wise sum .
so , the sum a comma <num> and thi sum up each row of a and each row of a also sum up to <num> .
now let's sum the diagon element of a and make sure that thei , that that also sum up to the same thing .
so what i'm go to do is , construct a nine by nine ident matrix , that's i9 , and let me take a and construct , multipli a element wise .
so here's my matrix of a .
i'm gonna do a . xi9 and what thi will do is take the element wise product of these <num> matric , and so thi should wipe out everyth except for the diagon entri and now i'm go to sum , sum of a of that and thi give me the sum of these diagon element , and inde it is <num> .
you can sum up the other diagon as well .
so thi top left to bottom right .
you can sum up the opposit diagon from bottom left to top right .
the sum , the command for thi is somewhat more cryptic .
you don't realli need to know thi .
i'm just show you just in case ani of you ar curiou , but let's see .
flip ud stand for flip up down .
if you do that , that turn out to sum up the element in the opposit of , the other diagon that also sum up to <num> .
here , let me show you , wherea i9 is thi matrix , flip up down of i9 , you know , take the ident matrix and flip it vertic so you end up with , excus me , flip ud , end up with on on thi opposit diagon as well .
just on last command and then that's it , and then that will be it for thi video .
let's sai a to be the 3x3 magic squar again .
if you want to invert the matrix , you type p inv a , thi is typic call a pseudo infer , but it doesn't matter .
think of it as basic the invers of a and that's the invers of a and second set , you know , <num> equal p of a and of temp time a .
thi is inde the ident matrix with essenti on on the diagon and zero on the off diagon , up to a numer round off .
so , that's it for how to do differ comput oper on the data in matric .
and after run a learn algorithm , often on of the most us thing is to be abl to look at your result , or to plot , or visual your result .
and in the next video i'm go to veri quickli show you how , again , with on or two line of code us octav you can quickli visual your data , or plot your data and us that to better understand , you know , what your learn algorithm ar do .
when develop learn algorithm , veri often a few simpl plot can give you a better sens of what the algorithm is do and just saniti check that everyth is go okai and the algorithm do what is suppos to .
for exampl , in an earlier video , i talk about how plot the cost function j of theta can help you make sure that gradient descent is converg .
often , plot of the data or of all the learn algorithm output will also give you idea for how to improv your learn algorithm .
fortun , octav ha veri simpl tool to gener lot of differ plot and when i us learn algorithm , i find that plot the data , plot the learn algorithm and so on ar often an import part of how i get idea for improv the algorithm and in thi video , i'd like to show you some of these octav tool for plot and visual your data .
here's my octav window .
let's quickli gener some data for us to plot .
so i'm go to set t to be equal to , you know , thi arrai of number .
here's t , set of number go from <num> up to . <num> .
let's set y1 equal sine of <num> pie <num> and if i want to plot the sine function , it's veri easi .
i just type plot t comma y <num> and hit enter .
and up come thi plot where the horizont axi is the t variabl and the vertic axi is y1 , which is the sine you saw in the function that we just comput .
let's set y2 to be equal to the cosin of two pi  , four t , like so .
and if i plot t comma y2 , what octav will i do is i'll take my sine plot and it will replac with thi cosin function and now , you know , cosin of xi of <num> .
now , what if i want to have both the sine and the cosin plot on top of each other ?
what i'm go to do is i'm go to type plot t , y1 .
so here's my sine function , and then i'm go to us the function hold on .
and what hold doe it close octav to now figur on top of the old on and let me now plot t y2 .
i'm go to plot the cosin function in a differ color .
so , let me put there r in quotat mark there and instead of replac the current figur , i'll plot the cosin function on top and the r indic the what is an event color .
and here addit command x label time , to label the x axi , or the horizont axi .
and y label valu a , to label the vertic axi valu , and i can also label my two line with thi command legend sine cosin and thi put thi legend up on the upper right show what the <num> line ar , and final titl my plot is the titl at the top of thi figur .
lastli , if you want to save thi figur , you type print dpng myplot . png .
so png is a graphic file format , and if you do thi it will let you save thi as a file .
if i do that , let me actual chang directori to , let's see , like that , and then i will print that out .
so thi will take a while depend on how your octav configur is setup , mai take a few second , but chang directori to my desktop and octav is now take a few second to save thi .
if i now go to my desktop , let's hide these window .
here's myplot . png which octav ha save , and you know , there's the figur save as the png file .
octav can save thousand other format as well .
so , you can type help plot , if you want to see the other file format , rather than png , that you can save figur in .
and lastli , if you want to get rid of the plot , the close command caus the figur to go awai .
as i figur if i type close , that figur just disappear from my desktop .
octav also let you specifi a figur and number .
you type figur <num> plot t , y<num> .
that start up first figur , and that plot t , y1 .
and then if you want a second figur , you specifi a differ figur number .
so figur two , plot t , y2 like so , and now on my desktop , i actual have <num> figur .
so , figur <num> and figur <num> thu <num> plot the sine function , <num> plot the cosin function .
here's on other neat command that i often us , which is the subplot command .
so , we're go to us subplot <num> <num> <num> .
what it doe it sub divid the plot into a on by two grid with the first <num> paramet ar , and it start to access the first element .
that's what the final paramet <num> is , right ?
so , divid my figur into a on by two grid , and i want to access the first element right now .
and so , if i type that in , thi product , thi figur , is on the left .
and if i plot t , y1 , it now fill up thi first element .
and if i i'll do subplot <num> .
i'm go to start to access the second element and plot t , y2 .
well , throw in y2 in the right hand side , or in the second element .
and last command , you can also chang the axi scale and chang axi these to <num> . <num> minu <num> <num> and thi set the x rang and y rang for the figur on the right , and concret , it assess the horizont major valu in the figur on the right to make sure <num> to <num> , and the vertic axi valu us the rang from minu on to on .
and , you know , you don't need to memor all these command .
if you ever need to chang the access or you need to know is that , you know , there's an access command and you can alreadi get the detail from the usual octav help command .
final , just a coupl last command clf clear is a figur and here's on uniqu trait .
let's set a to be equal to a <num> by <num> magic squar a .
so , a is now thi <num> by <num> matrix doe a neat trick that i sometim us to visual the matrix , which is i can us imag sc of a what thi will do is plot a five by five matrix , a five by five grid of color .
where the differ color correspond to the differ valu in the a matrix .
so concret , i can also do color bar .
let me us a more sophist command , and imag sc a color bar color map grai .
thi is actual run three command at a time .
i'm run imag sc then run color bar , then run color map grai .
and what thi doe , is it set a color map , so a grai color map , and on the right it also put in thi color bar .
and so thi color bar show what the differ shade of color correspond to .
concret , the upper left element of the a matrix is <num> , and so that correspond to kind of a mint shade of grai .
wherea in contrast the second element of a sort of the <num> <num> element of a is <num> .
right , so it's a <num> <num> is <num> .
so that correspond to thi squar out here , which is nearli a shade of white .
and the small valu , sai a what is that ?
a <num> <num> , you know , is a valu <num> over here that correspond you can see on my color bar that it correspond to a much darker shade in thi imag .
so here's anoth exampl , i can plot a larger , you know , here's a magic <num> that give you a <num> by <num> magic squar and thi give me a plot of what my <num> by <num> magic squar valu look like .
and final to wrap up thi video , what you've seen me do here is us comma chain of function call .
here's how you actual do thi .
if i type a equal <num> , b equal <num> , c equal <num> , and hit enter , then thi is actual carri out three command at the same time .
or realli carri out three command , on after anoth , and it print out all three result .
and thi is a lot like a equal <num> , b equal <num> , c equal <num> , except that if i us semicolon instead of a comma , it doesn't print out anyth .
so , thi , you know , thi thing here we call comma chain of command , or comma chain of function call .
and , it's just anoth conveni wai in octav to put multipl command like imag sc color bar , colon map to put multi command on the same line .
so , that's it .
in thi video , i'd like to tell you how to write control statement for your octav program , so thing like for , while and if statement and also how to defin and us function .
here's my octav window .
let me first show you how to us a for loop .
i'm go to start by set v to be a <num> by <num> vector <num> .
now , here's i write a for loop for i equal <num> to <num> .
that's for i equal y colon <num> .
and let's see , i'm go to set v of i equal two to the power of i , and final end .
the white space doe not matter , so i am put the space just to make it look nice indent , but you know space doesn't matter .
but if i do thi , then the result is that v get set to , you know , two to the power on , two to the power two , and so on .
so thi is syntax for i equal on colon <num> that make i loop through the valu on through <num> .
and by the wai , you can also do thi by set your indic equal on to <num> , and so the indic in the arrai from on to <num> .
you can also write for i equal indic .
and thi is actual the same as if i equal on to <num> .
you can do , you know , displai i and thi would do the same thing .
so , that is a for loop , if you ar familiar with break and continu , there's break and continu statement , you can also us those insid loop in octav , but first let me show you how a while loop work .
so , here's my vector v .
let's write the while loop .
i equal <num> , while i is less than or equal to <num> , let's set v i equal on hundr and increment i by on , end .
so thi sai what ?
i start off equal to on and then i'm go to set v i equal on hundr and increment i by on until i is , you know , greater than five .
and as a result of that , wherea previous v wa thi power of two vector .
i've now taken the first five element of my vector and overwritten them with thi valu on hundr .
so that's a syntax for a while loop .
let's do anoth exampl .
y equal on while true and here i want to show you how to us a break statement .
let's sai v i equal <num> and i equal i <num> if i equal <num> break and end .
and thi is also our first us of an if statement , so i hope the logic of thi make sens .
sinc i equal on and , you know , increment loop .
while repeatedli set v i equal <num> and increment i by <num> , and then when <num> i get up to <num> , do a break which break here although the while do and so , the effect is should be to take the first five element of thi vector v and set them to <num> .
and ye , inde , we're take v and overwritten the first five element with <num> .
so , thi is the syntax for if statement , and for while statement , and notic the end .
we have two end here .
thi end here end the if statement and the second end here end the while statement .
now let me show you the more gener syntax for how to us an if els statement .
so , let's see , v <num> is equal to <num> , let's type v1 equal to <num> for thi exampl .
so , let me type if v <num> equal <num> displai the valu as on .
here's how you write an els statement , or rather here's an els if v <num> equal <num> .
thi is , if in case that's true in our exampl , displai the valu as <num> , els displai , the valu is not on or two .
okai , so that's a if els if els statement it end .
and of cours , here we've just set v <num> equal <num> , so hopefulli , yup , displai that the valu is <num> .
and final , i don't think i talk about thi earlier , but if you ever need to exit octav , you can type the exit command and you hit enter that will caus octav to quit or the 'q' quit command also work .
final , let's talk about function and how to defin them and how to us them .
here's my desktop , and i have predefin a file or pre save on my desktop a file call squarethisnumb . m .
thi is how you defin function in octav .
you creat a file call , you know , with your function name and then end in . m , and when octav find thi file , it know that thi where it should look for the definit of the function squarethisnumb . m .
let's open up thi file .
notic that i'm us the microsoft program wordpad to open up thi file .
i just want to encourag you , if your us microsoft window , to us wordpad rather than notepad to open up these file , if you have a differ text editor that's fine too , but notepad sometim mess up the space .
if you onli have notepad , that should work too , that could work too , but if you have wordpad as well , i would rather us that or some other text editor , if you have a differ text editor for edit your function .
so , here's how you defin the function in octav .
let me just zoom in a littl bit .
and thi file ha just three line in it .
the first line sai function y equal squar root number of x , thi tell octav that i'm gonna return the valu y , i'm gonna return on valu and that the valu is go to be save in the variabl y and moreov , it tell octav that thi function ha on argument , which is the argument x , and the wai the function bodi is defin , if y equal x squar .
so , let's try to call thi function squar , thi number <num> , and thi actual isn't go to work , and octav sai squar thi number it's undefin .
that's becaus octav doesn't know where to find thi file .
so as usual , let's us pwd , or not in my directori , so let's see thi c user ang desktop .
that's where my desktop is .
oop , a littl typo there .
user ang desktop and if i now type squar root number <num> , it return the answer <num> .
as kind of an advanc featur , thi is onli for those of you that know what the term search path mean .
but so if you want to modifi the octav search path and you could , you just think of thi next part as advanc or option materi .
onli for those who ar either familiar with the concept of search path and permit languag , but you can us the term addpath , safeti colon , slash user ang desktop to add that directori to the octav search path so that even if you know , go to some other directori i can still , octav still know to look in the user ang desktop directori for function so that even though i'm in a differ directori now , it still know where to find the squar thi number function .
okai ?
but if you're not familiar with the concept of search path , don't worri about it .
just make sure as you us the cd command to go to the directori of your function befor you run it and that actual work just fine .
on concept that octav ha that mani other program languag don't is that it can also let you defin function that return multipl valu or multipl argument .
so here's an exampl of that .
defin the function call squar and cube thi number x and what thi sai is thi function return <num> valu , y1 and y<num> .
when i set down , thi follow , y1 is squar , y2 is execut .
and what thi doe is thi realli return <num> number .
so , some of you depend on what program languag you us , if you're familiar with , you know , cc your offer .
often , we think of the function as return in just on valu .
but just so the syntax in octav that should return multipl valu .
now back in the octav window .
if i type , you know , a , b equal squar and cube thi number <num> then a is now equal to <num> and b is equal to the cube of <num> equal to <num> .
so , thi is often conveni if you need to defin a function that return multipl valu .
final , i'm go to show you just on more sophist exampl of a function .
let's sai i have a data set that look like thi , with data point at <num> , <num> , <num> , <num> , <num> , <num> .
and what i'd like to do is to defin an octav function to comput the cost function j of theta for differ valu of theta .
first let's put the data into octav .
so i set my design matrix to be <num> , <num> , <num> , <num> , <num> , <num> .
so , thi is my design matrix x with x0 , the first column be the said term and the second term be you know , my the x valu of my three train exampl .
and let me set y to be <num> <num> <num> as follow , which were the y axi valu .
so let's sai theta is equal to <num> semicolon <num> .
here at my desktop , i've predefin doe cost function j and if i bring up the definit of that function it look as follow .
so function j equal cost function j equal x y theta , some common , specifi the input and then vari few step set m to be the number trade exampl thu the number of row in x .
comput the predict , predict equal x time theta and so thi is a common that's wrap around , so thi is probabl the preced comment line .
comput script error by , you know , take the differ between your predict and the y valu and take the element of y squar and then final comput the cost function j .
and octav know that j is a valu i want to return becaus j appear here in the function definit .
feel free by the wai to paus thi video if you want to look at thi function definit for longer and kind of make sure that you understand the differ step .
but when i run it in octav , i run j equal cost function j x y theta .
it comput .
oop , made a typo there .
it should have been capit x .
it comput j equal <num> becaus if my data set wa , you know , <num> , <num> then set , theta <num> equal <num> , theta <num> equal <num> , thi give me exactli the <num> degre line that fit my data set perfectli .
wherea in contrast if i set theta equal sai <num> , <num> , then thi hypothesi is predict zero on everyth the same , theta <num> equal <num> , theta <num> equal <num> and i comput the cost function then it's <num> . <num> and that's actual equal to <num> squar , which is my squar error on the first exampl , plu <num> squar , plu <num> squar and then divid by 2m , which is <num> time number of train exampl , which is inde <num> . <num> and so , that saniti check that thi function here is , you know , comput the correct cost function and these ar the coupl exampl we tri out on our simpl train exampl .
and so that saniti track that the cost function j , as defin here , that it is inde , you know , seem to comput the correct cost function , at least on our simpl train set that we had here with x and y be thi simpl train exampl that we solv .
so , now you know how to right control statement like for loop , while loop and if statement in octav as well as how to defin and us function .
in the next video , i'm go to just veri quickli step you through the logist of work on and submit problem set for thi class and how to us our submiss system .
and final , after that , in the final octav tutori video , i wanna tell you about vector , which is an idea for how to make your octav program run much fast .
in thi video , i'd like to tell you about the idea of vector .
so , whether you're us octav or a similar languag like matlab or whether you're us python and numpi or java cc .
all of these languag have either built into them or have readili and easili access , differ numer linear algebra librari .
thei're usual veri well written , highli optim , often so that develop by peopl that , you know , have phd in numer comput or thei ar realli special numer comput .
and when you're implement machin learn algorithm , if you're abl to take advantag of these linear algebra librari or these numer linear algebra librari and mix the routin call to them rather than sort of right call yourself to do thing that these librari could be do .
if you do that then often you get that first is more effici .
so , just run more quickli and take better advantag of ani parallel hardwar your comput mai have and so on .
and second , it also mean that you end up with less code that you need to write .
so have a simpler implement that is , therefor , mayb also more like to be bug free .
and as a concret exampl .
rather than write code yourself to multipli matric , if you let octav do it by type a time b , that will us a veri effici routin to multipli the <num> matric .
and there's a bunch of exampl like these where you us appropri vector implement .
you get much simpler code , and much more effici code .
let's look at some exampl .
here's a usual hypothesi of linear regress and if you want to comput h of x , notic that there is a sum on the right .
and so on thing you could do is comput the sum from j equal <num> to j equal n yourself .
anoth wai to think of thi is to think of h of x as theta transpos x and what you can do is think of thi as you know , comput thi in a product between <num> vector where theta is , you know , your vector sai theta <num> , theta <num> , theta <num> if you have <num> featur .
if n equal <num> and if you think of x as thi vector , x0 , x1 , x2 and these <num> view can give you <num> differ implement .
here's what i mean .
here's an unvector implement for how to comput h of x and by unvector i mean , without vector .
we might first initi , you know , predict to be <num> .
thi is go to eventu , the predict is go to be h of x and then i'm go to have a for loop for j equal on through n <num> predict get increment by theta j time xj .
so , it's kind of thi express over here .
by the wai , i should mention in these vector right over here , i had these vector be <num> index .
so , i had theta <num> theta <num> , theta <num> , but becaus matlab is on index , theta <num> in matlab , we might end up repres as theta <num> and thi second element end up as theta <num> and thi third element mai end up as theta <num> just becaus vector in matlab ar index start from <num> even though our real theta and x here start , index from <num> , which is why here i have a for loop j goe from <num> through n <num> rather than j go through <num> up to n , right ?
but so , thi is an unvector implement in that we have a for loop that sum up the n element of the sum .
in contrast , here's how you write a vector implement which is that you would think of x and theta as vector , and you just set predict equal theta transpos time x .
you're just comput like so .
instead of write all these line of code with the for loop , you instead have on line of code and what thi line of code on the right will do is it us octav highli optim numer linear algebra routin to comput thi inner product between the two vector , theta and x .
and not onli is the vector implement simpler , it will also run more effici .
so , that wa octav , but issu of vector appli to other program languag as well .
let's look at an exampl in c .
here's what an unvector implement might look like .
we again initi predict , you know , to <num> and then we now have a full loop for j0 up to n .
predict equal theta j time x j where again , you have thi x for loop that you write yourself .
in contrast , us a good numer linear algebra librari in c , you could us write the function like or rather .
in contrast , us a good numer linear algebra librari in c , you can instead write code that might look like thi .
so , depend on the detail of your numer linear algebra librari , you might be abl to have an object that is a c object which is vector theta and a c object which is a vector x , and you just take theta dot transpos time x where thi time becom c to overload the oper so that you can just multipli these two vector in c .
and depend on , you know , the detail of your numer and linear algebra librari , you might end up us a slightli differ and syntax , but by reli on a librari to do thi in a product .
you can get a much simpler piec of code and a much more effici on .
let's now look at a more sophist exampl .
just to remind you here's our updat rule for gradient descent for linear regress and so , we updat theta j us thi rule for all valu of j equal <num> , <num> , <num> , and so on .
and if i just write out these equat for theta <num> theta on , theta two .
assum we have two featur .
so n equal <num> .
then these ar the updat we perform to theta zero , theta on , theta two .
where you might rememb my sai in an earlier video that these should be simultan updat .
so let's see if we can come up with a vector implement of thi .
here ar my same <num> equat written on a slightli smaller font and you can imagin that <num> wait to implement thi three line of code is to have a for loop that sai , you know , for j equal <num> , <num> through <num> the updat theta j or someth like that .
but instead , let's come up with a vector implement and see if we can have a simpler wai .
so , basic compress these three line of code or a for loop that , you know , effect doe these <num> set , <num> set at a time .
let's see who can these <num> step and compress them into <num> line of vector code .
here's the idea .
what i'm go to do is i'm go to think of theta as a vector and i'm go to updat theta as theta minu alpha time some other vector , delta , where delta is go to be equal to <num> over m , sum from i equal on through m and then thi term on the right , okai ?
so , let me explain what's go on here .
here , i'm go to treat theta as a vector so , there's an n <num> dimension vector .
i'm sai that theta get , you know , updat as that's the vector , our n <num> .
alpha is a real number and delta here is a vector .
so , thi subtract oper , that's a vector subtract .
okai ?
becaus alpha time delta is a vector and so i'm sai if theta get , you know , thi vector , alpha time delta subtract from it .
so , what is the vector delta ?
well , thi vector delta look like thi .
and what thi meant to be is realli meant to be thi thing over here .
concret , delta will be a n <num> dimension vector and the veri first element of the vector delta is go to be equal to that .
so , if we have the delta , you know , if we index it from <num> thi is delta <num> , delta <num> , delta <num> .
what i want is that delta <num> is equal to , you know , thi first box also green up abov and inde , you might be abl to convinc yourself that delta <num> is thi <num> of m , sum of , you know , h of x .
xi minu yi time xi0 .
so , let's just make sure that we're on the same page about how delta realli is comput .
delta is on of m time the sum over here and , you know , what is thi sum ?
well , thi term over here , that's a real number .
and the second term over here , xi .
thi term over there is a vector , right ?
becaus xi might be a vector .
that would be xi0 , xi1 , xi2 right ?
and what is the summat ?
well , what doe summat sai is that thi term over here .
thi is equal to h x1 y1 time x1 h of x2 y2 time x2 you know , and so on .
okai ?
becaus thi is a summat of the i .
so , as i rang from i1 through m , you get these differ term and you're sum up these term .
and the mean of each of these term is a lot like if you rememb actual from the earlier quiz in thi , if you solv thi equat .
we said that in order to vector thi code , we will instead set u2v 5w .
so , we're sai that the vector u is equal to <num> time the vector v plu <num> time the vector w .
so , just an exampl of how to add differ vector and thi summat is the same thing .
it's a sai that thi summat over here is just some real number right ?
that's kind of like the number <num> and some other number time the vector x1 .
thi is like <num> time v instead with some other number time x1 and then plu , you know , instead of 5xw , we instead have some other real number plu some other vector and then you add on other vector , you know , plu . . .
plu the other vector , which is why overal , thi thing over here , that whole quantiti , that delta is just some vector , and concret , the <num> element of delta correspond if n2 , the <num> element of delta correspond exactli to thi thing to the second thing and thi third thing , which is why when you updat theta , accord to theta minu alpha delta , we end up have exactli the same simultan updat as the updat rule that we have on top .
so , i know that there wa a lot that happen on the slide , but again , feel free to paus the video and i either encourag you to step through the differ .
if you're unsur of what just happen , i encourag you to step through the slide to make sure you understand why is it that thi updat here with thi definit of delta , right ?
why is it that that equal to thi updat on top and it's still not clear when insight is that , you know , thi thing over here .
that's exactli the vector x and so , we're just take , you know , all <num> of these comput and compress them into on step with the thi vector delta , which is why we can come up with a vector implement of thi step of linear regress thi wai .
so i hope thi step make sens , and do look at the video and make sure and see if you can understand it .
in case you don't understand the equival of thi math if you implement thi , thi turn out to be the right answer anywai , so even if you didn't quit understand the equival , if you just implement it thi wai , you'll be abl to get linear regress to work .
so , if you're abl to figur out why these <num> step ar equival then hopefulli that would give you a better understand of vector as well , and final , if you're implement linear regress us more than on or two featur .
so , sometim we us linear regress with ten or hundr thousand of featur , but if you us the vector implement of linear regress , usual that will run much faster than if you had sai your old for loop that wa you know , updat theta <num> then theta <num> then theta <num> yourself .
so , us a vector implement , you should be abl to get a much more effici implement of linear regress .
and when you vector later algorithm that we'll see in thi class is a good trick whether an octav or some of the languag , the c java for get your code to run more effici .
in thi video , i want to just quickli step you through the logist of how to work on homework in thi class and how to us the submiss system which will let you verifi right awai that you got the right answer for your machin learn program exercis .
here's my octav window and let's first go to my desktop .
i save the file for my first exercis , some of the file on my desktop in thi directori , 'ml class ex1' .
and we provid a number file and ask you to edit some of them .
so the first file should meet the detail in the pdf file for thi program exercis .
but on of the file we ask you to edit is thi file call warmupexercis . m , where the exercis is realli just to make sure that you're familiar with the submiss system .
and all you need to do is return the 5x5 ident matrix .
so the solut to thi exercis i just show you is to write a ey <num> .
so that modifi thi function to gener the 5x5 ident matrix .
and thi function warmupexercis now return the 5x5 ident matrix .
and i'm just go to save it .
so i've done the first part of thi homework .
go back to my octav window , let's now go to my directori , 'c user ang desktop ml class ex1' .
and if i want to make sure that i've implement thi , type 'warmupexercis ' like so .
and yup , it return the 5x5 ident matrix that we just wrote the code to creat .
and i can now submit the code as follow .
i'm go to type 'submit ' in thi directori and i'm readi to submit part <num> so i'm go to enter choic '<num>' .
so it ask me for my email address .
i'm go go to the cours websit .
thi is an intern test site , so your version of the websit mai look a littl bit differ .
but that's my email address and thi is my submiss password , and i'm just go to type them in here .
so i have ang cs . stanford . edu and my submiss password is 9yc75ussgf .
i'm go to hit enter ; it connect to the server and submit it , and right awai it tell you congratul !
you have successfulli complet homework <num> part <num> .
and thi give you a verif that you got thi part right .
and if you don't submit the right answer , then it will give you a messag indic that you haven't quit gotten it right yet .
and you can us thi submiss password and you can gener new password ; it doesn't matter .
but you can also us your regular websit login password , but becaus thi password here is type in clear text on your monitor , we gave you thi extra submiss password in case you don't want to type in your websit's normal password onto a window that , depend on your oper system , mai or mai not appear as text when you type it into the octav submiss script .
so , that's how you submit the homework after you've done it .
good luck , and , when you get around to homework , i hope you get all of them right .
and final , in the next and final octav tutori video , i want to tell you about vector , which is a wai to get your octav code to run much more effici .
in thi and the next few video , i want to start to talk about classif problem , where the variabl y that you want to predict is discreet valu .
we'll develop an algorithm call logist regress , which is on of the most popular and most wide us learn algorithm todai .
here ar some exampl of classif problem .
earlier , we talk about email , spam classif as an exampl of a classif problem .
anoth exampl would be classifi onlin transact .
so , if you have a websit that sell stuff and if you want to know if a physic transact is fraudul or not , whether someon ha , you know , is us a stolen credit card or ha stolen the user's password .
that's anoth classif problem , and earlier we also talk about the exampl of classifi tumor as a cancer malign or as benign tumor .
in all of these problem , the variabl that we're try to predict is a variabl y that we can think of as take on two valu , either zero or on , either a spam or not spam , fraudul or not fraudul , malign or benign .
anoth name for the class that we denot with <num> is the neg class , and anoth name for the class that we denot with <num> is the posit class .
so <num> mai denot the benign tumor and <num> posit class mai denot a malign tumor .
the assign of the <num> class , you know , spam , no spam , and so on the assign of the <num> class to posit and neg , to <num> and <num> is somewhat arbitrari and it doesn't realli matter .
but often there is thi intuit that the neg class is convei the absenc of someth , like the absenc of a malign tumor , wherea on , the posit class , is convei the presenc of someth that we mai be look for .
but the definit of which is neg and which is posit is somewhat arbitrari and it doesn't matter that much .
for now , we're go to start with classif problem with just two class ; zero and on .
later on , we'll talk about multi class problem as well , whether variabl y mai take on sai , for valu zero , on , two and three .
thi is call a multi class classif problem , but for the next few video , let's start with the two class or the binari classif problem .
and we'll worri about the multi class set later .
so , how do we develop a classif algorithm ?
here's an exampl of a train set for a classif task for classifi a tumor as malign or benign and notic that malign take on onli two valu zero or no or on or on or ye .
so , on thing we could do given thi train set is to appli the algorithm that we alreadi know , linear regress to thi data set and just try to fit the straight line to the data .
so , if you take thi train set and fill a straight line to it , mayb you get hypothesi that look like that .
all right , so that's my hypothesi , h of x equal theta transpos x .
if you want to make predict , on thing you could try do is then threshold the classifi output at <num> .
that is at the vertic access valu <num> .
and if the hypothesi output a valu that's greater than equal to <num> you predict y equal on .
if it's less than <num> , you predict y equal zero .
let's see what happen when we do that .
so , let's take <num> , and so , you know , that's where the threshold is .
and thu , us linear regress thi wai .
everyth to the right of thi point , we will end up predict as the posit class becaus of the output valu ar greater than <num> on the vertic axi and everyth to the left of that point we will end up predict as a neg valu .
in thi particular exampl , it look like linear regress is actual do someth reason even though thi is a classif task we're interest in .
but now let's try chang problem a bit .
let me extend out the horizont axi of orbit and let's sai we got on more train exampl wai out there on the right .
notic that that addit train exampl , thi on out here , it doesn't actual chang anyth , right ?
look at the train set , it is pretti clear what a good hypothesi is .
well , everyth to the right of somewher around here to the right of thi we should predict as posit , and everyth to the left we should probabl predict as neg becaus from thi train set it look like all the tumor larger than , you know , a certain valu around here ar malign , and all the tumor smaller than that ar not malign , at least for thi train set .
but onc we've ad that extra exampl out here , if you now run linear regress , you instead get a straight line fit to the data .
that might mayb look like thi , and if you now threshold thi hypothesi at <num> , you end up with a threshold that's around here so that everyth to the right of thi point you predict as posit , and everyth to the left of that point you predict as neg .
and thi seem a pretti bad thing for linear regress to have done , right ?
becaus , you know , these ar our posit exampl , these ar our neg exampl .
it's pretti clear , we should realli be separ the two class somewher around there , but somehow by ad on exampl wai out here to the right , thi exampl realli isn't give us ani new inform .
i mean , it should be no surpris to the learn out of that the exampl wai out here turn out to be malign .
but somehow ad that exampl out there caus linear regress to chang in straight line fit to the data from thi magenta line out here to thi blue line over here , and caus it to give us a wors hypothesi .
so , appli linear regress to a classif problem usual isn't , often isn't a great idea .
in the first instanc , in the first exampl befor i ad thi extra train exampl , previous linear regress wa just get lucki and it got us a hypothesi that , you know , work well for that particular exampl , but usual appli linear regress to a data set , you know , you might get lucki but often it isn't a good idea , so i wouldn't us linear regress for classif problem .
here is on other funni thing about what would happen if we were to us linear regress for a classif problem .
for classif , we know that y is either zero or on , but if you ar us linear regress , well the hypothesi can output valu much larger than on or less than zero , even if all of good the train exampl have label y equal zero or on , and it seem kind of strang that even though we know that the label should be zero on , it seem kind of strang if the algorithm can offer valu much larger than on or much smaller than zero .
so what we'll do in the next few video is develop an algorithm call logist regress which ha the properti that the output , the predict of logist regress ar alwai between zero and on , and doesn't becom bigger than on or becom less than zero and by the wai , logist regress is and we will us it as a classif algorithm in some , mayb sometim confus that the term regress appear in hi name , even though logist regress is actual a classif algorithm .
but that's just the name it wa given for histor reason so don't be confus by that .
logist regress is actual a classif algorithm that we appli to set where the label y is discreet valu .
the <num> .
so hopefulli you now know why if you have a causat problem us linear regress isn't a good idea .
in the next video we'll start work out the detail of the logist regress algorithm .
let's start talk about logist regress .
in thi video , i'd like to show you the hypothesi represent , that is , what is the function we're go to us to repres our hypothesi where we have a classif problem .
earlier , we said that we would like our classifi to output valu that ar between zero and on .
so , we like to come up with a hypothesi that satisfi thi properti , that these predict ar mayb between zero and on .
when we were us linear regress , thi wa the form of a hypothesi , where h of x is theta transpos x .
for logist regress , i'm go to modifi thi a littl bit , and make the hypothesi g of theta transpos x , where i'm go to defin the function g as follow g of z if z is a real number is equal to on over on plu e to the neg z .
thi call the sigmoid function or the logist function .
and the term logist function , that's what give rise to the name logist progress .
and , by the wai , the term sigmoid function and logist function ar basic synonym and mean the same thing .
so the two term ar basic interchang and either term can be us to refer to thi function g .
and if we take these two equat , and put them togeth , then here's just an altern wai of write out the form of my hypothesi .
i'm sai that h of x is on over on plu e to the neg theta transpos x , and all i've done is i've taken the variabl z , z here's a real number and plug in theta transpos x , so i end up with , you know , theta transpos x , in place of z there .
lastli , let me show you where the sigmoid function look like .
we're go to plot it on thi figur here .
the sigmoid function , g of z , also call the logist function , look like thi .
it start off near zero and then rise until it process <num> at the origin and then it flatten out again like so .
so that's what the sigmoid function look like .
and you notic that the sigmoid function , well , it asymptot at on , and asymptot at zero as z against the horizont axi is z .
as z goe to minu infin , g of z approach zero and as g of z approach infin , g of z approach <num> , and so becaus g of z offer valu that ar between <num> and <num> we also have that h of x must be between <num> and <num> .
final , given thi hypothesi represent , what we need to do , as befor , is fit the paramet theta to our data .
so given a train set , we need to pick a valu for the paramet theta and thi hypothesi will then let us make predict .
we'll talk about a learn algorithm later for fit the paramet theta .
but first let's talk a bit about the interpret of thi model .
here's how i'm go to interpret the output of my hypothesi h of x .
when my hypothesi output some number , i am go to treat that number as the estim probabl that y is equal to on on a new input exampl x .
here is what i mean .
here is an exampl .
let's sai we're us the tumor classif exampl .
so we mai have a featur vector x , which is thi x01 as alwai and then our on featur is the size of the tumor .
suppos i have a patient come in and , you know thei have some tumor size and i feed their featur vector x into my hypothesi and suppos my hypothesi output the number <num> .
i'm go to interpret my hypothesi as follow .
i'm go to sai that thi hypothesi is tell me that for a patient with featur x , the probabl that y equal on is <num> . <num> .
in other word , i'm go to tell my patient that the tumor , sadli , ha a <num> chanc or a <num> chanc of be malign .
to write thi out slightli more formal or to write thi out in math , i'm go to interpret my hypothesi output as p of y equal <num> , given x parametr by theta .
so , for those of you that ar familiar with probabl , thi equat might make sens , if you're a littl less familiar with probabl , you know , here's how i read thi express , thi is the probabl that y is equal to on , given x instead of given that my patient ha , you know , featur x .
given my patient ha a particular tumor size repres by my featur x , and thi probabl is parametr by theta .
so i'm basic go to count on my hypothesi to give me estim of the probabl that y is equal to <num> .
now sinc thi is a classif task , we know that y must be either zero or on , right ?
those ar the onli two valu that y could possibl take on , either in the train set or for new patient that mai walk into my offic or into the doctor's offic in the futur .
so given h of x , we can therefor comput the probabl that y is equal to zero as well .
concret , becaus y must be either zero or on , we know that the probabl of y equal zero , plu the probabl of y equal on , must add up to on .
thi first equat look a littl bit more complic but it's basic sai that probabl of y equal zero for a particular patient with featur x , and you know , given our paramet's theta , plu the probabl of y equal on for that same patient which featur x and you paramet theta must add up to on , if thi equat look a littl bit complic feel free to mental imagin it without that x and theta .
and thi is just sai that the probabl of y equal zero plu the probabl of y equal on must be equal to on .
and we know thi to be true becaus y ha to be either zero or on .
and so the chanc of y be zero plu the chanc that y is on , you know , those two must add up to on .
and so if you just take thi term and move it to the right hand side , then you end up with thi equat that sai probabl y equal zero is on minu probabl y equal and thu if our hypothesi if h of x give us that term you can therefor quit simpli comput the probabl , or comput the estim probabl that y is equal to zero as well .
so you now know what the hypothesi represent is for logist regress and we're see what the mathemat formula is defin the hypothesi for logist regress .
in the next video , i'd like to try to give you better intuit about what the hypothesi function look like .
and i want to tell you someth call the decis boundari and we'll look at some visual togeth to try to get a better sens of what thi hypothesi function of logist regress realli look like .
in the last video , we talk about the hypothesi represent for logist progress .
what i'd like to do now is tell you about someth call the decis boundari , and thi will give us a better sens of what the logist regress hypothesi function is comput .
to recap , thi is what we wrote out last time , where we said that the hypothesi is repres as h of x equal g of theta transpos x , where g is thi function call the sigmoid function , which look like thi .
so , it slowli increas from zero to on , asymptot at on .
what i want to do now is try to understand better when thi hypothesi will make predict that y is equal to on versu when it might make predict that y is equal to zero and understand better what the hypothesi function look like , particularli when we have more than on featur .
concret , thi hypothesi is out put estim of the probabl that y is equal to on given x is prime .
so if we want to predict is y equal to on or is y equal to zero here's someth we might do .
when ever the hypothesi it that the problem with y be on is greater than or equal to <num> so thi mean that it is more like to be y equal on than y equal zero then let's predict y equal on .
and otherwis , if the probabl of , the estim probabl of y be on is less than <num> , then let's predict y equal zero .
and i chose a greater than or equal to here and less than here .
if h of x is equal to <num> exactli , then we could predict posit or neg vector but a put a great deal on to here so we default mayb to predict a posit if your vector is <num> but that's a detail that realli doesn't matter that much .
what i want to do is understand better when it is exactli that h of x will be greater or equal to <num> , so that we end up predict y is equal to on .
if we look at thi plot of the sigmoid function , we'll notic that the sigmoid function , g of z , is greater than or equal to <num> whenev z is greater than or equal to zero .
so is in thi half of the figur that , g take on valu that ar <num> and higher .
thi is not clear , that's the <num> .
so when z is posit , g of z , the sigmoid function , is greater than or equal to <num> .
sinc the hypothesi for logist regress is h of x equal g of theta transpos x .
thi is therefor go to be greater than or equal to <num> whenev theta transpos x is greater than or equal to zero .
so what wa shown , right , becaus here theta transpos x take the row of z .
so what we're shown is that our hypothesi is go to predict y equal on whenev theta transpos x is greater than or equal to <num> .
let's now consid the other case of when a hypothesi will predict y is equal to <num> .
well , by similar argument , h of x is go to be less than <num> whenev g of z is less than <num> becaus the rang of valu of z that call z to take on valu less that <num> , well that's when z is neg .
so when g of z is less than <num> .
our hypothesi will predict that y is equal to zero , and by similar argument to what we had earlier , h of x is equal g of theta transpos x .
and so , we'll predict y equal zero whenev thi quantiti theta transpos x is less than zero .
to summar what we just work out , we saw that if we decid to predict whether y is equal to on or y is equal to zero , depend on whether the estim probabl is greater than or equal <num> , or whether it's less than <num> , then that's the same as sai that will predict y equal <num> whenev theta transpos axi greater than or equal to <num> , and we will predict y is equal to zero whenev theta transpos x is less than zero .
let's us thi to better understand how the hypothesi of logist regress make those predict .
now , let's suppos we have a train set like that shown on the slide , and suppos our hypothesi is h of x equal g of theta zero , plu theta on x1 plu theta two x2 .
we haven't talk yet about how to fit the paramet of thi model .
we'll talk about that in the next video .
but suppos that variabl procedur to be specifi , we end up choos the follow valu for the paramet .
let's sai we choos theta zero equal three , theta on equal on , theta two equal on .
so thi mean that my paramet vector is go to be theta equal minu <num> .
so , we're given thi choic of my hypothesi paramet , let's try to figur out where a hypothesi will end up predict y equal <num> and where it will end up predict y equal <num> .
us the formula that we work on the previou slide , we know that y equal <num> is more like , that is the probabl that y equal <num> is greater than <num> or greater than or equal to <num> .
whenev theta transpos x is greater than zero .
and thi formula that i just underlin minu three plu x1 plu x2 is , of cours , theta transpos x when theta is equal to thi valu of the paramet that we just chose .
so , for ani exampl , for ani exampl with featur x1 and x2 that satisfi thi equat that minu <num> plu x1 plu x2 is greater than or equal to <num> .
our hypothesi will think that y equal <num> is more like , or will predict that y is equal to on .
we can also take minu three and bring thi to the right and rewrit thi as x1 plu x2 is greater than or equal to three .
and so , equival , we found that thi hypothesi will predict y equal on whenev x1 plu x2 is greater than or equal to three .
let's see what that mean on the figur .
if i write down the equat , x1 plu x2 equal three , thi defin the equat of a straight line .
and if i draw what that straight line look like , it give me the follow line which pass through <num> and <num> on the x1 and the x2 axi .
so the part of the input space , the part of the x1 , x2 plane that correspond to when x1 plu x2 is greater than or equal to three .
that's go to be thi veri top plane .
that is everyth to the up , and everyth to the upper right portion of thi magenta line that i just drew .
and so , the region where our hypothesi will predict y equal <num> is thi region , you know , is realli thi huge region , thi half space over to the upper right .
and let me just write that down .
i'm gonna call thi the y equal on region , and in contrast the region where x1 plu x2 is less than three , that's when we will predict that y , y is equal to zero , and that correspond to thi region .
you know , itt's realli a half plane , but that region on the left is the region where our hypothesi predict y equal <num> .
i want to give thi line , thi magenta line that i drew a name .
thi line there is call the decis boundari .
and concret , thi straight line x1 plu x equal <num> .
that correspond to the set of point .
so that correspond to the region where h of x is equal to <num> exactli and the decis boundari , that is thi straight line , that's the line that separ the region where the hypothesi predict y equal on from the region where the hypothesi predict that y is equal to <num> .
and just to be clear .
the decis boundari is a properti of the hypothesi includ the paramet theta <num> , theta <num> , theta <num> .
and in the figur i drew a train set .
i drew a data set in order to help the visual .
but even if we take awai the data set , you know decis boundari and a region where we predict y equal <num> versu y equal zero .
that's a properti of the hypothesi and of the paramet of the hypothesi , and not a properti of the data set .
later on , of cours , we'll talk about how to fit the paramet and there we'll end up us the train set , or us our data , to determin the valu of the paramet .
but onc we have particular valu for the paramet theta <num> , theta <num> , theta <num> .
then that complet defin the decis boundari and we don't actual need to plot a train set in order to plot the decis boundari .
let's now look at a more complex exampl where , as usual , i have cross to denot my posit exampl and o's to denot my neg exampl .
given a train set like thi , how can i get logist regress to fit thi sort of data ?
earlier , when we were talk about polynomi regress or when we're linear regress , we talk about how we can add extra higher order polynomi term to the featur .
and we can do the same for logist regress .
concret , let's sai my hypothesi look like thi .
where i've ad two extra featur , x1 squar and x2 squar , to my featur .
so that i now have <num> paramet , theta <num> through theta <num> .
as befor , we'll defer to the next video our discuss on how to automat choos valu for the paramet theta <num> through theta <num> .
but let's sai that veri procedur to be specifi , i end up choos theta <num> equal minu <num> , theta <num> equal <num> , theta <num> equal <num> , theta <num> equal <num> , and theta <num> equal <num> .
what thi mean is that with thi particular choic of paramet , my paramet vector theta look like minu <num> , <num> , <num> , <num> , <num> .
follow our earlier discuss , thi mean that my hypothesi will predict that y is equal to <num> whenev minu <num> plu x<num> squar plu x2 squar is greater than or equal to <num> .
thi is whenev theta transpos time my theta transpos my featur is greater than or equal to <num> .
and if i take minu <num> and just bring thi to the right , i'm sai that my hypothesi will predict that y is equal to <num> whenev x1 squar plu x2 squar is greater than or equal to <num> .
so , what doe decis boundari look like ?
well , if you were to plot the curv for x1 squar plu x2 squar equal <num> .
some of you will that is the equat for a circl of radiu <num> center around the origin .
so , that is my decis boundari .
and everyth outsid the circl i'm go to predict as y equal <num> .
so out here is , you know , my y equal <num> region .
i'm go to predict y equal <num> out here .
and insid the circl is where i'll predict y is equal to <num> .
so , by ad these more complex or these polynomi term to my featur as well .
i can get more complex decis boundari that don't just try to separ the posit and neg exampl of a straight line .
i can get in thi exampl a decis boundari that's a circl .
onc again the decis boundari is a properti not of the train set , but of the hypothesi and of the paramet .
so long as we've given my paramet vector theta , that defin the decis boundari which is the circl .
but the train set is not what we us to defin decis boundari .
the train set mai be us to fit the paramet theta .
we'll talk about how to do that later .
but onc you have the paramet theta , that is what defin the decis boundari .
let me put back the train set just for visual .
and final , let's look at a more complex exampl .
so can we come up with even more complex decis boundari and thi ?
if i have even higher order polynomi term , so thing like x1 squar , x1 squar x2 , x1 squar x2 squar , and so on .
if i have much higher order polynomi , then it's possibl to show that you can get even more complex decis boundari and logist regress can be us to find the zero boundari that mai , for exampl , be an ellips like that , or mayb with a differ set of the paramet , mayb you can get instead a differ decis boundari that mai even look like , you know , some funni shape like that .
or for even more complex exampl you can also get decis boundari that can look like , you know , more complex shape like that .
where everyth in here you predict y equal <num> , and everyth outsid you predict y equal <num> .
so these higher order polynomi featur you can get veri complex decis boundari .
so with these visual , i hope that give you a what's the rang of hypothesi function we can repres us the represent that we have for logist regress .
now that we know what h of x can repres .
what i'd like to do next in the follow video is talk about how to automat choos the paramet theta .
so that given a train set we can automat fit the paramet to our data .
in thi video we'll talk about how to fit the paramet theta for logist regress .
in particular , i'd like to defin the optim object or the cost function that we'll us to fit the paramet .
here's to supervis learn problem of fit a logist regress model .
we have a train set of m train exampl .
and as usual each of our exampl is repres by featur vector that's n plu <num> dimension .
and as usual we have x <num> equal <num> .
our first featur , or our <num> featur is alwai equal to <num> , and becaus thi is a classif problem , our train set ha the properti that everi label y , is either <num> or <num> .
thi is a hypothesi and the paramet of the hypothesi is thi theta over here .
and the question i want to talk about is given thi train set how do we choos , or how do we fit the paramet theta ?
back when we were develop the linear regress model , we us the follow cost function .
i've written thi slightli differ , where instead of <num> 2m , i've taken the <num> <num> and put it insid the summat instead .
now , i want to us an altern wai of write out thi cost function which is that instead of write out thi squar and return here , let's write here , cost of h of x comma y , and i'm go to defin that term cost of h of x comma y to be equal to thi .
it's just equal to just on half of the squar root error .
so now , we can see more clearli that the cost function is a sum over my train set , or is <num> m time the sum over my train set of thi cost term here .
and to simplifi thi equat a littl bit more , it's gonna be conveni to get rid of those superscript .
so just defin cost of h of x comma y to be equal to <num> <num> of thi squar root error and the interpret of thi cost function is that thi is the cost i want my learn algorithm to , you know , have to pai , if it output that valu it thi predict is h of x , and the actual label wa y .
so just cross off those superscript .
all right .
and no surpris for linear regress the cost for you to defin is that .
well the cost for thi is , that is <num> <num> time the squar differ between what ar predict and the actual valu that we observ for y .
now , thi cost function work fine for linear regress , but here we're interest in logist regress .
if we could minim thi cost function that is plug into j here .
that will work okai .
but it turn out that if we us thi particular cost function thi would be a non convex function of the paramet theta .
here's what i mean by non convex .
we have some cost function j of theta , and for logist regress thi function h here ha a non linear , right ?
it sai , you know , <num> over <num> plu e to the neg theta transfer x .
so it's a pretti complic nonlinear function .
and if you take the sigmoid function and plug it in here and then take thi cost function and plug it in there , and then plot what j of theta look like , you find that j of theta can look like a function just like thi .
you know with mani local optima and the formal term for thi is that thi a non convex function .
and you can kind of tell .
if you were to run gradient descent on thi sort of function , it is not guarante to converg to the global minimum .
wherea in contrast , what we would like is to have a cost function j of theta that is convex , that is a singl bow shape function that look like thi , so that if you run gradient descent , we would be guarante that gradient descent , you know , would converg to the global minimum .
and the problem of us the the squar cost function is that becaus of thi veri non linear sigmoid function that appear in the middl here , j of theta end up be a non convex function if you were to defin it as the squar cost function .
so what we'd would like to do is to instead come up with a differ cost function that is convex and so that we can appli a great algorithm like gradient descent and be guarante to find a global minimum .
here's a cost function that we're go to us for logist regress .
we're go to sai the cost or the penalti that the algorithm pai if it output a valu h of x .
so , thi is some number like <num> where it predict a valu h of x .
and the actual cost label turn out to be y .
the cost is go to be minu log h of x if y is equal <num> .
and minu log , <num> minu h of x if y is equal to <num> .
thi look like a pretti complic function .
but let's plot function to gain some intuit about what it's do .
let's start up with the case of y equal <num> .
if y is equal equal to <num> , then the cost function is log h of x , and if we plot that , so let's sai that the horizont axi is h of x .
so we know that a hypothesi is go to output a valu between <num> and <num> .
right ?
so h of x that vari between <num> and <num> .
if you plot what thi cost function look like .
you find that it look like thi .
on wai to see why the plot like thi it is becaus if you were to plot log z with z on the horizont axi .
then that look like that .
and it's approach is minu infin .
so thi is what the log function look like .
and so thi is <num> , thi is <num> .
here z is of cours plai the role of h of x .
and so minu log z will look like thi .
right just flip the sign .
minu log z .
and we're interest onli in the rang of when thi function goe between <num> and <num> .
so , get rid of that .
and so , we're just left with , you know , thi part of the curv .
and that's what thi curv on the left look like .
now thi cost function ha a few interest and desir properti .
first you notic that if y is equal to <num> and h of x is equal <num> , in other word , if the hypothesi exactli , you know , predict h equal <num> , and y is exactli equal to what i predict .
then the cost is equal <num> .
right ?
that correspond to , the curv doesn't actual flatten out .
the curv is still go .
first , notic that if h of x equal <num> , if the hypothesi predict that y is equal to <num> .
and if inde y is equal to <num> then the cost is equal to <num> .
that correspond to thi point down here .
right ?
if h of x is equal to <num> , and we're onli concern the case that y equal <num> here .
but if h of x is equal to <num> .
then the cost is down here is equal to <num> .
and that is what we like it to be .
becaus , you know , if we correctli predict the output y then the cost is <num> .
but now , notic also that h of x approach <num> .
so , that's h .
as the output of the hypothesi approach <num> the cost blow up , and it goe to infin .
and what thi doe is it captur the intuit that if a hypothesi , you know , output <num> .
that's like sai , our hypothesi is sai , the chanc of y equal <num> is equal to <num> .
it's kind of like our go to our medic patient and sai , the probabl that you have a malign tumor , the probabl that y equal <num> is zero . so , it's like absolut imposs that your tumor is malign .
but if it turn out that the tumor , the patient's tumor , actual is malign .
so if y is equal to <num> even after we told them you know , the probabl of it happen is <num> .
it's absolut imposs for it to be malign .
but if we told them thi with that level of certainti , and we turn out to be wrong , then we penal the learn algorithm by a veri , veri larg cost , and that's captur by have thi cost goe infin if y equal <num> and h of x approach <num> .
thi might consid of y1 , let's look at what the cost function look like for y0 .
if y is equal to <num> , then the cost look like thi express over here .
and if you plot the function minu log <num> minu z what you get is the cost function actual look like thi .
so , it goe from <num> to <num> .
someth like that .
and so if you plot the cost function for the case of y equal zero , you find that it look like thi and what thi curv doe is it now blow up , and it goe to plu infin as h of x goe to <num> .
becaus it's sai that if y turn out to be equal to <num> , but we predict that you know , y is equal to <num> with almost certainti with probabl <num> , then we end up pai a veri larg cost .
let's plot the cost function for the case of y equal <num> .
so if y equal <num> that's go to be our cost function .
if you look at thi express , and if you plot , you know , minu log <num> minu z , if you figur out what that look like , you get a figur that look like thi .
where , which goe from <num> to <num> with the z axi on the horizont axi .
so if you take thi cost function and plot it for the case of y equal <num> , what you get is that the cost function look like thi .
and what thi cost function doe is that it blow up or it goe to a posit infin as each h of x goe to on and thi captur the intuit that if a hypothesi predict that , you know , h of x is equal to <num> with certainti , with like probabl <num> , it's absolut got to be y equal <num> .
but if y turn out to be equal to <num> then it make sens to make the hypothesi , or make the learn algorithm pai a veri larg cost .
and convers , if h of x is equal to <num> and y equal zero , then the hypothesi nail it .
the predict y is equal to zero and it turn out y is equal to zero so at thi point the cost function is go to be <num> .
in thi video , we have defin the cost function for a singl train exampl .
the topic of convex analysi is beyond the scope of thi cours .
but it is possibl to show that with our particular choic of cost function thi would give us a convex optim problem as cost function , overal cost function j of theta will be convex and local optima free .
in the next video we're go to take these idea of the cost function for a singl train exampl and develop that further and defin the cost function for the entir train set , and we'll also figur out a simpler wai to write it than we have been us so far .
and base on that will work out gradient descent , and that will give us our logist regress algorithm .
in thi video , we'll figur out a slightli simpler wai to write the cost function than we have been us so far .
and we'll also figur out how to appli gradient descent to fit the paramet of logist regress .
so by the end of thi video you know how to implement a fulli work version of logist regress .
here's our cost function for logist regress .
our overal cost function is <num> over m time sum of the train set of the cost of make differ predict on the differ exampl of label y i .
and thi is a cost for a singl exampl that we work out earlier .
and i just want to remind you that for classif problem in our train and in fact even for exampl known in our train set , y is alwai equal to <num> or <num> .
right ?
that's sort of part of the mathemat definit of y .
becaus y is either <num> or <num> .
we'll be abl to come up with a simpler wai to write thi cost function .
and in particular , rather than write out thi cost function on two separ line with two separ case for y equal <num> and y equal <num> , i am go to show you a wai take these two line and compress them into on equat .
and thi will make it more conveni to write out the cost function and deriv gradient descent .
concret , we can write out the cost function as follow .
we'll sai the cost of h of x comma y .
i'm go to write thi as minu y time log h of x minu <num> minu y time log <num> minu h of x .
and i'll show you in a second that thi express , or thi equat is an equival wai or more compact wai of write out thi definit of the cost function that we had up here .
let's see why that's the case .
we know that there ar onli <num> possibl case .
y must be <num> or <num> .
so let's suppos y equal <num> .
if y is equal to <num> then thi equat is sai that the cost is equal to .
well if y is equal to on , then thi thing here is equal to on .
and on minu y is go to be equal to zero , right ?
so if y is equal to on , then on minu y is on minu on , which is therefor zero .
so the second term get multipli by zero and goe awai , and we're left with onli thi first term which is y time log , minu y time log h of x .
y is <num> so that's equal to minu log h of x .
and thi equat is exactli what we have up here for if y is equal to on .
the other case is if y is equal to <num> .
and if that is the case then , write of the cost function is sai that if y is equal to zero , then thi term here , will be equal to zero .
wherea <num> minu y , if y equal zero , would be equal to <num> , becaus <num> minu y becom <num> minu <num> , which is just equal to <num> .
and so the cost function simplifi to just thi last term here .
right ?
becaus the first term over here get multipli by zero , and so it disappear .
so we're just left with thi last term , which is minu log , <num> minu h of x .
and you can verifi that thi term here is just exactli what we had for when y is equal to <num> .
so thi show that thi definit for the cost is just a more compact wai of take both of these express , the case y equal <num> and y equal <num> , and write them in on , in a more conveni form with just on line .
we can , therefor , write all of our cost function for logist regress as follow .
it is thi on of m of the sum of thi cost function , and plug in the definit for the cost that we work out earlier , we end up with thi .
and we just brought the minu sign outsid .
and why do we choos thi particular cost function ?
when it look like there could be other cost function that we could have chosen .
although i won't have time to go into great detail of thi in thi cours , thi cost function can be deriv from statist us the principl of maximum likelihood estim , which is an idea statist for how to effici find paramet data for differ model .
and it also ha a nice properti that it is convex .
so thi is the cost function that , you know , essenti everyon us when put logist regress model .
if we don't understand the term i just sai and you don't know what the principl of maximum likelihood estim is , don't worri about .
there's just a deeper ration and justif behind thi particular cost function then i have time to go into in thi class .
given thi cost function , in order to fit the paramet , what we're go to do then is try to find the paramet theta that minim j of theta .
so if we , you know , try to minim thi .
thi would give us some set of paramet theta .
final , if we're given a new exampl with some set of featur x .
we can then take the theta that we fit our train set and output our predict as thi , and just to remind you the output of my hypothesi , i am go to interpret as the probabl that y is equal to <num> .
and thi is given the implement x and paramet by theta .
but think of thi as just my hypothesi is estim the probabl that y is equal to <num> .
so all that remain to be done is figur out how to actual minim j of theta as a function of theta so we can actual fit the paramet to our train set .
the wai we're go to minim the cost function is us gradient descent .
here's our cost function .
and if we want to minim it as a function of theta .
here's our usual templat for gradient descent .
where we repeatedli updat each paramet by take updat it as itself minu a learn rate alpha time thi deriv term .
if you know some calculu feel free to take thi term and try to comput a deriv yourself and see if you can simplifi it to the same answer that i get .
but even if you don't know calculu don't worri about it .
if you actual comput thi , what you get is thi equat .
and just write it out here .
the sum from i equal <num> through m of the , essenti the error , time x i j .
so if you take thi partial deriv term and plug it back in here , we can then write out our gradient descent algorithm as follow .
and all i've done is i took the deriv term from the previou line and plug it in there .
so if you have n featur , you would have , you know , a paramet vector theta , which paramet theta zero , theta on , theta two , down to theta n and you will us thi updat to simultan updat all of your valu of theta .
now if you take thi updat rule and compar it to what we were do for linear regress , you might be surpris to realiz that , well , thi equat wa exactli what we had for linear regress .
in fact , if you look at the earlier video and look at the updat rule , the gradient descent rule for linear regress , it look exactli like what i drew here insid the blue box .
so ar linear regress and logist regress differ algorithm or not ?
well , thi is resolv by observ that for logist regress , what ha chang is that the definit for thi hypothesi ha chang .
so wherea for linear regress we had h of x equal theta transpos x , now the definit of h of x ha chang and is instead now <num> over <num> plu e to the neg theta transpos x .
so even though the updat rule look cosmet ident , becaus the definit of the hypothesi ha chang , thi is actual not the same thing as gradient descent for linear regress .
in an earlier video , when we were talk about gradient descent for linear regress , we had talk about how to monitor gradient descent to make sure that it is converg .
i usual appli that same method to logist regress too to monitor gradient descent to make sure it's convers correctli .
and hopefulli you can figur out how to appli that techniqu to logist regress yourself .
when implement logist regress with gradient descent , we have all of these differ paramet valu , you know , theta <num> down to theta n that we need to updat us thi express .
and on thing we could do is have a for loop .
so for i equal <num> to n of i equal <num> to n plu <num> .
so updat each of these paramet valu in turn .
but of cours , rather than us a folder , ideal we would also us a vector implement .
and so that a vector implement can updat , you know , all of these n plu <num> paramet all in on fell swoop .
and to check your own understand , you might see if you can figur out how to do the vector implement of thi algorithm as well .
so now you know how to implement gradient descent for logist aggress .
there wa on last idea that we had talk about earlier for which wa featur scale .
we saw how featur scale can help gradient descent converg faster for linear regress .
the idea of featur scale also appli to gradient descent for logist regress .
and if you have featur that ar on veri differ scale .
then appli featur scale can also make it , gradient descent , run faster for logist regress .
so , that's it .
you now know how to implement logist regress , and thi is a veri power and probabl even most wide us classif algorithm in the world .
and you now know how we get to work with yourself .
in the last video , we talk about gradient descent for minim the cost function j of theta for logist regress .
in thi video , i'd like to tell you about some advanc optim algorithm and some advanc optim concept .
us some of these idea , we'll be abl to get logist regress to run much more quickli than it's possibl with gradient descent .
and thi will also let the algorithm scale much better to veri larg machin learn problem , such as if we had a veri larg number of featur .
here's an altern view of what gradient descent is do .
we have some cost function j and we want to minim it .
so what we need to is , we need to write code that can take as input the paramet theta and thei can comput two thing j of theta and these partial deriv term for , you know , j equal <num> , <num> up to n .
given code that can do these two thing , what gradient descent doe is it repeatedli perform the follow updat .
right ?
so given the code that we wrote to comput these partial deriv , gradient descent plug in here and us that to updat our paramet theta .
so anoth wai of think about gradient descent is that we need to suppli code to comput j of theta and these deriv , and then these get plug into gradient descent , which can then try to minim the function for us .
for gradient descent , i guess technic you don't actual need code to comput the cost function j of theta .
you onli need code to comput the deriv term .
but if you think of your code as also monitor converg of some such , we'll just think of ourselv as provid code to comput both the cost function and the deriv term .
so , have written code to comput these two thing , on algorithm we can us is gradient descent .
but gradient descent isn't the onli algorithm we can us .
and there ar other algorithm , more advanc , more sophist on , that , if we onli provid them a wai to comput these two thing , then these ar differ approach to optim the cost function for us .
so conjug gradient bfg and l bfg ar exampl of more sophist optim algorithm that need a wai to comput j of theta , and need a wai to comput the deriv , and can then us more sophist strategi than gradient descent to minim the cost function .
the detail of exactli what these three algorithm is well beyond the scope of thi cours .
and in fact you often end up spend , you know , mani dai , or a small number of week studi these algorithm .
if you take a class and advanc the numer comput .
but let me just tell you about some of their properti .
these three algorithm have a number of advantag .
on is that , with ani of thi algorithm you usual do not need to manual pick the learn rate alpha .
so on wai to think of these algorithm is that given is the wai to comput the deriv and a cost function .
you can think of these algorithm as have a clever inter loop .
and , in fact , thei have a clever inter loop call a line search algorithm that automat tri out differ valu for the learn rate alpha and automat pick a good learn rate alpha so that it can even pick a differ learn rate for everi iter .
and so then you don't need to choos it yourself .
these algorithm actual do more sophist thing than just pick a good learn rate , and so thei often end up converg much faster than gradient descent .
these algorithm actual do more sophist thing than just pick a good learn rate , and so thei often end up converg much faster than gradient descent , but detail discuss of exactli what thei do is beyond the scope of thi cours .
in fact , i actual us to have us these algorithm for a long time , like mayb over a decad , quit frequent , and it wa onli , you know , a few year ago that i actual figur out for myself the detail of what conjug gradient , bfg and o bfg do .
so it is actual entir possibl to us these algorithm successfulli and appli to lot of differ learn problem without actual understand the inter loop of what these algorithm do .
if these algorithm have a disadvantag , i'd sai that the main disadvantag is that thei're quit a lot more complex than gradient descent .
and in particular , you probabl should not implement these algorithm conjug gradient , l bgf , bfg yourself unless you're an expert in numer comput .
instead , just as i wouldn't recommend that you write your own code to comput squar root of number or to comput invers of matric , for these algorithm also what i would recommend you do is just us a softwar librari .
so , you know , to take a squar root what all of us do is us some function that someon els ha written to comput the squar root of our number .
and fortun , octav and the close relat languag matlab we'll be us that octav ha a veri good .
ha a pretti reason librari implement some of these advanc optim algorithm .
and so if you just us the built in librari , you know , you get pretti good result .
i should sai that there is a differ between good and bad implement of these algorithm .
and so , if you're us a differ languag for your machin learn applic , if you're us c , c , java , and so on , you might want to try out a coupl of differ librari to make sure that you find a good librari for implement these algorithm .
becaus there is a differ in perform between a good implement of , you know , contour gradient or lpfg versu less good implement of contour gradient or lpfg .
so now let's explain how to us these algorithm , i'm go to do so with an exampl .
let's sai that you have a problem with two paramet equal theta zero and theta on .
and let's sai your cost function is j of theta equal theta on minu five squar , plu theta two minu five squar .
so with thi cost function .
you know the valu for theta <num> and theta <num> .
if you want to minim j of theta as a function of theta .
the valu that minim it is go to be theta <num> equal <num> , theta <num> equal equal five .
now , again , i know some of you know more calculu than other , but the deriv of the cost function j turn out to be these two express .
i've done the calculu .
so if you want to appli on of the advanc optim algorithm to minim cost function j .
so , you know , if we didn't know the minimum wa at <num> , <num> , but if you want to have a cost function <num> the minimum numer us someth like gradient descent but prefer more advanc than gradient descent , what you would do is implement an octav function like thi , so we implement a cost function , cost function theta function like that , and what thi doe is that it return two argument , the first j val , is how we would comput the cost function j .
and so thi sai j val equal , you know , theta on minu five squar plu theta two minu five squar .
so it's just comput thi cost function over here .
and the second argument that thi function return is gradient .
so gradient is go to be a two by on vector , and the two element of the gradient vector correspond to the two partial deriv term over here .
have implement thi cost function , you would , you can then call the advanc optim function call the fminunc it stand for function minim unconstrain in octav and the wai you call thi is as follow .
you set a few option .
thi is a option as a data structur that store the option you want .
so grant up on , thi set the gradient object paramet to on .
it just mean you ar inde go to provid a gradient to thi algorithm .
i'm go to set the maximum number of iter to , let's sai , on hundr .
we're go give it an initi guess for theta .
there's a <num> by <num> vector .
and then thi command call fminunc .
thi at symbol present a pointer to the cost function that we just defin up there .
and if you call thi , thi will comput , you know , will us on of the more advanc optim algorithm .
and if you want to think it as just like gradient descent .
but automat choos the learn rate alpha for so you don't have to do so yourself .
but it will then attempt to us the sort of advanc optim algorithm .
like gradient descent on steroid .
to try to find the optim valu of theta for you .
let me actual show you what thi look like in octav .
so i've written thi cost function of theta function exactli as we had it on the previou line .
it comput j val which is the cost function .
and it comput the gradient with the two element be the partial deriv of the cost function with respect to , you know , the two paramet , theta on and theta two .
now let's switch to my octav window .
i'm gonna type in those command i had just now .
so , option equal optimset .
thi is the notat for set my paramet on my option , for my optim algorithm .
grant option on , maxit , <num> so that sai <num> iter , and i am go to provid the gradient to my algorithm .
let's sai initi theta equal zero's two by on .
so that's my initi guess for theta .
and now i have of theta , function val exit flag equal fminunc constraint .
a pointer to the cost function .
and provid my initi guess .
and the option like so .
and if i hit enter thi will run the optim algorithm .
and it return pretti quickli .
thi funni format that's becaus my line , you know , my code wrap around .
so , thi funni thing is just becaus my command line had wrap around .
but what thi sai is that numer render , you know , think of it as gradient descent on steroid , thei found the optim valu of a theta is theta <num> equal <num> , theta <num> equal <num> , exactli as we're hope for .
the function valu at the optimum is essenti <num> to the minu <num> .
so that's essenti zero , which is also what we're hope for .
and the exit flag is <num> , and thi show what the converg statu of thi .
and if you want you can do help fminunc to read the document for how to interpret the exit flag .
but the exit flag let's you verifi whether or not thi algorithm thing ha converg .
so that's how you run these algorithm in octav .
i should mention , by the wai , that for the octav implement , thi valu of theta , your paramet vector of theta , must be in rd for d greater than or equal to <num> .
so if theta is just a real number .
so , if it is not at least a two dimension vector or some higher than two dimension vector , thi fminunc mai not work , so and if in case you have a on dimension function that you us to optim , you can look in the octav document for fminunc for addit detail .
so , that's how we optim our trial exampl of thi simpl quick drive cost function .
howev , we appli thi to let's just sai progress .
in logist regress we have a paramet vector theta , and i'm go to us a mix of octav notat and sort of math notat .
but i hope thi explan will be clear , but our paramet vector theta compris these paramet theta <num> through theta n becaus octav index , vector us index from <num> , you know , theta <num> is actual written theta <num> in octav , theta <num> is gonna be written .
so , if theta <num> in octav and that's gonna be a written theta n <num> , right ?
and that's becaus octav index is vector start from index of <num> and so the index of <num> .
so what we need to do then is write a cost function that captur the cost function for logist regress .
concret , the cost function need to return j val , which is , you know , j val as you need some code to comput j of theta and we also need to give it the gradient .
so , gradient <num> is go to be some code to comput the partial deriv in respect to theta <num> , the next partial deriv respect to theta <num> and so on .
onc again , thi is gradient <num> , gradient <num> and so on , rather than gradient <num> , gradient <num> becaus octav index is vector start from on rather than from zero .
but the main concept i hope you take awai from thi slide is , that what you need to do , is write a function that return the cost function and return the gradient .
and so in order to appli thi to logist regress or even to linear regress , if you want to us these optim algorithm for linear regress .
what you need to do is plug in the appropri code to comput these thing over here .
so , now you know how to us these advanc optim algorithm .
becaus , us , becaus for these algorithm , you're us a sophist optim librari , it make the just a littl bit more opaqu and so just mayb a littl bit harder to debug .
but becaus these algorithm often run much faster than gradient descent , often quit typic whenev i have a larg machin learn problem , i will us these algorithm instead of us gradient descent .
and with these idea , hopefulli , you'll be abl to get logist progress and also linear regress to work on much larger problem .
so , that's it for advanc optim concept .
and in the next and final video on logist regress , i want to tell you how to take the logist regress algorithm that you alreadi know about and make it work also on multi class classif problem .
in thi video we'll talk about how to get logist regress to work for multi class classif problem , and in particular i want to tell you about an algorithm call on versu all classif .
what's a multi class classif problem ?
here ar some exampl .
let's sai you want a learn algorithm to automat put your email into differ folder or to automat tag your email .
so , you might have differ folder or differ tag for work email , email from your friend , email from your famili and email about your hobbi .
and so , here , we have a classif problem with <num> class , which we might assign the number , the class y1 , y2 , y3 and y4 to , anoth exampl for a medic diagnosi if a patient come into your offic with mayb a stuffi nose , the possibl diagnos could be that thei're not ill , mayb that's y1 ; or thei have a cold , <num> ; or thei have the flu .
and the third and final exampl , if you ar us machin learn to classifi the weather , you know , mayb you want to decid that the weather is sunni , cloudi , raini or snow , or if there's gonna be snow .
and so , in all of these exampl , y can take on a small number of discreet valu , mayb <num> to <num> , <num> to <num> and so on , and these ar multi class classif problem .
and by the wai , it doesn't realli matter whether we index as <num> or as <num> , i tend to index that my class start from <num> rather than start from <num> .
but either wai , where often , it realli doesn't matter .
wherea previous , for a binari classif problem , our data set look like thi .
for a multi class classif problem , our data set mai look like thi , where here , i'm us three differ symbol to repres our three class .
so , the question is given the data set with three class where thi is a the exampl of on class , that's the exampl of the differ class , and , that's the exampl of yet , the third class .
how do we get a learn algorithm to work for the set ?
we alreadi know how to do binari classif , us logist regress , we know how the , you know , mayb , for the straight line , to separ the posit and neg class .
us an idea call on versu all classif , we can then take thi , and , make it work for multi class classif , as well .
here's how on versu all classif work .
and , thi is also sometim call on versu rest . let's sai , we have a train set , like that shown on the left , where we have <num> class .
so , if y1 , we denot that with a triangl if y2 the squar and , if y3 then , the cross .
what we're go to do is , take a train set , and , turn thi into three separ binari classif problem .
so , i'll turn thi into three separ two class classif problem .
so let's start with class <num> , which is a triangl .
we ar go to essenti creat a new , sort of fake train set .
where class <num> and <num> get assign to the neg class and class <num> get assign to the posit class when we creat a new train set if that's show on the right and we're go to fit a classifi , which i'm go to call h subscript theta superscript <num> of x where here , the triangl ar the posit exampl and the circl ar the neg exampl .
so , think of the triangl be assign the valu of <num> and the circl the sum , the valu of zero .
and we're just go to train a standard logist regress crossfir and mayb that will give us a posit boundari .
ok ?
the superscript <num> here is the class on .
so , we're do thi for the triangl first class .
next , we do the same thing for class <num> .
go to take the squar and assign the squar as the posit class and assign everi thing els the triangl and the cross as the neg class .
and then we fit a second logist regress classifi .
i'm gonna call thi h of x superscript <num> , where the superscript <num> denot that we're now do thi treat the squar class as the posit class and mayb we get the classifi like that .
and final , we do the same thing for the third class and fit a third classifi h superscript <num> of x and mayb thi will give us a decis boundari or give us a classifi that separ the posit and neg exampl like that .
so , to summar , what we've done is we fit <num> classifi .
so , for i equal <num> <num> <num> we'll fit a classifi h superscript i subscript theta of x , thu try to estim what is the probabl that y is equal to class i given x and priorit by theta .
right ?
so , in the first instanc , for thi first on up here , thi classifi with learn to by the triangl .
so it's think of the triangl as a posit class .
so , x superscript on is essenti try to estim what is the probabl that the y is equal to on , given x and parametr by theta .
and similarli , thi is treat , you know , the squar class as a posit took paus so it try to estim the probabl that y2 and so on .
so we now have <num> classifi each of which wa train is on of the three cross .
just to summar , what we've done is we've , we want to train a logist regress classifi , h superscript i of x , for each plu i that predict it's probabl a y i .
final , to make a predict when we give it a new input x and we want to make a predict , we do is we just run let's sai three what run our <num> of our classifi on the input x and we then pick the class i that maxim the three .
so , we just you know , basic pick the classifi , pick whichev on of the three classifi is most confid , or most enthusist sai that it think it ha a right class .
so , whichev valu of i give us the highest probabl , we then predict y to be that valu .
so , that's it for multi class classif and on versu all method .
and with thi littl method you can now take the logist regress classifi and make it work on multi class classif problem as well .
by now , you've seen a coupl differ learn algorithm , linear regress and logist regress .
thei work well for mani problem , but when you appli them to certain machin learn applic , thei can run into a problem call overfit that can caus them to perform veri poorli .
what i'd like to do in thi video is explain to you what is thi overfit problem , and in the next few video after thi , we'll talk about a techniqu call regular , that will allow us to amelior or to reduc thi overfit problem and get these learn algorithm to mayb work much better .
so what is overfit ?
let's keep us our run exampl of predict hous price with linear regress where we want to predict the price as a function of the size of the hous .
on thing we could do is fit a linear function to thi data , and if we do that , mayb we get that sort of straight line fit to the data .
but thi isn't a veri good model .
look at the data , it seem pretti clear that as the size of the hous increas , the hous price plateau , or kind of flatten out as we move to the right and so thi algorithm doe not fit the train and we call thi problem underfit , and anoth term for thi is that thi algorithm ha high bia .
both of these roughli mean that it's just not even fit the train data veri well .
the term is kind of a histor or technic on , but the idea is that if a fit a straight line to the data , then , it's as if the algorithm ha a veri strong preconcept , or a veri strong bia that hous price ar go to vari linearli with their size and despit the data to the contrari .
despit the evid of the contrari is preconcept still ar bia , still close it to fit a straight line and thi end up be a poor fit to the data .
now , in the middl , we could fit a quadrat function enter and , with thi data set , we fit the quadrat function , mayb , we get that kind of curv and , that work pretti well .
and , at the other extrem , would be if we were to fit , sai a fourth other polynomi to the data .
so , here we have five paramet , theta zero through theta four , and , with that , we can actual fill a curv that process through all five of our train exampl .
you might get a curv that look like thi .
that , on the on hand , seem to do a veri good job fit the train set and , that is process through all of my data , at least .
but , thi is still a veri wiggli curv , right ?
so , it's go up and down all over the place , and , we don't actual think that's such a good model for predict hous price .
so , thi problem we call overfit , and , anoth term for thi is that thi algorithm ha high varianc . .
the term high varianc is anoth histor or technic on .
but , the intuit is that , if we're fit such a high order polynomi , then , the hypothesi can fit , you know , it's almost as if it can fit almost ani function and thi face of possibl hypothesi is just too larg , it's too variabl .
and we don't have enough data to constrain it to give us a good hypothesi so that's call overfit .
and in the middl , there isn't realli a name but i'm just go to write , you know , just right .
where a second degre polynomi , quadrat function seem to be just right for fit thi data .
to recap a bit the problem of over fit come when if we have too mani featur , then to learn hypothesi mai fit the train side veri well .
so , your cost function mai actual be veri close to zero or mai be even zero exactli , but you mai then end up with a curv like thi that , you know tri too hard to fit the train set , so that it even fail to gener to new exampl and fail to predict price on new exampl as well , and here the term gener refer to how well a hypothesi appli even to new exampl .
that is to data to hous that it ha not seen in the train set .
on thi slide , we look at over fit for the case of linear regress .
a similar thing can appli to logist regress as well .
here is a logist regress exampl with two featur x1 and x2 .
on thing we could do , is fit logist regress with just a simpl hypothesi like thi , where , as usual , g is my sigmoid function .
and if you do that , you end up with a hypothesi , try to us , mayb , just a straight line to separ the posit and the neg exampl .
and thi doesn't look like a veri good fit to the hypothesi .
so , onc again , thi is an exampl of underfit or of the hypothesi have high bia .
in contrast , if you were to add to your featur these quadrat term , then , you could get a decis boundari that might look more like thi .
and , you know , that's a pretti good fit to the data .
probabl , about as good as we could get , on thi train set .
and , final , at the other extrem , if you were to fit a veri high order polynomi , if you were to gener lot of high order polynomi term of speech , then , logist regress mai contort itself , mai try realli hard to find a decis boundari that fit your train data or go to great length to contort itself , to fit everi singl train exampl well .
and , you know , if the featur x1 and x2 offer predict , mayb , the cancer to the , you know , cancer is a malign , benign breast tumor .
thi doesn't , thi realli doesn't look like a veri good hypothesi , for make predict .
and so , onc again , thi is an instanc of overfit and , of a hypothesi have high varianc and not realli , and , be unlik to gener well to new exampl .
later , in thi cours , when we talk about debug and diagnos thing that can go wrong with learn algorithm , we'll give you specif tool to recogn when overfit and , also , when underfit mai be occur .
but , for now , let talk about the problem of , if we think overfit is occur , what can we do to address it ?
in the previou exampl , we had on or two dimension data so , we could just plot the hypothesi and see what wa go on and select the appropri degre polynomi .
so , earlier for the hous price exampl , we could just plot the hypothesi and , you know , mayb see that it wa fit the sort of veri wiggli function that goe all over the place to predict hous price .
and we could then us figur like these to select an appropri degre polynomi .
so plot the hypothesi , could be on wai to try to decid what degre polynomi to us .
but that doesn't alwai work .
and , in fact more often we mai have learn problem that where we just have a lot of featur .
and there is not just a matter of select what degre polynomi .
and , in fact , when we have so mani featur , it also becom much harder to plot the data and it becom much harder to visual it , to decid what featur to keep or not .
so concret , if we're try predict hous price sometim we can just have a lot of differ featur .
and all of these featur seem , you know , mayb thei seem kind of us .
but , if we have a lot of featur , and , veri littl train data , then , over fit can becom a problem .
in order to address over fit , there ar two main option for thing that we can do .
the first option is , to try to reduc the number of featur .
concret , on thing we could do is manual look through the list of featur , and , us that to try to decid which ar the more import featur , and , therefor , which ar the featur we should keep , and , which ar the featur we should throw out .
later in thi cours , where also talk about model select algorithm .
which ar algorithm for automat decid which featur to keep and , which featur to throw out .
thi idea of reduc the number of featur can work well , and , can reduc over fit .
and , when we talk about model select , we'll go into thi in much greater depth .
but , the disadvantag is that , by throw awai some of the featur , is also throw awai some of the inform you have about the problem .
for exampl , mayb , all of those featur ar actual us for predict the price of a hous , so , mayb , we don't actual want to throw some of our inform or throw some of our featur awai .
the second option , which we'll talk about in the next few video , is regular .
here , we're go to keep all the featur , but we're go to reduc the magnitud or the valu of the paramet theta j .
and , thi method work well , we'll see , when we have a lot of featur , each of which contribut a littl bit to predict the valu of y , like we saw in the hous price predict exampl .
where we could have a lot of featur , each of which ar , you know , somewhat us , so , mayb , we don't want to throw them awai .
so , thi subscrib the idea of regular at a veri high level .
and , i realiz that , all of these detail probabl don't make sens to you yet .
but , in the next video , we'll start to formul exactli how to appli regular and , exactli what regular mean .
and , then we'll start to figur out , how to us thi , to make how learn algorithm work well and avoid overfit .
in thi video , i'd like to convei to you , the main intuit behind how regular work .
and , we'll also write down the cost function that we'll us , when we were us regular .
with the hand drawn exampl that we have on these slide , i think i'll be abl to convei part of the intuit .
but , an even better wai to see for yourself , how regular work , is if you implement it , and , see it work for yourself .
and , if you do the appropri exercis after thi , you get the chanc to self see regular in action for yourself .
so , here is the intuit .
in the previou video , we saw that , if we were to fit a quadrat function to thi data , it give us a pretti good fit to the data .
wherea , if we were to fit an overli high order degre polynomi , we end up with a curv that mai fit the train set veri well , but , realli not be a , but overfit the data poorli , and , not gener well .
consid the follow , suppos we were to penal , and , make the paramet theta <num> and theta <num> realli small .
here's what i mean , here is our optim object , or here is our optim problem , where we minim our usual squar error caus function .
let's sai i take thi object and modifi it and add to it , plu <num> theta <num> squar , plu <num> theta <num> squar .
<num> i am just write down as some huge number .
now , if we were to minim thi function , the onli wai to make thi new cost function small is if theta <num> and data <num> ar small , right ?
becaus otherwis , if you have a thousand time theta <num> , thi new cost function gonna be big .
so when we minim thi new function we ar go to end up with theta <num> close to <num> and theta <num> close to <num> , and as if we're get rid of these two term over there .
and if we do that , well then , if theta <num> and theta <num> close to <num> then we ar be left with a quadrat function , and , so , we end up with a fit to the data , that's , you know , quadrat function plu mayb , tini contribut from small term , theta <num> , theta <num> , that thei mai be veri close to <num> .
and , so , we end up with essenti , a quadrat function , which is good .
becaus thi is a much better hypothesi .
in thi particular exampl , we look at the effect of penal two of the paramet valu be larg .
more gener , here is the idea behind regular .
the idea is that , if we have small valu for the paramet , then , have small valu for the paramet , will somehow , will usual correspond to have a simpler hypothesi .
so , for our last exampl , we penal just theta <num> and theta <num> and when both of these were close to zero , we wound up with a much simpler hypothesi that wa essenti a quadrat function .
but more broadli , if we penal all the paramet usual that , we can think of that , as try to give us a simpler hypothesi as well becaus when , you know , these paramet ar as close as you in thi exampl , that gave us a quadrat function .
but more gener , it is possibl to show that have smaller valu of the paramet correspond to usual smoother function as well for the simpler .
and which ar therefor , also , less prone to overfit .
i realiz that the reason for why have all the paramet be small .
why that correspond to a simpler hypothesi ; i realiz that reason mai not be entir clear to you right now .
and it is kind of hard to explain unless you implement yourself and see it for yourself .
but i hope that the exampl of have theta <num> and theta <num> be small and how that gave us a simpler hypothesi , i hope that help explain why , at least give some intuit as to why thi might be true .
let look at the specif exampl .
for hous price predict we mai have our hundr featur that we talk about where mai be x1 is the size , x2 is the number of bedroom , x3 is the number of floor and so on .
and we mai we mai have a hundr featur .
and unlik the polynomi exampl , we don't know , right , we don't know that theta <num> , theta <num> , ar the high order polynomi term .
so , if we have just a bag , if we have just a set of a hundr featur , it's hard to pick in advanc which ar the on that ar less like to be relev .
so we have a hundr or a hundr on paramet .
and we don't know which on to pick , we don't know which paramet to try to pick , to try to shrink .
so , in regular , what we're go to do , is take our cost function , here's my cost function for linear regress .
and what i'm go to do is , modifi thi cost function to shrink all of my paramet , becaus , you know , i don't know which on or two to try to shrink .
so i am go to modifi my cost function to add a term at the end .
like so we have squar bracket here as well .
when i add an extra regular term at the end to shrink everi singl paramet and so thi term we tend to shrink all of my paramet theta <num> , theta <num> , theta <num> up to theta <num> .
by the wai , by convent the summat here start from on so i am not actual go penal theta zero be larg .
that sort of the convent that , the sum i equal on through n , rather than i equal zero through n .
but in practic , it make veri littl differ , and , whether you includ , you know , theta zero or not , in practic , make veri littl differ to the result .
but by convent , usual , we regular onli theta through theta <num> .
write down our regular optim object , our regular cost function again .
here it is .
here's j of theta where , thi term on the right is a regular term and lambda here is call the regular paramet and what lambda doe , is it control a trade off between two differ goal .
the first goal , captur it by the first goal object , is that we would like to train , is that we would like to fit the train data well .
we would like to fit the train set well .
and the second goal is , we want to keep the paramet small , and that's captur by the second term , by the regular object .
and by the regular term .
and what lambda , the regular paramet doe is the control the trade of between these two goal , between the goal of fit the train set well and the goal of keep the paramet plan small and therefor keep the hypothesi rel simpl to avoid overfit .
for our hous price predict exampl , wherea , previous , if we had fit a veri high order polynomi , we mai have wound up with a veri , sort of wiggli or curvi function like thi .
if you still fit a high order polynomi with all the polynomi featur in there , but instead , you just make sure , to us thi sole of regular object , then what you can get out is in fact a curv that isn't quit a quadrat function , but is much smoother and much simpler and mayb a curv like the magenta line that , you know , give a much better hypothesi for thi data .
onc again , i realiz it can be a bit difficult to see why strengthen the paramet can have thi effect , but if you implement yourselv with regular you will be abl to see thi effect firsthand .
in regular linear regress , if the regular paramet monitor is set to be veri larg , then what will happen is we will end up penal the paramet theta <num> , theta <num> , theta <num> , theta <num> veri highli .
that is , if our hypothesi is thi is on down at the bottom .
and if we end up penal theta <num> , theta <num> , theta <num> , theta <num> veri heavili , then we end up with all of these paramet close to zero , right ?
theta <num> will be close to zero ; theta <num> will be close to zero .
theta three and theta four will end up be close to zero .
and if we do that , it's as if we're get rid of these term in the hypothesi so that we're just left with a hypothesi that will sai that .
it sai that , well , hous price ar equal to theta zero , and that is akin to fit a flat horizont straight line to the data .
and thi is an exampl of underfit , and in particular thi hypothesi , thi straight line it just fail to fit the train set well .
it's just a fat straight line , it doesn't go , you know , go near .
it doesn't go anywher near most of the train exampl .
and anoth wai of sai thi is that thi hypothesi ha too strong a preconcept or too high bia that hous price ar just equal to theta zero , and despit the clear data to the contrari , you know choos to fit a sort of , flat line , just a flat horizont line .
i didn't draw that veri well .
thi just a horizont flat line to the data .
so for regular to work well , some care should be taken , to choos a good choic for the regular paramet lambda as well .
and when we talk about multi select later in thi cours , we'll talk about a wai , a varieti of wai for automat choos the regular paramet lambda as well .
so , that's the idea of the high regular and the cost function review in order to us regular in the next two video , let take these idea and appli them to linear regress and to logist regress , so that we can then get them to avoid overfit .
for linear regress , we had previous work out two learn algorithm , on base on gradient descent and on base on the normal equat .
in thi video we will take those two algorithm and gener them to the case of regular linear regress .
here's the optim object , that we came up with last time for regular linear regress .
thi first part is our usual , object for linear regress , and we now have thi addit regular term , where londer is our regular paramet , and we like to find paramet theta , that minim thi cost function , thi regular cost function , j of theta .
previous , we were us gradient descent for the origin cost function , without the regular term , and we had the follow algorithm for regular linear regress , without regular .
we will repeatedli updat the paramet theta j as follow for j equal <num> , <num> up through n .
let me take thi and just write the case for theta zero separ .
so , you know , i'm just gonna write the updat for theta zero separ , then for the updat for the paramet <num> , <num> , <num> , and so on up to n .
so , i haven't chang anyth yet , right ?
thi is just write the updat for theta zero separ from the updat from theta <num> , theta <num> , theta <num> , up to theta n .
and the reason i want to do thi is you mai rememb that for our regular linear regress , we penal the paramet theta <num> , theta <num> , and so on up to theta n , but we don't penal theta zero .
so when we modifi thi algorithm for regular linear regress , we're go to end up treat theta zero slightli differ .
concret , if we want to take thi algorithm and modifi it to us the regular object , all we need to do is take thi term at the bottom and modifi as follow .
we're gonna take thi term and add minu londer m , time theta j .
and if you implement thi , then you have gradient descent for try to minim the regular cost function j of f theta , and concret , i'm not gonna do the calculu to prove it , but concret if you look at thi term , thi term that's written is squar bracket .
if you know calculu , it's possibl to prove that that term is the partial deriv , with respect of j of theta , us the new definit of j of theta with the regular term .
and somebodi on thi term up on top , which i guess i am draw the salient box that's still the partial deriv respect of theta zero for j of theta .
if you look at the updat for theta j , it's possibl to show's someth pretti interest , concret theta j get updat as theta j , minu alpha time , and then you have thi other term here that depend on theta j .
so if you group all the term togeth that depend on theta j .
we can show that thi updat can be written equival as follow and all i did wa have , you know , theta j here is theta j time <num> and thi term is londer over m .
there's also an alpha here , so you end up with alpha londer over m , multipli them to theta j and thi term here , on minu alpha time londer m , is a pretti interest term , it ha a pretti interest effect .
concret , thi term on minu alpha time londer over m , is go to be a number that's , you know , usual a number that's a loop and less than <num> , right ?
becaus of alpha time londer over m is go to be posit and usual , if you're learn rate is small and m is larg .
that's usual pretti small .
so thi term here , it's go to be a number , it's usual , you know , a littl bit less than on .
so think of it as a number like <num> . <num> , let's sai and so , the effect of our updat of theta j is we're go to sai that theta j get replac by thetata j time <num> . <num> .
all right so theta j time <num> . <num> ha the effect of shrink theta j a littl bit toward <num> .
so thi make theta j a bit smaller .
more formal , thi you know , thi squar norm of theta j is smaller and then after that the second term here , that's actual exactli the same as the origin gradient descent updat that we had .
befor we ad all thi regular stuff .
so , hopefulli thi gradient descent , hopefulli thi updat make sens , when we're us regular linear regress what we're do is on everi regular were multipli data j by a number that is a littl bit less than on , so we're shrink the paramet a littl bit , and then we're perform a , you know , similar updat as befor .
of cours that's just the intuit behind what thi particular updat is do .
mathemat , what it's do is exactli gradient descent on the cost function j of theta that we defin on the previou slide that us the regular term .
gradient descent wa just on our two algorithm for fit a linear regress model .
the second algorithm wa the on base on the normal equat where , what we did wa we creat the design matrix x where each row correspond to a separ train exampl .
and we creat a vector y , so thi is a vector that is an m dimension vector and that contain the label from a train set .
so wherea x is an m by n plu <num> dimension matrix .
y is an m dimension vector and in order to minim the cost function chang we found that of on wai to do is to set theta to be equal to thi .
we have x transpos x , invers x transpos y .
i am leav room here , to fill in stuff of cours .
and what thi valu for theta doe , is thi minim the cost function j of theta when we were not us regular .
now that we ar us regular , if you were to deriv what the minimum is , and just to give you a sens of how to deriv the minimum , the wai you deriv it is you know , take partial deriv in respect to each paramet , set thi to zero , and then do a bunch of math , and you can then show that is a formula like thi that minim the cost function .
and concret , if you ar us regular then thi formula chang as follow .
insid thi parenthesi , you end up with a matrix like thi .
zero , on , on , on and so on , on until the bottom .
so thi thing over here is a matrix , who's upper leftmost entri is zero .
there's on on the diagon and then the zero everywher els on thi matrix .
becaus i am draw thi a littl bit sloppi .
but as a concret exampl if n equal <num> , then thi matrix is go to be a three by three matrix .
more gener , thi matrix is a n plu on by n plu on dimension matrix .
so then n equal two then that matrix becom someth that look like thi .
zero , and then on on the diagon , and then zero on the rest of the diagon .
and onc again , you know , i'm not go to those thi deriv .
which is frankli somewhat long and involv .
but it is possibl to prove that if you ar us the new definit of j of theta , with the regular object .
then thi new formula for theta is the on that will give you the global minimum of j of theta .
so final , i want to just quickli describ the issu of non invert .
thi is rel advanc materi .
so you should consid thi as option and feel free to skip it or if you listen to it and you know , possibl it don't realli make sens , don't worri about it either .
but earlier when i talk the normal equat method .
we also had an option video on the non invert issu .
so thi is anoth option part , that is sort of add on earlier option video on non invert .
now consid set where m the number of exampl is less than or equal to n the number featur .
if you have fewer exampl then featur then thi matrix x transpos x will be non invert or singular , or the other term for thi is the matrix will be degener and if you implement thi in octav anywai , and you us the p in function to take the psuedo invers .
it will kind of do the right thing that is not clear that it will give you a veri good hypothesi even though numer the octav p in function will give you a result that kind of make sens .
but , if you were do thi in a differ languag .
and if you were take just the regular invers which an octav is denot with the function inv .
we're try to take the regular invers of x transpos x , then in thi set you find that x transpos x is singular , is non invert and if you're do thi in a differ program languag and us some linear algebra librari try to take the invers of thi matrix .
it just might not work becaus that matrix is non invert or singular .
fortun , regular also take care of thi for us , and concret , so long as the regular paramet is strictli greater than zero .
it is actual possibl to prove that thi matrix x transpos x plu paramet time , you know , s thi funni matrix here , is possibl to prove that thi matrix will not be singular and that thi matrix will be invert .
so us regular also take care of ani non invert issu of the x transpos x matrix as well .
so , you now know how to implement regular linear regress .
us thi , you'll be abl to avoid overfit , even if you have lot of featur in a rel small train set .
and thi should let you get linear regress to work much better for mani problem .
in the next video , we'll take thi regular idea and appli it to logist regress .
so that you'll be abl to get logist impress to avoid overfit and perform much better as well .
for logist regress , we previous talk about two type of optim algorithm .
we talk about how to us gradient descent to optim as cost function j of theta .
and we also talk about advanc optim method .
on that requir that you provid a wai to comput your cost function j of theta and that you provid a wai to comput the deriv .
in thi video , we'll show how you can adapt both of those techniqu , both gradient descent and the more advanc optim techniqu in order to have them work for regular logist regress .
so , here's the idea .
we saw earlier that logist regress can also be prone to overfit if you fit it with a veri , sort of , high order polynomi featur like thi .
where g is the sigmoid function and in particular you end up with a hypothesi , you know , whose decis bound to be just sort of an overli complex and extrem contort function that realli isn't such a great hypothesi for thi train set , and more gener if you have logist regress with a lot of featur .
not necessarili polynomi on , but just with a lot of featur you can end up with overfit .
thi wa our cost function for logist regress .
and if we want to modifi it to us regular , all we need to do is add to it the follow term plu londer over 2m , sum from j equal <num> , and as usual sum from j equal <num> .
rather than the sum from j equal <num> , of theta j squar .
and thi ha to effect therefor , of penal the paramet theta <num> theta <num> and so on up to theta n from be too larg .
and if you do thi , then it will the have the effect that even though you're fit a veri high order polynomi with a lot of paramet .
so long as you appli regular and keep the paramet small you're more like to get a decis boundari .
you know , that mayb look more like thi .
it look more reason for separ the posit and the neg exampl .
so , when us regular even when you have a lot of featur , the regular can help take care of the overfit problem .
how do we actual implement thi ?
well , for the origin gradient descent algorithm , thi wa the updat we had .
we will repeatedli perform the follow updat to theta j .
thi slide look a lot like the previou on for linear regress .
but what i'm go to do is write the updat for theta <num> separ .
so , the first line is for updat for theta <num> and a second line is now my updat for theta <num> up to theta n .
becaus i'm go to treat theta <num> separ .
and in order to modifi thi algorithm , to us a regular co function , all i need to do is pretti similar to what we did for linear regress is actual to just modifi thi second updat rule as follow .
and , onc again , thi , you know , cosmet look ident what we had for linear regress .
but of cours is not the same algorithm as we had , becaus now the hypothesi is defin us thi .
so thi is not the same algorithm as regular linear regress .
becaus the hypothesi is differ .
even though thi updat that i wrote down .
it actual look cosmet the same as what we had earlier .
we're work out gradient descent for regular linear regress .
and of cours , just to wrap up thi discuss , thi term here in the squar bracket , so thi term here , thi term is , of cours , the new partial deriv for respect of theta j of the new cost function j of theta .
where j of theta here is the cost function we defin on a previou slide that doe us regular .
so , that's gradient descent for regular linear regress .
let's talk about how to get regular linear regress to work us the more advanc optim method .
and just to remind you for those method what we need to do wa to defin the function that's call the cost function , that take us input the paramet vector theta and onc again in the equat we've been write here we us <num> index vector .
so we had theta <num> up to theta n .
but becaus octav index the vector start from <num> .
theta <num> is written in octav as theta <num> .
theta <num> is written in octav as theta <num> , and so on down to theta n plu <num> .
and what we need to do wa provid a function .
let's provid a function call cost function that we would then pass in to what we have , what we saw earlier .
we will us the fminunc and then you know at cost function , and so on , right .
but the f min , u and c wa the f min unconstrain and thi will work with fminunc wa what will take the cost function and minim it for us .
so the two main thing that the cost function need to return were first j val .
and for that , we need to write code to comput the cost function j of theta .
now , when we're us regular logist regress , of cours the cost function j of theta chang and , in particular , now a cost function need to includ thi addit regular term at the end as well .
so , when you comput j of theta be sure to includ that term at the end .
and then , the other thing that thi cost function thing need to deriv with a gradient .
so gradient on need to be set to the partial deriv of j of theta with respect to theta zero , gradient two need to be set to that , and so on .
onc again , the index is off by on .
right , becaus of the index from on octav user .
and look at these term .
thi term over here .
we actual work thi out on a previou slide is actual equal to thi .
it doesn't chang .
becaus the deriv for theta zero doesn't chang .
compar to the version without regular .
and the other term do chang .
and in particular the deriv respect to theta on .
we work thi out on the previou slide as well .
is equal to , you know , the origin term and then minu londer m time theta <num> .
just so we make sure we pass thi correctli .
and we can add parenthes here .
right , so the summat doesn't extend .
and similarli , you know , thi other term here look like thi , with thi addit term that we had on the previou slide , that correspond to the gradient from their regular object .
so if you implement thi cost function and pass thi into fminunc or to on of those advanc optim techniqu , that will minim the new regular cost function j of theta .
and the paramet you get out will be the on that correspond to logist regress with regular .
so , now you know how to implement regular logist regress .
when i walk around silicon vallei , i live here in silicon vallei , there ar a lot of engin that ar frankli , make a ton of monei for their compani us machin learn algorithm .
and i know we've onli been , you know , studi thi stuff for a littl while .
but if you understand linear regress , the advanc optim algorithm and regular , by now , frankli , you probabl know quit a lot more machin learn than mani , certainli now , but you probabl know quit a lot more machin learn right now than frankli , mani of the silicon vallei engin out there have veri success career .
you know , make ton of monei for the compani .
or build product us machin learn algorithm .
so , congratul .
you've actual come a long wai .
and you can actual , you actual know enough to appli thi stuff and get to work for mani problem .
so congratul for that .
but of cours , there's still a lot more that we want to teach you , and in the next set of video after thi , we'll start to talk about a veri power caus of non linear classifi .
so wherea linear regress , logist regress , you know , you can form polynomi term , but it turn out that there ar much more power nonlinear quantifi that can then sort of polynomi regress .
and in the next set of video after thi on , i'll start tell you about them .
so that you have even more power learn algorithm than you have now to appli to differ problem .
in thi and in the next set of video , i'd like to tell you about a learn algorithm call a neural network .
we're go to first talk about the represent and then in the next set of video talk about learn algorithm for it .
neutral network is actual a pretti old idea , but had fallen out of favor for a while .
but todai , it is the state of the art techniqu for mani differ machin learn problem .
so why do we need yet anoth learn algorithm ?
we alreadi have linear regress and we have logist regress , so why do we need , you know , neural network ?
in order to motiv the discuss of neural network , let me start by show you a few exampl of machin learn problem where we need to learn complex non linear hypothes .
consid a supervis learn classif problem where you have a train set like thi .
if you want to appli logist regress to thi problem , on thing you could do is appli logist regress with a lot of nonlinear featur like that .
so here , g as usual is the sigmoid function , and we can includ lot of polynomi term like these .
and , if you includ enough polynomi term then , you know , mayb you can get a hypothes that separ the posit and neg exampl .
thi particular method work well when you have onli , sai , two featur x1 and x2 becaus you can then includ all those polynomi term of x1 and x2 .
but for mani interest machin learn problem would have a lot more featur than just two .
we've been talk for a while about hous predict , and suppos you have a hous classif problem rather than a regress problem , like mayb if you have differ featur of a hous , and you want to predict what ar the odd that your hous will be sold within the next six month , so that will be a classif problem .
and as we saw we can come up with quit a lot of featur , mayb a hundr differ featur of differ hous .
for a problem like thi , if you were to includ all the quadrat term , all of these , even all of the quadrat that is the second or the polynomi term , there would be a lot of them .
there would be term like x1 squar , x1x2 , x1x3 , you know , x1x4 up to x1x100 and then you have x2 squar , x2x3 and so on .
and if you includ just the second order term , that is , the term that ar a product of , you know , two of these term , x1 time x1 and so on , then , for the case of n equal <num> , you end up with about five thousand featur .
and , asymptot , the number of quadrat featur grow roughli as order n squar , where n is the number of the origin featur , like x1 through x100 that we had .
and it actual closer to n squar over two .
so includ all the quadrat featur doesn't seem like it's mayb a good idea , becaus that is a lot of featur and you might up overfit the train set , and it can also be computation expens , you know , to be work with that mani featur .
on thing you could do is includ onli a subset of these , so if you includ onli the featur x1 squar , x2 squar , x3 squar , up to mayb x100 squar , then the number of featur is much smaller .
here you have onli <num> such quadrat featur , but thi is not enough featur and certainli won't let you fit the data set like that on the upper left .
in fact , if you includ onli these quadrat featur togeth with the origin x1 , and so on , up to x100 featur , then you can actual fit veri interest hypothes .
so , you can fit thing like , you know , access a line of the ellips like these , but you certainli cannot fit a more complex data set like that shown here .
so <num> featur seem like a lot , if you were to includ the cubic , or third order known of each other , the x1 , x2 , x3 .
you know , x1 squar , x2 , x10 and x11 , x17 and so on .
you can imagin there ar gonna be a lot of these featur .
in fact , thei ar go to be order and cube such featur and if ani is <num> you can comput that , you end up with on the order of about <num> , <num> such cubic featur and so includ these higher auto polynomi featur when your origin featur set end is larg thi realli dramat blow up your featur space and thi doesn't seem like a good wai to come up with addit featur with which to build none mani classifi when n is larg .
for mani machin learn problem , n will be pretti larg .
here's an exampl .
let's consid the problem of comput vision .
and suppos you want to us machin learn to train a classifi to examin an imag and tell us whether or not the imag is a car .
mani peopl wonder why comput vision could be difficult .
i mean when you and i look at thi pictur it is so obviou what thi is .
you wonder how is it that a learn algorithm could possibl fail to know what thi pictur is .
to understand why comput vision is hard let's zoom into a small part of the imag like that area where the littl red rectangl is .
it turn out that where you and i see a car , the comput see that .
what it see is thi matrix , or thi grid , of pixel intens valu that tell us the bright of each pixel in the imag .
so the comput vision problem is to look at thi matrix of pixel intens valu , and tell us that these number repres the door handl of a car .
concret , when we us machin learn to build a car detector , what we do is we come up with a label train set , with , let's sai , a few label exampl of car and a few label exampl of thing that ar not car , then we give our train set to the learn algorithm train a classifi and then , you know , we mai test it and show the new imag and ask , what is thi new thing ? .
and hopefulli it will recogn that that is a car .
to understand why we need nonlinear hypothes , let's take a look at some of the imag of car and mayb non car that we might feed to our learn algorithm .
let's pick a coupl of pixel locat in our imag , so that's pixel on locat and pixel two locat , and let's plot thi car , you know , at the locat , at a certain point , depend on the intens of pixel on and pixel two .
and let's do thi with a few other imag .
so let's take a differ exampl of the car and you know , look at the same two pixel locat and that imag ha a differ intens for pixel on and a differ intens for pixel two .
so , it end up at a differ locat on the figur .
and then let's plot some neg exampl as well .
that's a non car , that's a non car .
and if we do thi for more and more exampl us the pluse to denot car and minus to denot non car , what we'll find is that the car and non car end up ly in differ region of the space , and what we need therefor is some sort of non linear hypothes to try to separ out the two class .
what is the dimens of the featur space ?
suppos we were to us just <num> by <num> pixel imag .
now that suppos our imag were pretti small on , just <num> pixel on the side .
then we would have <num> pixel , and so the dimens of our featur size will be n equal <num> where our featur vector x is a list of all the pixel test , you know , the pixel bright of pixel on , the bright of pixel two , and so on down to the pixel bright of the last pixel where , you know , in a typic comput represent , each of these mai be valu between sai <num> to <num> if it give us the grayscal valu .
so we have n equal <num> , and that's if we were us grayscal imag .
if we were us rgb imag with separ red , green and blue valu , we would have n equal <num> .
so , if we were to try to learn a nonlinear hypothesi by includ all the quadrat featur , that is all the term of the form , you know , xi time xj , while with the <num> pixel we would end up with a total of three million featur .
and that's just too larg to be reason ; the comput would be veri expens to find and to repres all of these three million featur per train exampl .
so , simpl logist regress togeth with ad in mayb the quadrat or the cubic featur that's just not a good wai to learn complex nonlinear hypothes when n is larg becaus you just end up with too mani featur .
in the next few video , i would like to tell you about neural network , which turn out to be a much better wai to learn complex hypothes , complex nonlinear hypothes even when your input featur space , even when n is larg .
and along the wai i'll also get to show you a coupl of fun video of histor import applic of neural network as well that i hope those video that we'll see later will be fun for you to watch as well .
neural network ar a pretti old algorithm that wa origin motiv by the goal of have machin that can mimic the brain .
now in thi class , of cours i'm teach neural network to you becaus thei work realli well for differ machin learn problem and not , certainli not becaus thei're logic motiv .
in thi video , i'd like to give you some of the background on neural network .
so that we can get a sens of what we can expect them to do .
both in the sens of appli them to modern dai machineri problem , as well as for those of you that might be interest in mayb the big ai dream of somedai build truli intellig machin .
also , how neural network might pertain to that .
the origin of neural network wa as algorithm that try to mimic the brain and those a sens that if we want to build learn system while why not mimic perhap the most amaz learn machin we know about , which is perhap the brain .
neural network came to be veri wide us throughout the <num>'s and <num>'s and for variou reason as popular diminish in the late <num>'s .
but more recent , neural network have had a major recent resurg .
on of the reason for thi resurg is that neural network ar computation some what more expens algorithm and so , it wa onli , you know , mayb somewhat more recent that comput becam fast enough to realli run larg scale neural network and becaus of that as well as a few other technic reason which we'll talk about later , modern neural network todai ar the state of the art techniqu for mani applic .
so , when you think about mimick the brain while on of the human brain doe tell me same thing , right ?
the brain can learn to see process imag than to hear , learn to process our sens of touch .
we can , you know , learn to do math , learn to do calculu , and the brain doe so mani differ and amaz thing .
it seem like if you want to mimic the brain it seem like you have to write lot of differ piec of softwar to mimic all of these differ fascin , amaz thing that the brain tell us , but doe is thi fascin hypothesi that the wai the brain doe all of these differ thing is not worth like a thousand differ program , but instead , the wai the brain doe it is worth just a singl learn algorithm .
thi is just a hypothesi but let me share with you some of the evid for thi .
thi part of the brain , that littl red part of the brain , is your auditori cortex and the wai you're understand my voic now is your ear is take the sound signal and rout the sound signal to your auditori cortex and that's what's allow you to understand my word .
neuroscientist have done the follow fascin experi where you cut the wire from the ear to the auditori cortex and you re wire , in thi case an anim's brain , so that the signal from the ey to the optic nerv eventu get rout to the auditori cortex .
if you do thi it turn out , the auditori cortex will learn to see .
and thi is in everi singl sens of the word see as we know it .
so , if you do thi to the anim , the anim can perform visual discrimin task and as thei can look at imag and make appropri decis base on the imag and thei're do it with that piec of brain tissu .
here's anoth exampl .
that red piec of brain tissu is your somatosensori cortex .
that's how you process your sens of touch .
if you do a similar re wire process then the somatosensori cortex will learn to see .
becaus of thi and other similar experi , these ar call neuro rewir experi .
there's thi sens that if the same piec of physic brain tissu can process sight or sound or touch then mayb there is on learn algorithm that can process sight or sound or touch .
and instead of need to implement a thousand differ program or a thousand differ algorithm to do , you know , the thousand wonder thing that the brain doe , mayb what we need to do is figur out some approxim or to whatev the brain's learn algorithm is and implement that and that the brain learn by itself how to process these differ type of data .
to a surprisingli larg extent , it seem as if we can plug in almost ani sensor to almost ani part of the brain and so , within the reason , the brain will learn to deal with it .
here ar a few more exampl .
on the upper left is an exampl of learn to see with your tongu .
the wai it work is thi is actual a system call brainport undergo fda trial now to help blind peopl see but the wai it work is , you strap a grayscal camera to your forehead , face forward , that take the low resolut grayscal imag of what's in front of you and you then run a wire to an arrai of electrod that you place on your tongu so that each pixel get map to a locat on your tongu where mayb a high voltag correspond to a dark pixel and a low voltag correspond to a bright pixel and , even as it doe todai , with thi sort of system you and i will be abl to learn to see , you know , in ten of minut with our tongu .
here's a second exampl of human echo locat or human sonar .
so there ar two wai you can do thi .
you can either snap your finger , or click your tongu .
i can't do that veri well .
but there ar blind peopl todai that ar actual be train in school to do thi and learn to interpret the pattern of sound bounc off your environ that's sonar .
so , if after you search on youtub , there ar actual video of thi amaz kid who tragic becaus of cancer had hi eyebal remov , so thi is a kid with no eyebal .
but by snap hi finger , he can walk around and never hit anyth .
he can ride a skateboard .
he can shoot a basketbal into a hoop and thi is a kid with no eyebal .
third exampl is the haptic belt where if you have a strap around your waist , ring up buzzer and alwai have the northmost on buzz .
you can give a human a direct sens similar to mayb how bird can , you know , sens where north is .
and , some of the bizarr exampl , but if you plug a third ey into a frog , the frog will learn to us that ey as well .
so , it's pretti amaz to what extent is as if you can plug in almost ani sensor to the brain and the brain's learn algorithm will just figur out how to learn from that data and deal with that data .
and there's a sens that if we can figur out what the brain's learn algorithm is , and , you know , implement it or implement some approxim to that algorithm on a comput , mayb that would be our best shot at , you know , make real progress toward the ai , the artifici intellig dream of somedai build truli intellig machin .
now , of cours , i'm not teach neural network , you know , just becaus thei might give us a window into thi far off ai dream , even though i'm person , that's on of the thing that i person work on in my research life .
but the main reason i'm teach neural network in thi class is becaus it's actual a veri effect state of the art techniqu for modern dai machin learn applic .
so , in the next few video , we'll start dive into the technic detail of neural network so that you can appli them to modern dai machin learn applic and get them to work well on problem .
but for me , you know , on of the reason the excit me is that mayb thei give us thi window into what we might do if we're also think of what algorithm might somedai be abl to learn in a manner similar to humankind .
in thi video , i want to start tell you about how we repres neural network , in other word how we repres our hypothes or how we repres our model when us your neural network .
neural network were develop at simul neuron or network of neuron in the brain .
so , to explain the hypothes represent .
let's start by look at what a singl neuron in the brain look like .
your brain and mine is jam pack full of neuron like these and neuron ar cell in the brain and the two thing to draw attent to ar that first that the neuron ha a cell bodi like so and moreov , the neuron ha a number of input wire and these ar call the dendrit who think of them as input wire and these receiv input from other locat and the neuron also ha an output wire call the axon .
and thi output wire is what it us to send signal to other neuron or to send messag to other neuron .
so , at a simplist level , what a neuron is is a comput unit that get a number of input through it input wire , doe some comput .
and then it send output , via it axon to other node or other neuron in the brain .
here's an illustr of a group of neuron .
the wai that neuron commun with each other is with littl puls of electr .
thei're also call spike , but thei're just mean of littl puls of electr .
so , here's on neuron and what it doe is if it want to send a messag , what it doe is it send the littl puls of electr via it axon to some differ neuron and here thi axon .
there is thi open wire .
connect to the input wire or connect to the dendrit of thi second neuron over here , which then accept thi incom messag doe some comput and mai in turn decid to send out it o messag on it axon to other neuron .
and thi is the process by which all human thought happen as these neuron do comput and pass messag to other neuron as a result of what other input thei've got .
and by the wai , thi is how our sens and our muscl work as well .
if you want to move on of your muscl , the wai that work is that a neuron mai send these puls of electr to your muscl and that caus your muscl to contract and your ey if some sensor like your ey want to send a messag to your brain , what it doe is it send it puls of electr to a neuron in your brain like so .
in a neural network , or rather in an artifici neural network that we implement in a comput , we're go to us a veri simpl model of what a neuron doe .
we're go to model a neuron as just a logist unit .
so , when i draw a yellow circl like that , you should hink of that as plai a role analog to mayb the bodi of a neuron , and we then feed the neuron a few input via it dendrit or it input wire and the neuron doe some comput and output some valu on thi output wire or in a biolog neuron that sort the axon and whenev i draw a diagram like thi , what thi mean is that thi repres a comput of , you know , h of x equal <num> over <num> e to the neg theta transpos x where , as usual , x and theta ar our paramet vector like so .
so , thi is a veri simpl mayb a vastli over simplifi model of the comput that the neuron doe where it get the number of input , x1 , x2 , x3 and it output some valu comput like so .
when i draw a neural network , usual i draw onli the input nose x1 , x2 , x3 , sometim when it's us to do so .
i draw an extra node for x zero .
thi x zero node is sometim call the bia unit or the bia neuron but becaus x0 is alreadi equal to <num> .
sometim , i draw with it , sometim i won't just depend on whether there's more the rotation conveni for that exampl .
final , on last bit of terminolog when we talk about neural network , sometim we'll sai that thi is a neuron an artifici neuron with a sigmoid or a logist activ function .
so thi activ function in the neuronetro terminolog , thi is just anoth term for that function for that non linear g of z , equal <num> over <num> plu e to the neg z .
and wherea so far i've been call theta the paramet of the model ar mostli continu to us that terminolog to conjug to the paramet , but the neural network .
in the neural network literatur and sometim you might hear peopl talk about weight of a model and weight just mean exactli the same thing as paramet of the model .
but almost to us the terminolog paramet in these video , but sometim you mai hear other us the weight terminolog .
so , thi littl diagram repres a singl neuron .
what a neural network is is just a proof of these differ neuron strung togeth .
concret , here we have input unit x1 , x2 , and x3 and onc again , sometim can draw thi extra node x0 or sometim not .
so , i just draw that in here .
and here we have three neuron , which i have written , you know , a <num> <num> , a <num> <num> and a <num> <num> around top bottl indic later and onc again , we can if we want ad thi a0 and add an extra bia unit there .
it alwai output the valu of <num> .
then final we have thi third node at the final layer , and it's thi third node that open the valu that the hypothes h of x comput .
to introduc a bit more terminolog in a neural network , the first layer , thi is also call the input layer becaus thi is where we input our featur , x1 x2 x3 .
the final layer is also call the output layer becaus that layer ha the neuron thi on over here that output the final valu comput by a hypothes and then layer two in between , thi is call the hidden layer .
the term hidden layer isn't a great terminolog , but the intuit is that , you know , in supervis learn where you get to see the input , and you get to see the correct output .
wherea the hidden layer ar valu you don't get to observ in the train set .
if it's not x and it's not y and so we call those hidden .
and later on we'll see neural network with more than on hidden layer , but in thi exampl we have on input layer , layer <num> ; on hidden layer , layer <num> ; and on output layer , layer <num> .
but basic anyth that isn't an input layer and isn't a output layer is call a hidden layer .
so , i want to be realli clear about what thi neural network is do .
let's step through the comput step that ar embodi by thi , repres by thi diagram .
to explain the specif comput repres by a neural network , here's a littl bit more notat .
i'm go to us a superscript j subscript i to denot the activ of neuron i or of unit i in layer j .
so concret , thi a superscript <num> subscript <num> doe the activ of the first unit in layer <num> , in our hidden layer .
and by activ , i just mean , you know , the valu that is comput by and that is output by a specif .
in addit , our neural network is parametr by these matric , theta superscript j where our theta j is go to be a matrix of wave control the function map from on layer , mayb the first layer to the second layer or from the second layer to the third layer .
so , here ar the comput that ar repres by thi diagram .
thi first hidden unit here , ha it valu comput as follow is a a <num> <num> is equal to the sigmoid function , or the sigmoid activ function also call the logist activ function , appli to thi sort of linear combin of it input .
and then thi second hidden unit ha thi activ valu comput as sigmoid of thi .
and similarli , for thi third hidden unit , it's comput by that formula .
so here , we have three input unit and the three hidden unit .
and so the dimens of theta on which the matrix of paramet govern our map from all three input unit , about three hidden unit theta <num> is go to be a <num> , theta <num> is go to be a <num> by <num> dimension matrix and more gener , if a network ha sj unit and their j and sj <num> unit in their j <num> then the matrix theta j which govern the function map from layer j to layer j <num> that we'll have to mention sj <num> by sj <num> .
just be clear about thi notat , right ?
thi is s subscript j <num> and that's s subscript j , and then thi whole thing , plu <num> .
of thi whole thing , that's j <num> , okai ?
so that's s subscript j plu <num> plu , by so , that's s subscript j plu <num> by sj <num> where as plu <num> is not part of the subscript .
so , we talk about what the three hidden unit do to comput their valu .
final , thi last , the spinal in optim layer , we have on more unit which comput h of x and that's equal , can also be written as a <num> <num> and that's equal to thi .
and you notic that i've written thi with a superscript <num> here becaus theta superscript <num> is the matrix of paramet , or the matrix of weight that control the function that map from the hidden unit , that is the layer <num> unit , to the <num> layer <num> unit that is the output unit .
to summar , what we've done is shown how a pictur like thi over here defin an artifici neural network which defin a function h that map your x's input valu to hopefulli to some space and provis y ?
and these hypothes after parametr by paramet that i am denot with a capit theta so that as we be vari theta we get differ hypothes .
so we get differ function map sai from x to y .
so thi give us a mathemat definit of how to repres the hypothes in the neural network .
in the next few video , what i'd like to do is give you more intuit about what these hypothes represent do , as well as go through a few exampl and talk about how to comput them effici .
in the last video , we gave a mathemat definit of how to repres or how to comput the hypothes us by neural network .
in thi video , i like show you how to actual carri out that comput effici , and that is show you a vector rise implement .
and second , and more importantli , i want to start give you intuit about why these neural network represent might be a good idea and how thei can help us to learn complex nonlinear hypothes .
consid thi neural network .
previous we said that the sequenc of step that we need in order to comput the output of a hypothes is these equat given on the left where we comput the activ valu of the three hidden us and then we us those to comput the final output of our hypothes h of x .
now , i'm go to defin a few extra term .
so , thi term that i'm underlin here , i'm go to defin that to be z superscript <num> subscript <num> .
so that we have that a <num> <num> , which is thi term is equal to g of z to <num> .
and by the wai , these superscript <num> , you know , what that mean is that the z2 and thi a2 as well , the superscript <num> in parenthes mean that these ar valu associ with layer <num> , that is with the hidden layer in the neural network .
now thi term here i'm go to similarli defin as z <num> <num> .
and final , thi last term here that i'm underlin , let me defin that as z <num> <num> .
so that similarli we have a <num> <num> equal g of z <num> <num> .
so these z valu ar just a linear combin , a weight linear combin , of the input valu x0 , x1 , x2 , x3 that go into a particular neuron .
now if you look at thi block of number , you mai notic that that block of number correspond suspici similar to the matrix vector oper , matrix vector multipl of x1 time the vector x .
us thi observ we're go to be abl to vector thi comput of the neural network .
concret , let's defin the featur vector x as usual to be the vector of x0 , x1 , x2 , x3 where x0 as usual is alwai equal <num> and that defin z2 to be the vector of these z valu , you know , of z <num> <num> z <num> <num> , z <num> <num> .
and notic that , there , z2 thi is a three dimension vector .
we can now vector the comput of a <num> <num> , a <num> <num> , a <num> <num> as follow .
we can just write thi in two step .
we can comput z2 as theta <num> time x and that would give us thi vector z2 ; and then a2 is g of z2 and just to be clear z2 here , thi is a three dimension vector and a2 is also a three dimension vector and thu thi activ g .
thi appli the sigmoid function element wise to each of the z2's element .
and by the wai , to make our notat a littl more consist with what we'll do later , in thi input layer we have the input x , but we can also thing it is as in activ of the first layer .
so , if i defin a1 to be equal to x .
so , the a1 is vector , i can now take thi x here and replac thi with z2 equal theta1 time a1 just by defin a1 to be activ in my input layer .
now , with what i've written so far i've now gotten myself the valu for a1 , a2 , a3 , and realli i should put the superscript there as well .
but i need on more valu , which is i also want thi a <num> <num> and that correspond to a bia unit in the hidden layer that goe to the output there .
of cours , there wa a bia unit here too that , you know , it just didn't draw under here but to take care of thi extra bia unit , what we're go to do is add an extra a0 superscript <num> , that's equal to on , and after take thi step we now have that a2 is go to be a four dimension featur vector becaus we just ad thi extra , you know , a0 which is equal to <num> correspond to the bia unit in the hidden layer .
and final , to comput the actual valu output of our hypothes , we then simpli need to comput z3 .
so z3 is equal to thi term here that i'm just underlin .
thi inner term there is z3 .
and z3 is state <num> time a<num> and final my hypothes output h of x which is a3 that is the activ of my on and onli unit in the output layer .
so , that's just the real number .
you can write it as a3 or as a <num> <num> and that's g of z<num> .
thi process of comput h of x is also call forward propag and is call that becaus we start of with the activ of the input unit and then we sort of forward propag that to the hidden layer and comput the activ of the hidden layer and then we sort of forward propag that and comput the activ of the output layer , but thi process of comput the activ from the input then the hidden then the output layer , and that's also call forward propag and what we just did is we just work out a vector wise implement of thi procedur .
so , if you implement it us these equat that we have on the right , these would give you an effici wai or both of the effici wai of comput h of x .
thi forward propag view also help us to understand what neural network might be do and why thei might help us to learn interest nonlinear hypothes .
consid the follow neural network and let's sai i cover up the left path of thi pictur for now .
if you look at what's left in thi pictur .
thi look a lot like logist regress where what we're do is we're us that note , that's just the logist regress unit and we're us that to make a predict h of x .
and concret , what the hypothes is output is h of x is go to be equal to g which is my sigmoid activ function time theta <num> time a0 is equal to <num> plu theta <num> plu theta <num> time a2 plu theta <num> time a<num> whether valu a1 , a2 , a3 ar those given by these three given unit .
now , to be actual consist to my earli notat .
actual , we need to , you know , fill in these superscript <num>'s here everywher and i also have these indic <num> there becaus i have onli on output unit , but if you focu on the blue part of the notat .
thi is , you know , thi look awfulli like the standard logist regress model , except that i now have a capit theta instead of lower case theta .
and what thi is do is just logist regress .
but where the featur fed into logist regress ar these valu comput by the hidden layer .
just to sai that again , what thi neural network is do is just like logist regress , except that rather than us the origin featur x1 , x2 , x3 , is us these new featur a1 , a2 , a3 .
again , we'll put the superscript there , you know , to be consist with the notat .
and the cool thing about thi , is that the featur a1 , a2 , a3 , thei themselv ar learn as function of the input .
concret , the function map from layer <num> to layer <num> , that is determin by some other set of paramet , theta <num> .
so it's as if the neural network , instead of be constrain to feed the featur x1 , x2 , x3 to logist regress .
it get to learn it own featur , a1 , a2 , a3 , to feed into the logist regress and as you can imagin depend on what paramet it choos for theta <num> .
you can learn some pretti interest and complex featur and therefor you can end up with a better hypothes than if you were constrain to us the raw featur x1 , x2 or x3 or if you will constrain to sai choos the polynomi term , you know , x1 , x2 , x3 , and so on .
but instead , thi algorithm ha the flexibl to try to learn whatev featur at onc , us these a1 , a2 , a3 in order to feed into thi last unit that's essenti a logist regress here .
i realiz thi exampl is describ as a somewhat high level and so i'm not sure if thi intuit of the neural network , you know , have more complex featur will quit make sens yet , but if it doesn't yet in the next two video i'm go to go through a specif exampl of how a neural network can us thi hidden there to comput more complex featur to feed into thi final output layer and how that can learn more complex hypothes .
so , in case what i'm sai here doesn't quit make sens , stick with me for the next two video and hopefulli out there work through those exampl thi explan will make a littl bit more sens .
but just the point o .
you can have neural network with other type of diagram as well , and the wai that neural network ar connect , that's call the architectur .
so the term architectur refer to how the differ neuron ar connect to each other .
thi is an exampl of a differ neural network architectur and onc again you mai be abl to get thi intuit of how the second layer , here we have three head unit that ar comput some complex function mayb of the input layer , and then the third layer can take the second layer's featur and comput even more complex featur in layer three so that by the time you get to the output layer , layer four , you can have even more complex featur of what you ar abl to comput in layer three and so get veri interest nonlinear hypothes .
by the wai , in a network like thi , layer on , thi is call an input layer .
layer four is still our output layer , and thi network ha two hidden layer .
so anyth that's not an input layer or an output layer is call a hidden layer .
so , hopefulli from thi video you've gotten a sens of how the feed forward propag step in a neural network work where you start from the activ of the input layer and forward propag that to the first hidden layer , then the second hidden layer , and then final the output layer .
and you also saw how we can vector that comput .
in the next , i realiz that some of the intuit in thi video of how , you know , other certain layer ar comput complex featur of the earli layer .
i realiz some of that intuit mai be still slightli abstract and kind of a high level .
and so what i would like to do in the two video is work through a detail exampl of how a neural network can be us to comput nonlinear function of the input and hope that will give you a good sens of the sort of complex nonlinear hypothes we can get out of neural network .
in thi and the next video i want to work through a detail exampl , show how a neural network can comput a complex nonlinear function of the input and hopefulli , thi will give you a good sens of why neural network can be us to learn complex , nonlinear hypothes .
consid the follow problem where we have input featur x1 and x2 that ar binari valu , so either zero or on .
so x1 and x2 can each take on onli on of two possibl valu .
in thi exampl , i've drawn onli two posit exampl and two neg exampl , but you can think of thi as a simplifi version of a more complex learn problem where we mai have a bunch of posit exampl in the upper right and the lower left and a bunch of neg exampl to notifi the circl , and what we'd like to do is learn a nonlinear , you know , decis boundari that we need to separ the posit and the neg exampl .
so how can a neural network do thi and rather than us an exampl on the right .
i'm go to us thi , mayb easier to examin exampl on the left .
concret , what thi is is realli comput the target label y equal x1 xor x2 .
or thi is actual the x1 xnor x2 function where xnor is the altern notat for not x1 or x2 .
so x1 , xor or x2 that's true onli if exactli on of x<num> or x2 is equal to <num> .
it turn out that the specif exampl i'm go to us work out a littl bit better if we us the xnor exampl , instead .
these two ar the same , of cours .
it mean not x1 xor x2 , and so we're go to have posit exampl if either both ar true or both ar fals and we'll have that's y equal <num> , y equal <num> and we're go to have y equal <num> if onli on of them is true and we want to figur out if we can get a neural network to fit to thi sort of train set .
in order to build up to a network that fit the xnor exampl , we're go to start to a slightli simpler on and show a network that fit the and function .
concret , let sai we have input x1 and x2 that ar again binari .
so , it's either zero or on .
and let's sai our target label y ar you know , is equal to x1 and x2 .
thi is a logic and .
so can we get a on unit network to comput thi logic and function ?
in order to do so , i'm go to actual draw in the bia unit as well , the plu on unit .
now , let me just assign some valu to the weight or the paramet of thi network .
i am go to write down the paramet on thi diagram .
write minu <num> here plu <num> and plu <num> and what thi mean is that i'm assign a valu of minu thirti to the valu associ with x0 .
thi is plu <num> go to thi unit and a paramet valu of plu <num> that multipli in x1 in a valu of plu <num> for the paramet that multipli into x2 .
so , concret , thi is sai that my hypothes h of x is equal to g of <num> 20x1 20x2 .
so sometim it's just conveni to draw these weight and draw these paramet up here , you know , in the diagram of the neural network .
and of cours thi minu <num> thi is actual theta <num> of <num> , <num> .
thi is theta <num> of <num> , <num> and that's theta <num> of <num> , <num> but it's just easier think about it as , you know , associ these paramet with the edg of the network .
let's look at what thi littl singl neuron network will comput .
just to remind you , the sigmoid activ function g of z look like thi .
it start from <num> , rise smoothli , cross <num> , and then it asymptot at on .
and to give you some landmark , if the horizont axi valu z is equal to <num> , then the sigmoid function is equal to <num> . <num> .
thi is veri close to <num> and kind of symmetr if it is neg <num> , then the sigmoid function there is equal to <num> . <num> which is veri close to <num> .
let's look at the four possibl input valu for x1 and x2 and look at whether the hypothesi will open in that case .
if x1 and x2 ar both equal to <num> if you look at thi , if x1 and x2 ar both equal to <num> then the hypothes of point g of <num> .
so , it's like veri far to the left of thi diagram .
thi will be veri close to <num> .
if x1 equal <num> and x2 equal <num> then thi formula here evalu to g , thu the sigmoid function appli to <num> and again , that's , you know , to the far left of thi plot and so , that's again veri close to <num> .
thi is also g of <num> .
that is if x1 is equal to <num> and x <num> <num> , thi is <num> plu <num> , which is <num> .
and final if x<num> equal <num> , x2 equal <num> , then you have g of <num> <num> <num> , so that's g of <num> , which is therefor veri close to <num> .
and if you look in thi column , thi is exactli the logic and function .
so , thi is comput h of x is , you know , approxim x1 and x2 .
in other word , it output <num> if and onli if x1 and x2 ar both equal to <num> .
so by write out our littl truth tabl like thi , we manag to figur out what's the logic function that our neural network comput .
thi network shown here comput the or function just to show you how i work that out .
if you ar to write out the hypothes you find that it's comput g of <num> <num> x1 <num> x2 .
and so if you fill in these valu you find that's g of <num> which is approxim <num> , g of <num> which is approxim <num> , and so on .
these ar approxim <num> , and approxim <num> , and these number is essenti the logic or function .
so , hopefulli with thi , you now understand how singl neuron in a neural network can be us to comput logic function like and and or and so on .
in the next video , we'll continu build on these exampl and work through a more complex exampl .
we'll get to show you how a neural network , now with multipl layer of unit can be us to comput more complex function like the xor function or the xnor function .
in thi video , i'd like you to work in through our exampl to show how a neural network can comput complex nonlinear hypothes .
in the last video , we saw how a neural network can be us to comput the function x1 and x2 and the function x1 or x2 when x1 and x2 ar binari .
that is , when thei take on valu of <num> , <num> .
we can also have a network to comput negat , that is to comput the function not x1 .
let me just write down the wai associ with thi network .
we have onli on input featur , x1 in thi case and the bia unit plu <num> and if i associ thi with the weight <num> and <num> then my hypothes is comput thi .
h of x equal sigmoid of <num> minu <num> time x1 so when x1 is equal to <num> , my hypothesi will be comput g of <num> minu <num> time <num> which is just <num> .
and so that's approxim <num> , and when is x is equal to <num> thi will be g of <num> , which is therefor approxim equal to <num> .
and if you look at what these valu ar , that's essenti the not x1 function .
so to includ negat , the gener idea is to put a larg neg weight in front of the variabl you want to negat .
so if it's <num> , multipli by x1 and , you know , that's the gener idea of how you end up negat x1 .
and so , in an exampl that i hope you will figur out yourself , if you want to comput a function like thi not x1 and not x2 you know , while part of that would probabl be put larg neg weight in front of x1 and x2 , but it should be feasibl to get a neural network with just on output unit to comput thi as well .
all right ?
so , thi larg fill function not x1 and not x2 is go to be equal to <num> if , and onli if , x1 equal x2 equal zero , right ?
so thi is a logic function , thi is not x1 , that mean x1 must be zero and not x2 .
that mean x2 must be equal to zero as well .
so thi logic function is equal to <num> if , and onli if , both x1 and x2 ar equal to zero .
and hopefulli , you should be abl to figur out how to make a small neural network to comput thi logic function as well .
now , take the three piec that we have put togeth , the network for comput x1 and x2 and the network for comput not x1 and not x2 and on last network for comput x1 or x2 , we should be abl to put these three piec togeth to comput thi x1 , xnor x2 function .
and just to remind you , if thi wa x1 , x2 , thi function that we want to comput would have neg exampl here and here and we'd have posit exampl there and there .
and so clearli thi , you know , we'll need a nonlinear decis boundari in order to separ the posit and neg exampl .
let's draw the network .
i'm go to take my input plu <num> , x<num> , x2 , and creat my first hidden unit here .
i'm go to call thi a <num> <num> becaus that's my first hidden unit .
and i'm go to copi the weight over from the red network , x1 and x2 network .
so now minu <num> , <num> , <num> .
next , let me creat a second hidden unit , which i'm go to call a <num> <num> that is the second hidden unit of layer two .
and i'm go to copi over the cyan network in the middl , so i'm go to have the weight <num> , minu <num> , minu <num> .
and so , let's pull some of the truth tabl valu .
for the red network , we know that wa comput the x1 and x2 .
and so thi is go to be approxim <num> , <num> , <num> , <num> , depend on the valu of x<num> and x2 .
and for a <num> <num> , that's the cyan network .
well that we know the function not x1 and not x2 then output <num> , <num> , <num> , <num> for the <num> valu of x1 and x2 .
final , i'm go to creat my output note , my output unit that is a <num> <num> .
thi is on more output h of x and i'm go to copi over the or network for that and i'm go to need a plu on bia unit here .
so , draw that in and i'm go to copi over the weight from the green network .
so , it's minu <num> , <num> , <num> and we know earlier that thi comput the or function .
so , let's go on the truth tabl entri .
for the first entri is <num> or <num> , which is gonna be <num> then next <num> or <num> , which is <num> , <num> , or <num> , which is <num> , <num> or <num> and that all is to <num> and thu , h of x is equal to <num> when either both x1 and x2 ar <num> or when x1 and x2 ar both <num> .
and concret , h of x output <num> exactli at these two locat and it output <num> otherwis and thu , with thi neural network , which ha an input layer , on hidden layer and on output layer , we end up with a nonlinear decis boundari that comput thi xnor function .
and the more gener intuit is that in the input layer , we just had our raw input then we had a hidden layer , which comput some slightli more complex function of the input that is shown here , these ar slightli more complex function , and then by ad yet anoth layer , we end up with an even more complex nonlinear function .
and thi is the sort of intuit about why neural network can comput pretti complic function that when you have multipl layer , you have , you know , rel simpl function of the input , and the second layer , but the third layer can build on that to comput even more complex function and then the layer after that can comput even more complex function .
to wrap up thi video , i want to show you a fun exampl of an applic of a neural network that captur thi intuit of the deeper layer comput more complex featur .
i want to show you a video that i got from a good friend of mine , yon khun .
yon is a professor at new york univers , at nyu , and he wa on of the earli pioneer of neural network research and sort of a legend in the field now and hi idea ar us in all sort of product and applic throughout the world now .
so , i want to show you a video from some of hi earli work in which he wa us a neural network to recogn handwrit to do handwritten digit recognit .
you might rememb earli in thi class , at the start of thi class , i said that on of earli success of neural network wa try to us it to read zip code , to help us , you know , send mail along .
so , to read postal code .
so , thi is on of the attempt .
so , thi is on of the algorithm us to try to address that problem .
in the video i'll show you thi area here is the input area that show a handwritten charact shown to the network .
thi column here show a visual of the featur comput by so that the first hidden layer of the network and so the first hidden layer , you know , thi visual show differ featur , differ edg and line and so on detect .
thi is a visual of the next hidden layer .
it's kind of harder to see how to understand deeper hidden layer and that's the visual of what the next hidden layer is comput .
you probabl have a hard time see what's go on , you know , much beyond the first hidden layer , but then final , all of these learn featur get fed to the output layer and shown over here is the final answer , the final predict valu for what handwritten digit the neural network thing that is be shown .
so , let's take a look at the video .
so , i hope you enjoi the video and that thi hopefulli gave you some intuit about the sort of pretti complic function neural network can learn in which it take thi input thi imag , just take thi input the raw pixel and the first end of the layer comput some set of featur , the next end of the layer comput even more complex featur and even more complex featur and these featur can then be us by essenti the final layer of logist regress classifi to make accur predict about what ar the number that the network see .
in thi video , i want to tell you about how to us neural network to do multiclass classif where we mai have more than on categori that we're try to distinguish amongst .
in the last part of the last video , where we had the handwritten digit recognit problem , that wa actual a multiclass classif problem becaus there were ten possibl categori for recogn the digit from <num> through <num> and so , if you want us to fill you in on the detail of how to do that .
the wai we do multiclass classif in a neural network is essenti an extens of the on versu all method .
so , let's sai that we have a comput vision exampl , where instead of just try to recogn car as in the origin exampl that i start off with , but let's sai that we're try to recogn , you know , four categori of object and given an imag we want to decid if it is a pedestrian , a car , a motorcycl or a truck .
if that's the case , what we would do is we would build a neural network with four output unit so that our neural network now output a vector of four number .
so , the output now is actual need to be a vector of four number and what we're go to try to do is get the first output unit to classifi is the imag a pedestrian , ye or no .
the second unit to classifi is the imag a car , ye or no .
thi unit to classifi is the imag a motorcycl , ye or no , and thi would classifi is the imag a truck , ye or no .
and thu , when the imag is of a pedestrian , we would ideal want the network to output <num> , <num> , <num> , <num> , when it is a car we want it to output <num> , <num> , <num> , <num> , when thi is a motorcycl , we get it to or rather , we want it to output <num> , <num> , <num> , <num> and so on .
so thi is just like the on versu all method that we talk about when we were describ logist regress , and here we have essenti four logist regress classifi , each of which is try to recogn on of the four class that we want to distinguish amongst .
so , rearrang the slide of it , here's our neural network with four output unit and those ar what we want h of x to be when we have the differ imag , and the wai we're go to repres the train set in these set is as follow .
so , when we have a train set with differ imag of pedestrian , car , motorcycl and truck , what we're go to do in thi exampl is that wherea previous we had written out the label as y be an integ from <num> , <num> , <num> or <num> .
instead of repres y thi wai , we're go to instead repres y as follow name yi will be either <num> , <num> , <num> , <num> or <num> , <num> , <num> , <num> or <num> , <num> , <num> , <num> or <num> , <num> , <num> , <num> depend on what the correspond imag xi is .
and so on train exampl will be on pair xi colon yi where xi is an imag with , you know on of the four object and yi will be on of these vector .
and hopefulli , we can find a wai to get our neural network to output some valu .
so , the h of x is approxim y and both h of x and yi , both of these ar go to be in our exampl , four dimension vector when we have four class .
so , that's how you get neural network to do multiclass classif .
thi wrap up our discuss on how to repres neural network that is on our hypothes represent .
in the next set of video , let's start to talk about how take a train set and how to automat learn the paramet of the neural network .
neural network ar on of the most power learn algorithm that we have todai .
in thi , and in the next few video , i'd like to start talk about a learn algorithm for fit the paramet of the neural network given the train set .
as for the discuss of most of the learn algorithm , we're go to begin by talk about the cost function for fit the paramet of the network .
i'm go to focu on the applic of neural network to classif problem .
so , suppos we have a network like that shown on the left .
and suppos we have a train set like thi of thi of xi , yi pair of m train exampl .
i'm go to us upper case l to denot the total number of layer in thi network .
so , for the network shown on the left , we would have capit l equal <num> .
and , i'm go to us s subscript l , to denot the number of unit , that is a number of neuron , not count the bia unit in layer l of the network .
so , for exampl , we would have a s1 which is the input layer equal s3 unit , s2 in my exampl is five unit .
and the output layer s4 .
which is also equal sl , becaus capit l is equal to four .
the output layer in my exampl in the left ha four unit .
we're go to consid two type of classif problem .
the first is binari classif , where the label y ar either zero or on .
in thi case , we would have on output unit .
so , thi neural network on top ha four output unit , but if we had binari classif , we would have onli on output unit that comput h of x .
and the output of the neural network would be h of x is go to be a real number .
and in thi case the number of output unit , sl , where l is again the index of the final layer becaus that's the number of layer we have in the network .
so the number of unit we have in the output layer is go to be equal to on .
in thi case , to simplifi notat later , i'm also go to set k equal <num> .
so , you can think of k as also denot the number of unit in the output layer .
the second type of classif problem we'll consid will be multiclass classif problem where we mai have k distinct class .
so , our earli exampl , i had thi represent for y if we have four class and in thi case , we would have cap lock k output unit and our hypothes will output vector that ar k dimension .
and the number of output unit will be equal to k .
and usual we will have k greater than or equal to three in thi case , becaus if we had two class then , you know , we don't need to us the on versu all method .
we need to us the on versu all method onli if we have k greater than or equal to three class so we onli have two class we will need to us onli on output unit .
now , let's defin the cost function for our cost function for our neural network .
the cost function we us for the neural network is go to be a gener of the on that we us for logist regress .
for logist regress , we us to minim the cost function j of theta that wa minu <num> over m of thi cost function and then plu thi extra regular term here , where thi wa a sum from j equal <num> through n , becaus we did not regular the bia term theta zero .
for a neural network our cost function is go to be a gener of thi .
where instead of have basic just on logist regress output unit , we mai instead have k of them .
so here's our cost function .
neural network now output vector in rk where k might be equal to <num> if we have the binari classif problem .
i'm go to us thi notat , h of x subscript i , to denot the ith output .
that is h of x is a k dimension vector .
and so thi subscript i just select out the ith element of the vector that is output by my neural network .
my cost function , j of theta is now go to be the follow is minu on over m of a sum of a similar term to what we have in logist regress .
except that we have thi sum from k equal on through k .
the summat is basic a sum over my k output unit .
so , if i have four upper unit .
that is the final layer of my neural network ha four output unit then thi sum from , thi is a sum from k equal on through four of basic the logist regress algorithm cost function but sum that cost function over each of my four output unit in turn .
and so , you notic in particular that thi appli to yk , hk , becaus we're basic take the k upper unit and compar that to the valu of yk , which is you know , which is that on of those vector to sai what caus it should be .
and final , the second term here is the regular term similar to what we had for logist regress .
thi summat term look realli complic and alwai do is a sum over these term , theta j i l for all valu of i j and l .
except that we don't sum over the term correspond to these bia valu like we had for logist progress .
concret , we don't sum over the term correspond to where i is equal to zero .
so , that is becaus when we ar comput the activ of the neuron , we have term like these , you know theta , i0 plu theta , i1 , x1 plu , and so on , where i guess we could have a <num> there if thi is the first hidden layer , and so the valu with the <num> there at that correspond to someth that multipli into an x0 or an a0 and so , thi is kind of like a bia unit and by analog to what we were do for logist progress , we won't sum over those term in our regular term becaus we don't want to regular them and string the valu <num> .
but thi is just on possibl convent and even if you were to sum over , you know , i equal <num> up to sl , it will work about the same and it doesn't make a big differ .
but mayb thi convent of not regular the bia term is just slightli more common .
so , that's the cost function we're go to us to fill on your own network .
in the next video , we'll start to talk about an algorithm for try to optim the cost function .
in the previou video , we talk about a cost function for the neural network .
in thi video , let's start to talk about an algorithm , for try to minim the cost function .
in particular , we'll talk about the back propag algorithm .
here's the cost function that we wrote down in the previou video .
what we'd like to do is try to find paramet theta to try to minim j of theta .
in order to us either gradient descent or on of the advanc optim algorithm .
what we need to do therefor is to write code that take thi input the paramet theta and comput j of theta and these partial deriv term .
rememb , that the paramet in the the neural network of these thing , theta superscript l subscript ij , that's the real number and so , these ar the partial deriv term we need to comput .
in order to comput the cost function j of theta , we just us thi formula up here and so , what i want to do for the most of thi video is focu on talk about how we can comput these partial deriv term .
let's start by talk about the case of when we have onli on train exampl , so imagin , if you will that our entir train set compris onli on train exampl which is a pair xy .
i'm not go to write x1y1 just write thi .
write a on train exampl as xy and let's tap through the sequenc of calcul we would do with thi on train exampl .
the first thing we do is we appli forward propag in order to comput whether a hypothes actual output given the input .
concret , the call the a <num> is the activ valu of thi first layer that wa the input there .
so , i'm go to set that to x and then we're go to comput z <num> equal theta <num> a <num> and a <num> equal g , the sigmoid activ function appli to z <num> and thi would give us our activ for the first middl layer .
that is for layer two of the network and we also add those bia term .
next we appli <num> more step of thi four and propag to comput a <num> and a <num> which is also the upward of a hypothes h of x .
so thi is our vector implement of forward propag and it allow us to comput the activ valu for all of the neuron in our neural network .
next , in order to comput the deriv , we're go to us an algorithm call back propag .
the intuit of the back propag algorithm is that for each note we're go to comput the term delta superscript l subscript j that's go to somehow repres the error of note j in the layer l .
so , recal that a superscript l subscript j that doe the activ of the j of unit in layer l and so , thi delta term is in some sens go to captur our error in the activ of that neural duo .
so , how we might wish the activ of that note is slightli differ .
concret , take the exampl neural network that we have on the right which ha four layer .
and so capit l is equal to <num> .
for each output unit , we're go to comput thi delta term .
so , delta for the j of unit in the fourth layer is equal to just the activ of that unit minu what wa the actual valu of <num> in our train exampl .
so , thi term here can also be written h of x subscript j , right .
so thi delta term is just the differ between when a hypothes output and what wa the valu of y in our train set wherea y subscript j is the j of element of the vector valu y in our label train set .
and by the wai , if you think of delta a and y as vector then you can also take those and come up with a vector implement of it , which is just delta <num> get set as a4 minu y .
where here , each of these delta <num> a<num> and y , each of these is a vector whose dimens is equal to the number of output unit in our network .
so we've now comput the era term's delta <num> for our network .
what we do next is comput the delta term for the earlier layer in our network .
here's a formula for comput delta <num> is delta <num> is equal to theta <num> transpos time delta <num> .
and thi dot time , thi is the element y's multipl oper that we know from matlab .
so delta <num> transpos delta <num> , that's a vector ; g prime z3 that's also a vector and so dot time is in element y's multipl between these two vector .
thi term g prime of z3 , that formal is actual the deriv of the activ function g evalu at the input valu given by z3 .
if you know calculu , you can try to work it out yourself and see that you can simplifi it to the same answer that i get .
but i'll just tell you pragmat what that mean .
what you do to comput thi g prime , these deriv term is just a3 dot time1 minu a3 where a3 is the vector of activ .
<num> is the vector of on and a3 is again the activ the vector of activ valu for that layer .
next you appli a similar formula to comput delta <num> where again that can be comput us a similar formula .
onli now it is a2 like so and i then prove it here but you can actual , it's possibl to prove it if you know calculu that thi express is equal to mathemat , the deriv of the g function of the activ function , which i'm denot by g prime .
and final , that's it and there is no delta1 term , becaus the first layer correspond to the input layer and that's just the featur we observ in our train set , so that doesn't have ani error associ with that .
it's not like , you know , we don't realli want to try to chang those valu .
and so we have delta term onli for layer <num> , <num> and for thi exampl .
the name back propag come from the fact that we start by comput the delta term for the output layer and then we go back a layer and comput the delta term for the third hidden layer and then we go back anoth step to comput delta <num> and so , we're sort of back propag the error from the output layer to layer <num> to their to henc the name back complic .
final , the deriv is surprisingli complic , surprisingli involv but if you just do thi few step step of comput it is possibl to prove viral frankli some what complic mathemat proof .
it's possibl to prove that if you ignor author then the partial deriv term you want ar exactli given by the activ and these delta term .
thi is ignor lambda or altern the regular term lambda will equal to <num> .
we'll fix thi detail later about the regular term , but so by perform back propag and comput these delta term , you can , you know , pretti quickli comput these partial deriv term for all of your paramet .
so thi is a lot of detail .
let's take everyth and put it all togeth to talk about how to implement back propag to comput deriv with respect to your paramet .
and for the case of when we have a larg train set , not just a train set of on exampl , here's what we do .
suppos we have a train set of m exampl like that shown here .
the first thing we're go to do is we're go to set these delta l subscript i j .
so thi triangular symbol ?
that's actual the capit greek alphabet delta .
the symbol we had on the previou slide wa the lower case delta .
so the triangl is capit delta .
we're gonna set thi equal to zero for all valu of l i j .
eventu , thi capit delta l i j will be us to comput the partial deriv term , partial deriv respect to theta l i j of j of theta .
so as we'll see in a second , these delta ar go to be us as accumul that will slowli add thing in order to comput these partial deriv .
next , we're go to loop through our train set .
so , we'll sai for i equal <num> through m and so for the i iter , we're go to work with the train exampl xi , yi .
so the first thing we're go to do is set a1 which is the activ of the input layer , set that to be equal to xi is the input for our i train exampl , and then we're go to perform forward propag to comput the activ for layer two , layer three and so on up to the final layer , layer capit l .
next , we're go to us the output label yi from thi specif exampl we're look at to comput the error term for delta l for the output there .
so delta l is what a hypothes output minu what the target label wa ?
and then we're go to us the back propag algorithm to comput delta l minu <num> , delta l minu <num> , and so on down to delta <num> and onc again there is now delta <num> becaus we don't associ an error term with the input layer .
and final , we're go to us these capit delta term to accumul these partial deriv term that we wrote down on the previou line .
and by the wai , if you look at thi express , it's possibl to vector thi too .
concret , if you think of delta ij as a matrix , index by subscript ij .
then , if delta l is a matrix we can rewrit thi as delta l , get updat as delta l plu lower case delta l plu on time al transpos .
so that's a vector implement of thi that automat doe an updat for all valu of i and j .
final , after execut the bodi of the four loop we then go outsid the four loop and we comput the follow .
we comput capit d as follow and we have two separ case for j equal zero and j not equal zero .
the case of j equal zero correspond to the bia term so when j equal zero that's why we're miss is an extra regular term .
final , while the formal proof is pretti complic what you can show is that onc you've comput these d term , that is exactli the partial deriv of the cost function with respect to each of your perimet and so you can us those in either gradient descent or in on of the advanc author algorithm .
so that's the back propag algorithm and how you comput deriv of your cost function for a neural network .
i know thi look like thi wa a lot of detail and thi wa a lot of step strung togeth .
but both in the program assign write out and later in thi video , we'll give you a summari of thi so we can have all the piec of the algorithm togeth so that you know exactli what you need to implement if you want to implement back propag to comput the deriv of your neural network's cost function with respect to those paramet .
in the previou video , we talk about the back propag algorithm .
to a lot of peopl see it for the first time , the first impress is often that wow , thi is a veri complic algorithm and there ar all these differ step .
and i'm not quit sure how thei fit togeth and it like kind of a black box with all these complic step .
in case that 's how you ar feel about back propag , that's actual okai .
back propag mai be unfortun is a less mathemat clean or less mathemat simpl algorithm compar to linear regress or logist regress , and i've actual us back propag , you know , pretti successfulli for mani year and even todai , i still don't sometim feel like i have a veri good sens of just what it's do most of intuit about what background propag is do .
for those of you that ar do the program exercis that will at least mechan step you through the differ step of how to implement back prop so you will be abl to get it to work for yourself .
and what i want to do in thi video is look a littl bit more at the mechan step of back propag and try to give you a littl more intuit about what the mechan step of back prop is do to hopefulli convinc you that , you know , it is at least a reason algorithm .
in case even after thi video , in case back propag still seem veri black box and kind of like , you know , too mani complic step , a littl bit magic to to you , that's actual okai .
and even though , you know , i have us back prop for mani year , sometim it's a difficult algorithm to understand .
but hopefulli thi video will help a littl bit .
in order to better understand back propag , let's take anoth closer look at what forward propag is do .
here's the neural network with two input unit that is not count the bia unit , and two hidden unit in thi layer and two hidden unit in the next layer , and then final on output unit .
and again , these count <num> , <num> , <num> ar not count these bia unit on top .
in order to illustr forward propag , i'm go to draw thi network a littl bit differ .
and in particular , i'm go to draw thi neural network with the node drawn as these veri fat ellips , so that i can write text in them .
when perform forward propag , we might have some particular exampl , sai some exampl x i comma y i and it will be thi x i that we feed into the input layer , so that thi mai be , x i <num> and x i <num> ar the valu we set the input layer to and when we forward propag it to the first hidden layer here , what we do is comput z <num> <num> and z <num> <num> , so these ar the weight sum of input of the input unit and then we appli the sigmoid of the logist function and the sigmoid activ function appli to the z valu , give us these activ valu .
so that give us a <num> <num> and a <num> <num> , and then we forward propag again to get , you know , here z <num> <num> , appli the sigmoid of the logist function , the activ function to that , to get the <num> and similarli like so , until we get z <num> <num> , appli the activ function thi give us a <num> <num> which is the finer output valu of the network .
let's eras thi arrow to give myself some space , and if you look at what thi comput realli is do , focus on thi hidden unit let sai we have that thi weight , shown in magenta there , is my weight theta <num> <num> <num> the index is not import , and thi wai here which i guess i am highlight in red , that is theta <num> <num> <num> and thi weight here , which i'm draw in green , in a cyan , is theta <num> <num> <num> so the wai the comput valu z <num> <num> is z <num> <num> is as equal to thi weight , time thi valu so that's theta <num> <num> <num> time <num> , plu thi red weight time thi valu , so that's theta <num> <num> <num> time a <num> <num> , and final thi cyan red time thi valu , which is therefor , plu theta <num> <num> <num> time a <num> <num> .
and so that's forward propag .
and it turn out that , as we see later on in thi video , what back propag is do , is do a process veri similar to thi , except that instead of the comput flow from the left to the right of thi network , the comput is there flow from the right to the left of the network , and us a veri similar comput as thi , and i'll sai in two slide exactli what i mean by that .
to better understand what back propag is do , let's look at the cost function , it's just the cost function that we had for when we have onli on output unit .
if we have more than on output unit , we just have a summat , you know , over the output unit index , if onli on output unit then thi is a cost function oper and we do forward propag and back propag on on exampl at a time .
so , let's just focu on the singl exampl x i y i , and focu on the case of have on output unit so y i here is just a real number , and let's ignor regular , so lambda equal zero , and thi final term , that regular term goe awai .
now , if you look insid thi summat , you find that the cost term associ with the i'f train exampl , that is , the cost associ with train exampl x i y i , that's go to be given by thi express , that the cost , sort of , of train exampl i is written as follow .
and what thi cost function doe , is it plai a role similar to the squar error .
so , rather than look at thi complic express , if you want you can think of co of i be approxim , you know , the squar of differ between or the neural network output versu what is the actual valu .
just as in logist regress , we actual prefer to us thi slightli more complic cost function us the log , but for the purpos of intuit , feel free to think of the cost function as be sort of the squar error cost function , and so thi co of i measur how well is the network do on correctli predict exampl i .
how close is the output to the actual observ label y i .
now let's look at what back propag is do .
on us intuit is that back propag is comput these delta superscript l subscript j term , and we can think of these as the quot error of the activ valu that we got for unit j in the layer , in the lth layer .
more formal , and thi is mayb onli for those of you that ar familiar with calculu , more formal , what the delta term actual ar is thi thei're the partial deriv with respect to z l j , that is the weight sum of input that we're comput the z term , partial deriv respect of these thing of the cost function .
so concret the cost function is a function of the label y and of the valu , thi h of x output valu neural network .
and if we could go insid the neural network and just chang those z l j valu a littl bit , then that would affect these valu that the neural net .
and so that will end up chang the cost function .
and again realli thi is onli for those of you expert in calculu .
if you ar familiar with comfort with partial deriv .
what these delta term ar , is thei're , thei turn out to be the partial deriv of the co function with respect to these intermedi term that we're comput .
and so their measur of how much would we like to chang the neural network's weight in order to affect these intermedi valu of the comput , so as to affect the final output the neural network h of x and therefor affect the overal cost .
in case thi last part of thi partial deriv intuit , in case that didn't make sens , don't worri about it , the rest of thi we can do without realli talk partial deriv but let's look in more detail at what back propag is do .
for the output layer , if first set thi delta term , we sai delta <num> <num> , as y i if we're do forward propag and back propag on thi train exampl i .
it sai it's y i minu a <num> <num> , so it's realli the error , it's the differ between the actual valu of y minu what wa the valu predict .
and so we're go to comput delta <num> <num> like so .
next we're go to do propag these valu backward .
i explain thi in a second and end up comput the delta term of the previou layer .
we're go to end up with delta <num> <num> ; delta <num> <num> ; and then we're go to propag thi further backward and end up comput delta <num> <num> and delta <num> <num> .
now the back propag calcul is a lot like run the forward propag algorithm , but do it backward .
so here's what i mean .
let's look at how we end up with thi valu of delta <num> <num> .
so we have delta <num> <num> and similar to forward propag , let me label a coupl of the weight .
so thi weight should be on cyan let's sai that weight is theta <num> of <num> , <num> and thi weight down here , let me highlight thi in red .
that's go to be , let's sai , theta <num> of <num> , <num> .
so if we look at how delta <num> <num> is comput .
how it's comput for thi note .
it turn out that what we're go to do is we're go to take thi valu and multipli it by thi weight and add it to thi valu multipli by that weight .
so it's realli a weight sum of the new , these delta valu .
weight by the correspond edg strength .
so concret , let me fill thi in .
thi delta <num> , <num> is go to be equal to theta <num> <num> <num> , which is that magenta weight , time delta <num> <num> plu , and then the thing i have in red , that's theta <num> <num> <num> time delta <num> <num> .
so it is realli , liter thi red weight time thi valu , plu thi magenta weight time it's valu and that's how we wind up with that valu of delta .
and just as anoth exampl , let's look at thi valu .
how did we get that valu ?
well , it's a similar process , if thi weight , which i'm go to highlight in green , if thi weight is equal to , sai , delta <num> <num> <num> , then we have that , delta <num> <num> is go to be equal to that green weight , theta <num> <num> <num> time delta <num> <num> .
and by the wai , so far i've been write the delta valu onli for the hidden unit and not , but not , exclud the bia unit .
depend on how you defin the back propag algorithm or depend on how you implement it , you know , you mai end up implement someth to comput delta valu for these bia unit as well .
the bia unit is alwai output the valu plu on and thei ar just what thei ar and there's no wai for us to chang the valu and so , depend on your implement of back prop , the wai i usual implement it , i do end up comput these delta valu , but we just discard them and we don't us them , becaus thei don't end up be part of the calcul need to comput the deriv .
so , hopefulli , that give you a littl bit of intuit about what back propag is do .
in case of all thi , thei still seem so magic and so black box , in a later video , in the put it togeth video , i'll try to give a littl more intuit about what that back propag is do .
but , unfortun , thi is , you know , a difficult algorithm to try to visual and understand what it is realli do .
but fortun , you know , often i guess , mani peopl have been us it veri successfulli for mani year and if you infer the algorithm , you have a veri effect learn algorithm , even though the inner work of exactli how it work can be harder to visual .
in the previou video , we talk about how to us back propag to comput the deriv of your cost function .
in thi video , i want to quickli tell you about on implement detail of unrol your paramet from matric into vector , which we need in order to us the advanc optim routin .
concret , let's sai you've implement a cost function that take thi input , you know , paramet theta and return the cost function and return deriv .
then you can pass thi to an advanc author algorithm by fminunc and fminunc isn't the onli on by the wai .
there ar also other advanc author algorithm .
but what all of them do is take those input pointedli the cost function , and some initi valu of theta .
and both , and these routin assum that theta and the initi valu of theta , that these ar paramet vector , mayb rn or rn plu <num> .
but these ar vector and it also assum that , you know , your cost function will return as a second return valu thi gradient which is also rn and rn plu <num> .
so also a vector .
thi work fine when we were us logist progress but now that we're us a neural network our paramet ar no longer vector , but instead thei ar these matric where for a full neural network we would have paramet matric theta <num> , theta <num> , theta <num> that we might repres in octav as these matric theta <num> , theta <num> , theta <num> .
and similarli these gradient term that were expect to return .
well , in the previou video we show how to comput these gradient matric , which wa capit d1 , capit d2 , capit d3 , which we might repres an octav as matric d1 , d2 , d3 .
in thi video i want to quickli tell you about the idea of how to take these matric and unrol them into vector .
so that thei end up be in a format suitabl for pass into as theta here off for get out for a gradient there .
concret , let's sai we have a neural network with on input layer with ten unit , hidden layer with ten unit and on output layer with just on unit , so s1 is the number of unit in layer on and s2 is the number of unit in layer two , and s3 is a number of unit in layer three .
in thi case , the dimens of your matric theta and d ar go to be given by these express .
for exampl , theta on is go to a <num> by <num> matrix and so on .
so in if you want to convert between these matric .
vector .
what you can do is take your theta <num> , theta <num> , theta <num> , and write thi piec of code and thi will take all the element of your three theta matric and take all the element of theta on , all the element of theta <num> , all the element of theta <num> , and unrol them and put all the element into a big long vector .
which is thetavec and similarli the second command would take all of your d matric and unrol them into a big long vector and call them dvec .
and final if you want to go back from the vector represent to the matrix represent .
what you do to get back to theta on sai is take thetavec and pull out the first <num> element .
so theta <num> ha <num> element becaus it's a <num> by <num> matrix so that pull out the first <num> element and then you can us the reshap command to reshap those back into theta <num> .
and similarli , to get back theta <num> you pull out the next <num> element and reshap it .
and for theta <num> , you pull out the final eleven element and run reshap to get back the theta <num> .
here's a quick octav demo of that process .
so for thi exampl let's set theta <num> equal to be on of <num> by <num> , so it's a matrix of all on .
and just to make thi easier seen , let's set that to be <num> time on , <num> by <num> and let's set theta <num> equal <num> time <num>'s of <num> by <num> .
so thi is <num> separ matric theta <num> , theta <num> , theta <num> .
we want to put all of these as a vector .
thetavec equal theta <num> ; theta <num> theta <num> .
right , that's a colon in the middl and like so and now thetavec is go to be a veri long vector .
that's <num> element .
if i displai it , i find that thi veri long vector with all the element of the first matrix , all the element of the second matrix , then all the element of the third matrix .
and if i want to get back my origin matric , i can do reshap thetavec .
let's pull out the first <num> element and reshap them to a <num> by <num> matrix .
thi give me back theta <num> .
and if i then pull out the next <num> element .
so that's indic <num> to <num> .
i get back all of my <num>'s .
and if i go from <num> up to the last element , which is element <num> , and reshap to <num> by <num> , i get back theta <num> .
to make thi process realli concret , here's how we us the unrol idea to implement our learn algorithm .
let's sai that you have some initi valu of the paramet theta <num> , theta <num> , theta <num> .
what we're go to do is take these and unrol them into a long vector we're gonna call initi theta to pass in to fminunc as thi initi set of the paramet theta .
the other thing we need to do is implement the cost function .
here's my implement of the cost function .
the cost function is go to give us input , thetavec , which is go to be all of my paramet vector that in the form that's been unrol into a vector .
so the first thing i'm go to do is i'm go to us thetavec and i'm go to us the reshap function .
so i'll pull out element from thetavec and us reshap to get back my origin paramet matric , theta <num> , theta <num> , theta <num> .
so these ar go to be matric that i'm go to get .
so that give me a more conveni form in which to us these matric so that i can run forward propag and back propag to comput my deriv , and to comput my cost function j of theta .
and final , i can then take my deriv and unrol them , to keep the element in the same order as i did when i unrol my theta .
but i'm gonna unrol d1 , d2 , d3 , to get gradientvec which is now what my cost function can return .
it can return a vector of these deriv .
so , hopefulli , you now have a good sens of how to convert back and forth between the matrix represent of the paramet versu the vector represent of the paramet .
the advantag of the matrix represent is that when your paramet ar store as matric it's more conveni when you're do forward propag and back propag and it's easier when your paramet ar store as matric to take advantag of the , sort of , vector implement .
wherea in contrast the advantag of the vector represent , when you have like thetavec or dvec is that when you ar us the advanc optim algorithm .
those algorithm tend to assum that you have all of your paramet unrol into a big long vector .
and so with what we just went through , hopefulli you can now quickli convert between the two as need .
in the last few video , we talk about how to do forward propag and back propag in a neural network in order to comput deriv .
but back prop as an algorithm ha a lot of detail and , you know , can be a littl bit tricki to implement .
and on unfortun properti is that there ar mani wai to have subtl bug in back prop so that if you run it with gradient descent or some other optim algorithm , it could actual look like it's work .
and , you know , your cost function j of theta mai end up decreas on everi iter of gradient descent , but thi could pull through even though there might be some bug in your implement of back prop .
so it look like j of theta is decreas , but you might just wind up with a neural network that ha a higher level of error than you would with a bug free implement and you might just not know that there wa thi subtl bug that's give you thi perform .
so what can we do about thi ?
there's an idea call gradient check that elimin almost all of these problem .
so todai , everi time i implement back propag or a similar gradient descent algorithm on the neural network or ani other reason complex model , i alwai implement gradient check .
and if you do thi it will help you make sure and sort of gain high confid that your implement of forward prop and back prop or whatev , is <num> correct .
and in what i've seen thi pretti much all the problem associ with sort of a buggi implement of the background .
and in the previou video , i sort of ask you to take on faith that the formula i gave for comput the delta , and the d's , and so on , i ask you to take on faith that those actual do comput the gradient of the cost function , but onc you implement numer gradient check , which is the topic of thi video , you'll be abl to verifi for yourself that the code you're write is inde comput the deriv of the cost function j .
so here's the idea .
consid the follow exampl .
suppos i have the function j of theta , and i have some valu , theta , and for thi exampl , i'm go to assum that theta is just a real number .
and let's sai i want to estim the deriv of thi function at thi point .
and so the deriv is , you know , equal to the slope of that sort of tangent line .
here's how i'm go to numer approxim the deriv , or rather here's a procedur for numer approxim the deriv i'm go to comput theta plu epsilon , so valu a littl bit to the right .
and we ar go to comput theta minu epsilon .
and i'm go to look at those two point and connect them by a straight line .
and i'm go to connect these two point by a straight line and i'm go to us the slope of that littl red line as my approxim to the deriv , which is the true deriv is the slope of the blue line over there .
so , you know , it seem like it would be a pretti good approxim .
mathemat , the slope of thi red line is thi vertic height , divid by thi horizont width , so thi point on top is j of theta plu epsilon .
thi point here is j of theta minu epsilon .
so thi vertic differ is j of theta plu epsilon , minu j of theta , minu epsilon , and thi horizont distanc is just <num> epsilon .
so , my approxim is go to be that the deriv , with respect to theta of j of theta add thi valu of theta that that's approxim j of theta plu epsilon , minu j of theta , minu epsilon , over <num> epsilon .
usual , i us a pretti small valu for epsilon and set epsilon to be mayb on the order of <num> to the minu <num> .
there's usual a larg rang of differ valu for epsilon that work just fine .
and in fact , if you let epsilon becom realli small then , mathemat , thi term here actual , mathemat , you know , becom the deriv , becom exactli the slope of the function at thi point .
it's just that we don't want to us epsilon that's too , too small becaus then you might run into numer problem .
so , you know , i usual us epsilon around <num> to the minu <num> , sai .
and by the wai some of you mai have seen it altern formula for estim the deriv which is thi formula .
thi on on the right is call the on side differ .
wherea , the formula on the left that's call a two side differ .
the two side differ give us a slightli more accur estim , so i usual us that rather than just thi on side differ estim .
so , concret , what you implement in octav is you implement the follow .
you implement call to comput , gradapprox which is go to be approxim to zero rel as just , you know , thi formula j of theta plu epsilon , minu j of theta , minu epsilon , divid by two time epsilon .
and thi will give you a numer estim of the gradient at that point .
and in thi exampl it seem like it's a pretti good estim .
now , on the previou slide , we consid the case of when theta wa a real number .
now , let's look at the more gener case of where theta is a vector paramet .
so let's sai theta is an rn , and it might be unreal version of the paramet of our neural network .
so theta is a vector that ha n element , theta <num> up to theta n .
we can then us a similar idea to approxim all of the partial deriv term .
concret , the partial deriv of a cost function with respect to the first paramet theta <num> , that can be obtain by take j and increas theta <num> .
so you have j of theta <num> plu epsilon , and so on minu j of thi theta <num> minu epsilon and divid it by <num> epsilon .
the partial deriv respect to the second paramet theta <num> , is again thi thing , except you're take j of , here you're increas theta <num> by epsilon .
and here you're decreas theta <num> by epsilon .
and so on down to the deriv with respect to theta n .
would be if you increas and decreas theta n by epsilon over there .
so , these equat give you a wai to numer approxim the partial deriv of j with respect to ani on of your paramet thei deriv .
concret , what you implement is therefor , the follow .
we implement the follow in octav to numer comput the deriv .
we sai for i equal <num> through n where n is the dimens of our paramet vector theta .
and i usual do thi with the unrol version of the paramet .
so you know theta is just a long list of all of my paramet in my neural network .
i'm go to set theta plu equal theta , then increas theta plu the ith element by epsilon .
and so thi is basic theta plu is equal to theta except for theta plu i , which is now increment by epsilon .
so if theta plu is equal to , right , theta <num> , theta <num> , and so on and then theta i ha epsilon ad to it , and then it go down to theta n .
so thi is what theta plu is .
and similarli these two line set theta minu to someth similar except that thi , instead of theta i plu epsilon , thi now becom theta i minu epsilon .
and then final , you implement thi gradapprox i , and thi will give you your approxim to the partial deriv with respect to theta i of j of theta .
and the wai we us thi in our neural network implement is we would implement thi , implement thi for loop to comput , you know , the top partial deriv of the cost function with respect to everi paramet in our network .
and we can then take the gradient that we got from back prop .
so dvec wa the deriv we got from back prop .
right , so back prop , back propag wa a rel effici wai to comput the deriv or the partial deriv of a cost function with respect to all of our paramet .
and what i usual do is then take my numer comput deriv , that is thi gradapprox that we just had from up here and make sure that that is equal or approxim equal up to , you know , small valu of numer round off that is pretti close to the dvec that i got from back prop .
and if these two wai of comput the deriv give me the same answer or at least give me veri similar answer , you know , up to a few decim place .
then i'm much more confid that my implement of back prop is correct .
and when i plug these dvec vector into gradient descent or some advanc optim algorithm , i can then be much more confid that i'm comput the deriv correctli and therefor , that hopefulli my code will run correctli and do a good job optim j of theta .
final , i want to put everyth togeth and tell you how to implement thi numer gradient check .
here's what i usual do .
first thing i do , is implement back propag to comput defect .
so , thi is a procedur we talk about in an earlier video to comput dvec which mai be our unrol version of these matric .
then what i do , is implement a numer gradient check to comput gradapprox .
so thi is what i describ earlier in thi video , in the previou slide .
then you should make sure that dvec and gradapprox give similar valu , you know , let's sai up to a few decim place .
and final , and thi the import step , the more you start to us your code for learn , for serious train your network , it is import to turn off gradient check .
and to no longer comput thi gradapprox thing us the numer deriv formula that we talk about earlier in thi video .
and the reason for that is the numer code gradient check code , the stuff we talk about in thi video , that's a veri computation expens , that's a veri slow wai to try to approxim the deriv .
wherea in contrast , the back propag algorithm that we talk about earlier , that is the thing that we talk about earlier for comput , you know , d1 , d2 , d3 , or for dvec .
back prop is a much more computation effici wai of comput the deriv .
so onc you've verifi that your implement of back propag is correct , you should turn off gradient check , and just stop us that .
so just to reiter , you should be sure to disabl your gradient check code befor run your algorithm for mani iter of gradient descent , or for mani iter of the advanc optim algorithm in order to train your classifi .
concret , if you were to run numer gradient check on everi singl integr of gradient descent , or if you were in the inner loop of your cost function , then your code will be veri slow .
becaus the numer gradient check code is much slower than the back propag algorithm , than a back propag method where you rememb we were comput delta <num> , delta <num> , delta <num> , and so on .
that wa the back propag algorithm .
that is a much faster wai to comput deriv than gradient check .
so when you're readi , onc you verifi the implement of back propag is correct , make sure you turn off , or you disabl your gradient check code while you train your algorithm , or els your code could run veri slowli .
so that's how you take gradient numer .
and that's how you can verifi that your implement of back propag is correct .
whenev i implement back propag or similar gradient descent algorithm for a complic model , i alwai us gradient check .
thi realli help me make sure that my code is correct .
in the previou video , we put togeth almost all the piec you need in order to implement and train in your network .
there's just on last idea i need to share with you , which is the idea of random initi .
when you're run an algorithm like gradient descent or also the advanc optim algorithm , we need to pick some initi valu for the paramet theta .
so for the advanc optim algorithm , you know , it assum that you will pass it some initi valu for the paramet theta .
now let's consid gradient descent .
for that , you know , we also need to initi theta to someth .
and then we can slowli take step go downhil , us grade descent , to go downhil to minim the function j of theta .
so what do we set the initi valu of theta to ?
is it possibl to set the initi valu of theta to the vector of all zero .
wherea thi work okai when we were us logist regress .
initi all of your paramet to zero actual doe not work when you're trade a neural network .
consid train the follow neural network .
and let's sai we initi all of the paramet in the network to zero .
and if you do that then what that mean is that at the initi thi blue weight , that i'm cover blue is go to equal to that weight .
so , thei're both zero .
and thi weight that i'm cover in in red , is equal to that weight .
which i'm cover it in red .
and also thi weight , well which i'm cover it in green is go to be equal to the valu of that weight .
and what that mean is that both of your hidden unit a1 and a2 ar go to be comput the same function of your input .
and thu , you end up with for everyon of your train your exampl .
you end up with a <num> <num> equal a <num> <num> .
and moreov becaus , i'm not go to show thi too much detail , but becaus these out go weight ar the same you can also show that the delta valu ar also go to be the same .
so concret , you end up with delta <num> <num> , delta <num> <num> , equal delta <num> <num> .
and if you work through the map further , what you can show is that the partial deriv with respect to your paramet will satisfi the follow .
that the partial deriv of the cost function with respect to write out the deriv respect to these two blue weight neural network .
you'll find that these two partial deriv ar go to be equal to each other .
and so , what thi mean , is that even after sai , on gradient descent updat .
you're go to updat , sai thi first blue weight with , you know , learn rate time thi .
and you're go to updat the second blue weight to a sum learn rate time thi .
but what thi mean is that even after on gradient descent updat , those two blue weight , those two blue color paramet will end up the same as each other .
so thei'll be some non zero valu now , but thi valu will be equal to that valu .
and similarli , even after on gradient descent updat .
thi valu will equal to that valu .
there will be some non zero valu .
just that the two red valu will be equal to each other .
and similarli the two green weight , thei'll both chang valu but thei'll both end up the same valu as each other .
so after each updat , the paramet correspond to the input go to each of the two hidden unit ident .
that's just sai that the two green weight must be sustain , the two red weight must be sustain , the two blue weight ar still the same and what that mean is that even after on iter of sai , gradient descent , you find that your two hidden unit ar still comput exactli the same function that the input .
so you still have thi a <num> <num> equal a <num> <num> .
and so you're back to thi case .
and as keep run gradient descent .
the blue weight , the two blue weight will stai the same as each other .
the two red weight will stai the same as each other .
the two green weight will stai the same as each other .
and what thi mean is that your neural network realli can't comput veri interest function .
imagin that you had not onli two hidden unit but imagin that you had mani mani hidden unit .
then what thi is sai is that all of your hidden unit ar comput the exact same featur , all of your hidden unit ar comput all of the exact same function of the input .
and thi is a highli redund represent .
becaus that mean that your final logist regress unit , you know , realli onli get to see on featur .
becaus all of these ar the same and thi prevent your neural network from learn someth interest .
in order to get around thi problem , the wai we initi the paramet of a neural network therefor , is with random initi .
concret , the problem we saw on the previou slide is sometim call the problem of symmetr weight , that is if the weight all be the same .
and so thi random initi is how we perform symmetri break .
so what we do is we initi each valu of theta to a random number between minu epsilon and epsilon .
so thi is a notat to mean number between minu epsilon and plu epsilon .
so my weight on my paramet ar all go to be randomli initi between minu epsilon and plu epsilon .
the wai i write code to do thi in octav , thi i've said you know theta <num> to be equal to thi .
so thi rand <num> by <num> .
that's how you comput a random <num> by <num> dimension matrix , and all of the valu ar between <num> and <num> .
so these ar go to be real number that take on ani continu valu between <num> and <num> .
and so , if you take a number between <num> and <num> , multipli it by <num> time an epsilon , and minu an epsilon , then you end up with a number that's between minu epsilon and plu epsilon .
and incident , thi epsilon here ha noth to do with the epsilon that we were us when we were do gradient check .
so when we were do numer gradient check , there we were ad some valu of epsilon to theta .
thi is , you know , an unrel valu of epsilon .
which is why i am denot in it epsilon , just to distinguish it from the valu of epsilon we were us in gradient check .
absolut , if you want to initi theta <num> to a random <num> by <num> matrix , you can do so us thi piec of code here .
so , to summar , to train a neural network , what you should do is randomli initi the weight to , you know , small valu close to <num> , between minu epsilon and plu epsilon , sai , and then implement back propag ; do gradient check ; and us either gradient descent or on of the advanc optim algorithm to try to minim j of theta as a function of the paramet theta start from just randomli chosen initi valu for the paramet .
and by do symmetri break , which is thi process .
hopefulli , gradient descent or the advanc optim algorithm will be abl to find a good valu of theta .
so , it's taken us a lot of video to get through the neural network learn algorithm .
in thi video , what i'd like to do is try to put all the piec togeth , to give a overal summari or a bigger pictur view , of how all the piec fit togeth and of the overal process of how to implement a neural network learn algorithm .
when train a neural network , the first thing you need to do is pick some network architectur and by architectur i just mean connect pattern between the neuron .
so , you know , we might choos between sai , a neural network with three input unit and five hidden unit and four output unit versu on of <num> , <num> hidden , <num> hidden , <num> output and here ar <num> , <num> , <num> , <num> unit in each of three hidden layer and four open unit , and so these choic of how mani hidden unit in each layer and how mani hidden layer , those ar architectur choic .
so , how do you make these choic ?
well first , the number of input unit well that's pretti well defin .
and onc you decid on the fix set of featur x the number of input unit will just be , you know , the dimens of your featur x i would be determin by that .
and if you ar do multiclass classif the number of output of thi will be determin by the number of class in your classif problem .
and just a remind if you have a multiclass classif where y take on sai valu between <num> and <num> , so that you have ten possibl class .
then rememb to right , your output y as these were the vector .
so instead of claus on , you recod it as a vector like that , or for the second class you recod it as a vector like that .
so if on of these appl take on the fifth class , you know , y equal <num> , then what you're show to your neural network is not actual a valu of y equal <num> , instead here at the upper layer which would have ten output unit , you will instead feed to the vector which you know with on in the fifth posit and a bunch of zero down here .
so the choic of number of input unit and number of output unit is mayb somewhat reason straightforward .
and as for the number of hidden unit and the number of hidden layer , a reason default is to us a singl hidden layer and so thi type of neural network shown on the left with just on hidden layer is probabl the most common .
or if you us more than on hidden layer , again the reason default will be to have the same number of hidden unit in everi singl layer .
so here we have two hidden layer and each of these hidden layer have the same number five of hidden unit and here we have , you know , three hidden layer and each of them ha the same number , that is five hidden unit .
rather than do thi sort of network architectur on the left would be a perfect abli reason default .
and as for the number of hidden unit usual , the more hidden unit the better ; it's just that if you have a lot of hidden unit , it can becom more computation expens , but veri often , have more hidden unit is a good thing .
and usual the number of hidden unit in each layer will be mayb compar to the dimens of x , compar to the number of featur , or it could be ani where from same number of hidden unit of input featur to mayb so that three or four time of that .
so have the number of hidden unit is compar .
you know , sever time , or some what bigger than the number of input featur is often a us thing to do so , hopefulli thi give you on reason set of default choic for neural architectur and and if you follow these guidelin , you will probabl get someth that work well , but in a later set of video where i will talk specif about advic for how to appli algorithm , i will actual sai a lot more about how to choos a neural network architectur .
or actual have quit a lot i want to sai later to make good choic for the number of hidden unit , the number of hidden layer , and so on .
next , here's what we need to implement in order to trade in neural network , there ar actual six step that i have ; i have four on thi slide and two more step on the next slide .
first step is to set up the neural network and to randomli initi the valu of the weight .
and we usual initi the weight to small valu near zero .
then we implement forward propag so that we can input ani excel neural network and comput h of x which is thi output vector of the y valu .
we then also implement code to comput thi cost function j of theta .
and next we implement back prop , or the back propag algorithm , to comput these partial deriv term , partial deriv of j of theta with respect to the paramet .
concret , to implement back prop .
usual we will do that with a fore loop over the train exampl .
some of you mai have heard of advanc , and frankli veri advanc factor method where you don't have a four loop over the m train exampl , that the first time you're implement back prop there should almost certainli the four loop in your code , where you're iter over the exampl , you know , x1 , y1 , then so you do forward prop and back prop on the first exampl , and then in the second iter of the four loop , you do forward propag and back propag on the second exampl , and so on .
until you get through the final exampl .
so there should be a four loop in your implement of back prop , at least the first time implement it .
and then there ar frankli somewhat complic wai to do thi without a four loop , but i definit do not recommend try to do that much more complic version the first time you try to implement back prop .
so concret , we have a four loop over my m train exampl and insid the four loop we're go to perform fore prop and back prop us just thi on exampl .
and what that mean is that we're go to take x i , and feed that to my input layer , perform forward prop , perform back prop and that will if all of these activ and all of these delta term for all of the layer of all my unit in the neural network then still insid thi four loop , let me draw some curli brace just to show the scope with the four loop , thi is in octav code of cours , but it's more a sequenc java code , and a four loop encompass all thi .
we're go to comput those delta term , which ar is the formula that we gave earlier .
plu , you know , delta l plu on time a , l transpos of the code .
and then final , outsid the have comput these delta term , these accumul term , we would then have some other code and then that will allow us to comput these partial deriv term .
right and these partial deriv term have to take into account the regular term lambda as well .
and so , those formula were given in the earlier video .
so , how do you done that you now hopefulli have code to comput these partial deriv term .
next is step five , what i do is then us gradient check to compar these partial deriv term that were comput .
so , i've compar the version comput us back propag versu the partial deriv comput us the numer estim as us numer estim of the deriv .
so , i do gradient check to make sure that both of these give you veri similar valu .
have done gradient check just now reassur us that our implement of back propag is correct , and is then veri import that we disabl gradient check , becaus the gradient check code is computation veri slow .
and final , we then us an optim algorithm such as gradient descent , or on of the advanc optim method such as lb of gs , contract gradient ha embodi into fminunc or other optim method .
we us these togeth with back propag , so back propag is the thing that comput these partial deriv for us .
and so , we know how to comput the cost function , we know how to comput the partial deriv us back propag , so we can us on of these optim method to try to minim j of theta as a function of the paramet theta .
and by the wai , for neural network , thi cost function j of theta is non convex , or is not convex and so it can theoret be suscept to local minima , and in fact algorithm like gradient descent and the advanc optim method can , in theori , get stuck in local optima , but it turn out that in practic thi is not usual a huge problem and even though we can't guarante that these algorithm will find a global optimum , usual algorithm like gradient descent will do a veri good job minim thi cost function j of theta and get a veri good local minimum , even if it doesn't get to the global optimum .
final , gradient descent for a neural network might still seem a littl bit magic .
so , let me just show on more figur to try to get that intuit about what gradient descent for a neural network is do .
thi wa actual similar to the figur that i wa us earlier to explain gradient descent .
so , we have some cost function , and we have a number of paramet in our neural network .
right here i've just written down two of the paramet valu .
in realiti , of cours , in the neural network , we can have lot of paramet with these .
theta on , theta two all of these ar matric , right ?
so we can have veri high dimension paramet but becaus of the limit the sourc of part we can draw .
i'm pretend that we have onli two paramet in thi neural network .
although obvious we have a lot more in practic .
now , thi cost function j of theta measur how well the neural network fit the train data .
so , if you take a point like thi on , down here , that's a point where j of theta is pretti low , and so thi correspond to a set of the paramet .
there's a set of the paramet theta , where , you know , for most of the train exampl , the output of my hypothesi , that mai be pretti close to y i and if thi is true than that's what caus my cost function to be pretti low .
wherea in contrast , if you were to take a valu like that , a point like that correspond to , where for mani train exampl , the output of my neural network is far from the actual valu y i that wa observ in the train set .
so point like thi on the line correspond to where the hypothesi , where the neural network is output valu on the train set that ar far from y i .
so , it's not fit the train set well , wherea point like thi with low valu of the cost function correspond to where j of theta is low , and therefor correspond to where the neural network happen to be fit my train set well , becaus i mean thi is what's need to be true in order for j of theta to be small .
so what gradient descent doe is we'll start from some random initi point like that on over there , and it will repeatedli go downhil .
and so what back propag is do is comput the direct of the gradient , and what gradient descent is do is it's take littl step downhil until hopefulli it get to , in thi case , a pretti good local optimum .
so , when you implement back propag and us gradient descent or on of the advanc optim method , thi pictur sort of explain what the algorithm is do .
it's try to find a valu of the paramet where the output valu in the neural network close match the valu of the y i 's observ in your train set .
so , hopefulli thi give you a better sens of how the mani differ piec of neural network learn fit togeth .
in case even after thi video , in case you still feel like there ar , like , a lot of differ piec and it's not entir clear what some of them do or how all of these piec come togeth , that's actual okai .
neural network learn and back propag is a complic algorithm .
and even though i've seen the math behind back propag for mani year and i've us back propag , i think veri successfulli , for mani year , even todai i still feel like i don't alwai have a great grasp of exactli what back propag is do sometim .
and what the optim process look like of minim j if theta .
much thi is a much harder algorithm to feel like i have a much less good handl on exactli what thi is do compar to sai , linear regress or logist regress .
which were mathemat and conceptu much simpler and much cleaner algorithm .
but so in case if you feel the same wai , you know , that's actual perfectli okai , but if you do implement back propag , hopefulli what you find is that thi is on of the most power learn algorithm and if you implement thi algorithm , implement back propag , implement on of these optim method , you find that back propag will be abl to fit veri complex , power , non linear function to your data , and thi is on of the most effect learn algorithm we have todai .
in thi video , i'd like to show you a fun and histor import exampl of neural network learn .
of us a neural network for autonom drive that is get a car to learn to drive itself .
the video that i show a minut , wa someth that i've gotten from dean pomilieu , who colleagu who work out in carnegi mellon univers out on the east coast of the unit state , and in part of the video you see visual like thi , and what i should tell you what the visual look like befor start to video .
down here on the lower left is the view seen by the car of what's in front of it and so here you know , you will kind of see you know , a road that's mayb go a bit to the left and go a littl bit to the right , and up here on top , thi first horizont bar show the direct select by the human driver and is the locat of thi bright white band that show the steer direct select by the human driver , where , you know , here , far to the left correspond to steer hard left ; here correspond to steer hard to the right ; and so thi locat , which is a littl bit to the left , a littl bit left of center , mean that the human driver , at thi point , wa steer slightli to the left .
a nd thi second part here correspond to the steer direct select by the learn algorithm ; and again , the locat of thi sort of white band , mean the neural network wa here , select a steer direct just slightli to the left and in fact , befor the neural network start learn initi , you see that the network output a grei band , like a grei uniform , grei band throughout thi region , so the uniform grei fuzz correspond to the neural network have been randomli initi , and initi have no idea how to drive the car , or initi have no idea what direct to steer in .
and it's onli after it's learn for a while that it will then start to output like a solid white band in just a small part of the region correspond to choos a particular steer direct .
and that correspond to when a neural network .
becom more confid in select , you know , a and in on locat rather than output a sort of light grai fuzz , but instead output a white band that's more constantli select on steer direct .
alban is a system of artifici neural network , that learn to steer by watch a person drive .
alban is design to control the tube a modifi armi humve who could put sensor , comput and actuat for autonom navig experi .
the initi spec in configur alban is train in the train the person drive to be a car while alban watch .
onc everi two second , alban digit a video imag of the road ahead , and record the person's steer direct .
thi train imag is reduc in resolut to <num> by <num> pixel and provid as input to alban's three layer network .
us the back propag learn algorithm ; alban is train to output the same steer direct as the human driver for that imag initi , the network's steer respons is random .
after about two minut of train , the network learn to accur imit the steer reaction of the human driver .
thi same train procedur is repeat for other road type .
after the network have been train the oper push the run switch and often begin drive .
<num> time per second , alban digit an imag and feed it to it neural network .
each network , run in parallel , produc a steer direct and a measur of it's confid in it respons .
the steer direct from the most confid network .
in thi case , the network train for the on lane road is us to control the vehicl .
suddenli , an intersect appear ahead of the vehicl .
as the vehicl approach the intersect , the confid of the on lane network decreas .
as it cross the intersect , and the two lane road ahead come into view , the confid of the two lane network rise .
when it's confid rise , the two lane network is select to steer , safe guid the vehicl into it's lane , on the two lane road .
so that wa autonom drive us a neural network .
of cours , there ar more recent more modern attempt to do autonom drive in a few properti , in the u . s . , in europ , and so on .
thei're give more robust drive control than thi , but i think it's still pretti remark and pretti amaz how a simpl neural network train with back propag can , you know , actual learn to drive a car somewhat well .
