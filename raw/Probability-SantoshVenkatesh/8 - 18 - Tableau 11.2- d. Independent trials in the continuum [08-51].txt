Recall that independence is at
its heart a rule of products.
As we've already seen in tableau nine part
one, in the case of a composite experiment
in the discrete setting
a product space was engendered
with a product measure obtained by
multiplying individual mass functions.
This intuition carries over
seamlessly into the continuum,
with a provisor of course that the mass
functions in the discrete domain
are replaced by mass densities
in the continuous domain.
As George Pulley suggests, it is
always wise to begin with the simplest
non trivial version of the problem, and
in this case the simplest non trivial
version involves two independent trials.
Accordingly, consider
two trials leading to
continuous chance variables,
random variables, say X and Y.
X is governed by a density function,
say p sub 1,
Y is governed by a density function,
say p sub 2.
The trials are said to be independent,
if together they engender a composite
experiment where the sample space is
described by a pair of real numbers.
In other words the sample space
of the Euclidean plane, and
the pair of real numbers forming
the composite outcome of this experiment
are governed by a mass
density in two dimensions,
which is separable into a product of
two-one dimensional mass densities.
This is very much what we
saw in the discrete domain.
Now, why does this imply independence in
the sense of multiplication rules for fx.
Well, the argument goes
exactly the same fashion sum's
segwaying into integrals
it's to verify independence.
Suppose A is a subset of real numbers,
B is another subset of real numbers,
and we want to know the probability of
the joint occurrence of the events that
the first outcome x is in A and
the second experiment's outcome is in B.
So now, we have a composite experiment
with two individual experiments
composing it.
What does this look like?
Well, naturally we're thinking of events
as sets, A is a subset of the real line in
this case I've shown you an interval,
B is another subset of the real line,
another interval in this
particular example.
And we're interested in
that set in the plane for
which the first coordinate
variable lies in A, and
the second coordinate variable lies in B.
Of course, you recall there's
a Cartesian product of A with B.
And so, the event at hand is
the set of all pairs x,y,
for which x lies in A, and
y lies in B, in other words,
the Cartesian product of A with B.
If A and B are rect, are intervals,
then the Cartesian product
is a rectangle as you say.
How do you compute a probability?
Simply, accumulate the mass density
over the region of interest or
in other words, integrate out the mass
density over this Cartesian product.
Naturally when faced with
a two-dimensional integral we simplify by
writing it as an iterated integral.
What is the region of interest?
Well, x has to ri,
lie in the region A, and
a y has to lie in the region B, and
so we have now an iterated integral.
And we observe that the integral, since
it's separable into a function of x and
a function of y.
The intregrand separated the two pieces
and therefore so do the integrals.
And so we promptly write our integral
down as a product of an integral over x
with an integral over y, and
we start at the expression on the right.
The first integral is the integral
of the density function
of x over the region A and
of course this stands for
the probability that the first
coordinate variable lies in A.
Likewise, a second integral is
the integral of the density function
of the second coordinate
variable over a region B.
It stands for
the probability that the second
coordinate variable takes values in B.
Take stock,
the probability of the joint occurrence of
the events that X lies in A and
Y lies in B is product
of the two probability that X isn't
A with the probability that Y isn't B.
Or in other reds,
events specified by X alone
are independent of events
specified by Y alone.
If we specify for the composite
experiment in the product space a product
measure which is inherited from
a product of two mass densities.
Then this implies independence for
all events specified by X with
respect to events specified by Y.
All right, now once we understand
this way very quickly generalize
through a general setting
with say n trials.
Imagine that we have n
individual constituted
independent trials resulting in continuous
variables, and now we're going to need
a more cumbersome mutation that we
have now n variables to deal with.
Naturally, we'll identify the trials
by subscripts 1, 2, 3, up to n,
let X sub 1 be the first quantum variable,
X sub 2 the second variable,
X sub n the last variable.
Each of these experiments is governed
by an underlying probability law.
X1 has a mass density function p1,
X2 has a density p2,
Xn has a density pn,
by saying the trials are independent
we mean that the composite
experiment gives rise to a vector,
an n-tuple of chance variables.
The sample space here is implicitly
n dimensional eccludian space,
and the probability measure is
inherited from a product measure,
where the joint density of these
end variables is factored,
is separable into a product of each
of the end individual mass densities.
Verifying independence is,
follows the same pattern.
Suppose A1 is a region of the real line,
A2 is in the region,
An is still end of the region.
What are the chances that the first
coordinate variable lies in A1,
the second coordinate
variable lies in A2 and
so on with the init coordinate
variable lying in An?
Naturally, we integrate out the joined
density, the mass density which
now has units of probability mass but
in unit and dimensional volume.
Integrated out over
the region of interest,
which is the Cartesian product of
A1 with A2 and so on through An.
Does n dimensional integrals simplifies
the game because the integrand
has separated into a product of individual
one dimensional functions, and so
this integral separates into a product
of n1 dimensional integrals.
Each of the integrals on the right
represents a probability, and so we find
that the right hand side evolves into
a product of n individual probabilities.
And again, we verify the rule of products.
The probability of X1 taking value
A in a region A1, X2 in a region A2,
and so on, Xn in a region An is a product
of the individual probabilities.
We verified again, that events
specified individually by X1, X2,
through Xn are independent.
But, if the student looks back at the arg,
what she will realize that, essentially
the same argument carries through.
For events specified by
disjoint groups of these Xs,
or that happens is that the integrals
will now separate into one group here,
one group here, one group here, and
again, you have a rule of products.
Again, independence is manifested
in a product space when we
have a product measure.

