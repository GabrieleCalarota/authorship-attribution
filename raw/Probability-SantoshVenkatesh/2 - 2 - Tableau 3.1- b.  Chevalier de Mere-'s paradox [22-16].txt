So let us begin with a setting
involving the war of Adai.
The time is the 17th century.
And this was a period of intellectual
awakening in Western Europe and
in the United Kingdom.
In the early 1600s,
the ideals of series and
sequences had already been provided.
And calculus was waiting to
peek coyly around the corner
near the end of the century.
And it was at this time that
in 17th century France,
the intellectual engagement in salons
caused a, an eruption of ideas.
In particular, in the theory of chance.
A name associated with this is
that of the Chevalier de Mere.
His real name was Antoine Gombaud.
He was a, a writer and
also an intellectual,
a prominent salon purist.
And a problem that he posed has now
come to be associated with him and
it's called de Mere's problem or
de Mere's paradox.
It's a very simply worded problem and
it was known well before de Mere and
it can be stated in simple
terms as you see on the screen.
If one looks at two games of chance,
one in which one takes a regular
six-sided fair die and
throws it four times in succession.
One wants to bet on whether
in those four throws,
one achieves at lease one ace.
An ace in the common parlance in cards or
in dice connotes a surface
with a single pip.
Or occasionally, a,
an outcome which has the largest value.
Let us for our purposes take
an ace in terms of dice to
mean the showing of a face with six pips.
So the question that de Mere
posed was is it more advantageous
to wager on getting at least one
ace in four throws of one die.
Or is it preferable,
is it more likely that
if one throws a pair of dice, 24 times.
That somewhere in those 24 throws,
one gets a pair of aces.
I'll pause to let you think about this for
a moment.
Where does your intuition lead you?
All right.
Now you had a chance to think about it.
Let me begin by throwing out an analysis,
which is suspicious and
actually incorrect.
Here is how an argument might go,
a naive argument.
When one throws a die,
every face is equally likely.
And so in particular, a six or an ace has
got a one in six chance of appearing.
Since one is throwing the die four times,
there is a four in six
chance of getting an ace.
Now it sounds reasonable,
but let's carry on.
If one applies this logic to
throws of a pair of dice,
then when one throws a pair of dice,
the chance of observing a double ace.
Well, there are 36 possibilities for
the pair of dice.
So to get a double ace, there's a on
in 36 chance of seeing a double ace.
And therefore,
if one throws a pair of dice 24 times,
the chance of observing a double
ace should then be 24 in 36.
Both of these cases result in two-thirds.
And therefore, a naive argument might say.
Well, there's an equal chance of observing
either a single ace in four throws
of one die or a double ace in twenty
four throws of a pair of dice.
Simple but incorrect.
Now this logic is in
the popular literature,
frequently attributed to de Mere.
But there are reasons to doubt whether he
actually committed such a sloppy piece
of analysis.
One can very quickly see why an argument
like this is going to break.
What is the key principle at
the heart of such an argument?
Well, if one identifies the key
central idea, it would be this.
That the chance of observing
a success increases
proportionately with the number of trials.
Thus, for example,
if one is tossing a die repeatedly and
if one wants to observe an ace,
the chance of observing an ace
in is one in six per trial.
And therefore, in two trials,
we anticipate a two in six chance.
In three trials, a three and
six of four trials four and six and so on.
But of course, this is manifestly absurd.
In six trials then, the chance of
observing an ace should be six and six or
it should be certain that we
observe an ace in six throws.
But this is clearly patternly ridiculous.
In fact,
if you go beyond six throws it'll say,
you are more than certain that you are,
we will observe an ace.
Something has clearly gone
wrong with the logic.
What is it?
Well, the setting is simple
enough that we can directly do
an analysis using purely
combinatorial arguments.
Let us begin.
In this setting, one starts with a die and
throws it repeatedly.
[SOUND] Once.
[SOUND] Twice.
[SOUND] Thrice.
[SOUND] And four times.
The very first throw happened to
give us an ace and we were done.
Now let's see if we can
abstract this idea.
Okay.
And the combinatorial notion of balls and
urns give us a convenient metaphor
to capture this model experiment.
So imagine that each throw
is represented by a ball.
So you have ball one for throw one.
Ball two for throw two.
Ball three for throw three.
Ball four for throw, for throw four.
Each throw can result in one of six
possible phrases, six possible results.
Label these possible results one,
two, three, four,
five and six by six distinct
urns as seen in your figure.
And now schematically,
as one does the experiment,
ball one goes in this case to urn five.
Throw two results in one,
throw three in five, throw four in two.
And you've got a sequence of throw
outcomes modeled schematically.
Now we can compact all of this
in a very simple arrangement.
All we have to do is specify in order
the values that each throw gave us.
All we have to do is specify
in order four different urns
corresponding to
the values that were seen.
And in this case, we get a sequence five.
The first throw gave us a five.
One, the second throw gave us a one.
Five again,
the third throw gave us a five.
And two, the fourth throw gave us a two.
Now we have the beginnings
of a terminological and
notational structure for this problem.
Okay.
So let's quickly abstract this and
look at what the general setting is.
Bear in mind that what we are looking for
is the emergence of the true.
Which gives us a six, an ace.
And so we are looking for the presence
of an ace anywhere in the sequence of
four outcomes that you have seen.
Now in general,
you can get any set of four outcome, and
we need some notation for this.
Let's call the first throw
of the die a value k1.
The second throw, a value k2,
value k3, value k4.
The results of your four dies throws
are now given by an ordered sequence
of four numbers.
It's an ordered sample of size four,
sampled from the collection of six ends,
with replacements.
Throws can repeatedly generate in
principle the same value, the same urn.
And now we have a setting of
sampling with replacement.
This is very simple.
How many possible sequences
of throws are there?
Well, since it's sampling, a sample
of size four with replacement from
a population of size six, the answer
is immediately 6 to the power 4.
So the number of different outcomes for
the experiment is very large.
We have 6 to the power 4 different
outcomes for the experiment.
Of all these outcomes,
which outcomes result
in observing an ace somewhere
in your four throws?
Well, in a setting like this,
it is easier to examine what'll happen
if the of what is desired happens.
What is the complement of what we desire?
Well, the complement of what we desire is
that none of the throws results in an ace.
Which means that we are looking
at strings of four numbers
where none of the four numbers is a six.
Alternately, this means we are looking
at an ordered sample of size four
drawn from a population of
the first five urns alone,
eschewing the last or the sixth urn.
Well this immediately is again
sampling with replacement, but
from a smaller population
of five urns this time.
The number of possibilities
is 5 to the power 4.
And therefore, there are 5 to
the power 4 possible outcomes for
the experiment where you
do not observe an ace.
Out of 6 to the power 4 possible
results with the experiment
where you look at all possible outcomes.
The chance of not observing an ace
therefore, because naturally enough,
all outcomes in these tosses
are considered to be equally likely,
is 5 to the power 4,
divided by 6 to the power of 4.
The chance therefore of
observing at least one ace,
is obtained by subtracting
this quantity from 1.
And so, let's put in some notation here.
Let's write the upper case letter
A to denote the event that in
four throws of my die,
we obtain at least one ace.
Let's write an upper case bold font letter
P to denote the chance, or
the probability of that event.
And therefore in notation, we capture
this by saying P(A), the probability
of the event A is 1 minus 5 to the power
4, divided by 6 to the power of 4.
Evaluation shows that this
is approximately 52%.
So far, so good.
The analysis, you'll agree,
was not at all hard.
It required a proper understanding
of what experiment was,
suitably abstracting out the combinatorial
elements and just simply writing down
estimates of various quantities
involving sampling with replacement.
Now, what about the event, B,
where we throw a pair of dice 24 times,
and we are looking for a double ace.
Well, once we've done a problem,
we should not be cavalier in
throwing away our intuition.
We should begin with our understanding and
see whether we can extend
that to the new setting.
And let's try to see how we can do this.
So remember, that,
in throwing one die four times,
the chance of seeing at least an ace,
per our calculations, is about 52%, 0.52.
Our experiment now involves
throwing a pair of dice.
And they're going to throw the pair
of dice repeatedly once, twice,
thrice, and so
on until we've thrown them 24 times.
What would an appropriate model be for
such an experiment?
If we were to draw upon our intuition,
where we threw one die repeatedly,
then we should identify each throw
of a pair of dice with a ball.
In which case we have 24 distinguished
balls, one representing each throw.
Each throw gives us two faces.
How many different out, outcomes or
possibilities are there?
Well the first die has six faces.
The second die has six faces.
So together there are 6 times 6, or
36 possibilities for
each throw of a pair of dice.
It is easiest to represent this
graphically in a six by six grid.
Now at this point, each square on the grid
represents a possible pair of faces.
And now we throw the dice repeatedly and
we identify which throw lands
in which pair of faces.
One, two, three, four, five.
All the way up through 24.
You will notice that our 16th throw,
landed up with a pair of aces,
which was what was desired.
So, the key element was of course, the
square in the upper-right of your screen,
where a throw results in a pair of,
of aces.
How should we model this in general?
Well of course notation is going
to get inescapably more cumbrous.
We have more moving parts but
the principle is going to be the same.
The first throw is represented
by a pair of numbers.
The second throw by
another pair of numbers.
A third by a third pair of numbers.
The 24th by a, the 24th pair on numbers.
Let's call them j1 and k1, for
the results of the first throw.
J2 and k2 for
the results of the second throw.
J24, k24 for
the results on the 24th throw.
The notation is admittedly much more co,
cumbrous, but the principle and
logical element at
the heart of the argument
is no bit different from what we
encountered when we threw one die.
Now, a,
an outcome of the experiment corresponds
to giving me a sequence of 24 pairs.
Each pair landing in one of 36 urns,
or 36 possibilities.
This corresponds to again,
a sampling with replacement scenario.
The same urn, the same fair pair of
face values, could recur again and
again and again.
How many possibilities are there for
the experiment as a whole?
Well this is an ordered sample of size
24 drawn from a population of size 36.
And therefore, the total number
of outcomes of this experiment is
a mind bogglingly large number,
36 to the power 24.
How many of these result
in at least one double ace?
As before,
it is easier to ask the obverse question.
How many of these result
in no double aces?
This is the complement
of the event at hand.
Now, if there are no double aces,
then a pair j,k can
take any values with j running
from one through five and
k running from one through five.
One of the two could be six,
but both cannot.
This means that in your
square of 36 possibilities,
you issue just the element
in the northeast corner.
Just the element labeled, 6,6.
And so,
each throw has now 35 possibilities,
where a double ace is not seen.
And now again, it's sampling with
replacement from 35 possibilities.
And so the number of outcomes
that are favorable for
the event that there is no double
ace is 35 to the power of 24.
The ratio of 35 to the 24
over 36 to the 24 naturally
now is our probability that we
do not observe a double ace.
And therefore,
the probability that at least one
double ace is seen somewhere
in the course of 24
throws of a pair of dice
is 1 minus this ratio.
Evaluation shows that this
clocks in at just about 49%.
Again, in notation,
a bold font P for probability.
The letter B for the event that one or
more double aces are seen in 24 throws.
And we read this as saying, P of B,
the probability of B is about 0.49.
Now, we can take a couple of
immediate lessons from this.
One, calculations involving
probabilities in such combinatorial
settings very quickly
involve huge quantities.
We have a massive numerator
divided by a massive denominator.
In such settings, we are ill equipped
to guess at what the answer might be.
Nothing in our common experience
prepares us adequately for
handling such large ratios.
And so, it should come as no surprise
at all that intuition can frequently
flounder in such settings,
even with apparently very simple games.
But the analysis is quite elementary.
It just required an understanding,
careful to be sure of a setting where
we have sampling with replacement.
And now, a consideration of the two
possibilities shows us
that it is marginally.
More better, more likely.
That we observe a single ace
in four throws of a dice,
then that we observe a double ace
in 24 throws of a pair of dice.
This would not have been
easy to anticipate.
Okay.
But this is what it is.
These numbers are close.
They are both very close to
mimicking a fair coin, but
the event A is marginally more likely.
It's slightly more advantageous
to wager on getting one ace or
more in four throws of
a die than in wagering on
a pair of aces in 24
throws of a pair of dice.
In, in the fork law,
in the literature it is
the story is often told
with a romantic cast to it.
Themary is identified as an aristocrat,
which actually was not true.
He was a commoner,
Antoine Gombaud was his real name.
He is identified as
an itinerant gambler and
this again was perhaps
not strictly accurate.
Gombaud was actually a writer and
a thinker.
He was a prominent salon
theorist of that time.
But this story,
which take has legs because of frequent
repetition is cost of
the following the terms.
The Mary did this calculation
on naive calculation and
concluded that the odds were
two-thirds for both cases.
And so from a theoretical point of view,
he believed that the cases
should have the same chance.
But based on empirical evidence and so
the story goes, he won a lot of ma,
money on possibility A and
lost a lot of money on possibility B.
And therefore, on empirical grounds,
he doubted his theory.
And so he went and
asked the mathematician, philosopher,
logician Blaise Pascal his take on
the story and Pascal set him right.
There's considerable reason to
doubt this story on all fronts.
One Gombaud was actually a commoner and
a writer.
He took to calling himself Chevalier,
which means knight in French.
After a character in one of his
novels who espoused the kinds of
beliefs that he himself did and
he studied in Mary.
And therefore, he became the knight
of Mary, Chevalier the Mary and
this is his popular moniker.
He has gone down in history and
this problem is very associated with him.
Perhaps not so much that he
actually solved the problem, but
because he initiated a dialog of
the very foundations of chance.
And this, in the middle of the 17th
century went on to revolutionize science.
It created the seeds for a magnificent
modern endeavor, the theory of chance.

