[MUSIC]
Tableau 3, part 3, beyond balls and
urns, unequal probabilities and
infinite spaces.
So, in our earlier tableau,
we looked at chance in commonplace
combinatorial settings.
Where the metaphor of a ball and
urn was appropriate and led to
purely combinatorial ways of evaluating
chance and computing probabilities.
We will now want to move on
to a setting where chance
is at play but
outcomes are not equally likely.
Let me immediately begin by giving you
an example from the popular lexicon.
This is in the game of craps.
Now, a game of craps is
played by throwing a pair of
dice repeatedly, [SOUND] and
summing the face values.
The question here is what is
the chance that you win on
the very first throw in craps?
So let's walk into the game.
So if you walk into a casino,
and you see a,
a game of craps going, this is roughly
how you'll find it being played.
The game proceeds as I've told you but
repeated throws of a pair of dice.
[SOUND] At each throw,
you sum the face values of the dice.
And depending on what the sum is,
you have one of three possibilities.
You either win, or you lose.
Or the game continues by further
throws of the pair of dice.
Now we are going to look at
the simplest version of the game.
If in the first throw of the pair of dice,
[SOUND] you happen to roll a seven or
an eleven, then you win immediately.
If you are unlucky enough to draw 2 or
3, or 12, then you lose immediately.
If the sum of the face values is 4,
5, 6, 8,
9, or 10, then you continue playing by
repeatedly rolling the pair of dice,
summing their face values of each time.
Stopping at the first instant where you
either replicate your original throw 4,
5, 6, 8, 9 or 10, or
you have the misfortune of throwing a 7.
If you replicate your original thrown
on the concluding throw, you win.
If you happen to throw a seven on
the concluded throw, you lose.
Now let's look at the first part of
the game where you look at one throw and
you ask what is the chance I win?
What is a proper model for
this experiment?
Now, before we launch into an analysis,
we should come up with a way of describing
mathematically what is going on.
What are the outcomes of
this thought experiment?
Well you realize that if
you throw a pair of dice,
then the smallest of
the face values is one,
and therefore the sum of face values
is going to have to be at least two.
On the other hand, the largest of
the face values of the die is 6, and
so the sum of the face
values cannot exceed 12.
And so it becomes apparent that
in this thought experiment,
for one throw of a pair of dice
where you sum the face values,
the outcomes are the numbers 2, 3,
4, 5, 6, 7, 8, 9, 10, 11 and 12.
What is the measure of chance we should
ascribe to these basic possibilities?
Now let's decompose the game
down a little bit further.
So, the possible outcomes of
the experiment, as far as chance and
craps is concerned,
are the numbers 2 through 12.
But you can arise at these
numbers in a myriad of ways.
Let's visually take a look
at how we could do this.
The result when you throw a pair of
dice is going to be a pair of numbers,
one for each die.
Die one and die two.
We can as before, arrange these in
a 6 by 6 grid of possibilities.
Now, which of these possibilities
trigger the value 2?
Now, naively, we might have thought,
before we did any analysis, that well,
there are 11 possibilities,
2 through 12, and
they should all then be equally likely.
Each should have a 1 in
11 chance of arising.
But just a little thought shows that,
that is not very right.
That our logic was missing ways
of partitioning the problem and
that certain numbers have much
richer partitions than others.
For example, to get to a sum of 2,
there's only one way of doing this.
Each die will have to show a face of one.
Well, how about 3?
Now, at this case,
you have two possibilities.
The first die could show two, and the
second die could show one, or one and two.
What about 4?
Now there are here possibilities and
now you're beginning to see a pattern.
It's going across a diagonal
on a 2 dimensional grid.
5 has got 4 possibilities.
6 has got five possibilities.
And 7 has 6 possibilities.
And now we hit diminishing returns.
At 8,
the number of possibilities is smaller.
It's 5, for 9 you have 4 possibilities.
For 10, you have 3 possibilities.
For 11, 2 possibilities.
And finally, for 12,
the only way to configure a 12 is if
you roll a 6 for each of the dice.
And now this immediately gives us an idea
of what the natural chance mechanism
that should be ascribed as.
So it beginning with a set of 11
possibilities for a chance experiment,
they are arrived at by various
combinations for a pair of dice.
And since there is no reason to expect
any one combination with a pair of
dice to be any different from the others,
we ascribe to all possible paired
combinations the same chance of 1 in 36.
And therefore, a natural ascribing
of chance in this experiment,
is to assign to 2 the chance of 1 in 36.
To assign to 3 the chance of 2 in 36.
To 4, the chance of 3 in 36, and so on.
To 7, the chance of 6 in 36.
And now the numbers start decreasing.
8 has got a chance of 5 and
36, 9 of 4 in 36, and
finally, 12 has a chance of 1 in 36.
From a modeling point of view,
this is equivalent to considering
a situation where you had an 11-sided die.
With the numbers 2 through 12 inscribed on
the various faces, but the die is loaded.
2 and 12 are unlikely to occur.
They occur only one
thirty-sixth of the time.
If you do the experiment 36 times by
rolling this loaded die 36 times,
you'd expect to see a 2, only on average,
about once in those 36 tries.
7 is the most heavily loaded outcome for
this 11-sided die,
it occurs 6 in 36 times,
or once every 6 rolls.
We now have an understanding
of a chance experiment
with a finite number of outcomes,
11 outcomes in all.
The numbers 2 through 12.
But these outcomes are not
equally likely and
it is clear now from this setting why
they should not be equally likely.
We have identified events in the setting.
The event that I have succinctly
labeled win, standing for
the concept of winning on
the first throw at craps.
But this we identify very
completely by the pair of elements,
the aggregate of elements 7 and 11.
You win if you happen to throw a 7 or
11 on the first throw.
The event lose, we identify with
an aggregate of three elements to 3 or 12.
And a third event, which is that you
continue after the first thrown craps,
if you throw any one of the aggregate
of six elements 4, 5, 6, 8, 9 or 10.
A next step in a program
is naturally enough to ask
how should we assign
chance to these events?
And now, we're going to touch
upon a central principle,
not just in probability but
in all of mathematics.
The hugely important
principle of additivity.
This principle captures
the idea that is implicit.
That the whole is always
the sum of its parts.
At its heart, additivity is
a guiding principle which suggests
that if a problem is partitioned into
pieces, we can assemble the whole
by simply putting together and
adding up the individual pieces.
Sounds banal.
Sound trite.
You look at me and say like duh.
But, this principle you'll say is
incredibly nuanced, incredibly subtle.
And the engine which fuels
some of the most delicate and
sophisticated analyses in the subject.
Now let's put this understanding
of additivity to work
in this very simple setting.
To win on the first throw at craps,
the event I have succinctly
just called win,
means that I throw a 7 or an 11.
In other words,
you decompose a partition, the idea,
the event of a win into either a 7
being thrown, or an 11 being thrown.
And therefore,
the principle of additivity says,
to the event called win,
I ascribe a chance, in notation, P of win.
Which is obtained by adding up the
probabilities of throwing a 7 or an 11.
Very simple, very deep, and
here is a guiding principle of additivity.
So the probability,
we see by just looking at a table,
the probability of winning on
the first roll of craps is 2 and 9.
What about the probability of
losing in the first throw of craps?
Appealing to additivity again,
we look at the event lose
as corresponding to throwing a 2,
or a 3, or a 12.
The probability of losing,
therefore, is a sum of the chance
probabilities for each of these objects.
And looking at our table again,
we see that it evaluates to 1 and 9.
Pause the lecture for
a moment while you work through and
verify the simple calculation.
And now we find that the chance of
winning on the first throw in craps
is twice that of losing on
the first throw in craps.
Should we hasten to the Casino and
start playing the game?
Not so hasty.
We've forgotten a third eventuality.
The possibility that the game does
not conclude on the first throw, but
continues.
Let us ask now,
what is the chance that you will continue
playing craps after the first throw?
Well, the event continue is identified
as an aggregate of six elements,
4, 5, 6, 8, 9 or 10.
The principle of additivity tells us, we
compute the probability of continuing by
simply adding up
the individual probabilities.
And a quick look at our table tells us,
the chance of continuing in craps is 6 and
9, or 2 and 3.
There's a two-thirds chance,
that the game of craps will not
conclude on the first throw.
This is a lion share of the possibility
and so the next question would be,
of course,
well what if the game continues?
Now what is my chance of winning?
Well that story will have to wait until
we develop a little more machinery.
So thus far, we have now looked at our
combinatorial setting, where we have
a chance experiment, with a finite
number of outcomes, each equally likely.
And now moving into a setting where
the outcomes are still finite,
but the die is loaded,
the coin is not fair.
The individual outcomes do
not have an equal chance.
The next step in the program is
to go beyond finite outcomes,
to settings where the outcomes are,
at least in principle, infinite.
Now, the listener might well ask,
well why should I care?
Isn't any real experiment
explicitly finite?
Yes, but there is a virtue in considering
settings where the experiment can,
as a model, in principle,
continue indefinitely.
Let me give you a concrete illustration.
For example, in evaluations of risk,
actuaries prepare actuarial
tables which provide elements
where you talk about life expectancy and
the chance of a life expectancy.
But these actuarial tables carry on
much beyond real life expectancies.
Now, why should we do this?
Well there are two reasons.
One, you would say, it is artificial
to put a limit on human life, and
say well,
you can't live past 101 for example.
That is artificial, and
clearly there will be occasional,
albeit rare examples, where that
number turns out to be insufficient.
So, it is artificial to put
constraints on a number.
You might as well imagine a setting
where things are unbounded.
A second virtue in allowing
the numbers to become unbounded, and
in principle, allowing infinite or
unbounded life,
is that by not putting an artificial
boundary around the problem,
constraining it,
the analysis becomes smooth and simple.
We are not put into a corset by boundaries
which are artificial in nature.
And don't inform us about
the essential nature of the problem.
So in such settings, we'll think of
a sanitized model where we can imagine,
conceptually, an experiment
which goes on forever.
This is an example of
a thought experiment.
A gedankenexperiment.
An experiment which can be conceived of,
but which might never actually be done.
This isn't exactly the same
spirit as a Euclidean geometry,
where we take our understanding of
things like lines, by taking foot rules,
or edges of buildings, or beams of light.
And we axiomatize it,
we abstract it, and
come up with the Euclidean idea of a line,
being an object which has got
a length without breadth.
But that's absurd, isn't it?
What is an object which has
length without breadth?
Okay, there's no physical object
which has got length without breadth.
But nonetheless,
there's abstraction of an essential
idea proves to be enormously powerful.
It is in the same spirit that
we consider experiments which
have an infinite range
of possible outcomes.
And as we shall see, for many deep
applications, important practical
applications, this kind of modeling allows
us to get to the heart of the matter.
So, are there experiments we can conceive
of which are not hideously complicated,
which could, in principle,
have an unlimited number of outcomes.
Well, let's go back, inevitably,
to the toss of a coin.

