Let me sketch for you a proof of
the theorem of inclusion and exclusion.
There are several ways we
can go about doing this, but
let me pick one way,
which has a salutary value
of being particularly useful as a way
of thinking about these problems, and
it has got the ancillary benefit of being
particular useful in the advanced theory.
The idea borrows from the old magician's
standby pick a card, any card.
We are going to try to do the same thing,
with our view now from a sample point.
So let's begin with
a collection of n events,
A1 through An, in some probability space.
We will not worry now about whether there
are any dependency constraints
between these events or not.
It does not matter for our purposes,
these are arbitrary events
in a probability space.
Let's put together indicators for
the occurrences of these events.
Say let's say that X1 is the indicator for
the occurrence of the event A1.
In other words X1 is equal to 1, if A1
occurs and X1 is equal to 0 otherwise.
X2 likewise is the indicator for
the occurrence of the event A2 and
proceeding along these lines,
generically let's write X sub j for
the indicator for
the occurrence of the event A sub j.
Now, recall that Inclusion-exclusion
principle devolved upon
various inclusion exclusion sums.
And the notation was formidable, but the
concept at heart was elegant and simple.
Let's say we fix any value k between 1 and
n.
Pick any collection of
k out of the n events.
It's an arbitrary collection, so
let's tag them with generic indices j1,
j2, j3, through j sub k.
Look at the probability of
the intersection of those k events.
Now, some such probabilities over
all choices of k events out of n,
and that is all that the formidable
looking sum represents.
Sk in words is the sum of
all ky's intersection probabilities
of the underlying events A1 thru An,
of course k here is a generic
integer between 1 and n.
In our inclusion exclusion formulations,
we're going to see terms like Sk,
Sk plus 1.
Well, what is Sk plus 1?
Well, simply in the formulation
replace k by k plus 1,
in other words, add all k plus 1
Ys intersection probabilities.
If we replace k by k plus 2,
then simply add all k plus
2 Ys intersection probabilities
replacing k by k plus 2 in the sum.
And likewise, Sk plus j for the generic j,
would be the sum of all the k plus
JYs intersection probabilities,
replace k by k plus j in the sum.
Okay, with this in place there
is the generic principle of inclusion and
exclusion.
The principle says
something about the number
of occurrences of these
underlying events A1 through An.
If you look at the sum of the indicators,
X1 plus X2 plus X3 through Xn,
the sum will just flag
whichever events occurred.
You'll get a 1 when precisely that
event occurred, and therefore the sum
will give you exactly the number of
occurrences of the events A1 through An.
So on the left-hand side what you discover
is the probability that the number of
occurrences takes some given value k,
k of course is arbitrary.
It could be a number between 0 and n.
On the right-hand side,
we get an alternating sum,
and it looks complex assuredly but
what we take away from this is
atop all those binomial coefficients which
appear on the right, what you're seeing
are the terms which involve the KYs
intersection of probabilities,
the k plus 1Ys intersection
of probabilities,
the k plus 2Ys intersection of
probabilities, and so on and so forth.
The high level principle here is this,
if it turns out
that intersection probabilities are
relatively easy to compute in the problem,
then these probabilities for
the distribution for
the number of occurrences of these
events is now readily computable.
Perhaps not in closed form, but
at least numerically computable.
Of course the simplest of these settings,
remember is when we have independence
because an intersection probability
is just evolve into products.
The great worth of this principle is this
is going to take us beyond independence.
Even in settings where
the events are not independent,
but the degree of
independence is not severe.
If it is mild,
then perhaps we have a chance
of computing intersection probabilities,
perhaps by dint of a little more effort.
And if we can do that,
then we can compute the distribution
of the number of occurrences.
Look so, here for the first time in
our entire sequence of lectures,
we are hitting upon a theoretical
principle which will allow us to move
beyond independence albeit in
a modest way towards mild dependence.
Okay.
So this is the setting, and why this
kind of structure will be important.
How do we go about verifying
a formulation like this?
Now in the case when k was 0,
then we are targeting the question,
the problem of.
What is the probability that
none of these events occur?
And you'll recall from our context in civs
if these events A1 through
An reflect bad events.
Then you're asking what's the probability
of the occurrence of something bad?
Venn diagrams prove to be particularly
efficacious in that setting.
And we could almost read out
the Inclusion-exclusion formula
by over counting, under counting,
over counting, under counting, and
edging up to a solution.
We could progress along similar lines for
a general formulation, but
as I promised you,
we're going to take a different tack here.
The tack of the magician take a card,
any card.
In our context, fix any value k,
and pick any sample point,
say little omega.
This at least has a salutary
value of forcing you to ask
what is the basic underlying
sample space for the problem?
The very first question we
should have started with.
Starting with that pick a sample point,
any point.
Now this sample point will reside
in maybe none of the events A1 through An,
perhaps in one of those events,
perhaps in say l of them,
where l is any number between 0 and n.
Pick a sample point and ask this equation,
how much does this sample
point contribute to the left-hand side of
the equation and to the right-hand side?
If it contributes an equal amount
to the left and to the right, and
this is true for every sample point,
then you'll have proved the principle
of inclusion and exclusion.
So let's directly start by saying
the selected sample point whatever it is,
is in a set of number of
these events A1 through An.
Lets say l where l is
a number between 0 and n.
What can we conclude?
Well let's identify which l of the events,
this omega actually is n.
Of course I don't know ahead of time,
which l let's give them generic names.
Let's say omega lies in the events,
A sub j1 and
also an A sub j2 and so
on, and also in a sub jl and
in none of the others.
All right, now we've identified
which of the events omega triggers,
which of the events this particular
outcome is favorable for?
What would you tell me that the particular
sample point omega that you have selected
lies in these l events?
Then we know that the number of
events that occur is exactly
l or another word in a slightly
more verbose mathematical language.
The sum of the indicators X1 through
Xn is l, because precisely l
of the Xs take value 1, and
the remaining take value is 0.
The Xs record exactly which events
occur when omega is the outcome.
Excellent.
Now once we understand this,
now we've got an equation.
If omega is an l of the events,
then we know that the event on the left
is triggered precisely when l is equal
to k, remember k is a fixed value.
There are now three cases,
and here they are.
The number of events that omega lies
in could be either smaller than k,
equal to k, or larger than k.
We should take this in time,
and so let's promptly do this.

