So imagine that a company has been
working for a long time in a laboratory,
perhaps with animals and
has come to the conclusion
that a particular drug is
going to be a lifesaving and
going to be wonderful and is going to be
the next best thing since sliced bread.
But, of course, have remarked earlier.
Even strong faith must be
fortified by statistical test.
So what kind of test could we do?
Let's say that, testing has been down and
it is now believed that the drug isn't
that efficacious and
does what it's supposed to do.
But the question now is,
whether there are serious side effects.
In other words, let's say that we are
looking to see whether the drug is causing
an increased risk of cardiac arrest.
Now what does a serious side effect mean?
Of course, at one hand, we're talking
about something life threatening, but
we understand that,
in the general population,
just the very nature of chance
driven life, that a certain
percentage of the population will
undergo cardiopulmonary complications.
So in our instance thing,
the case is not so much that a certain
percentage of people who take a drug
may find that they have heart attacks.
No, the question is,
whether there is an increased or
enhanced risk of a heart attack,
if one takes this drug.
How should one go about evaluating this?
Naturally enough, we do a random sample.
So, we construct a statistical test,
as follows.
To begin, we construct a controlled test,
where patients are given the drug
and other patients are given
a sugar pill or a placebo.
The listener should contrast this with the
example we started with in ten, part one,
where we talked about testing SERION
vaccines, where we have known,
what the incidence of a problem
was in the general population.
If one knew, what the rate of hear
attacks in the general population is,
call that a fraction p of the population,
then a pool would do the job for us.
All we have to do is, test in
the sample of patients given the drug,
whether the fraction who
actually have complications
is similar to the fraction
in the general population.
But run into the difficulty that we don't
know [INAUDIBLE] rate, what fraction of
the general population has adverse
problems, has cardiovascular problems.
To get around this, we construct,
essentially, a double sample.
So the idea is as follows.
First, generate a sufficiently large
sample, now with Chebyshev's inequality
under our belts, we now understand what
we mean by a sufficiently large sample.
Generate a sufficiently large sample,
that we can engender a high
confidence in our pronouncement.
And then, make sure that
the sample of suitably large size
is independent and avoids bias.
In other words we want to randomly select,
from the entire patient pool.
Of course, ideally sampling as
with replacement, but of course,
in such a setting, we rely on the fact
that the patient pool is large enough,
that sampling without replacement, is
very close to sampling with replacement.
And once you've got a large
pool of patients to test on,
break them up into two categories.
One subgroup, one subpopulation is going
to be given the experimental drug.
The other subpopulation,
is going to be given a sugar pill.
But we need to manage bias, you see,
there are psychological factors here,
if a patient knows that she
is getting a particular drug,
that might condition her
body's response to it.
And so, to make sure there
is a control on the bias,
both on the side of the patient and
on the side of the physician
administering the drugs,
we do it in a doubled blind process.
The patients do not know
which group they belong to,
whether they are going to get the drug or
the sugar pill, and
the doctors administering the test don't
know which patient is getting which, and
again, the idea here is to control bias.
Good, now at this point we have
all the conditions in place for
a statistical test.
We report on whether complications
arose in the subgroup who
are given the drug, and
the subgroup who are not given the drug.
Of course this is a chance driven
process because individuals responses,
are chance driven.
Now, in, individuals given the drug,
a certain fraction will,
have complications,
will have say, cardiac issues.
The fraction of individuals
who are given a drug, who en,
who endure complications, then gives
rise to a bias in that direction.
Sampling from the population then
engenders an individual with
complications with a certain probability,
in other words,what you are doing
is generating a Bernoulli trial, flipping
a coin toss, of course this is macabre.
Success here means that
there's a health complication.
Similarly, in the population at large,
who are given a sugar pill,
a certain fraction will have
complications for natural reasons.
Random sampling from that pool,then
engenders a different coin toss,
with a possibly different success
probability, success again here,
being a macabre idea that
doesn't compel complication.
Now we have two groups, so we need to now
make a notation a little more compress.
Let's call a sample from the patient
group, who are given the drug y,
it's a Bernoulli trial,
with a particular success probability.
And let's call zed,
the result of a Bernoulli trial,
a selection of a from
a group given a placebo.
And now we have a double sample.
For the drug, we have n individuals, and
we monitor their response to the drug.
We tabulate which individuals had a health
complication, let's say a cardiac arrest,
and which individuals did not,
we have a sequence of Bernoulli trials.
Similarly for the placebo, we have
another sequence of Bernoulli trials,
this time let's say Zed 1 through Zed n,
which tag those individuals
in that control group,
who reported health problems.
All right?
Bear in mind, that these
are Bernoulli trials with a priori,
unknown success probabilities, okay?
Of course,
success here is in this peculiar,
macabre view of life, where a success
means a health problem, a cardiac arrest.
Okay, where do we go from here?
Well the idea is to compare the,
the complication frequency
in the group given the drug,
with a complication frequency in
the group who got a sugar pill.
The fraction of individuals, who were
given the drug who reported complications,
is the sum of y1 to yn divided by n,
this gives you exactly the number
of individuals who had complications in
that sub group and divided by gives you
the fraction, the relative frequency
of complications in that group.
Likewise, the relative frequency of
complications in the second group,
Zed 1 through Zed n and you add them up,
it tells you how many complications that
you had in the individuals who are given
the placebo, divide by n,
you've got a relative frequency.
The absolute difference, between these two
terms is the discrepancy in the relative
frequency, it is the observed difference,
visually, between these two samples.
Lets call this by the uppercase
Greek letter delta, the d in Greek.
So, delta is what we observe, remember?
So what are the conditions
of the experiment?
We don't know a priori.
Which sub-group here or what is the
proportion of individuals given a drug who
are going to report problems,and we don't
know a priori, what proportions of healthy
individuals or what proportion we do use
with health and drug, what are problems.
We select a name suitably large,
and then we create a double sample,
properly avoiding bias,
by doing a blind double sample.
And then we count the relative frequency
of complications in one group and
the other and compare.
The difference is the discrepancy.
So here's what we know.
Now, this number delta is available to us,
you see this what we're
empirically observed.
So now we have this number delta,
knowing this delta,
what can we say about the drug, and
let's come right down to the number,
and if you'll forgive the pun,
here is the heart of the matter, okay.
How likely is it that the observed
discrepancy, between the two samples,
the observed discrepancy in outcomes,
between patients given the drug and
the placebo is due not because
the drug does something nefarious or
bad, but
is due just to chance fluctuation.
We now have at hand the critical basis for
a principal statistical test.

