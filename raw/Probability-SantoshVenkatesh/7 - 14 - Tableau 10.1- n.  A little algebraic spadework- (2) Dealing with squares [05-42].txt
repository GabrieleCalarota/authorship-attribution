Find a simpler expression for
k squared times b n of k.
You're going to keep p fixed but
arbitrary, and
what you would like to do
is find an expression for
k squared of b n of k in terms of an
expression involving, of course k and n.
Pause the lecture and
see if we can make some progress into
trying to simplify this expression.
A key is going to be found
in the observation that k
squared can be decomposed
into a product k times k.
Restart the lecture when you're ready.
So let us begin by writing down
an expression for k square times b n of k.
With this observation in mind,
by factoring k squared as k times k,
let's group one of the 2 ks with
the binomial probability and
keep the other k outside
the round brackets.
Now take a look at the expression
inside the round brackets.
Does that look familiar?
Of course it does.
This is indeed our basic
binomial identity.
Replace k times b f k by n p
times b n minus 1 of k minus 1,
and now we've got a new
expression on the right.
Let's massage this,
collect terms, put k and
the binomial probability back together.
And now, we've got an expression
that we wish to massage further.
Now, this looks promising.
Inside their own brackets on the right,
I've got k times a binomial
probability involving a minus 1.
That looks suggestive of the second
of our basic identities.
Except for one small thing.
If I had k minus 1 instead of k,
then I could directly use
the second basic identity.
Well, no matter.
Let's start with k, and simply replace it
by k minus 1 plus 1, by the simple
expedient of subtracting 1 and adding 1.
Now, the moment I did that, then our
expression inside the long brackets
expands a little bit, but it's beginning
to look more formidable, to be sure.
But, here's the key.
The first term inside the long brackets
is of the form k minus 1 times
a binomial probability
involving n minus 1.
And the second end of the terms is just
the binomial probability by itself.
We're in business,
because now we've got a game of basic
binomial identity that we can use.
And we simply replace
the first of those terms
by a binomial probability
involving n minus 2 now.
All right.
Now we've got a bigger expression.
And of course, we could simplify it
a little bit by first collecting together
everything involving the binomial
probability, involving a minus 2 trials,
and then everything involving the binomial
probability involving n minus 1 trials.
And now we've got an identity.
Have we made any progress what so ever?
Look on the left we actually
have a very simple expression,
k squared times b n of k.
On the right it looks like
we've got a god awful mess, but
it is actually a simplification.
The key is the multiplying factor scale
the left have all vanished on the right.
The factors k have all folded
inside the binomial probabilities.
And this has got a great advantage because
of normalisation of probability measure.
Imagine that we simply summed both
sides of our identity overall values k.
On the left,
I've got an integrable looking sum.
K squared times b n of k sum double k.
But, on the right, I end up with sums
of just pure binomial probabilities.
And we know that these sums add to one.
So for example, if we fix at, affix b.
And we all sum over all k.
Then the probability of getting 0,
1, 2, 3,
or n successes in n tosses
of the coin is assuredly 1.
If it is to be considered an experiment
where we toss the coin in minus one times
and we sum the probabilities being
minus one of k minus one over all k.
Well, that just says sum of all
possibilities for successes in n trials,
and again the binomial
probabilities add to 1.
And likewise, if you some of roll k, the
probability is p n minus 2, of k minus 2.
It came we are considering an experiment,
this time involving n
minus 2 tosses of the coin, and
we're summing all possibilities for
the accumulated number of successes and
again these probabilities add to 1.
This observation simplifies
all our calculations.
And let's immediately put it
to good use by coming back
to the question of the expected
value of the binomial.

