So let me begin by turning
to Burt's paper of 1961 and
providing a selected commentary
on what we might discover there,
said to remind you to jog your memory.
These are the two tables on IQ
presented by Burt in his paper for
adults and for the children.
When one examines this data,
several questions come to mind.
One, when and
where was the study performed?
How were the tests administered?
What exactly 1,000 adults and
1,000 children tested?
Was more than one child
tested from a given family?
How did the mean IQs for
adults and for children?
Both turn out to be exactly 100.
Are the numbers three individuals
in the upper professional classes,
higher professional classes big enough to
provide reliable statistical evidence?
The listener can add more
questions along these lines.
Now to answer these,
we will have to turn to Burt's paper.
But as Cayman and others have pointed out,
it is remarkable how little Burt
actually says in that paper.
So here are some selected
quotations from Burt's paper.
Now let's naturally bear in mind that
quotes taken out of context could be
entirely misleading.
And so to get an accurate and
complete perspective,
she should turn to the original paper.
But having said that, let me glean
selected quotes, which I think.
Establish a tenure and the characteristics
of the paper and the results.
So to begin here's one.
In the paper, we find the sentence
that the surveys and the subsequent
inquiries were carried over quite
substantial period of about 50 years.
Now you should pause and
think about this for a moment.
A study, which has gone for
a very prolonged period time would imply
that the results were put together from
several smaller studies carried out
perhaps under different conditions.
Today, a statistician would
call this a meta-analysis.
But this was well before
meta-analyses were actually
formally put out on the table and
analyzed and understood.
It is not that they are useless.
Of course, there is utility in
meta-analyses properly done at the hands
of a trained statistician.
But the moment we put together
several studies, many of them small,
one should anticipate that variability and
uncertainty is going to increase and
so it does.
The, let's now might
remember the case of Avandia
from GlaxoSmithKline in
the discussion on drug testing.
Doubts were cast on the safety
of Avandia using a meta study,
a meta-analysis and
based on that analysis, the Food and
Drugs Administration enjoined that a
caution be placed on the sale of Avandia.
Making explicit observation
that a risk of cardiovascular
adverse event could be
enhanced by taking the drug.
A few years later, further studies,
caused the Food and
Drug Administration to
change their minds and
overturn the original ruling and
say that there was actually no
evidence that Avandia was in fact
as dangerous as originally thought.
The point here of course is that,
that studies like that these,
which combine data are important and
can be useful,
but carry enhanced variability and risk.
Another quote from the paper says or
at least cast
some light on how and
where the test were performed.
So Burt says that the children for
the bulk of
the data were obtained
from a particular county,
a burrow in London, which was and
the emphasis is mine,
typical of the whole county.
There are no details provided
on what typicality means.
So the reader has to form our
own conclusions based upon
at ball centers like this.
About the likelihood that the data
were in fact represented.
Yet, another quotation from the paper.
The occupational characteristics
were based not on prestige or
income, but on the degree of
ability required for the work.
Again, notice that there's
a significant subjective element
in the classifications from one through
six of the adults in the survey.
This is not in itself bad or
reprehensible, but
what is difficult is for
the reader to form a firm assessment
of whether the subject of
evaluations were well founded.
And yet another, the assessments of adult
intelligence were less thorough and
less reliable.
Why?
Because Burt goes on to say
that some of the tests were
conducted by interviews,
others by actual testing.
But there is no data provided on what
fraction of the tests were conducted
verbally, what fraction were conducted
by actual running of the tests.
What was in the test?
Which group were tested verbally?
All of this is opaque.
Here's one more and this shed some light
on some of the numbers that we have seen.
Burt goes on to say that
the frequencies inserted, so
they call that in the upper
professional classes.
Three individuals were apparently
tested adults and children.
He goes on to say that the numbers
were much more than three.
Again, the emphasis are mine.
He says, the number three was
actually more near 120 and
that all the numbers were
skilled were weighted
proportionately to reflect the estimated
proportions in the population as a whole.
How will these estimates come out,
we do not know.
Was the waiting done proportionately,
the same for all the categories.
Presumably, but
Burt doesn't always say this.
But if we were to make that reference,
then if three were to be
about one hundred twenty.
Then perhaps 1,000,
the number in the study for
each table was perhaps more like 40,000.
Three to one hundred twenty.
1,000 to 40,000.
But again, I caution you that does not
actually say that 40,000 adults and
40,000 children were tested.
But perhaps, it could be suggested
by the wording in the sentence.
Goes on to explain that the numbers
themselves were rescaled and
recentered, so that the mean of
the whole group was exactly 100 and
the standard deviation 15 or the variance,
the square of the standard
deviation 15 squared or 225.
Why would he do this?
It's not clear, but
perhaps one explanation could be that,
assessments of IQ have been
traditionally placed on a scale with
100 at the midpoint with
a certain variability, where 40 or
50 was considered very deficient and
140 was considered highly proficient.
And so, it is natural to try and
center the data along those lines.
The student who has done any
kind of experimentation is well
aware of the vagaries of
experimental apparatus.
If one, for example, does ultrasound
imagery, then depending upon the equipment
used and the skill of the operator
various base lines could move around and
so for the radiologists to interpret
what the imagery actually is.
She will have to recenter, rescale it, so
that all the images appear
on a standardized scale.
So perhaps, immortuation along these lines
was at work when Burt rescaled the data.
But again, he does not say this.
Now, at the end of this,
the reader might will
go away with the feeling that, well,
that was certainly sloppy in
the presentation of his data.
And this is a heretical statement perhaps.
Perhaps, not unusually so for
those tablets of that time.
But to move from sloppiness
to an acquisition of fraud is
a very very large jump.
So this is what we want to
try to get a handle on.
Let me try to summarize some of
the features that I have illustrated for
you in through these comments and
that's paper.
So let's look at what the original says or
at least summarize it and
in parenthesis might take
on what it does not say.
First, the data were collected
over a long period of time,
50 years, but the methodology is unclear.
For example, some of the interview
were done orally, some by test.
The children were selected from
one burrow, representative of
the county as a whole, but we do not
know what that means or how it was done.
We don't know if more than one
child was tested in a given family.
So these are all unclear,
the methodology was fundamentally unclear.
Second, the sample size
was standardized to a mil,
a thousand, but
it is suggested in the paper that
the actual numbers interviewed were much,
much larger.
That in the upper professional categories,
for example,
three was more near to around one and
twenty.
A scaling factor of 40 from 3 to 120.
It seems suggested perhaps,
then that the entire table if scaled
proportionally would lead to
1,000 being actually more
like 40,000 individuals in each
of the tables who are testing,
but this is not explicitly said.
And finally,
that the IQ's were resented and rescaled.
So that the mean was exactly at 100 and
the standard deviation,
the unit spread was at 15.
It is not this, but it could be
perhaps that said that the design
was to fit to a theoretical normal
distribution with the mean of 100 and
a variance of 225 or
a standard deviation of 15.
But what was the process of translation?
Was there any unconscious bias?
Or misunderstanding of
how to massage the data?
This is unclear.

