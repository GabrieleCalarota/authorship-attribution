With this in hand we are quite equipped to
begin an assault on the question of what
does k red balls in a row say about the
chance of a k plus 1 red ball in a row.
Recall the implicit measure places
equal mass on the events A0,
A1, through An and gives you conditional
probabilities in a very natural sense.
Now, suppose we ask,
what can I say about a probability.
That k red balls in a row were chosen,
from which of were overselected.
The event H sub k is now stands
in the role of the event
H in the definition of conditional
probability on your upper right.
We naturally decompose this event in
terms of the ancillary events A0,
A1 through An which tells
which urn was selected, and
now we've got a change rule for
conditional probability.
Observe that in the sum it was more
natural to begin the sum at j equal to 0
and run it all the way up to N.
The implicit specification
of the probability measure
reduces the sum into a nice and
simple form.
Now at this step, the probabilistic
intuition of the problem is exhausted.
We've now got a sum.
The sum may or may not be reducible
in terms of simpler elements,
but now the probability, or
chance elements, are exhausted.
But, of course,
we don't want to leave a sum in that form.
We'd like to see if we can simplify it,
get some information from what
the nature of the sum is.
In particular, we'd like to say something
about what happens to such a sum
if a number of possibilities for urns,
if a number of balls N is very large?
Now let's write the sum out explicitly.
Right, so the sum now are of the form
an integer over N to the power k.
And they're multiplied by
values 1 over N plus 1.
Recall, N is a large number.
So we've got these small increments,
1 over N plus 1 multiplying a power of k.
This begins to look familiar.
We've seen sums like this on
the pathway in the basic calculus,
on the pathway to integrals.
Let's focus on again what
are the things we're adding.
We're adding weighted powers of k.
Well let's take a look at a power of k.
Naturally enough, we call it x to
the power of k, x runs from 0 to 1,
and we've got a smooth increasing curve.
What does each summand look like?
All right.
If you look at, say, the jth summand, it's
got a height, j over N to the power k.
And so,
that gives you the height of the curve
x to the power k at the point j over N.
It's multiplied by 1 over N plus 1.
If we subdivide the unit
interval into N plus 1 pieces,
each of width N over 1 plus 1,
the the jth term corresponds
to a rectangle of height j over N to
the power k and width 1 over N plus 1.
And therefore the jth term is identified
as the area under the jth rectangle.
When you sum up all these terms, we're
summing areas of a sequence of rectangles.
As N becomes large,
these rectangles get closer and
closer and
closer to the area under the curve.
We begin to recognize a Riemann sum.
As an approximation to an ordinary,
garden variety Riemann integral.
And this integral is particularly
simple and beguiling.
And so if we know make the natural
step and say, N is large.
Then the sum in question
is indeed an approximation
to the integral from 0 to
1 of x to the power k.
But of course,
this is a completely elementary integral.
And we evaluate it, and we find that
the answer is beguiling in its simplicity.
Under this probability model, for repeated
selections of balls from a random N,
the chance that k red
balls are drawn in a row,
is approximately 1 over k plus 1.
And the approximation gets tighter and
tighter and tighter the larger N becomes.
We're now equipped to answer
the following question.
Given that our red balls
in a row have been drawn,
what is the chance that the next
draw will result in a red ball?
From a mathematical prospective,
this is equivalent to asking what
a conditional probability of
the occurrence of the event Hr plus 1,
given that the event, Hr, has occurred.
Now we promptly just write down
the definition of conditional probability.
And, we get a ratio of probabilities, and
the key here is to observe
that the events, Hr and
Hr plus 1 stand at a particular relation.
Hr plus 1 means that r plus 1
red balls have not preserved.
But if r plus 1 red balls were drawn,
then manifestly it is true that r red
balls must have been drawn prior to that.
And, therefore, the event Hr plus 1,
will imply the occurrence of the event,
Hr.
From a perspective, the event Hr,
plus 1, is a subset of Hr, and
therefore, the intersection of the two,
results in the smaller of the two sets.
In other words, simply Hr plus 1.
And therefore,
the conditional probability in question
devolves into a ratio of probabilities.
Hr plus 1, the numerator,
Hr in the denominator.
And now we simply plug in our
beautiful Reimann approximation.
And if we do this, we discover that
the conditional probability of drawing
a red ball,
given that r red balls have been drawn,
differs from 1 only in
the reciprocal of r plus 2.
One could hardly ask for
a simpler, cleaner explanation.
Now, before we go back to Laplace,
let's do a quick sanity check.
And to make sure we have
the mechanism under control,
let's ask the following question.
What can we say about
the probability that given
r red balls have been drawn in a row,
the next s draws result in red balls.
In other words,
what is the probability of the event Hr
plus s conditioned upon
the occurrence of the event Hr?
Take a minute and
see if you can work out an approximation.
If we follow through exactly
the same line of argument,
as is sketched about,
we find that the probability is
given by the ratio of r plus 1,
to s plus r plus 1.
And the argument is exactly the same.
How does this fit in with the original
question in that Laplace raised?
To get a proper understanding would
require a careful, historical study
to get at what Laplace intended
by this kind of analogy, okay.
But one could imagine
making a tenuous connection
if we replace balls by
let's say universes,
a large number of potential universes,
one of which is chosen at random.
And then we model the sun
rising everyday of the year as
a random experiment with replacement, what
all that means in that given universe.
Then we have in a very, very vague and
tenuous way a connection
to the Zern problem.
And of course, as I've said, to get a real
understanding of what Laplace meant,
we'd really have to undertake
a detailed study, and
that would take us a little far afield.
As a side note, that, remarkably
these ideas of multiple universes
are now getting currency in various models
of our quantum mechanical universe.
But that takes us further afield.
Let's come back to Laplace.
The kind of mathematical analysis
we wanted taken is impeccable.
The probability models there,
the probability space is clear.
There's no ambiguity.
And therefore,
the conclusion's also very, very clear.
The connection with the original question
of the sun rising is much more tenuous.
This requires a measure of
faith in some underlying,
stylized, sanitized model of randomness.
Which of course is would be highly
debatable in the best of times.
Even if one were willing to buy into
an argument involving a large number of
universes, the Laplacian kind of argument
captured in that quote from Laplace
would posit the occurrence
of the following event.
That a sun has risen for
a large number of days,
about 1.8 million days, without a break.
Of course,
we believe in something like that for
the same reason as we believe
that the sun will rise tomorrow.
Of course, the underlying foundation for
our belief structure here,
we draw from the mechanical
universe of Isaac Newton.
And simple models of physics,
which allow us to predict and
test various hypothesis, 'kay.
Laplace, of course,
was quite cognizant of this.
And, so here's another quote,
which tells us that this kind of analysis
should in context like this,
should be taken with a large bit of salt.

