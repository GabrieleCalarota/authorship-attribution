So we're now come full circle.
Back to our original
problem of estimation.
What is the size of a sub-population
in a given population?
What is the proportion
of that sub-population?
So, to recall,
this was a model for a poll.
We start with a population, of which a
certain fraction, a certain proportion p,
constitute a sub population of type 1 and
the remaining proportion q, 1 minus p,
is the proportion of a sub
population of type 0.
How do we estimate the fixed parameter p?
Well, we sample.
And we model this by a sequence
of repeated independent trials,
coin tosses, Bernoulli trials
with success probability p.
The accumulated number
of successes S of n,
is governed by a binomial distribution
with parameters n and p, and
a question is,
is Sn over n a good approximation to p?
Now, look all we got all
the data about Sn at this point.
To let us takes talk of what
it is we know in this setting,
and what it is that we want to figure out,
at.
The heart of this is going
to be a new principle,
that is articulated by
the statistician R.A.
Fisher, in the very early
part of the 20th century.
Let's begin by putting down what we know.
We've done a sample of size n.
We've got these Bernoulli trials,
X1 through Xn.
Once you do the experiment, of course,
these Xs are chance-driven, but
once you do them,
you know the outcomes of your experiment.
You know the Xs, and therefore, by adding
up the 0s and 1s, you know S sub n.
So this is what we know.
The accumulated sum,
S sub n is chance-driven.
But once the experiment is
preformed it is known to you.
The experiment is driven by
an underlying bias parameter, p.
The weight of your coin.
This is a fixed real number.
If there's,
it is not at all chance-driven.
It is fixed, it's deterministic.
But sadly, we just don't know what it is.
So, here is our question.
I know this chance to an entity
once I do the experiment.
I know S.
How can I infer p?
Which is fixed but unknown,
from this chance experiment.
And Fisher articulated a very simple and
elegant idea.
His maximum likelihood principle
just says, estimate the bias
by that value which best
explains the observation S.
Now, let's pause and savor this.
It's so elegantly simple.
Estimate the bias by that value,
which best explains the observation S.
Only experience will teach
a student that elegant,
simple prescriptions
like this are worth much,
much more than ponderous
condition beset settings.
Where what is not even clear how
one could go about doing something.
The genius of such a simple
prescription is that one,
it is transparent and once articulated,
it is clear that it is right.
How else would we do it?
And two, the simplicity of
the pronouncement allows us to put
together a formal evaluation framework
relatively easily and simply.
Let's go ahead and
put a mathematical frame back around this.
So, what is the basic setting?
We have conducted a sequence of trials,
with a coin, with a fixed but
unknown success probability p,
we accumulate the successes
from our variable S of n, but once we've
done the experiment, we know S of n.
We're going to put this to good use.
The idea is treat p, the fixed but
unknown probability of the coin,
the bias of the coin,
as a variable x to be determined.
Why do I call it x?
Well of course, habituation and
tradition have intuitively the thinking
of real variables as text.
And so we want to back tradition.
I'm going to think of all
possible values for the bias x.
And then select that value which
best explains the observation S.
Or in our setting for
any possible bias for the coin x,
the chance of obs, obtaining the observed
S is governed by a binomial probability.
And now the expanded notation for
the binomial probability becomes useful.
What is known here?
I know what the number of trials.
I know n.
What is known here?
I know the observed value S.
I know how many successes we obtained in
tossing that metaphorical coin in sampling
from a population.
I know n, and I know S.
The question is which x gives me
the best expli, explanation for S?
Well, let us ask the following question.
If the coin had a success probability x,
what can I say about the probability that
it gives me S successes in n trials?
Again, what do we know?
I know n.
I know S.
For each x I can evaluate
this probability.
The maximum likelihood principle says
something very clean and simple.
Right?
This probability, the binomial probability
that I can write down,
it varies as x varies.
What can we say about it?
Well, let's massage it a little bit.
The idea is, I'm going to select that x,
which maximizes its probability.
A little algebraic massaging
will make matters simple.
What matters is the fraction S over n,
which is going to represent
the proportion of one's in my sample.
Let's multiply and
divide by n to get everything in
terms of the fraction S over n.
Now on the right hand side you'll find x
to the, to the power n times S over n,
and 1 minus x to the power
n times 1 minus S over n.
The two thing on the right
both have a power n in them,
let's group them and
raise the power n outside.
Then we have an expression
of the following kind.
In the square brackets, x to the power
S over n times 1 minus x to the power,
1 minus S over n,
the whole product to the power n.
Our goal is to find an x which
maximizes the quantity on the right.
Now, the binomial coefficient n choose S,
is neither here nor there,
it's a fixed constant.
It does not affect the value of
the right-hand side, as x varies.
Power functions are monotonically
increasing functions, right, so
the listener knows how
the power functions go.
Right?
The function x goes like this.
X squared goes like a parabola.
X cubed goes up even faster.
All powers increase steeply.
They're monotonically increasing,
and therefore,
if I want to maximize the right
hand side by varying x,
it will suffice to maximize the thing
inside the square brackets.
This gives rise to this beautiful
maximum likelihood principle.
Suppose I observe S successes in n trials.
The fraction of successes is S over n,
let's give it a name, let's call it r.
What I would like to do is to find that
value x, which maximizes the product of
x to the power r,
times 1 minus x to the power 1 minus r.
This of course for
each given r is a function of x.
Let's call it f of x.
All right, now we have this clean and
beautiful mathematical problem.
I'm given r,
because I've told S and I know n.
Given r,
I'm going to look at a function f of x,
which is x to the power r times
1 minus x to the power minus r.
Find where its maximum lies.
Of course it's going to depend upon r.
Right.
It's easiest here to simply
draw a bunch of graphs and
explore what happens to this function
as r varies between 0 and 1.
And let's promptly do this.
Here are various graphs of the function.
I've given you examples when r is 0.2.
R is 0.4.
R is 0.5.
R is 0.6 and 0.8.
And even a cursory look at these graphs
shows that the function where r is
0.2 has a peak, a maximum value,
exactly at 0.2.
The function with r is equal to 0.4 has
a maximum value a little bit further
delayed, but
either of course at exactly 0.4.
The function when r is equal to
0.5 is completely symmetric on
both sides of one-half.
And it achieves its maximum
exactly at one-half.
When r is 0.6 the function achieves
it's maximum at x equal to 0.6,
and then r is equal to 0.8 the function
achieves it's maximum at r equal,
at x equal to 0.8.
The evidence is, is compelling and
at this point the less dilemma I'd
be willing to quite believe that in fact,
the function, f of x given by x
to the power r times 1 minus x to the
power minus r, is maximized for a given r.
Precisely the point x is equal to r.
Remember r represents the fraction
of successes in my sample S over n.
The x value for
which the function is maximized is
exactly the proportion of
ones in my sample, S over n.
And this immediately
gives us a strong reason
to believe in the native
intuitive procedure.
Sample n, and
count the successes in that sample.
Look at the frequency by dividing by n.
And this is your estimate of
what your underlying p is.
And in fact, in some sense, this is
the best estimate you could come up with.
This is the maximum likelihood estimate,
this is that value
of buyers which best
explains the observed data.
It's going to be hard to come up
with much better motivation for
saying this intuitive process of sampling
and taking fractions is the way to do it.
But of course this leaves
a couple of questions.
Right?
Two new questions arise.
The first and
we've alluded to this earlier,
how big should the number of trials be?
How big should the sample be?
So that we can get an adequate
confidence in our estimates.
In other words, I would like to be
able to give statistical guarantees
about how good your
estimate is going to be.
And of course, the derivation of such
estimates is going to be important.
Because if we, if we,
if you can't give guarantees,
then in settings like public health,
we are in a morass of uncertainty.
Now, we would like something more.
We'd like to know with what kind of
guarantee, our estimates are good.
So there's an issue of trying
to tease out more information.
And if I can do that then
a subsequent question would then be,
how big does the trial have to be?
How many trials before I can
get adequate con, confidence?
This is going to require us to delve
a little deeper into the structure and
the nature of the binomial distribution.
And so, we should do that next.
But before I do that, for
that reader who doesn't believe in just
the evidence of the pictures that
the function f was maximized exactly at r,
here's a pure calculus proof.
For the reader who is willing
to accept this in faith,
she can simple skip over
the next mini lecture, and
move on to a digging into the in
art of the binomial distribution.
But for the reader who's got a little bit
of calculus, not very much is needed.
All that is needed is
an understanding of a derivative and
the fact that to maximize a function,
you set a derivative equal to zero.
For such a reader follow along
with the next mini lecture.

