At the end of this all, we've discovered
something a little unexpected.
We started with an experiment with
a distinctly discreet provenance,
tossing a coin repeatedly.
And out of the ruins
emerged a real number.
Somehow, we have transited from
a discreet setting into the continuum.
This understanding propels the start of
a new structure to handle
problems in the continuum.
So let's begin again.
We're starting with the coin tossing
experiment, tossing a coin repeatedly.
The sample points of such an experiment
are unending sequences of heads and tails.
And if we write zero for a tail and
one for a head, we have unending
sequences of zeroes and ones.
And as we saw,
such sequences can be identified
with a dyadic expansion for
a real number, in this case one-thirds.
And this leads to a correspondence, a
dictionary of translation between the coin
tossing experiment and an experiment
involving a continuum of real numbers.
Our outcomes now are numbers which
take values between 0 and 1.
Now let's take stock right.
If we remove the, the super fluid details
here which is adding color to the game,
the idea of the coin and the tossing.
What we are left with is a plain,
unvanished real number.
The sample space now
is a continuous space.
Omega is the unit interval.
And formally, we'll write this
as the set of real numbers x
where x ranges between 0 and 1.
The sample points here
are numbers x between 0 and 1.
What are the natural
events in such a setting?
Now the moment one has
a continuum to deal with,
individual points start
losing their significance.
There are just too many of them.
But what is natural and
appropriate here is that the basic
events are intervals of interest.
For example, the interval from a to b.
And naturally now, we want to ascribe
probabilities to these events and
to more general events.
And how do we assign probabilities?
We appeal to the fact that the symmetry
in the coin tossing endeavor
makes every quartile as likely
as every other quartile.
Each region is as likely
as any other region.
And therefore,
the probability of an interval should
be proportional to its length.
In this case, the interval a to
b has a probability b minus a.
Key here is the fact
that the probabilities
are invariant with respect
to where the integral is.
The probability only depends
upon the length of the interval.
This, if you will, a potent understanding
of what is going on, so let's start again.
Key here was its translation in variance,
probabilities do not depend
upon the interval positioning, but
only on the length of the interval.
Suppose we consider
an infinitesimal interval
situated at x with
an infinitesimal length dx.
Right?
Indicated by the red bar in the figure.
Well, what probability
should be assigned to this?
Naturally, the length of the interval.
In this case,
that infinitesimal length dx.
Now, pause for a moment and
look at their equation.
On the left, we have a probability, or
more precisely a probability mass,
it's got weight gravitas.
On the right, we've got a length.
Now, to equate mass to length, there
must be something multiplying length and
what must multiply length?
Mass divided by length.
Now suppose we rewrite
d of x as 1 times dx.
Dx again is going to represent length.
1 must then perforce represent
a mass per unit length.
And this mass per unit length is
uniform everywhere at the interval.
Of course we're going to multiply this
mass per unit length by a unit of length.
And together, we obtain that mass divided
by length, times length, gives you mass.
Now what is object mass divided by length?
That is what we call a density in physics,
and we use a saying,
nomenclature, the same kind of
vivid physical illusion here,
to think of a density as something which
has got units of mass per unit length.
Now, once we have this in hand,
we can stitch together
probabilities by using additivity.
Let's start by taking our interval and
breaking it up into a whole bunch
of teensy weensy little pieces.
A whole bunch of infinitesimal pieces.
Well, we'll simply write
down that the sum of
these probabilities must then
give us the true probability.
Now what's the sum innate clean notation?
We sum over all these tiny intervals of
the probabilities of those intervals.
Of course we're going to make these sub
intervals tinier and tinier and tinier.
And in the limit, you'll recognize the
kind of transition we have into calculus.
Whether you go from discreet to continues,
sums segue
naturally into the real integral,
and therefore, the sum,
in the limit as these infinitesimal
intervals become tinier and tinier.
Becomes the integral over that
the interval from a to b of what?
Of 1 times dx.
This must therefore, in the limit,
as the interval sizes become tinier and
tinier and tinier, be exactly
the probability of the interval a to b.
But of course,
this is an elementary interval.
And you evaluate it and
of course we get as we must b minus a.
But this is a potent understanding.
What we have done is represented
an interval probability as an integral,
as an area under a curve, let's promptly
consolidate this understanding.
So, here again,
an infinitesimal interval of
length dx has got probability 1 times dx,
identify 1 as a uniform
density per unit length.
The probability of the integral is
then the integral of 1 times dx
over this interval.
Let us introduce a function and
naturally we're going to call it
the uniform density in the unit interval.
Let's call this function u of x,
u of course is for uniform.
It's a mnemonic.
U of x takes value 1 in the unit
interval and 0 outside.
We're going to think of u of x
as telling us something about
the mass per unit length at the point x.
How do we compute probabilities?
We simply integrate this function.
Little bit, u of x is just a fancy name
for 1 as long as x is between 0 and 1.
Off side of 0 and 1, it is 0.
The probability is obtained but
integrating a density over
the region of interest.
That gives rise now to this idea
that probabilities in the continuum
can be associated with integrals
with areas under a curve.
This is a potent idea because
now this leads to the idea
that we can perhaps have
other continuum experiments
with different mass distributions for
unit length.
This is next.

