Chebyshev's Inequality was to
have a very deep consequence
right across the theory but
it immediately provides us
a vehicle to analyze and
understand why polls really work.
So, let us begin with
a quick recapitulation of what
the essence of a poll is.
We imagine an underlying
population which has individuals
of two types, one or zero,
Republican or Democrat.
These subpopulations appear
in a proportion P and
a proportion Q that
are a priori unknown to us.
We wish to understand what
the distribution of these proportions is,
in other words,
we'd like to estimate p and q.
To this end,
we start by sampling randomly,
independently, without bias,
from the entire population.
Recall that sampling is,
at least nominally, with replacement.
And we generate,
we engender a random sample of size N.
X1 through XN.
Correspond to Bernoulli trials with
a fixed but unknown probability,
p, and naturally we
immediately form an accumulated
sum of successes in the sample,
and this is what we call s sub n.
Of course, s sub n is equipped with a
binomial distribution with two parameters.
A number of trials n, the number of times
we've tossed this metaphorical coin and
the bias parameter p representing
the sub-population proportion
that we are interested in estimating.
Bear in mind that once we
generate a sample, we know n.
Of course, this is the number of
data points we have accumulated.
But we do not know p.
We have been led to believe that
the estimate of the relative
frequency of successes in the sample,
s sub n divided by n,
is indeed a good estimate of
the underlying population proportion p.
How good is it?
So, here's a stage where we first realized
that it's a chance experiment, so
certainty is going to be elusive.
We are going to per force
compelled to make errors.
But we would like to control
the size of the errors.
It's a chance experiment,
therefore we can't have certainty, so
we're going to have to say things
with a certain amount of confidence.
And so the error we make, the confidence
with which we make a pronouncement.
And the sample size,
are intimately connected.
What is the desired item
that our estimate of P,
in other words a relative
frequency of successive Sn over n,
deviate from the fixed underlying
sub-population proportion P.
But even a small amount,
epsilon the error told us.
This probability should
not exceed a number,
delta, where 1 minus delta is
a confidence we wish to have.
For definiteness, we could think of,
say, epsilon as a small number, say 3%.
Delta is another small number, say 5%.
So we want no more than a 3%
error with a confidence of 95%.
It's a very simple,
beautiful, elegant equation.
And its estimation is facilitated
by Chebyshev's inequality.
The probability at hand is
bounded about by the reciprocal
of 4 times the sample size n times
the square of the error parameter epsilon.
And so it suffices if this
bound is no more than delta.
And so, we have a slogan.
If the sample size exceeds the reciprocal
of 4 epsilon squared delta,
then we can assert that a estimate
of the underlying population
proportion, p,
has made an error which is no larger than
epsilon with the confidence
of at least 1 minus delta.
Some numerical estimates
will add flesh and
color to these bare mathematical bones.
So, let's go ahead and
properly plug in some numbers.
Suppose we look at a situation
where we are permitted to make
no more than say a 10% error.
And we want a confidence of at
least 90% in our pronouncement.
We plug in epsilon is point 1,
delta is point 1.
And we observe that a sample
size that is requisite is 250.
What if we want a tighter error tolerance,
say 5%?
Epsilon is 0.05, and
say we want a tighter confidence,
we want a confidence in our
pronouncement that of at least 95%.
In other words, delta is also 5%.
Plug in epsilon and delta,
both being 0.05, and
we find that a sample size of 2,000
suffices to guarantee an error
of no more than 5% with
a confidence of at least 95%.
And if we get a little greedier still.
An error of 3% and a confidence of 95%,
epsilon is 0.03, delta is 0.05 and
now we find that a sample size
a little in excess of 5,500
will suffice to give us a very friendly
small area of no more than 3%.
With a high confidence of at least 95%.
There are some things that
are worth taking stock here.
Observe that our sample size estimate for
a desired error tolerance and
for a desired confidence, our sample size
estimate nowhere contains within it.
This high of the underlying population.
It is independent of how a small or
large the underlying population is.
It makes no matter whether we
are dealing with a population of 10,00,
a 100,000, a million,
10 million or a billion.
Whatever the size of the underlying
population, if it is dichotomous and
contains sub-populations of two species,
two types, two characters, two colors.
A fixed sample of size about 5,500 will
estimate the relative sizes
of these sub-populations.
With an error of no more than 3% and
a confidence in excess of 95%.
This is magic.
And of course we should promptly
encapsulate it in these political days
via a slogan.
So here is our slogan.
A relatively small, honest, random sample.
What does honesty mean here?
That in fact the sample is independent and
that it is unbiased.
A relatively small sample of
the order of a few thousands,
whose size does not depend upon
the underlying size of the population or
upon what the particular mix of
sub-populations is, what p is.
So a sample size independent
of these parameters gives
a very good estimate of the underlying
sub-population proportions.
This is magic of a high order.
And this is why polls work.
On the face of it,
they have no business working.
A sample of a size a few thousands
doesn't seem reasonable that
it would contain within it,
within it the sentiments of a very large
underlying population, but it does.
And at the heart of all of this
is the inequality of Chebyshev.

