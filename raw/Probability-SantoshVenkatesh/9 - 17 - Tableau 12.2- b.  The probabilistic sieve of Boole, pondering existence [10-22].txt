Let me begin our discussion by
taking you on a small detour.
Through the ancient art of sieves.
Sieves have been around since antiquity.
Here are some images from around the world
showing you sieves in use today.
Where does one use these sieves?
Well, to strain materials for impurities.
To get at stones mixed
in with bushels of corn.
Perhaps if one is panning for gold,
the impurities are in fact the gold.
You pan for gold nuggets and try to the
sieve away the dirt in which it resides.
Now, while sieves have been
in common use for centuries,
in the modern day sieves continue to
be of use in a variety of settings,
sieving flour, sieves in
a teapot to catch the tea leaves.
Sieves in high technology, to purify and
catch impurities in the production,
for example, of semiconductors.
So sieves have been around for
a great long while.
What we shall do is take a new look at
sieves from a mathematical perspective.
We're going to be talking
about a metaphorical sift.
In mathematical filter, we are going
to be fishing in a croissant pond.
So to set the stage, let me go back to
an ancient and well-understood inequality.
I'm going to take you back to five and
a discussion of one of
city whence emerged.
This basic and simple inequality
that we call Boole's inequality or
the union bound.
Captured in language it says
something very, very simple.
The probability of the union of
a collection of events is no
larger than the sum of
the associated probabilities.
Now this is a very blunt instrument,
the right hand
side is hardly a good estimate
of the left hand side
unless of course the events are disjoint,
are mutually exclusive.
But in general the bound does
not give us very sharp answers.
None the less, it has utility and
we've seen examples of where
Boole's inequality turns out to
be surprisingly efficacious.
But let's take a good hard look at a bound
and say, well I have an inequality.
I have a right hand side,
where is it likely to be useful?
I'm going to now focus, zoom in,
on two regions where this bound
becomes strangely interesting.
The first reason is obvious, what if
the sum on the right is a small number?
Now, that'll force the probability
of the union to be a small number.
In such regimes,
the inequality is not grossly bad and
one can imagine that it
might well be useful.
And it is but
there's another region less obvious where
the sum turns out to be remarkably useful.
And this is going to be
the thrust of our lecture today.
What if the sum on right is is large?
Now what does that mean?
Well, if a sum is one or larger then
that is patently useless because we know
that probability on the left
can not exceed one.
Or what if the sum on right is not small?
But it is not one exactly,
can anything useful be said.
Turns out remarkably, yes.
Some terminology and
some color will add to
the picture, so here's some
colorful notation and terminology.
Let us think of the events,
A1, A2, A3 and so
fourth as bad events,
something bad happens.
And then of course naturally
the complements of these events,
the age A complements are what
you call good events.
Now with this kind of idea to give us
a feeling for what we are discussing.
In the union of all the ages means,
that if this occurs then
some bad event occurs.
One or more bad events occur,
something wicked this way comes.
Conversely, if the compliment of
the union, other word, in other words,
the intersection of the compliments of
the ages occur then no bad events occur.
That's an interesting thing to look at.
So with this metaphorical view of these
events, let's turn to the two regions
where Boole's inequality
might perhaps be useful.
So let's start with a setting
that we're familiar with,
what if Boole's bound is near zero?
Now we can immediately conclude that
if the right hand side is small
than the left hand side is sandwiched
between zero and a small number.
And therefore the left hand
side isn't immediately small.
If you want to be very mathematically
precise about it, if the sum on the right
is no larger than some given tiny,
positive quantity epsilon.
Then the probability of the intersections
of the complements of these events.
1 minus the probability of
the union of the of these events.
A probability that nothing bad
happens will exceed 1 minus epsilon.
Although they,
this is an important observation.
Again if the sum is small then
the probability that no bad
event occurs is quite large is near 1.
This could be put immediately to
use in a variety of circumstances.
So for example, what are the kinds
of things we might want to look at?
Well, let's say we take
something from medicine.
We are watching a patient with
cardiovascular problems over
a period of time.
If over the period of observation,
new cardiovascular event occurs,
no bad event occurs then
it is manifestly good.
And the chance of that is high,
we are doing well.
So, something which is as worthy as this
is definitely deserving of a slogan.
So here is our slogan, if Boole's bound
is near zero then most outcomes are good.
Nothing bad happens, excellent.
What if the boundary is not near zero,
what can we say now?
Well let's suppose that Boole's bound is
potentially quite large but less than one.
In that case,
what can we possibly conclude?
Well if the right hand
side is less than 1,
that manifestly sums the left hand side.
And so this says that if the sum
on the right is no bigger
than 1 then the probability
that no bad event occurs is
strictly positive.
What does that buy us?
It tells us that somewhere
in the space of outcomes
there is at least one outcome for
this idealized chance experiment for
which none of that bad events will occur.
This is telling us something about
the existence of good outcomes and
we'll promptly codify it in a slogan.
We'll call it Boole's sieve,
we are fishing in a probabilistic pond.
We are hunting for a probabilistic
needle in a probabilistic hay stack and
we don't know if it's there.
But Boole's sieve tells us that if
the sum of probabilities is strictly
less than one even if it's quite large,
the sum could be say 99%.
That would mean the probability
that no bad event occurs,
that all events are good simultaneously.
No cardiac arrest occurs over
a period of observation.
None of a group of mobile phone
calls are dropped by the carrier.
If only good events occur then
there is one sample point for
which that will happen.
This is telling us something about
the existence of a good outcome for
an experiment.
This seems like very stony ground but
look out of all of this
a principal has emerged.
The setting is one where we
are doing a chance experiment.
We don't know if there are any
good outcomes for the experiment.
We will see under these
conditions allows us to conclude
that there exists at
least one good outcome.
And of course, proving existence
is an important first step.
We won't look for
a hypothetical quantity which may or
may not be there unless we have
some guarantees it actually exists.
We'll promptly put this to use and
you'll see how delicate arguments emerge
from his apparently innocuous observation.

