Poisson points, waiting times.
A dangerous bend segment,
proceed with caution.
The Poisson process is a fundament in
characterizing the theory of queues,
congestions, arrival processes and
random scatter.
At it's heart,
it is characterized by two requirements.
That, in any interval, the number of
arrivals is categorized by a Poisson
variable, with a certain mean
arrival rate, say alpha.
And furthermore, that in disjoint regions,
the number of arrivals
constitute independent trials.
The listener may well feel that this
is a very complex set of requirements,
the consequences of which
are not entirely apparent.
And the listener might
also recall my strident
exhortations in problems and
chance to always
begin with the right understanding
of the underlying probability space.
So, what is the probability space
that underlies a Poisson process?
It would be wise to follow the sage
advice of George Paul here and begin with
an elementary setting, the first, simplest
thing that characterizes the process.
And if one thinks of the process
as an arrival process,
naturally enough we think of
time following to the right.
And then, an object of curiosity
becomes the first arrival.
So now let's focus on this.
The first arrival occurs at some random
point in time, and now naturally,
it is important to focus on
the time of the first arrival.
Let us promptly deduce
a little bit of notation.
Let us introduce X1 to denote the time
at which the first arrival occurs.
Naturally X1 is a chance variable.
What is its distribution?
How do we compute
probabilities relevant to X1?
At this point a key observation makes
matters completely transparent and,
to wit, that if you pick
an arbitrary point in time, say, t,
the event that the first
arrival occurs after that t
is equivalent to saying
that the number of arrivals
up to t is exactly 0.
Let me repeat that again.
The event that the first
arrival occurs after t
occurs if and only if the event that
there are no arrivals up to t occurs.
And the moment we say something like this,
we now have a direct path to calculating
the probabilities associated
with the time of first arrival.
And so, directly, the probability that X1,
the time of first arrival,
exceeds a given value t,
is exactly the probability that
there are no arrivals up to t.
But now we have related the distribution
of the first arrival time to
the distribution of a number of arrivals,
and we know exactly what this is.
N of t is governed by
a Poisson distribution
with an expected value of alpha t.
Therefore, in this case all we have to
do is look up the Poisson probabilities,
p of k with a parameter alpha t,
put in k equal to 0,
and just write down our observation, okay?
It's P, the Poisson probability
of no arrivals in a duration t.
Okay, now we just read out the answer,
right.
If in the Poisson formula
we put in k equal to 0,
the fraction becomes 1 over 1, and
all that remains is a simple exponential
form, e to the power, minus alpha t.
Naturally enough now,
the probabilities decay with time,
and they decay exponentially fast,
and therefore,
in a fit of originality,
we call this the exponential distribution.
Now notice how easily and simply we've
computed a probability involving what,
on the surface,
appears to be quite a complicated object.
X1 is clearly a chance variable,
but it is not discrete anymore.
In fact, it takes a continuum of values.
No matter.
We can relate its distribution to
that of the Poisson process N of t.
In such a formulation we already
have all the information we need
to calculate any relevant probability
involving the time of first arrival.
And, as a sanity check, let's see how
one could do one such calculation.
So let's begin now.
We know that the time of first arrival is
governed by an exponential distribution.
By which we mean that the probability that
the time of first arrival exceeds any
given positive time t is exactly
e to the power minus alpha t.
Now take a hand at evaluating a slightly
more complex prob, probability.
Suppose s and t are positive real values,
and s is less than t.
What are the chances that the first
arrival occurs between s and t?
[SOUND].
Pause the lecture for a moment and
see if we can make headway with this.
If you find you're stuck, run the lecture
again and you will see a hint appear.
Now here is a hint.
We may partition the interval
from 0 to t into two intervals,
an interval from 0 to s, and
a disjoint interval from s to t.
Or if you want to put it
in probability terms,
the event that the first
arrival occurs at or before t
is the same as saying that
one of the two events occur.
To wit, that the first arrival
occurs on or before s,
or the first arrival occurs after s and
before t.
Now pause the lecture again, and
with this suggestive partition in hand,
see if we can work
through the probability.
Now let's begin an assault on the problem.
We know that the interval from 0 to t can
be partitioned into two sub intervals,
one from 0 to s, and one from s to t.
Additivity of probability measure tells
us therefore, that the probability
that the first arrival is at or
before t is the sum of two probabilities.
That the first arrival is at or before s,
together with the probability that
the first arrival is is between s and t.
Let's rearrange this to focus
on the probability of interest.
And so the probability the first
arrival lies between s and
t is exactly the probability that
the first arrival occurs at or before t.
From which you take away the probability
that the first arrival is at or before s.
Again, this is just a consequence of
additivity of probability measure.
The two probabilities on the right are,
deal with probabilities
where the first arrival is at or
before a certain point in time.
But we've already seen that the
probability of the first arrival occurring
after any given point in time
is given in an exponential form.
Now all that remains is to
invoke additivity once more,
to message these
probabilities in the right,
to get probabilities of the form that the
arrival is after certain points in time.
And here we go.
Observe that the probability that
the first arrival is before t,
added to the probability the first
arrival is after t must give us 1.
The is additivity.
And similarly for s.
All right, the terms 1 on
the right hand side cancel out.
Let's rewrite the terms, and
we obtain that the desired probability is
given by the probability that
the first arrival is after s,
from which you take away the probability
that the first arrival is after t.
And now we simply read out
the exponential forms.
The first of the probabilities
on the right is of the form,
e to the minus alpha s.
The second of the probabilities
on the right is of the form
e to the power of minus alpha t.
And there we have it.
Simple and elementary.
The listener might want to play with
this formulation to see how other
relevant probabilities involving
the first arrival come out.

