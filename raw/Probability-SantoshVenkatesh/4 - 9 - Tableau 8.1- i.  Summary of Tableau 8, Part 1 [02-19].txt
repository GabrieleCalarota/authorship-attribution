Let us summarize our findings today.
Summary of Tableau 8, Part 1.
Characterising side information
in chance experiments, and
the role of conditional probability.
Side information in our chance
experiments, is always folded into
the fabric by the specification of
the occurrence of an ancillary event.
It's A, B.
We define the conditional probability of
A given that an event B of
positive probability has occurred.
To be inwards the proportional
part of A which resides in B,
and formally as a math,
as a matter of mathematical definition.
The ratio of the probability
of the intersection of A and
B to the probability of
the ancillary of A to B.
It's a very clean and simple definition,
this is something that
you should remember.
From the definition arises
another piece of insight.
The definition of conditional probability
is endelectibly intwined with
the idea of conjuctional probabilities.
So we could write down
conjunction probabilities,
probabilities of intersections, in terms
of a chain of conditional probabilities.
Either things of this kind
are occasionally useful,
when it transpires that the problem
setting makes computations of conditional
probabilities straightforward, where the
computation of conjunction probabilities
might not be quite so simple,
might be more opaque.
This is now the of conditional
probability that we will deal with.
In our next tableau, we will return to
our guiding principle of additivity,
one of the pillars on which this
entire science of probability rests.
And we shall see how
conditional probability puts this
principle in a new and beguiling light.
We shall discover
a panoply of applications.
Subtle, deep but elementary.
Arising out of this very simple
exercise of this principle.
So this will be on tap for
our next lecture.

