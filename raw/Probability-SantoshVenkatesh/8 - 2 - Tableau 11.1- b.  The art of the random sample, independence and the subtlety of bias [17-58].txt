Our focus now is on
the efficacy of the estimator.
How well does the relative frequency
of successes in a random sample
actually approximate a true
underlying population proportion?
But before we dive into the
technicalities, it would be well to step
back and take a look at what
underlies all our calculations.
And that is, the idea of a random sample.
I will phrase our discussion to
follow in the context of polls,
but what I'm going to say
is going to be valid for
any random sample generated
from any chance experiment.
Now, there is an art to a random sample.
What is the first step in
the idea of a random sample?
Well, the first step is to
construct a sequence of trials.
And there are two key features.
One, the idea of independence, and two,
the idea that the trials evolve from
an underlying chance experiment.
Let us take these one at a time.
First, this central and
key idea of independence.
This is the idea that runs a thread
through all of the theory of chance.
The key principle is keen of independence.
What does independence mean?
At its foundational level,
from a purely formal point of view,
independence implies a rule of products.
Formally, that when one looks at a sample
generated by independent trials, then
probabilities are obtained by multiplying
raw probabilities for each trial.
What does this mean in
the context of a poll?
Now for a poll,
we have some underlying population,
fixed, and for the purposes of the poll,
immutable, it does not change.
And sampling implies that we do it fairly,
that every member
of the population has an equal chance
of being selected in any given trial.
In other words, a member of the population
is chosen uniformly at random.
But that is not all.
The moment an individual is selected and
queried or looked at,
it is imperative from the formal
point of view that that individual
is replaced in the population before
an independent second trial is conducted.
In other words,
sampling is with replacement.
The listener can easily see why
the replacement idea is important,
especially when one
considers small populations.
Let's say one has a population of,
of three people.
The moment one queries something to one
person, if that person isn't replaced in
the population, the next sample element
is drawn from a population of two people.
We have changed the underlying
chance conditions.
The population has changed
from trial to trial.
Now admittedly,
when populations are large,
this effect becomes vanishingly small.
Say if a population has
got size of 100 million,
then it makes little matter whether
one member is replaced or not,
especially in the context of relatively
small samples of hundreds or thousands.
But this is an important guiding
principle to be kept in mind.
Sampling has to be done with replacement,
and uniformly from the entire population.
So at heart, the idea of independence
engenders a product space and
a product probability measure where
probabilities are obtained by multiplying.
If a listener will cast her
mind to tableau ten, and
when we looked at the construction of the
binomial distribution, she will realize
that at the heart of the construction was
a simple multiplication of probabilities.
So this is the first key central idea
in the notion of a random sample.
In an application,
the user will be well advised
to look at the provenances of
a sample before doing any analysis.
If somebody reports and says, I've got
such, such and such sample, it will
be well to cast an eye at the conditions
under which the sample was generated.
In practice, of course,
we deviate from these assumptions,
these sterile and beautiful assumptions
of independence in various ways.
The question then is, how much of
an artifact do we introduce in practice?
And to the extent that the assumption
of independence is violated,
to that as, extent,
our conclusions are suspect.
So this is our first key tenet,
independence.
But there is a second tenet.
And that is that the sampling is done by
sampling consistently from some
underlying chance experiment,
a target experiment which does not change
from sample point to sample point.
Now, it is very easy
to introduce bias into
an otherwise honest experiment.
The sampling might be done independently,
but
the target experiment might well not be
the one that we think we have in mind.
Bias may be conscious or unconscious.
When it's conscious, of course, this is as
talk and trade of the unscrupulous poster.
Bias can arise in several
different flavors.
And it is again important to
understand the nuances of how
uncertainties and
biases can creep into these examples.
The first example of bias is,
when in sampling from a population,
there is a bias in selection.
Now, let me give you a couple of examples.
In an earlier generation,
the genders were very firmly aligned
with different rules in society, right?
So for example,
in the early part of the 20th century,
in many societies men
worked outside the home.
Women stayed at home and
took care of the household.
Now, imagine a poll construc,
a, conducted, let's say,
in the 1950s when telephones were
just beginning to become widespread.
And a telephone poll is con, is conducted,
and the pollster says, well,
let me call homes at,
let's say, noon, or 1 p.m.
Would there be a problem
in conducting such a poll?
Assuming, of course,
that the numbers are chosen independently,
or as close to independently
as we can manage.
Nonetheless, it is clear that
a selection bias is introduced,
because who is at home in
the middle of the day?
Well, the homemaker.
Even if the poll is conducted
independently, the sample then reflects
that post percent of the population who
are at home in the middle of the day.
That percentage of the population, while
an honest accounting for that subgroup,
may or
may not represent the population at large.
And so, here's an example of a selection
bias that has insidiously crept
in to the sampling process.
Here is another historical example.
The year was 1936, and this was
a year of a US presidential election.
The two primary candidates were
a Democrat, Franklin Delano Roosevelt
on the one hand, and a little-known
Republican named Alf Landon on the other.
And they were contesting this election.
History buffs might recall that this was
the time of the Great Depression, right?
The economies were plunged into chaos,
families were thrown into straits.
Now, in this election, of course, there,
there was intense interest in who
was going to be the likely winner,
because that was going to likely determine
the policy for the country going forward.
A highly read magazine,
the Literary Digest,
at that time decided to conduct a poll
on who the likely winner of
that presidential election was.
They sent out ten million questionnaires,
received two million questionnaires back,
and concluded that the Republican Alf
Landon was going to win in a landslide.
Now, the US political election
system is a bit arcane.
It's a winner-take-all system, for those
who don't understand it, where each state
votes, and the majority vote
determines who wins that state.
Each state then contributes a certain
number of what are called electoral
college votes.
And in 1936, there were 531
electoral college votes available,
and the presidential candidate who wins
the majority of those wins the election.
The Literary Digest predicted
that Landon was going to win 360
of the 531 electoral
college votes on offer.
This is a landslide.
Of course, history showed they were wrong.
Roosevelt won, and won convincingly.
In fact, Roosevelt won by one of
the largest margins in history.
This had been predicted by
a young man named George Gallup,
who had conducted a poll on
ten thousand individuals.
Not very large, is it,
compared to a ten million.
And he observed that based on the polling
numbers, he predicted that all but
a small handful of six electoral
college votes would go Roosevelt's way.
In other words,
a diametrically opposed prediction.
And he was right.
Now, why would a poll involving tens of
thousands trump a poll involving millions?
The answer, of course,
resides in an insidious
bias that had not been factored
in by Literary Digest.
It turns out that the majority
of the readers of
Literary Digest were in rural communities.
And then in the United States, as now,
rural communities tend to
vote strongly Republican.
And therefore, the Literary Digest
reported an accurate estimate,
but for rural communities.
Of course, but rural communities do not
comprise the entirety of the country.
The Gallup poll, on the other hand,
looked at the entire country in fair and
just proportion, and thereby came up with
a much more accurate estimate, 'kay?
Of course, this was then the origins
of the Gallup Organization and
the prevalent Gallup Polls of today.
So, selection bias is a critical and
important thing to look at.
When one has a sample, one should cast
an eye and say, was this sample taken from
the entire population uniformly,
or was there some kind of
selection bias which focused on
a subgroup of the population?
A second idea of bias comes around,
about because, folks are impatient.
Look, and
this is the issue of non-response, or
what is also called refusal bias.
The listener today is well aware with
the common practice of calls coming in
to solicit opinions to sell products,
right?
I am a probabilist, but
I must confess that when I get home late
in the evening and
I'm ready for my dinner, and
I get a phone call from somebody who wants
my opinion on something or the other,
in principle, as a good probabilist
I should probably answer so
that their, the sample is unbiased and
representative.
In practice, I end up saying, no,
I don't wish to answer, and I hang up.
Here is an example of a refusal bias.
The difficult, this is very difficult to
combat, you see, because people naturally
value their time and don't want to spend
the time answering a stranger's questions.
But the moment one refuses,
then implicit here
is that the sample that is
actually obtained is obtained
from that subportion of the population
who are willing to answer questions.
In other words,
this is a coalition of the willing.
To the extent that that subgroup is
representative of the entire population or
not representative,
you'll find that this sample is
representative of the whole population or
not.
Look, and this is very,
very difficult to combat.
Still another area of bias arises
in the wording of the questions,
as a question of phrasing.
Now I've mentioned, this can be conscious
or unconscious, but words are powerful.
They convey meaning.
And if one uses them incautiously,
then what is understood
by the listener may be very different
from what is intended by the speaker.
Let me give you a, an example,
not entirely hypothetical, about how
an unscrupulous pollster can shade
a poll in any direction she wishes.
Imagine that there is a country
where at some point in
time, a law providing health care to
retired citizens has been provided.
In other words,
this is a senior citizen benefit
which allows them to have health benefits
from the government after they retire.
Suppose this is in place, but there's
no such law for the general population.
Imagine then that an enterprising
leader decides that he wants to provide
a law which provides a blanket coverage
of insurance for the entire population.
Now, good people can debate whether
this is a good idea or a bad idea.
But, let's say we want
to get the sentiments
of the population on whether this
is a good idea or a bad idea.
Here are a couple of questions
one could pose to the population.
Let us say that the existing law,
which provides health care for
seniors, has been working for
many years, and has been working well.
Suppose one asks a respondent,
would we want
our children to have the same health
care benefits that our parents do?
Now naturally, when one fo, pa, poses
a question like this, we all want good
things for our children, and therefore,
the tendency is to say, oh yes, of course.
But suppose one were to phrase
the question in the following way.
Do you want a nameless bureaucrat
to control your health care?
Of course, the way the question is
worded is extraordinary pejorative.
He feels very bad.
He says, certainly not.
I want to be in control of my own destiny.
But at its heart, both questions touch
upon a common underlying structure.
The posited health care benefits that
the seniors are receiving are provided by
the government.
It's a government entity.
And in both cases,
we are referring to something which
has been provided by the government.
But depending on how we
phrase the question,
we can elicit very different
responses from the same person.
And so, phrasing is important.
In a good poll, the pollster will make
an effort to be completely unbiased and
present questions raw, without tilting
it in one direction or the other.
When one evaluates a poll,
one should always look at this axiom.
Of course, you see when one is given data,
we have very little control over the data.
We have what it is.
But if we want to begin an analysis on it,
we should always begin with
the question of, are the data sound?
Is this really a random sample
from the experiment I had in mind?
Is independence approximately visible?
Is there bias?
Now with this for background, let us
now return to the question of the poll.

