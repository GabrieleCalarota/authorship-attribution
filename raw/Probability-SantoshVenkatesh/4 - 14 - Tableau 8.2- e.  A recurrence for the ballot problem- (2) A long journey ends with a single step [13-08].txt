A little introspection will tell you that,
the first step is not
likely to be profitable.
Because if the event h is to occur.
If Jane is to lead at
every step of the count.
Then the very first ballot must indeed
go to Jane and there's no possibility.
Otherwise, Bob will take an early lead.
Okay.That's doesn't seem very informative,
there's no variability possible at all for
the first step from the first ballot
if Jane's the lead at every step.
But the last ballot seems to
be relatively unconstrained.
Who does it go to?
Well, there are two possibilities.
It could go to Jane,
or it could go to Bob.
Now, this is suggested.
You see, the last ballot has
to go to one of two people.
It has to go to Jane or to Bob.
We now have a way of partitioning
the space using an ancillary event.
The event as to what
happens to the last ballot.
Let us introduce some notation now,
alright.
And using the notation we've been
using throughout this top level.
Let A denote the side information,
ancillary information about the game.
Let A denote the event that
Jane acquires the last ballot.
The complement of A, then of course, is
the event that Bob gets the last ballot.
We are now in place to put
together some early calculations.
Well, let's begin.
Let's take a look at the pictures
we have developed so far.
All right.
To begin, we have, n plus m ballots,
n go to Jane, m go to Bob.
If Jane gets the last ballot,
then the remaining ballots
are n plus m minus 1 in number.
And of those ballots,
remember Jane gets the last ballot,
Jane now gets n minus 1 and Bob gets m
of the first n plus m minus 1 ballots.
If on the other hand Bob
gets the last ballot,
then of the first n plus
m minus one ballots,
Jane still has to get n but
Bob now gets m minus one.
This is our picture.
Now let's see how we can milk this.
Remember our target event is h, that
Jane leads at every step of the count.
This event has got a certain probability
under our probability measure,
our combinatorial measure.
We don't know what it is.
We would dearly love to know what it is.
Of course,
this is the object of the exercise.
But, whatever it is, it is going to
depend on only two parameters.
The number of ballots that Jane gets, n,
and the number of ballots Bob gets, m.
In other words, the probability of H,
is a function of n and m.
Let's introduce a little notation here,
let's call this P with subscripts n m.
So we'll call this p of n and m.
Keep in mind that P sub m
represents the probability that Jane
leads bob at every step of the count.
When she gets n votes, Bob gets m votes.
And the notation is valid for
any choices of n and m.
Now, let us see what we can say
given this choice of notation for
the condition of probability that
Jane leads at every step of the count
given that she gets the last ballot.
Now, once Jane gets a last ballot, there
are n plus m minus one ballots remaining.
She gets m minus one of them.
Bob get m of those.
And whatever the arrangement, it has
to be the case that the running total
over those n plus m minus one ballots
has to favor Jane at every step.
This suggest that all we have done
is reduced the size of the problem
from n plus m ballots to
n plus m minus 1 ballots.
From n votes for Jane,
to n minus 1 votes for Jane.
From m votes for Bob to m votes for Bob.
And therefore, the conditional probability
that Jane leads every step of the way,
given that she gets the last ballot,
the conditional probability of H given
A is, our notation, P of n minus 1, m.
Recall P of n minus 1 comma m tells us
that in an election where one candidate,
Jane gets n minus 1 votes,
Bob gets n votes,
that the candidate Jane leads
at every step of the way.
That's exactly what is captured now
in our conditional probability.
What if Bob gets the last vote?
In this case,
we have n plus m minus one ballots.
The first n plus m minus
one ballots of these,
Jane has to get her full compliment
of n and Bob has to get n minus one.
And they have to be arranged in such a way
that Jane leads every step of the way.
And by our definition, by our notational
choice, the conditional probability
given the complement of A that Bob
gets a last ballot is exactly P sub n,
m minus 1,
a distinction with a difference.
This is subtle, so pause,
make sure we absorb this.
Okay.
The key idea here is that by focusing
on that last element,
what we manage to do is reduce
the size of the problem to
a smaller problem of the same type.
Once we have this in place,
we have all the elements needed
to put things together into
a beautiful formulation.
Okay.
Of course, we now want to need
to understand something about
the nature of the site information,
the ancillary event based on which we are
computing these conditional probabilities.
And here's where the artful choice
of partition comes to the fall.
By looking at that last tip,
it becomes easy to see
what the chance of the last ballot
going to one or the other candidate is.
Let's begin at Jane.
What is the probability that
Jane gets the last ballot?
Well, this is simple enough.
The last ballot now is fixed to be J,
that leaves M plus M minus one ballots.
Of those M plus M minus one ballots,
M belong to Bob.
And the number of ways
of arranging m Bs and
n minus 1 Js in the first n plus m minus
1 ballots is n plus m minus 1 choose m.
How many ways of there are of
arranging m votes for Bob in totality?
Well, there are n plus m ballots.
And Bob can be the m ballots for
Bob can be in any of m locations.
That's n + m, choose m.
We take a ratio.
Simplify the binomial coefficients,
and we get n over n+m.
Very simple.
We pause.
I say, is this reasonable?
Of course, it is.
There are n+m ballots.
The chance that a chosen ballot
goes to Jane isn't actually enough.
The proportional number of ballots for
Jane out of the total, n over n plus m.
What are the chances the last
ballots goes to Bob?
Well, this is the event,
the compliment of A.
And of course,
we could use a similar calculation,
or simply appeal to additivity and
subtract the probability of A from 1.
And we find this is, again, very
intuitive, very natural, m over n plus m.
All the raw materials now are at hand.
We've got second draw probabilities,
the probabilities of our side information,
our ancillary events.
We also have various conditional
probabilities, albeit in terms of
the still, awkward,
strange notation that we have created.
Well, let's put this all together and
see where we end up.
We are interested in
the probability of the event, h.
That gene leads at every step of
the count when she gets n ballots and
Bob gets m ballots.
By additivity, in conjunction with
chaining unconditional probabilities,
we can write the probability of H by
conditioning first on the occurrence of A,
that Jame gets the last ballot.
And then, by conditioning on a complement
that Bob gets a last ballot.
On your left, is the probability
that we have called P sub n m.
It depends on course on n and m.
On the right, we have a decomposition,
which is the first conditional probability
of H given A is P of N minus 1 comma M.
A has got probability N over N plus M.
The second conditional
probability P of H given he
complement of A is P of N comma M minus 1.
And in the probability of
a complement is m over n plus m.
This is looking complex, but
we've actually made great strides.
You see, on the left is the target,
an expression in terms of the n and
m given to us.
On the right is an expression involving
fixed ratios, involving an n and
m, and terms that depend upon n and
m for smaller values of n and m.
As a high level principle,
this is very important.
We've taken a complex problem,.
And in one step, reduced it to
an amalgamation of smaller problems.
This gives us hope.
Now, before we go on and
try to solve this,
such an expression holds for
a sudden range of values of m and n.
Which range of values?
Well, m has to be at least 1.
And n has to be larger than m.
What we've done is constructed
a recurrence with a range of validity.
Now, you may have
experience with recurrence
arguments in and duct arguments.
Recurrences arise, for example,
things like binomial coefficients and
a variety of other settings.
A familiar, important one is
that of the Fibonacci sequence.
But in general,
to solve a recurrence of this nature,
one needs boundary conditions, all right.
And so what happens at boundary values for
n and m?
And these are easy to intuit.
What can we say about P of n and
m, for example,
when m is bigger than n?
Well naturally, if, m,
is as big as, n, or larger,
then the chance that Jane will lead
at every step of the way is zero,
because sooner or later,
Bob will catch up with Jane's count.
What if then a zero, what if Bob,
the poor unfortunate Bob gets no votes.
Then as long as Jane gets any votes,
then she will take a lead and
she will never relinquish it.
The chance is certain.
This gives us boundary conditions.
Now together,
an recurrence with a range of validity and
boundary conditions give us all
the tools needed to solve the problem.
At this point, we've exhausted all the
chance to the elements for the problem.
We are now left with a calculus problem,
right?
A question of solving for
a double index sequence
satisfying a certain recurrence definition
with certain boundary conditions.
But, of course, now we don't
want to leave it at this point.
But we do want to carry it through
to see what the answer is and
see whether it comports with intuition.
So, let's spend a slide on building
up a solution for this problem.

