Our next problem
illustrating additivity in
conditional probability has
a classical provenance.
This is called the ballot problem,
and here's a clean and
simple version of this problem.
Imagine that you have a class election
in a class with ten students.
And, there are two protagonists
who are competing for
the exalted role of class prefect.
Say, let's call them Jane and Bob.
Jane picks up six votes.
Bob picks up four votes.
So, Jane wins the election.
Imagine that the ballots
are counted in some random order.
What are the chances that,
as you begin a running count,
starting with the first ballot cast,
what are the chances that
Jane leads at every step of this process?
Of course, Jane wins the election.
But, as you count,
is it the case that Jane
took an early lead and
never relinquishes it?
Now, here is a particular
instance of this problem.
All right, so
imagine you have ten ballots cast in
this particular order I have shown you.
Starting with a ballot for Jane, then a
ballot for Bob, then a ballot for Jane and
so on down.
Six in total for Jane,
four in total for Bob.
Now, let's start a running
count on the left.
With the first ballot cast,
Jane's count is one, Bob's is zero.
With the second ballot cast,
Bob picks up a vote.
Jane is one, Bob is one.
With the third ballot cast for
Jane, Jane is now two,
Bob is still one, and you go on down, and
by the time the tenth ballet is cast,
Jane has accumulated six, and
Bob has accumulated four.
Clearly in this particular example,
Bob has managed to draw even with or
even surpass Jane's count at
several places in the count,
though of course,
he eventually loses the election.
Now, we are now talking
about sequences of ballots
where Bob never catches up with Jane.
Of course, one can imagine combinatorial
ways of attacking this problem, but
already can say that it is,
it is not trivial,
it is actually of some complexity.
For instance, what if Jane had,
let's say, 51 votes of 100 and
Bob, 49,
what does your intuition tell you?
What are the chances that Jane will
lead it every step of the count?
If it's 51 to 49, then every vote is,
essentially, a coin flip.
There's almost just a 1 in 2 chance
that a given vote goes to Jane or Bob.
In such a setting, one might expect
that there are frequently changes,
but that eventually,
Jane gets her nose ahead and wins, yeah.
If you were to put a numerical
estimate of the chance
that Jane actually leads at every step,
what do you think it might be?
Think about it for a minute.
All right, we will do formal analysis in
a moment, but what does instinct tell you?
Now, if one wants a formal
attack to the problem,
then one might as well
deal with it in abstract.
Suppose Jane gets n votes
in an abstract setting and
Bob gets m votes in this abstract setting.
Naturally enough, we will require n to be
bigger than m, else Jane will eventually
lose election and Bob will have surely
caught up with her and surpassed her.
So, let us ask this
following question now.
We have a run-off election
between two candidates.
N plus m ballots are cast.
Jane gets n, Bob gets m.
The ballots are counted
in some random order.
And a running count is maintained
from the first ballot to the last.
At the end of the game,
Jane wins, n is bigger than m.
But, what is the chance that
the running count favors Jane
at every step of the process?
This problem has got an ancient and
classical vintage.
This was analyzed by W.A. Whitworth
in 1878 by combinatorial methods.
We shall look at the problem
through a different prism.
Conditioning ideas in this
setting provide an elegant and
beautiful approach which unlocks
the problem very elegantly, right?
So, let's think about how one
might approach such a problem.
Now, before we launch into the details,
before we utilize the,
the mechanism which is part
of this mathematical subject.
One should always pause and
think about the problem holistically.
At the end of the day, issues like
these all concern problem solving,
and problem solving demands that one
understand the logic of the problem
before one jumps into it and tries to
utilize this formula or that, all right?
We should want a principled basis for
how we approach a problem.
This problem looks rather complex.
How should one approach it?
Well, one suggestive line of thought
arises from the observation that this is,
in the class of problems which
are described sequentially,
one ballot at a time.
And, in sequential problems, it transpires
that a frequently efficacious
method is to look
at what happens at a given
step in that sequence.
And, typical useful steps to look at
are the first step or the last step.
You might be reminded of
the ancient Chinese proverb
attributed to Lao Tzu from about
the 5th century before the Common Era.
Where Lao Tzu says, and
transcribing very, very roughly.
A journey of a thousand miles
begins with a single step.
When you have sequential problem,
it is useful,
very frequently,
to ask what happens after a given step?
Say, the first step or,
perhaps, a last step.
So, let's look at problem now,
from a visual point of view.
N plus m ballots are cast.
I have arranged them on a screen for
you from left to right, labeled 1,
2, 3, up till n plus m.
N of those ballots go to Jane,
m go to Bob.
This is a chance experiment, and so
our first question inevitably is,
what is the sample space?
What is the space of idealized outcomes
of this conceptual experiment?
So, let's begin with this.
Now naturally, the sample space consists
of all such sequences comprising
n Js, j for Jane, and m Bs, B for Bob.
All such sequence, of course we
could enumerate them, but if n and
m are even modestly large, this is
a very large but finite sample space.
What does a random
ordering of ballots means?
Well, this gives us
a probability measure at hand.
The probability measure here
is implicitly combinatorial.
It is comprised of atoms where
every atom has equal probability.
All sequences of n Js and
m Bs are equally likely.
This is our mathematical model.
And, finally then,
we come to the question of,
what are the relevant
events of interest to us?
Naturally enough, the question posed is
the event that Jane leads
at every step of the way.
Now, this is easy to describe in language.
But, when you think about this
in a mathematical framework,
we realize,
this is not at all simple to describe.
We are looking at sequences of n plus m,
Js and Bs,
and arranged in such a way that
the running count of Js at
every one of the n plus m steps,
exceeds the running count for Bs.
Okay, now, in a given example,
I can write down a sequence.
For example, n Js to begin,
and m Bs to follow.
This clearly has the desired property.
Jane takes a massive early lead.
In fact, gets all the votes up front and
by the time the inert ballot is cast,
she leads by n to 0.
And then, Bob plays catch-up, but it's
too little, too late, because by the time
the last ballot is cast, he's still
only got to m, which is smaller than n.
Here's one example of a such a sequence.
You could construct other examples on
a trial and error basis, but, clearly,
this is very complex.
Right, you could imagine situations where
Jane leaps ahead and then Bob catches up
partway and then Jane jumps ahead again,
and Bob catches up a little bit more.
Okay, this looking,
is looking very, very complicated.
And any attempt at writing
down an entire sample's,
an event from the sample space based
on these, on these lines of thought.
It is going to involve
significant complexity.
Let us pause and ask, are there
ancillary events of interest to us
which could simplify the problem,
partition the problem?
And, we will appeal to the wisdom
of Lao Tzu and say, well,
what can you say about a step?
One step in this journey
of n plus m steps.
It turns out, for this problem,
that a very profitable step to look at is,
indeed, the last step.

