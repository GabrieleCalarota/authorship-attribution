We are now ready for a formal
definition of how to fold in side
information into the chance process.
Recall now that our experience
with simple examples tells us
that the way we proceed is
always by providing information
in the form of the occurrence of
an ancillary event, let's say B.
We have a target event A of
primary interest to us, and
a Venn diagram encapsulates
the picture quite nicely.
So, we have a target event and
an ancillary event, and now what matters,
given that the ancillary even has
occurred, is proportionately that portion
of the target event,
which resides in the ancillary event.
Now, let's formalize this.
We will say the conditional
probability of the target event A,
given the occurrence of an ancillary
event B, of positive probability.
In short, that's a mouthful, so we'll
simply say, the probability of A given B.
We will denote it succinctly,
mathematically, by using a bold font P for
probability, as always.
The target event A of interest to us,
a vertical bar as a separator to tell
us that there is information arising,
coming, from an ancillary event,
which follows the bar, that is B.
We are taking some liberties with notation
here, because of course, P stands for
a probability measure.
It is a set function.
The moment you see P, you anticipate
an argument which is a set, an event.
And now, I'm giving you two
events with a bar in between, but
it's a harmless liberty.
We take this object to mean
something very specific.
Colloquially, the proportionate
part of A that resides in B.
And formally, we define the conditional
probability of A given B to be the ratio
of the probability of the intersection
of A and B, to the probability of B.
Now, before we go on to test our
understanding and build more intuition for
what this definition is telling us,
we should extract some immediate features
from this very simple definition.
First, the chance, or the probability
of B, arises in the denominator.
And from early calculus, we know
that dividing by zero is forbidden.
The event of B has to have
strictly positive probability.
What if B has zero probability?
Well, in this case, a conditional
probability is simply undefined.
In most elementary settings, we will never
encounter the situation where we have
an event of zero probability.
But, when you do move into
the continuum ,we will
find that there are nontrivial
events of zero probability.
And in those instances we are going to
have to adapt this definition to do
something else.
But, for our purposes now,
we will define conditional probabilities
of events only when the side
information is in the form of an event
of strictly positive probability.
Now the events A and
B I've given you here,
are arbitrary events in some
common probability space.
We put no restriction on
the nature of these events.
They are subsets of the sample space.
And in particular, the ancillary event,
the side information,
B, could arise or could be specified
in any fashion whatsoever.
So for example,
B could be formed from intersections,
unions, other set
operations on other events.
B could be a composite event.
It makes little matter.
At the end of the day,
we have a subset, and
we're conditioning on
the occurrence of that subset.
One final feature we should extract
from the story is that, again,
we have two events, A and B.
What if we reverse the order?
What if B becomes a target event, and
we're given ancillary information,
side information,
in the form of the occurrence of A.
The definition will immediately tell us
that in general, conditional probabilities
are not symmetric with respect to the
order of specification of these events.
In general,
the probability of B given A is not
the same as the probability of A given B.
To settle understanding, write down
what the probability of B given A is.
And then ask yourself,
under what conditions can the two
conditional probabilities be the same?
Pause and see if you write it down.
Let's see if you came
up with these answers.
The probability of B given A.
Recall the definition says, the way
we write on a conditional probability
is in the numerator, you write
down the intersection probability.
In the denominator, you write down
the probability of the ancillary event,
the side information.
And so the probability of B given
A is a ratio of the probability of B
intersection A, to the probability of A.
Now, if you look at the two formulae,
you find that they're not the same.
The numerators are indeed the same.
Intersection is a commutative operator.
You can do it any order.
So, the chance of A intersection B is the
same as the chance of B intersection A.
But the denominators are rather different.
In general, A and
B need not have the same probability.
It's indicated visually in your figure,
but
I've shown you A and
B having different sizes and shapes.
But, when can these two
ratios be the same?
Well, the necessary and
sufficient condition is immediately,
that the denominators have to be the same,
and therefore,
the probably if B given A is equal
to the probability of A given B,
if and only if A and
B have the same probability.
We're not saying that A and
B are the same events,
we're just saying that they
have the same probability.
Okay, now we have
a definition under our belts.
We should immediately just settle
concepts to test our understanding of
the definition.

