We now have two hard won identities,
and we should hold them.
A basic binomial identity
involving k times b n of k.
And one we've discovered with just
a little bit of algebraic affect.
An identity involving k
squared times b n of k.
The first of those will be immediately
useful, the second very shortly.
So let's write down the expression for
the expectation of the accumulated
number of successes.
E of s n,
also in the common language called mu.
And given by a weighted sum
of binomial probabilities.
To the term k times b of k, we immediately
replace it by our basic binomial identity.
Since n times p does not depend upon k,
it can be pulled out of the sum.
And now we've got a sum of
binomial probabilities involving
a tacit experiment, where a coin has
been tossed n minus one times, and
we're summing overall k.
As we sum overall k, then we sum over
all possibilities for successes in those
n minus one tosses, from zero successes
all the way up to n minus one successes.
And the normalization of
probability measure tells us
that this sum must be exactly 1.
And so, the sum just vanishes,
quietly, like the snows of yesteryear.
And what remains is simply np times 1.
Or of course just n times p.
One could hardly ask for
a simpler, cleaner,
more intuitive solution to the problem.
The expectation of a binomial distribution
corresponding to n tosses of a coin,
who's sexist probability
is p is exactly n times p.
The expected value,
the probabilistic center of mass
coincides with the maximum probability.
The picture, here.
I mean, this, at some level,
might seem obvious.
But not at all so, really.
Because one could imagine a setting
where one had a mastiff, let's say.
Where one has a sharp peak and
then a long fallout.
If you had something like that, then yes,
you do have a unimodal character.
But most of the mass is on the other
side of the peak, and that for
the center of mass will be very
far from the maximum value.
The fact that this does not happen for
the binomial is important,
in fact, hugely important.
What our calculation tells us for
the expected value is that,
not only is the maximum
probability around n times p, but
this is a true center,
in that the probabilities,
the masses are distributed
fairly evenly around the center.
Not exactly equally, but roughly evenly,
in such a way that the center of mass
coincides exactly with the point
where the probability is largest.
We have further evidence now
that our estimation procedure
actually is doing something very well and
very correctly.
The maximum likelihood
estimate of an unknown p,
turns out to be s of n divided by n.
And now, we've got two more pieces
of evidence telling us that
this is actually very reasonable,
very intuitive, very proper.
Sn of n is not just the maximum
likelihood estimate of p,
it is the place where you have
the largest binomial probability and
it is also the place where the center of
mass of the entire distribution lies.

