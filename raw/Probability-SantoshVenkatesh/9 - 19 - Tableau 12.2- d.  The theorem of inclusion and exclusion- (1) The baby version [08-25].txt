So, our idea now is to think of
a metaphorical probability sieve.
Our sieve is going to try to sift
through possibilities at random and
try to find nuggets of information.
We are going to try to get a sieve,
which is a little
more delicate than the rather crude
sieve rate using pool's sieve.
And the provence here really
is going to be this and
here's where the big
pay off is going to be.
We're going to be dealing
the provence of rare events.
And therefore, we're looking for
this nugget of gold.
This nugget of information,
which may or may not be there.
And we're going to sieve through
the possibilities and try to discover it.
So this is the high-level
philosophical bent to how
we are approaching these issues.
So let me take you back to tableau five,
yet again.
The basic principles inform everything.
And this time,
going back to the idea of additivity
in the guise of
the inclusion-exclusion theorem.
When I teach my life classes,
my students joke that I invariably
talk about the importance of additivity
and I encourage my students to.
Or they wake up in the morning to
genuflect reverently three times in
the direction of that
magnificent principle.
So, I should exhort you to do the same.
Additivity is this guiding principle,
which I've oft repeated,
which is at the heart of mathematics.
In the guise of inclusion-exclusion
here is an identity we had discovered.
We discovered through the probably
of disjunction of the union of two
events could be written as the sum of
the event probabilities from which
you take away the probability of
the conjunction or the intersection.
And visually,
from a Venn diagrammatic point of view,
it's quite clear what's going on.
The union on the left,
talks about the two blobs put together.
On the right, we first add up
the individual probabilities of those two
pieces and then we've find we've
overcounted, we've overcompensated.
The lens in the middle was counted twice
and so we promptly subtracted once and
Bob's your uncle, you've got an identity.
Now, in a dangerous bend individual
lecture on tableau five,
this was the lecture titled
Something to Ruminate On.
We tried to extend this
principle to three events.
Now, I can have no compunction whatsoever
about showing you a dangerous bend
segment, because this entire part
is a dangerous bend tableau.
So here is the identity we've discovered,
if you need to go back to tableau
five to look at this lecture again to
remind yourself of whence this came.
The identity said that the probability
of the union of three events could
be decomposed as follows,
as a sum of event probabilities from which
you subtract various possibilities for the
conjunctions of events two at a time and
then you add back the probability of
the conjunction of all three events,
the intersection of all three of them.
If we were to extract a general
principle here it is this.
Add odds, subtract evens.
Let's immediately take this epiphany and
extract a deeper,
richer principle out of this.
So notice you've, I've given you
the two inclusion-exclusion identities.
And this time grouped in pieces,
in segments,
where it makes clear this idea of
adding odds and subtracting evens.
We are now looking forward to extending
this principle not just to three or
four events, but
to a generic number n of events.
And you want to say something about the
probability of the union of all of them.
Now the inclusion-exclusion principle in
its guises, when we had n equal to 2,
n equal to 3, such is the importance
of grouping in odds and evens.
Let's promptly introduce a little
notation to capture this.
So let us write S1 for the sum of
the individual event probabilities.
The probability of A1 plus the probability
of A2 through the probability of An.
Let's write S2 for
the sum of the probabilities of
the intersections of the events,
two at a time.
Probability of A1, intersection A2.
A1 and A3 and so on.
A1 through An.
A2 with A3.
A2 with A4.
A2 through An and so on, concluding
with An minus 1 accepted with An.
Out of all those possibilities,
call that S2.
S3, then is going to be the sum of
the probabilities of intersections of
the events, three at a time.
A1, A2 and A3.
A1, A2 and A4 and so on with all
possibilities of three at a time.
S4 is the four-wise intersection
probabilities of events, all added up.
And in general, as you see on your screen,
Sk represents the sum of all
k-wise intersection probabilities.
Now the sum of the right, admittedly
appears complex and intimidating.
But if we stare at it long enough,
the pieces become apparent.
What are we trying to do?
We are going to try to identify,
let's say, k events.
Identify them.
Say, j1, j2, j3 through jk.
Let's keep matters formalized and
clear by saying, let's make sure j1
is the smallest of indices and
jk is the largest of these indices.
Now take the probability of
the intersection of those k events.
And now look at all the possibilities for
j1 through jk,
as j1 is bounded below about 1 and
jk is bounded above by n and
run through all possibilities.
And now we should argue for
yourself that this sum captures
all ways of taking k events and
computing the probability of
the intersection and adding them.
All right.
So now we've got these sums.
Naturally, I'm using S for a sum here.
S1, one at a time.
S2, two at a time.
Sk, k at a time.
And now the general principle of
adding odd and subtracting evens says,
very simply the following.
The inclusion-exclusion theorem
in some level of generality says,
the probability of the union of n
events is given by an alternating
sum start with S1,
the sum of the events one at a time.
Subtract S2, the sum of the event
probabilities two at a time.
At back S3, the sum of even
probabilities three at a time.
And you go one that has automating sum,
adding and subtracting,
adding and subtracting.
And finally, you add or subtract Sn,
which has got only one probability,
the probability of
the intersection of all of them.
We notice that when n is even,
the last n is going to be negative.
And when n is all,
the last n is going to be positive.
And that explains the minus
1 to the power n minus 1.
When n is even, you get a negative number.
When n is odd, it becomes positive.
Now we'll call this the baby
version of the theorem.
Of course, that should have given you
a clue that a stronger industrial
strength version is
lurking in the background.
Before we launch into a proof of this,
let's extract the general version,
because the proof is now going to be
materially harder in a more gentle form.

