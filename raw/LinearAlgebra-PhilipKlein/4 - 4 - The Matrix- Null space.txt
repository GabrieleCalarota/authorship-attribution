
[BLANK_AUDIO]. 
Now we turn to the third vector space 
associated with the matrix. 
The null space of a matrix A is the 
set of vectors u 
such that A times u is the zero vector. 
And it's written, null of a. 
So, for example, this matrix times the 
vector 0,0,0 is the zero vector. 
So the null space of this matrix includes 
0,0,0. 
That's pretty trivial. 
Here's another example. 
This matrix times 6 minus 1 minus 1 is 
the zero vector. 
So the null space also includes 6 minus 1 
minus 1. 
By the dot product definition, the 
product of a matrix with rows a1 through 
am with a vector u, is a vector whose 
entries are the dot products of those 
rows with u. 
So, a vector u is in the null space of a 
matrix with rows a1 through am. 
If and only if, U is a solution to the 
homogeneous linear system, a1 dot x 
equals 0 through am dot x equals 0. 
So we just saw the null space of a matrix 
with rows a1 through am equals the 
solution set of the homogenous linear 
system. 
So this shows that the null space is in 
fact a vector space. 
But, let's show that in a different way 
directly 
by showing that it satisfies the 
algebraic properties of vector spaces. 
Property V1 requires that the set include 
the zero vector. 
Well, since A times a zero vector is 
always a zero vector. 
The null space does contain a zero 
vector. 
Now for property V2. 
If U is in the null space, then for any 
scale or alpha, A times the scale or 
alpha times U equals alpha times A times 
the vector. 
A times the vector is the zero vector. 
So this is alpha times the zero vector, 
which is zero. 
Which shows that alpha u is also in the 
null space. 
Finally, for property three. 
If u is in the null space, and v is in 
the null space, then a times the sum of u and v can be 
split up as A times u plus A times V, 
since each of u and V are in the null 
space, each of these is zero vector. 
So, their sum is also a zero vector. 
That proves V3, that the sum of u and V 
is in the null space of A. 
So, this shows that the null space of A 
is a vector space. 
Earlier we saw that if you have a 
solution u1, to a linear system, then the 
solution set of that linear system can be 
written as u1 plus big V, where big V is 
the solution set of the corresponding 
homogeneous linear system. 
We can restate that in the language of 
matrices. 
If you want, a solution to the matrix 
vector equation, a times x equals b, then 
the solution set of this matrix vector 
equation is u1 plus big v, where big v is 
the null space of a. 
Let's look at some simple but important 
consequences of this proposition. 
If the vector space, big v, which is 
defined to be null a, is a trivial vector 
space, 
then the solution u1 is the only solution 
to this matrix vector equation. 
And if big V is not trivial, then u1 is 
not the only solution. 
So, as a consequence, we get that the 
matrix equation A times X equals B, has 
at most one solution if and only if the 
null space of A is a trivial vector 
space. 
Now, how can we tell if the null space of 
a matrix is a trivial vector space? 
The answer to that will have to wait. 

