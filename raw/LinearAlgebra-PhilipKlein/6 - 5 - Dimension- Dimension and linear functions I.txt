
[BLANK_AUDIO]. 
Let's see how we can use arguments based 
on dimension to tell whether a linear 
function, f, is invertible. 
We know a function is invertible if it's 
one-to-one and onto. 
A linear function is one-to-one. 
If its kernel is trivial, that is, if its 
kernel has dimension zero. 
And now, what about onto? 
Well, a function is onto if its image 
equals its co-domain. 
We call that the image of a function f is 
the set of all vectors f of v, where v is 
in the domain. 
Long back we learned that the image of a 
linear function is a vector space, a 
subspace of the co-domain. 
Now, how can we tell if the image of f 
equals to co-domain? 
We'll use something I call the Dimension 
Lemma. 
Suppose big U is a subspace, of big W. 
Then the dimension of big U, is no more 
than the dimension of W and if the 
dimension of U, equals the dimension of 
W, it must be U equals W. 
Let's see the proof. 
We start with the basis for big U, u1 
through uk. 
By the Superset-Basis Lemma, we can take 
that basis and extend it to get a basis 
for W by adding a few more vectors. 
So there's a basis B for W that includes 
u1 through uk. 
The basis vectors for big u. 
Well that shows that k, the number of 
vectors in the basis for u is no more 
than the cardinality of B. 
And in fact, if k equals the cardinality 
of B, then we must not have added any 
vectors to get b. 
So the basis u one through u k of u is 
also a basis of w. 
And therefore u has the equal w. 
So that proves the dimension lemma. 
Now lets see how we can use it. 
We'll apply this second property, 
property D2. 
With big U being the image of f. 
Remember, we want a criterion for when 
the image of f equals the co-domain W. 
Property D2 shows that that U equals W if 
the dimension of U equals the dimension 
of W. 
That is if the dimension of the image of 
f equals the dimension of w. 
So we can conclude that f is invertible 
if and only if the kernel has dimension 
zero and the dimension of the image 
equals the dimension of the co-domain. 
Now, how does that relate to the 
dimension of the domain? 
When my conjecture that for a function to 
be invertible, the dimension of its 
domain should match the dimension of its 
co-domain. 
This corresponds to the intuition that 
the vectors in the domain can be made to 
correspond with the vectors in the 
co-domain. 
We'll eventually prove this conjecture 
but we're going to take a little detour. 
We're going to start with a linear 
function and extract from it and 
invertible function. 
So here's a picture of a function whose 
domain is V and whose co-domain is W. 
What we're going to do is extract an 
invertible function from this. 
How does this function fail to be 
invertible? 
Well, one thing we note is that it's not 
onto. 
There are elements of the co-domain that 
are not the image of any elements of the 
domain. 
So let's get rid of those elements. 
We'll set the co-domain of the function 
that we're extracting to be just the 
elements of the co-domain of the original 
function that are images of things in the 
domain. 
Now, we can make it one-to-one by 
choosing for each element in this new 
co-domain just one element that maps to 
it. 
And we throw away all the other ones. 
That's the intuition for extracting an 
invertible function. 
So let's go into this in more detail. 
The first step, starting with a linear 
function f whose domain is V and whose 
co-domain is W, the first step is to 
choose the smaller co-domain, which we'll 
call W*. 
The second step is choosing a smaller 
domain, which we'll call V*. 
And then we'll define the function f* 
with domain V* and co-domain W*. 
We use the same rule to define f*. 
So f* differs only in that it's domain is 
smaller, and it's co-domain is smaller. 
We end up choosing a basis for V* and for 
W*. 
Alright, how do we choose W*? 
As I said before, we're just going to let 
W* be the image of the function f. 
that is the set of all elements in the 
co-domain of the original function that 
are the image of elements in the domain. 
And let's let W1 through Wr be a basis 
for W*, our new co-domain. 
Now we'll choose the domain. 
Let v one through v r be pre-images of w 
one through w r. 
That means We choose v1 thru vR to be 
vector such that F of v1 equals W1 and so 
on up to F of vR equals R. 
We define the new domain, v*, to be the 
span of vectors v1 thru vR. 
We're going to show that the resulting function f*, whose 
domain is f V* and whose co-domain is W*, 
will show that it's onto and that it's 
one-to-one, namely that its kernel is 
trivial. 
And will also show that v1 through vr, 
the pre-images form a basis for the new 
domain V*. 
First let's look at Onto. 
Let w be any vector in our new domain W*. 
Well, because W1 through Wr form a basis 
for W*, there exist scalars, alpha 1 through 
alpha r, such that vector little w can be 
written as a linear combination with 
those scalars as coefficients. 
Now because f is linear, when we apply f 
to the corresponding linear combination 
of V1 through Vr We get that linear 
combinations of w1 through wr. 
So that shows that this vector w we 
started with is the image of something in 
the new co-domain. 
Namely, the linear combination of v1 
through vr given here. 
Now let's show 1 to 1. 
By the one-to-one lemma, all we need to 
do is show that the kernel is trivial. 
That is, that is consists only of the 0 
vector. 
Well, suppose little V* is in big V* and 
the image of little V* is the 0 vector. 
Because V* is the span of elements v1 
through vr. 
There must be coefficients alpha one 
through alpha r, such that we can express 
little V* in terms of v1 through vr. 
Applying f to both side of this equation. 
On the left side, F of V* equals the zero 
vector, so we get this. 
Let's apply F to the other side. 
By applying linearity, as we saw before, 
we get this linear combination. 
Now, W1 through Wr form a basis. 
For W*. 
And therefore they are linearly 
independent. 
We've gotten zero as a linear combination 
of those vectors. 
Therefore the coefficients must all be 
zero. 
And that shows that, in fact, the vector 
little V* Which is a, this corresponding 
linear combination of V1 through Vr is 
the zero vector. 
All these co-efficients are zero. 
That completes the proof that that the 
function f* is on two and one-to-one, and 
therefore it's invertible. 
And here's the promised bonus. 
We want to show that v1 through vr form a 
basis for the new domain big V*. 
Well we defined big V* to be the span of 
v1 through vr. 
So in order to show that v1 through vr 
form a basis, all we have to do show is 
that they're linearly independent. 
Well suppose you can get the zero vector 
as some linear combination of v one 
through v-r. 
On the left hand side applying a linear 
function to the zero vector always gives 
you a zero vector. 
On the right hand side as we saw before 
applying f to this linear combination of 
v one through v-r. 
Gives you the corresponding linear 
combination Of w1 through wr. 
Now, w1 through wr are linearly 
independent, so it must be that these 
coefficients are zero. 
And, that shows that, the only way to get 
zero as a linear combination of v1 
through vr, is with the trivial linear 
combination 
where all the coefficients are 0. 
We've shown how to extract an invertible 
linear function from the linear function 
f. 
Let's see an example of this 
construction. 
Let A be this matrix and let's define the 
function f from r3 to r3 by the rule f of 
x equals A times x. 
Now we define the new co-domain W* to be 
the image of the function f. 
That is, the column space of the matrix 
a, which is the span of its columns. 
Now one basis for W* consists of w1 and 
w2. 
Next we find pre-images of these vectors. 
Say, v1 and v2. 
These are pre-images because A times v1 
equals w1and A times v2 equals w2. 
Next, we define the, the co-domain to be 
the Span of those two vectors. 
Then the function f*, from big V* to 
the image of f, W*, is onto and 
one-to-one, and therefore invertible. 
Now, we're going to show the original 
function has the following property. 
That the original domain Big V is the 
direct sum of the kernel of f with this 
smaller domain, big V*. 
So, we have to prove two things: for the 
direct sum to even be defined, we have to 
show that the kernel of f and big V* 
share only the 0 vector. 
And once we've done that, the direct sum 
is defined to show that these two things 
are equal. 
We have to show that every vector in the 
original domain big V, can be written as 
a sum of a vector in the, in the kernel 
of f. 
And a vector in V*. 
So we already showed that the kernel of 
f* is trivial. 
This shows that the only vector in Ker f 
that's also in V* is the zero vector. 
So we've proved the first thing. 
So now let's prove the second thing. 
Let V be any vector in the original 
domain big V. 
Let W be image under F of that vector V. 
Now since F* is onto its domain V* contains some vector V* 
such that f of V* equals w. 
So we have two vectors, v and V*. 
F of v equals f of V*. 
So f of v minus f of V* is the zero 
vector. 
And then using linearity f of v minus V* 
is the 0 vector. 
So that shows that v minus V*, which 
we'll name u, is in the kernel of f. 
Changing this around a little bit, we can 
write v as the sum of u plus V*. 
That is we've written v the arbitrarily 
chosen vector in big V as the sum of a 
vector u which is in the kernel of f and 
a vector V* which is in big V*, the new 
domain. 
So we've proved the second thing as well. 
So, this is what we've proved, for any 
linear function. 
Here's an example. 
Let A be this matrix, we define the 
function F, from R 3 to R 3 by 
multiplication by this matrix. 
V1 and V2 are shown. 
And V* is the span of those two. 
The kernel of f is the span of this 
singleton set. 
It follows, therefore, that the original 
domain, big V is the direct sum of the 
kernel, 
the span of this singleton set, with the span of V1 and V2. 
By the direct sum dimension corollary, 
the dimension of the original domain 
equals the dimension of the kernel of F 
plus the dimension F plus the addition of 
the new dimension of the new domain, V. 
Now, since v1 through vr form a basis for 
V*, we know that dimension of big V* 
equals r, which is also the dimension of 
the image of f. 
So, what we've show is, for any linear 
function, the dimension of the kernel plus the dimension of the image equals 
the dimension of the domain. 
We call this Kernal-Image theorem and its 
a very significant result in linear 
algebra and very useful. 

