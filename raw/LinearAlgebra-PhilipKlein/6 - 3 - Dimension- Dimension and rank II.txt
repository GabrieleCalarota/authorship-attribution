Here's a basic result on bases.
I call it the subset-basis lemma.
Every finite set T of vectors contains
a subset S that is a basis for Span of T.
And the proof uses the Grow algorithm.
So here's the old Grow algorithm.
Initialize S to the empty set and
repeat while possible.
Select a vector v in a vector space,
big V,
that's not already spanned by
the vectors at S and put it in S.
We're going to use a revised version.
Initialize S to the empty set,
and repeat while possible.
Select a vector v in the set T,
that is not already spanned by
the vectors in S and put it in S.
Now, the original version,
if it terminated,
was guaranteed to find a basis for
the vector space.
Because the original produced a basis for
big V, this one will produce a basis for
Span of T.
So how does this differ from the original?
Well, this variant stops once Span of
S contains every vector in T.
Whereas the original
algorithm stops only once
every vector in the vector space
is in Span of S, but that's okay.
Once this algorithm reaches the point when
Span of S contains every vector in T,
it also contains all linear
combinations of vectors in T.
And therefore, Span of S equals Span of T.
So that shows that the original
algorithm can be guided
to make the same choices as this variant.
And therefore,
the variant also produces a basis.
Here's another basic result on bases.
The Superset-Basis Lemma.
Let big V be a vector space, and
let C be a linearly independent
set of vectors belonging to big V.
Then big V has a basis, S, cons-,
containing all the vectors in C.
So again we use a version
of the Grow algorithm.
The only change we make is that we
ask the Grow algorithm to prefer
to include vectors that are in C.
Initially, the grow algorithm will
just keep adding vectors in C to S.
It can keep doing this because C is
linearly independent, so at no point
will there be a vector in C that's already
spanned by the vectors we put into S.
After it's added all those vectors
in C to S, it'll keep going,
adding some more vectors until Span
of S equals the vector space V.
At which point, S is a, in a linearly
independent set of generators
for big V, and
it includes all the vectors in C.
But so far our proof is incomplete,
because we haven't shown that
the algorithm is guaranteed to terminate.
Here's a proof of
termination that will work
only when big V consists of
vectors with a finite domain, D.
Recall the standard generators for
F to the D.
A standard generator's entries are all 0,
except for 1.
For example, these are the standard
generators for R to the n.
The number of standard generators for
F to the D is the cardinality of D.
By the Grow-Algorithm Corollary,
the set S in the Grow algorithm,
remains linearly independent
throughout the algorithm.
Therefore, by the morphing lemma,
the cardinality of S is at most
the number standard generators,
that is, at most the cardinality of D.
Since S grows in each iteration,
the number of iterations is
at most the cardinality of D.
We've shown that the Grow-Algorithm
is guaranteed to terminate.
And that completes the proof
of the Superset-Basis Lemma.
The Superset-Basis Lemma holds
even when D is not finite, but
the proof is more involved, and it depends
on something called the Axiom of Choice.
Let's try estimating the dimension
of some vector spaces.
So, here's a set of vectors.
What's its rank?
That is,
what's the dimension of the Span of T?
By the Subset-Basis Lemma,
the set T contains a basis for Span of T.
Therefore, the dimension of the span of
T is no more than the cardinality of T.
That shows that the rank of T is
no more than the cardinality of T.
And in general, a set T of vectors
always contains a basis for
its Span and therefore always has
rank at most, its cardinality.
Now we're going to give an argument
based on the notion of dimension.
I call it the Dimension Lemma.
So, let's say U is a subspace of W.
In that case, the dimension of U is
no more than the dimension of W.
And if the dimension of U is
equal to the dimension of W,
then we can conclude
that in fact U equals W.
So, here's the proof.
Let u1 through uk be a basis for
the subspace U.
By the Superset-Basis Lemma,
there is a basis for
W that contains the vectors u1 through uk,
that form the basis for U.
So let's write down B.
It has u1 through uk, and
possibly some more vectors, b1 through br.
Well, it's clear that the number
of vectors, in the basis for
u, which is k is no more than
the cardinality of this set B.
Furthermore, if k,
the number of vectors in the basis for U,
equals the cardinality of B,
then there aren't any additional vectors.
B is precisely equal to
the set u1 through uk.
And therefore, the Span of those vectors,
which is U, equals the span of B,
which is W.
So that proves the second part.
Here's an example, suppose V is
the span of these two vectors.
Well, clearly V is a subspace of R2
because these vectors are in R2.
However, these vectors
are linearly independent.
And so the dimension of V is 2.
Well, because the dimension
of R2 is 2 as well,
property D2 shows us that
V is actually equal to R2.
These two vectors span all of R2.
Here's another example.
Well, we have some set S
consisting of four vectors.
Since every vector in S is a 4-vector,
Span of S is a subspace of R4.
Now, since the dimension of R4 is 4,
property D1 shows,
the Span of S, has dimension at most 4.
So, in general, any set of D vectors,
has rank at most, the cardinality of D.
Now we'll prove a very
fundamental fact about bases.
For finite D, every subspace of F to the
D, where F is a field, contains a basis.
Well here's the proof.
Let V be a subspace of F to the D.
It follows that the dimension of V
is at most the cardinality of D.
And therefore, the Grow algorithm
will eventually terminate.
After all, in each iteration, the Grow
algorithm adds another vector to S.
So after k iterations,
the cardinality of S equals k.
Okay, each point of the execution of the
algorithm the set is linearly independent.
So after k iterations,
the rank of S equals k.
Every vector added belongs
to the vector space.
So Span of S is a subspace of,
the vector space V.
So after dim V iterations,
Span of S has dimension, dim V.
So by the property D2
of the Dimension Lemma,
Span of S equals the vector space V.
Now, remember, the row rank of
a matrix is the rank of its rows,
that is the dimension of the row space.
The column rank is
the rank of its columns,
that is the dimension of the column space.
When we looked at examples, we saw that
row rank seemed to equal column rank,
at least for the examples we looked at.
It turns out this isn't a coincidence,
as we'll prove.
For every matrix,
row rank equals column rank.
To prove this,
we'll prove a lemma that says for
any matrix A, the row rank of A is
no more than the column rank of A.
And, here's how we'll use
the lemma to prove the theorem.
We apply the lemma to our matrix M
to show that the row rank of M is
no more than the column rank of M.
And then we'll apply the lemma to
the transpose of M to show that the row
rank of M transpose is no more than
the column rank of M transpose.
Well, the row rank of M transpose
is just the column rank of M.
And the column rank of M
transpose is the row rank of M.
So that proves that the row rank
of M equals the column rank of M.
So let's go back and prove the lemma.
The lemma states that for
any matrix A, the row rank of A is
no more than the column rank of A.
So let's start by writing
A in terms of its columns.
So let a1 through an be the columns of A.
Now, let's take a basis for
the column space, let's say b1 through br.
And that means that the dimension
of the column space is r.
That is, r is the column rank of A.
Our goal, then, will be to show that
the row rank is no more than r.
Now, each column of A lies
in the column space and
can, therefore, be written as a linear
combination of the basis vectors.
Using the linear combinations
definition of matrix vector multiply,
we can therefore write each column, as,
a matrix whose columns are the basis
vectors, times some other vector.
Now we use the matrix-vector definition
of matrix-matrix multiplication to write
all these equations.
Write it as a single matrix-matrix
equation, A equals B times U.
So B has r columns, and U has r rows.
Well, let's write A and
B in terms of rows now.
So, row A, row i of A equals
row i of B times the matrix U.
Now we write U in terms of rows.
And use the linear combinations
definition of vector-matrix multiply.
That is, we can express each row of
A as a row of B times U,
and a row of B times U is a linear
combination of the rows of U.
So we've shown that each row of A is
a linear combination of these rows.
How many are there?
There are r.
So, that shows each row of A is
in the span of these r vectors.
Now, these r vectors include a basis.
So the dimension of the row
space of U is no more than r.
And that shows that the dimension of
the row space of A is no more than r.
This shows that the row rank
of A is no more than r.
And that proves the lemma.
With what we know now, let's return
to the simple authentication scheme.
Recall that the password was an n-vector,
x hat over GF 2.
The computer would challenge the human by
sending a random n-vector over GF 2, a.
And the human was supposed to respond
by sending back the dot product of
a with the password.
And this is repeated until
the computer is convinced that
the human probably knows the password.
And recall that Eve, our eavesdropper
listens in on this communication.
In so doing, she learns a bunch of pairs
of vector a1, and the corresponding dot
product b1, and so on, up to vector am,
and the corresponding dot product bm.
That means that Eve can
calculate the right response
to any challenge that lies in
the span of vectors a1 through am.
Suppose the challenge
a is a linear combination
of these vectors a1 through am, then
the right response is the corresponding
linear combination of those bits,
b1 through bm.
Now it's a property of random vectors
over GF2 that the rank of the list
a1 through am is probably not much
less than the numbers of vectors, m.
Let's try this out with some
random 100 vectors over GF2.
Now, we can build some vectors.
Now I'll define a list
consisting of n hundred vectors.
We want to compute the rank of this list.
So we'll import the rank procedure
from the module independence,
and compute the rank of L.
We expect the rank of L to be about ten,
maybe a little smaller,
but very likely ten, and indeed.
Now, let's try the same thing with
a slightly longer list, maybe 50 vectors.
We still expect the rank to be 50,
and indeed.
Try a longer list.
And the rank now should be 80.
Only when we get very close to 100
is there a significant probability that
the rank would be even slightly less.
All right, so it's a little smaller.
Let's, let's take a few more vectors.
And we got up to 100.
So once m is up to n or
greater, it's probably the case
that the span of a1 through am
includes all of GF2 to the n.
So Eve can respond to any
challenge at that point.
In fact, note that the password
x hat is a solution to the matrix
vector equation, A times x equals b,
where A is the matrix whose rows
are those vectors a1 through am.
And b is the vector whose entries are,
are the bits, the dot products.
Now the solution set of this
matrix-vector equation is x hat
plus the Null space of A, but
once rank of A reaches n, the columns
of A are linearly independent, so the Null
space is the trivial vector space.
And that shows that the only solution
to this equation is the password x hat.
So Eve, using the solver,
can compute the password.

