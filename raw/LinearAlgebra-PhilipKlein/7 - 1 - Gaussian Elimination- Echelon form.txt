
﻿So far, we've been using solve as a black 
box. 
Now we're going to start to find out 
what's going on inside that box. 
Gaussian elimination is named after 
Gauss, but it actually was discovered at 
least 2000 years ago, it's been written 
up in a Chinese text. 
In Europe it was discovered by Isaac 
Newton and Michel Rolle in France. 
Gauss called the method common 
elimination. 
He came up with a a way to use it to 
solve another problem that we'll get to 
later and came up with a, a notation that 
was widely adopted. 
What's it good for? Well, it can find a basis 
for the span of given vectors, which also 
will give us an algorithm for rank. 
And, therefore, an algorithm for testing 
linear independence. 
Can be used for solving a matrix 
equation, which we know is the same as 
expressing a vector as a linear 
combination of other vectors, which is 
the same as solving a system of linear 
equations. 
It can be used for finding a basis for 
the null space of a matrix, which is the 
same as finding a basis for the solution 
set of homogeneous linear system, which 
we know is relevant to representing the 
solution set of an arbitrary linear 
system. 
The method is based on the idea of 
Echelon form. 
Here is an example of a matrix in echelon 
form. 
Now notice that the first nonzero entry 
in row 0 is in column 1. 
The first nonzero entry in row 1 is in 
column 2. 
The first nonzero entry in row 2 is in 
column 4. 
And the first nonzero entry in row 4 is 
in column 5. 
A matrix is in Echelon form if it 
satisfies the following condition: For 
every row if that row's first nonzero 
entry is in position k, than in all of 
the previous rows the first nonzero is to 
the left. 
As a consequence, as you go through the 
rows, the non-zeros form a sort of 
staircase descending down. 
So, for example, here’s the staircase for 
this one. 
Here's the staircase for this matrix. 
Notice that if a row is 0, then all 
subsequent rows also have to be 0. 
What good is it, having a matrix in 
echelon form? 
One thing is that if, that the nonzero 
rows of the matrix form a basis for the 
row space of the matrix. 
For example, in this matrix, a basis for 
the row space is given by these first 2 
rows. 
In particular, if every row is non zero, 
as in these matrices, then the rows form 
a basis for the row space. 
We know that the rows generate the row 
space of the matrix. 
That's the definition of row space. 
So what we have to show is that the 
non-zero vectors are linearly 
independent. 
And to do that, we’ll use the Grow 
algorithm. 
So, remember the Grow algorithm. 
Let’s try it out on this matrix. 
Adding the rows in reverse order, 
initially S is the empty set. 
The algorithm considers adding the last 
row. 
Now, since a span of the empty set 
doesn't contain this row, the grow 
algorithm will go ahead and add it. 
Next. 
Now S consists just of that row. 
Now every vector in Span of S has zeros 
in its first 3 entries, positions 0, 1, 
and 2. 
So Span S doesn’t contain this second 
row. 
So the algorithm goes ahead and adds 
that. 
Now S consists of these 2 vectors. 
Now still every vector in Span of S has a 
0 in positions 0 and 1, so Span of S so 
far does not include this vector. 
So, the grow algorithm goes ahead and 
adds that. 
Now S consists of these 3 vectors. 
Every vector in Span of S has a 0 in 
position 0. 
So Span of S doesn't include this. 
vector. 
So the Grow algorithm goes ahead and adds 
that as well. 
We know that at every stage in the 
execution of the Grow algorithm, the set 
S is linearly independent. 
So we've shown that all the rows of this 
matrix are linearly independent. 

