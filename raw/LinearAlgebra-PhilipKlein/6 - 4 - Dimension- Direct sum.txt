
You've seen the idea that you can add two 
vectors. 
Now, we'll see what it means to add two 
vector spaces. 
This is called the Direct Sum. 
So, let U and V be two vector spaces. 
And suppose that they share only the 0 
vector. 
We define the direct sum of U and V to be 
the set, little u plus little v, where 
little u belongs to big U, and little v 
belongs to big V, and it's written like 
this U plus V. 
That is, U plus V is the set of all sums 
of a vector in big U plus a vector in big 
V. 
In Python, you could write a list like 
this. 
So, here's an example. 
Let's start with vectors over GF(2). 
We'll let big U be the span of these two 
vectors. 
And let big V be the span of this one 
vector. 
Now, note that every nonzero vector in 
big U has a one in the first or the 
second position, or both. 
And every nonzero vector in big V has a 
one in the third position. 
There are no vectors in common other than 
the 0 vector. 
So we can form the Direct Sum. 
And here's the Direct Sum. 
Taking the set of all vectors obtained by 
taking one vector from big U and one 
vector from big V. 
And carrying out these additions, this is 
the set. 
Now, let's do an example of vectors over 
R. 
Define big U to be the vector space, the 
span of these two vectors, and define big 
V to be the null space of this matrix. 
Well, the vector 2, -2, -1, 2, is in big 
U. 
It can be written as a linear combination 
of these two vectors, in particular it's 
this one minus this one. 
That same vector is also in big V, 
because if you multiply the matrix by 
that vector, you get the 0 vector, which shows that this vector belongs to 
the null space of the matrix. 
There's a nonzero vector in both big U 
and big V. 
Therefore, we're not allowed to form the 
direct sum of U and V. 
Let's do another example of Direct Sum of 
vectors over the reals. 
We'll define big U to be the span of this 
set consisting only of this vector. 
You remember the span of a set consisting 
of one vector is the line through the 
origin and the point represented by the 
vector. 
Similarly, let big V be the span of a set 
consisting of this vector. 
So, this is also a line. 
Now, the only intersection of these two 
lines is at the origin. 
That is, big U and big V share only the 0 
vector. 
So, we can form the Direct Sum. 
And what is the Direct Sum? 
It's the set of vectors, little u plus 
little v, where little u is in big U, and 
little v is in big V. 
So, that's just span of the set 
consisting of these two vectors. 
And it's the plane that contains those 
two lines. 
Now, let's use our knowledge of 
generators, basis, and dimension, to 
better understand direct sums. 
So, it's easy to show that the direct sum 
of U and V is a vector space. 
You just use the properties of vector 
spaces. 
Somewhat more interesting is to show that 
the union of a set vectors, a set of 
generators of big U and a set of 
generators of big V is a set of 
generators for the direct sum U plus V. 
So, suppose u1 through are generators for 
big U, and v1 through vn are generators 
for big V. 
Well, every vector in big U can be 
written as a linear combination of the 
vectors u1 through because they're 
generators. 
Similarly, every vector in big V can be 
written as a linear combination of v1 
through vn because they're generators. 
So, every vector in U plus V can be 
written as a vector in u plus a vector in 
v. 
But what we've written is, a linear 
combination of the vectors u1 through 
 um together with v1 through vn. 
So, that shows that those vectors span 
the direct sum U plus V. 
Now, we're going to prove that the union 
of a basis for big U and a basis for big 
V is a basis for the direct sum U plus V. 
Well, a basis is a set of generators. 
So we already know from the previous 
lemma that the union of a basis for big U 
and a basis for a big B is a set of 
generators for U plus V. 
So, what remains to show, to be shown is 
that the union is linearly independent. 
Alright. 
So, let u1 through be a basis for U. 
Let v1 through vn be a basis for V. 
And we need to show that the union is a 
linearly independent. 
Well, suppose that you can write the 0 
vector, as a linear combination of all 
these vectors. 
By subtracting these vectors from both 
sides, we get this equation. 
Note that the left hand side is a vector 
in big U, because it's a linear 
combination of the basis vectors, for big 
U. 
And the right-hand side is a vector in 
big V because it's a linear combination 
of the basis vectors for big V. 
So, we've found a vector in big u that's 
equal to a vector in big V. 
Well, for the direct sum to even be 
defined it needs to be the case that big 
U and big V share only the 0 vector. 
So, we've shown that this must be the 0 
vector and this must be the 0 vector. 
That is 0 is equal to this linear 
combination. 
And 0 is equal to this linear 
combination. 
But u1 through form a basis. 
So, the only way to get the 0 vector as a 
linear combination is with a trivial 
linear combination. 
That is alpha 1 through alpha m have to 
all be 0. 
And similarly, v1 through vn form a 
basis. 
They're linearly independent. 
And so, the only way to get the 0 vector. 
By taking a linear combination, is if the 
linear combination is trivial, that is if 
the coefficients are all 0. 
So, that shows that all the coefficients 
here must be 0. 
If the only way to get 0 is a linear 
combination of u1 through together with 
v1 through vn, is with a trivial linear 
combination. 
And that shows that this whole set is 
linearly independent, and therefore, 
forms a basis for the direct sum. 
So, we've shown that the union of a basis 
for big U and a basis for big V is a 
basis for the direct sum. 
An immediate corollary of this lemma is 
the dimension of U plus the dimension of 
V equals the dimension of the direct sum 
of U and V. 
The proof is that a basis for U together 
with a basis for V forms a basis for U 
plus V. 
If the direct sum of U and V is the space 
w. 
We say U and V are complimentary sub 
spaces of W. 
For example, suppose big U is a plane in 
R3. 
So, in that case, any line through the 
origin, that does not lie completely 
within this plane is a complimentary sub 
space. 
Here's an example and here's another 
example. 
This shows that there's potentially more 
than one complimentary subspace, but 
let's show that there always exists at 
least one. 
We'll prove that for any, any finite 
dimensional vector space big W, and any 
subspace, big U, there's another sub 
space big V, such that U and V are 
complimentary sub spaces. 
We start with a basis for big U. 
Lets say u1 through uk form a basis for 
big U. 
Now, by the super set lemma. 
We can extend that basis to be a basis 
for big W by adding some vectors, let's 
say v1 through vr. 
Now, let's define big V to be the span of 
these extra vectors v1 through vr. 
We want to show that V is a complementary 
subspace. 
That is that the direct sum of u and v is 
w. 
There are two things to show. 
One, we have to show that U and V share 
only the 0 vector. 
Second, we have to show that the set of 
vectors obtained by taking a vector in U 
and adding it to a vector in V is exactly 
the vector space W. 
Let's do the second one first. 
Any vector in W can be written as a 
linear combination of its basis vectors. 
Here we've written an arbitrary vector, 
little w in big W as a linear combination 
of the basis vectors. 
Notice that this first part of the linear 
combination is a linear combination of 
the basis vectors of big U. 
And the second part of linear combination 
is a linear combination of the vectors 
spanning big V. 
This shows that this arbitrary vector 
little w in big W can be written as the 
sum of a vector in big U and a vector in 
big V. 
Now, it remains to show that u and v 
share only the 0 vector. 
Suppose some vector v lies in the span of 
u1 through uk, that is it's in U, and 
also lies in the span of v1 through vr, 
that is, it's in V. 
So, we write v in, as a linear 
combination, of each of those vectors. 
That shows that these two linear 
combinations are equal, and moving these 
vectors to the other side, that shows 
that you can write the 0 vector as this 
linear combination. 
But because these vectors, u1 through uk, 
together with v1 through vr, form a basis 
for w, they're linearly independent. 
And so, because you can write the 0 
vector as this linear combination, it 
must be that the coefficients are all 0. 
So, that shows that this vector v must be 
the 0 vector. 
So, we've shown that the only vector in 
both U and V is the 0 vector, so you can 
form the direct sum of U and V. 
And that completes the proof of the 
proposition. 

