[SOUND] In this session,
we are going to discuss
Constraint-Cased Clustering Methods.
We will first discuss how
to handle hard constraints.
What are hard constraints?
Simply says,
we want the algorithm to strictly respect
the constraints in
the cluster assignments.
That we were introduced one interesting
algorithm called Cop-k-means algorithm.
Essentially it is k-means but
in the constraint process it must
observe like a must-link and
a cannot-link constraints.
So, to follow the must-link
constraints as the hard constraints,
what we can do is we regenerate the super
instances, I mean super objects.
Suppose you got a five objects they
link together in some way, okay?
So you, what you can do is you
first using the must-link,
you based on a links to b,
b links to c, c links to d then abcd
should be a transitive
closure of these objects.
So you compute the transitive
closure of the must-link
constraints then you can wrap in the,
all those, objects.
They follow these constraints,
you wrapping them as a superset,
that means to wrap in such
a subset of the objects,
we can replace all those objects
in the subset by one super object.
The object you can take the mean,
as a center,
as this object of location and
these super objects should carry a weight.
If you get a four objects,
they finally merged into one super
object then the weight should be four
which is a number of object it represents.
Then for the remaining,
we can just wake up the k-means
to do all the clustering process.
Then, how can we modify the k-means one
to observe the cannot-link constraints?
That means, if these two objects, they
have a constraint say these two objects
cannot be linked together,
how can we do it?
What do we need to do is adjust it
to modify the center assignment
processing the k-means.
It simply says, you have to sign these
object to the nearest feasible center.
That simply says,
if you sign one object to its near, near,
nearest center, the oth, other objects
just cannot be signed to the center.
We have to send,
assign to another center, another
feedable center to the closest one, okay?
That means every time the object is
assigned to the nearest feasible center,
so the assignment will respect
all cannot-link constraints.
But this is the modification
of the k-means,
to handle hard constraints for
must-link and cannot-link constraints.
[MUSIC]

