[SOUND] In this session,
we are going to introduce
one bi clustering
method called delta bi clustering.
Bi clustering is quite useful for
micro array data analysis.
Let's look at this figure 8,
which we used 3 colors 3 objects or
you can think as 3 by okay.
If you link those gene values together,
okay.
What you is,
you couldn't find any obvious clusters or
patterns, because in gene a,b,c
you pretty see some goes up and
some goes down, is a little like irregular
its, its very hard to find a good pattern.
However, if you pick up some genes,
some subsets of genes.
Then you line them up together
you'll find a pretty nice pattern.
For example this figure
b shows a shift pattern,
because you shifted this green one down.
You'll find it's overlap
with the blue one.
If you up a little you'll find
it overlaps with the red one.
Okay.
Even figure C, what you see is if you
scale a little, like, the red one,
scale a little, you get a overlap or
almost overlaps with a green one,
and, if you scale a little more,
you overlap with a blue one.
So these are the shift patterns and
scaling patterns.
The problem is, can we find a nice
subset of objects, and subset of genes?
They really can have
rhythm in nice clusters.
Now we see what could be the algorithms.
They are in a bi-cluster algorithm,
it's one of such algorithms
find such nice clusters.
And we can define for
any sub matrix i times j,
that means you pick up sub rows and
sub columns, okay?
Subsets of rows and columns.
You can calculate mean of this row,
essentially is you take row, so
you pick all the the columns
of this submatrix.
You perceive and
add all the values together,
divide by size of these,
how many columns you get.
The mean of the row.
similarly you can get
a mean of j's column.
And you can get mean of
the whole submatrix.
Then we want to judge the quality
of this sub matrix as a bi-cluster.
What we can do is we take
this part as a residue.
And the residue essentially is
you take any item i j, okay.
This particular cell you look at, this
sub matrix you look at I's row mean and
j's column mean and the whole matrix mean.
Then you look at this value,
the difference between this, okay.
Then you take the squared.
We call mean squared residue.
[SOUND] Then you try to add them up and
divide by the size of i times J.
Okay.
For the quality of this,
if this value is within
more special data, then we can
say this one is data bi-cluster,
but this data is usually
a human set up value,
usually is a small value
if this delta is 0,
then this submatrix is a perfect
bi-cluster, with all the coherent values.
However, in many cases,
it cannot be so ideal.
But then,
you give a threshold greater than 0.
You can set up a tolerance threshold.
Essentially you want to find
the average noise per element against
a perfect bi-cluster.
This is why we use this residue value,
we can either judge whether the cluster
is a good or nice bi-cluster.
Then the problem is,
how can we find an efficient method
to find a maximum delta bi-cluster?
What is maximal one?
The maximal means, you enlarge a little
more no matter how you enlarge it
their quality will go beyond
this derehas threshold.
So within this derehas threshold,
it's the largest one,
of course the subset in many cases it
could be a nice pattern bi-cluster but
finding the largest one
will make more sense.
However to compute this, to find the
maximum delta-bi-clusters is very costly.
They develop a heuristic
greedy search method to obtain
local optimal maximum delta-bi-clusters.
So the maximal contains 2 phases,
1 called deletion phase,
another called addition phase.
In the deletion phase you
start from the whole matrix.
You say, oh, this one,
whole matrix is a nice delta bi-cluster,
in most cases, it is not.
What you need to do is you
iteratively remove some rows and
some columns if their mean
squared residue value is
over delta's threshold, of course,
how do you pick up this?
You put this one into an iteration loop,
so for each row or
column, you just examine their
mean squared residue value.
You look at the,
this row's mean squared residue value and
column's mean squared residue
value then you see which one,
which column or which row, actually
has the largest mean squared residue.
You just cut them off,
because this is the worst case, or
the least case they may for
a nice delta bi-cluster.
That's why i chop those rows and columns.
However, if you chop this,
you quite often this chopping is
too aggressive because you chop it
the other way and some subsets of rows and
columns they still form nice bi-clusters.
So, in that sense you need addition phase,
this one is probably too aggressive.
You want to grow a little.
How do you grow?
That means we try to expand
iteratively this delta bi-cluster
obtained from the deletion phase.
Okay?
And as long as when we expand this delta
bi-cluster requirement
is still maintained.
That means,
it's still within the delta structure.
That means,
we try to calculate all the rows and
columns not involving the current
bi-cluster sub-matrix.
The character there means we are residue.
Then the smallest mean square residue,
if this column or
this row, they have the smallest
mean squared residue.
You try to add them back.
To get the delta bi-cluster to see whether
they are still a delta bi-cluster, okay?
In this deletion-addition phase, you
actually only find one delta bi-cluster.
But you want to find
many delta bi-clusters,
you need to run this
phase is multiple times.
And how do you run this multiple times?
That means you just replace
the elements in the output bi-cluster
by random numbers.
That means you add this up,
you, the smallest one, what about
you add the second smallest one?
Third smallest one?
You can do this in a random number.
You can add a good quality
while you find other clusters.
So this is quite a costly search process,
but it's still quite interesting.
You'll find a quite a good
number of their bi-clusters.
[MUSIC]

