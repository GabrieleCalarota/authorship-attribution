[MUSIC]
In this session,
we are going to study another important
issue called clustering tendency.
What is clustering tendency?
That means we want to study
whether the data says we have
really contained clusters.
That means whether data contains
some inherent grouping structure.
Otherwise, even use random generated data,
you may find
the certain number of clusters,
however it does not really make sense.
That means we want to assess whether
the data is suitable for clustering.
However, to determine the clustering
tendency or clusterability is a hard task.
Just because there are so
many definitions of clusters.
For example, we studied partitioning
methods, hierarchical methods,
density-based methods,
graph-based methods.
All these different methods may have
different definitions of clusters.
That's why to study whether the data
is clusterable or not is pretty hard.
However, even when we just
fix the cluster type, for
example, we just study
the partitioning method,
it is still hard to define appropriate
null model for a data set.
However, there's still some studies
on clusterability assessment.
For example, there are methods
like spatial histogram method,
distance distribution method or
Hopkins statistic.
The general philosophies,
they try to compare their measure with
the measure generated from random samples
to see whether they are rather different.
For example, for spatial histogram method,
is try to contrast
the histogram of data,
with those, the histogram
generated from the random set to see
whether they are rather different.
For distance distribution is try to
compare the pairwise point distance from
the data, and the pairwise distance
from the randomly generated samples.
Hopkins statistic is to use a sparse
sampling test for spatial randomness.
And since they carry
a quite similar spirit,
we were only introduced one
spatial histogram method.
For spatial histogram approach,
the general philosophy is we
try to construct a d-dimensional
histogram of the input.
For example, this is a 2D, we may
construct a two-dimensional histogram for
the input dataset D with a histogram
generated it from random samples.
That means we won't compare the figure
generated from the left and
to that generated from the right figure.
Okay?
The data is clusterable if these
two histograms distributions
are rather different.
That means they are really generally
very different distribution then likely
this dataset is clusterable, okay?
The concrete method is we try to divide
each dimension into an equi-width bins.
Then we try to see each cells here,
how many points are in this set.
Then we can generate a empirical joint
probability mass function, okay.
Then for the random generated datasets,
we'll do the same,
we'll generate empirical joint
probability mass function.
Then what we will do is we try
to compare whether these two,
they differ quite a lot.
That means we're going to
compare how much they differ.
A typical method is we use KL divergence.
That means we calculate
the KL divergence value.
KL divergence is Kullback-Leibler
divergence is defined
based on some formulas.
I'm not going to introduce
the detail of KL divergence.
If you want to learn more, you can
check any textbook in statistics or
machine learning or data mining.
In general, they introduce this measure.
Then you find if they are very different,
then from the random samples,
then you will say this
dataset is clusterable.
Now we come to the lecture summary.
This lecture we discussed
clustering validation
then we introduced basic concept
why we want to validate clustering.
Especially we discussed why is how
to measure the clustering quality.
And we have the external measure and
that means we do have.
In that case,
we introduce matching-based measure,
entropy-based measures and
a pairwise measures.
Then we also study when we do not have
we will use some internal measures.
And we also study the relative measures
that simply says you have different
parameters, you generate different
clustering, you want to compare them.
Then we also studied
cluster stability issue,
we studied clustering tendency issue.
Okay?
Finally, I'm going to introduce a few
textbooks, chapters or general papers.
They discuss the clustering
validation measures.
Especially where it shows this one is a,
a summary of many research papers,
and Zaki's book,
it give a lot of details on other measures
we did not cover in this lecture.
Thank you.
[MUSIC]

