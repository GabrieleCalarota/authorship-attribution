[SOUND]
Hi,
welcome to Lecture 6, Probabilistic
Model-Based Clustering Methods.
In this lecture,
we are going to introduce basic concepts
of probabilistic model-based clustering.
Especially, we will discuss mixture
models for cluster analysis.
We will focus on Gaussian mixture models.
We will discuss
the expectation-maximization algorithm for
both univariate and a multivariate cases.
And then we will analyze the mixture
of model, model methods.
But for the first session we were
introduce the basic concepts of
probabilistic model-based clustering.
What is probabilistic model?
That is,
the model is trying to model the data from
a generative process,
that means we assume the data
are generated by a mixture of
underlying probabilistic distributions.
Then the method is trying to optimize
the fit between the observed data and
some mathematical model using
a probabilistic approach.
Then for probabilistic model-based
clustering as we, every cluster,
each cluster can be
represented mathematically
by a parametric
probabilistic distribution.
For example,
could be a Gaussian distribution,
could be Poisson distribution.
Then each cluster
actually is a set of data
points or objects that most likely
belong to the same distribution.
Then the clustering process
essentially is parameter estimation so
that they will have a maximum likelihood
fit to the model by a mixture of
K components, and these K component
distribution essentially are K clusters.
It has lots of applications, for
example for image segmentation,
document clustering, topic modeling,
recently in machine learning,
in statistics, and
in data mining topic model and
the EM algorithms are very popular method.
We were look at the typical
probabilistic based clustering methods.
First, we will examine mixture models
that means we assume observations to
be clustered are drawn from
one of several components, and
we'll infer the parameters
of these components, and
assign data points to specific
components of the mixture.
And each component we
can think is a cluster.
Then the expectation-maximization
algorithm is
a general technique to find the maximum
likelihood estimation in mixture models.
We were discuss the EM, the EM
algorithm for Gaussian mixture models.
Actually, there's another
very popular method,
method called probabilistic topic models.
This is very popularly used for
text clustering and analysis.
However, in this course,
we are not going to cover this part.
This part would be covered
in the text mining course.
Essentially, probabilistic
topic models include
probabilistic latent semantic analysis,
called PLSA,
and latent Dirichlet allocation,
called LDA.
[MUSIC]

