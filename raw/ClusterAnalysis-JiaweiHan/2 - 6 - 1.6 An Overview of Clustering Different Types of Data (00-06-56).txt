[MUSIC]
Hi.
In this session,
we are going to give a brief
overview on clustering different
types of data we encounter
various kinds of types of data.
For example, the early clustering
algorithm most times we,
the design was on numerical data And
the second type of data is category data.
Including binary data, that most
people consider as also can be handled
in categorical data category.
For example: gender, race,
zip code, or market-basket data
you will consider as discrete,
there's no natural outer.
For certain kind of datas,
text data, this is very popular in
web in social media and
the web or social networks.
Usually if we consider a word
as one dimension then you're,
we are handling very high dimensional
data, but they are very sparse.
Their value usually corresponding
to word frequencies.
The methods to handle such data include
a combination of k-means and agg,
agglomerative methods, topic mod, modeling
methods, or co-clustering methods.
We are going to discuss
this extensive later
Multimedia data is another kind
of data that needs clustering.
Usually images, audio, video,
those on Flickr and,
YouTube are actually multimedia data.
They are multi-modal in the sense
they have image, audio, video,
many cases they have
text as captions as well.
We can consider they are contextual data,
they contain both behavioral and
a contextual attributes.
For example for images,
we can consider the position
of a pixel represents its context,
the value represents its behavior.
For video and music data,
we can consider temporal ordering of
the records reference its meaning.
Time-series data is another
popular encounter data,
like in sensors stock markets,
temporal tracking or forecasting.
Those tasks usually handle time-series
Time-series we usually consider
data temporally dependent.
They are consecutive,
usually the interval is somehow equal.
Like, we can consider time
as contextual attributes,
data value as behavioral attribute.
Usually such analysis include
correlation-based online based
analysis like online clustering
of stocks to find stock tickers,
or we use shape based offline analysis.
For example,
cluster ECG based on overall shapes.
Sequence data is another kind of data.
Usually in weblog analysis, or
in biological sequence analysis, or
analyze the sequence, the system, commands, this
we can think the as placement rather than time,
the contextual attribute,
that means where they are, okay?
Then the similarity function include
hamming distance, added distance,
the longest common subsequence.
The clustering method we call sequence
clustering, may use suffix-tree,
may use generative model
like Hidden Markov Model.
Stream data is another kind of data,
stream data can be
considered as a real-time.
The data like a water flowing in and
out, it may evolve along time.
It may have concept shifts
because stream coming and it go.
So we need a single pass algorithm
rather than you can see it again, again.
And the typical method for stream
clustering could be micro-clustering,
that is we need to create
a efficient intermediate
representation by some kind
of a micro-clustering method.
Graphs and homogeneous networks,
or is another kind of data.
This kind of data usually, so
called homogeneous networks, that means,
we consider networks as graphs, but
nodes and edges are of one kind, one type.
Actually, any kind of data can be
considered, can be modeled as a graph.
With the nodes as different attributes of
entries and edge similarity values.
The typical method for handling graph
clustering could be generative models,
combinatorial algorithms, like graph cuts,
spectral clustering method,
non-negative matrix factorization methods.
Then a little beyond homogeneous
networks are heterogeneous networks.
This kind of network consists of
multiple types of nodes and edges.
Like bibliographical data, hospital, you
know, handling disease patients, doctors,
and treatments to cluster different
kinds of nodes and links together.
There's some interesting algorithms,
like a NetClus algorithm.
Uncertain data means
the data may contain noise,
may have approximate values or
multiple possible values.
Usually, we need to incorporate
some probabilistic information
like distribution or
approximate values, where that will
improve the quality of clustering.
Finally, recently,
there are lots of discussion on big data.
That means we can model
systems that may store and
process very big data
like weblog analysis.
Usually like Google's MapReduce
framework you
have map function to to distribute
the computation across many machines.
Then have Reduce function, to aggregate
the results obtained from the map stat.
So, we can see that the data is very rich.
That's why the clustering is rather
sophisticated methodologies.
You know trying to handle
different kinds of data.
[MUSIC]

