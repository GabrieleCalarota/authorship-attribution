[MUSIC]
Now, we introduce the concept
of pattern-based classification.
Pattern-based classification
means we use the frequent and
discriminative patterns to
do effective classification.
Wh, what is pattern-based classification?
If we can see it's pattern-based mining,
like a pattern discovery, this is
one messed knowledge in data mining.
Classification is another messed knowledge
in data mining, mission learning and
the statistics.
If we effectively mine interesting
patterns, we use this patterns
to serve as good classifiers,
or help classification process.
That one we call
pattern-based classification.
Philosophically, this is
an integration of both schemes,
pattern discovery and classification, then
we work on a pattern-based classification.
But why we want to do
pattern-based classification?
One interesting thing is patterns
actually usually is a little longer,
like you know, frequent one itemset,
two itemset, to k itemset.
This is a feature construction process.
We can get, you know,
start from single feature.
We can construct multiple features
together, you get higher order, but
they could be discriminative,
they could be compact as well.
Just give you a simple example.
Suppose in many cases you just give
a single word, ask people what it is.
Sometimes it's very hard to say.
For example, apple.
I actually do not know whether you mean
for apple, whether apple is a fruit or
whether Apple is a company,
or something else, 'kay?
But if you give me a phrase,
that means you combine multiple words
together, take that one as a feature.
For example, you give me apple pie, or you
give me another one, say apple iPad, okay.
Immediately, I have no
ambiguity to interpret what do
you mean this apple because apple pie,
this apple is a fruit.
But Apple iPad, this Apple is a company.
That's a product, okay.
So in that sense,
we say feature construction
constructs a higher order feature.
If they are very discriminative,
very telling, it is worthwhile, okay.
Another important thing for pattern-based
classification is we will be able
to use complex features,
for example, graphs.
If you say what, the graph is rather
complicated, whether it should be
a feature, whether this nitrogen
is a feature, oxygen is a feature,
or whether their structure is feature,
there are so many possibilities.
So it's pretty hard to capture
the most important features.
The similar thing happens in sequences,
in semi-structured/unstructured
data like images or text.
We may, see,
give you one example of the graphs.
Suppose we have three graphs,
they are labeled, one labeled as inactive,
the other one says active,
the third one says inactive again.
For example, for cer, for
designing certain drugs,
you will want to find active components or
active, active ingredients, okay?
Then, if you think this
structure is rather diverse,
it's pretty hard to analyze,
what about we do a little pattern mining?
Suppose we said minimus,
minimus support is two?
Okay, then we may be able
to find two patterns.
One is marked as blue,
the other was marked as red, okay.
With this structure, we may be able to,
to say this red one is su, su,
substructure is g sub 1.
This blue substructure is g sub 2.
Then we may be able to transform
these graphs into a small table.
The table actually you can see,
we have two features, g sub 1, g sub 2.
We have one cla,
class labeled as attribute.
We have 0 means inactive, 1 means active.
Okay, if you change this set of graphs
into a small table,
which contains just features and
a class label, for classification,
this become much, much easier task.
That's the reason,
if we do pattern-based classification,
we transform some complicated things
into a set of clear discriminative
patterns we will be able to perform
more effective classification.
Then we're going to dis, discuss
a little more on these pattern-based
classification or some people call
this as associative classification.
The philosophy is if we get a set of data,
it could be transaction data,
micro data, sequence of graphs,
many things,
text, if we can find patterns or
association rules we will
be able to construct good
classification models.
I'm going to introduce you a few
pieces of interesting work.
For example CBA, or
we say classification-based associations,
was done by Bing Liu et.
al.
In KDD 1998, their philosophy
is to use high-confidence,
high-support class association
rules to build classifiers.
Another interesting study,
is by Guozhu Dong and Li eh,
published in KDD 1999,
called Emerging Patterns.
They used those patterns to
support changes significantly
between the two classes,
then to do effective classification.
Another interesting study was by us,
back in 2001 at ICDM, called CMAR.
This classification based
on multiple rules, okay.
The, that means we,
instead of using one rule to make
a final decision we use multiple rules.
CPAR was done by us in 2003
was using beam search on
multiple prediction rules.
Another interesting study was
done by Cong at SIGMOD 2005,
construct a classifier idea called
RCBT is to build a classifier
based on mining top-k covering rule
groups with row enum, enumeration.
This is for high-dimensional data like for
some bioinformatics data.
It shows amazing accuracy
on classification.
There's also a study on how to
construct a lazy classifier.
That means for a particular test t, we can
predict the training data D on this t,
then mine rules from this D sub
t to predict on the best rule.
Finally we're going to introduce another
interesting study is using discriminative
pattern-based classification to do
effective classification, okay.
So this one is done
Hong Cheng in ICDE 2007.
Those marked in green
are the several typical example
we will study in more detail.
[SOUND]
[MUSIC]

