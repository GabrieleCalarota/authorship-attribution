[SOUND] Now we come down to compare
those Null-Invariant Measures.
So which one is better?
We know,
we probably can sense that not all
null-invariant measures are created equal.
So, we want to see which one's
better in all the cases?
Let's examine the two
variable contingency table
the transactions containing milk and
a coffee.
Let's look at a case in this data set.
So the first, you look at D1 and D2.
D1 and D2 you probably can see
the differences are only on the number
of null transactions, but
you also can see very likely milk and
coffee should get together,
they should be positive.
In that sense, you probably see,
all those 5 null-invariant measures,
they give equal value
in the sense no matter
how many transactions on the null part,
okay, they do not change their value.
And also, they are very close to one in
the sense these are possibly
getting together.
Then you look at D3.
D3 means, mc getting together is
quite rare because they get along,
actually, it's more frequent.
In that sense, all the other
values are very close to zero.
And then you look at D4.
D4 says, mc getting together or
mc alone, they are all like 1,000,
1,000, and 1,000 cases.
No matter how many null transactions.
They actually does things right in the
middle, this 0.5, 0.5, only Jaccard, 0.33,
actually this, in Jaccard this one means
it's balance is right in the middle.
Then we look at three cases,
it could be D5 and D6.
D5, if you see, this is 1,110 cases.
So, what you probably can see
is from coffee point of view,
like a coffee guy may say, oh, mc are
likely getting together because they get
along, its 100 cases buying coffee but
not milk.
1,000 cases,
they buy both coffee and milk.
But, for a milk guy, they probably say oh,
they are very unlikely getting
together because I've got 10,000
cases buying milk but not coffee, but
only 1,000 case buying milk and coffee.
So, in that case you look
at different measures.
It's interesting, you see AllConf and
Jaccard, they also say
it's closer to zero.
Yeah, unlikely getting together.
But MaxConf says, it's close to one,
they are very likely getting together.
Then we look at Kulczynski said I'm
right in the middle because the tug of
the war each side is ten to one.
And then Cosine said I'm a little
prone to unlikely getting together.
Now, we change this one even more.
This is 1,000 to 10 or 1,000 to 100,000.
The coffee guys said they are very,
very likely to getting together.
But, milk guys said that they are,
very unlikely getting together.
Now, in this case you probably can see,
AllConf and
Jaccard dropped down to 0.01, and
even Cosine dropped down to 0.1 but
in MaxConf says I'm very confident they
are very close to one because they
are very likely getting together but
a Kulczynski said I'm still in the neutral
because this is 100 to one the other is
is one to 100 they have the equal ratio.
So which one do you like?
So, probably we can see D4 to D6
are the real cases that differentiate
the 5 null-invariant measures.
But we probably can see Kulczynski measure
holds firm when in this very imbalanced
cases, but the ratio is balance on
both sides and it holds firm at 0.5.
That looks interesting.
But on the other hand, we also know
those cases some are very imbalanced.
We may want to introduce another
measure for Imbalance Ratio.
The Imbalance Ratio is introduced in
the sense, the support of items at A and
support of items at B.
Their differences play important role
in this imbalance ratio computation.
Then you proceed for
the same cases in the last of three,
the Kulczynski measure holds firm, at 0.5.
But the imbalance ratio, okay, the, the,
D of 4 cases is 0 because
they are really balanced.
And D of 5 cases becomes 0.89,
they are rather imbalanced.
And, D of 6 cases,
it is a very imbalanced.
So, imbalanced ratio really can show you,
you know, how balanced the two sides are.
So, we feel Kulczynski
plus imbalanced ratio,
these two things getting together
will present a clear picture for
all these three data sets, D4 through D6,
because D4 is neutral imbalanced.
D5 Is neutral but inbalanced and
D6 is neutral but very imbalanced.
Finally we are going to show
you some real data sets,
like the DBLP data sets, we will want
to look at coauthor relationships.
So let's look at this table.
This table we got around the year 2007.
We study the recent database
conferences we look at those Authors.
They publish papers and they coauthor
papers in database conferences.
But you probably can see
the interesting thing is for
example, you look at
Hans-Peter Kriegel and Martin Pfeifle.
Martin Pfieffle got 18 papers, but
all of them are with Hans-Peter Kriegel.
Hans-Peter Kriegel got 146 papers,
18 was with Martin Pfieffle.
What can, you can see in that case is
Kulczynski shows pretty strong value.
That simply says they're,
these two authors are closely
tied together in some way.
But they are imbalanced, as well.
You probably can see the imbalanced ratio.
Using the calculator,
imbalance ratio is reasonably high.
So in that case, you probably can
easily judge Hans-Peter Kriegel likely
to be the advisor of Martin Pfeifle.
So using Kulczynski and imbalanced ratio,
we can easily find advisor-advisee
relationships and the close collaborators.
In one research paper on
finding advisor-advisees we
are really using those measures to
find them with really high accuracy.
So, finally,
we will show you a bunch of papers.
These are the papers quite
a representative on how to
judge the correlation relationship.
The different measures including
the interesting measure on
the null-invariant ones and the measure
we discussed on the Kulczynski.
Thank you.
[MUSIC]

