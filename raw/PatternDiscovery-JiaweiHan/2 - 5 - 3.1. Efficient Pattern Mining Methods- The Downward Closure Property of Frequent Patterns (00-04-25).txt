[MUSIC]
Hi, in this lecture we're
going to introduce some
efficient pattern mining methods.
Since we already know frequent pattern
is a very important concept and
mining frequent pattern in large
datasets could be challenging.
So then, we are going to study
some interesting principles and
algorithms for mining frequent patterns.
But first, we are going to introduce you
a very property of frequent patterns,
which is called the downward closure
property of frequent patterns.
Let's look at this simple
transaction database, TDB1.
It contains only two transactions,
T sub 1 and T sub 2.
Suppose we get a frequent
itemset a1 to a50.
Then we actually can clearly
see all its subsets like a1,
a2 or
a1 a2 is itemset that are all frequent.
Then you may wonder,
there may, must be some
interesting hidden relationships
among different frequent itemsets.
Actually, there is one called downward
closure property of frequent patterns,
which is also called the Apriori property,
okay?
Now, let's look at this.
Suppose we know {beer, diaper,
nuts}, this itemset is frequent.
Obviously {beer, diaper} should be
frequent as well, because any transaction
which contains {beer, diaper, nuts} must
also contain {beer, diaper} as an itemset.
That's why the {beer,
diaper} as a itemset should be at least
as frequent as {beer, diaper, nuts}.
So we can easily derive this property.
Said any subsets of
a frequent itemset must be
frequent if we keep the minimal
support ratio as the same.
So in that context, we can derive
an efficient mining methodology.
The general philosophy is this.
If you find an itemset S,
any of its subset is infrequent,
then there's no chance for S to become
frequent because based on this Apriori
property, then we do not even
have to consider to mine S.
This actually turns out to be
a sharp knife for pruning.
So, this Apriori pruning and,
based on this,
it generates quite a lot of
scalable pattern mining methods.
So the first Apriori pruning principle
was discovered by Rakesh Agrawal and
Srikant in VLDB 1994.
Heikki Mannila in KDD 94 workshop
also generated a similar methodology.
The methodology generally
says if there's any subset,
any itemset which is infrequent,
then it's superset should not even be
considered or not even be generated.
Based on this,
there are three major approaches
developed in subsequent studies.
One essentially is Apriori.
The first representative
work was published in
VLDB 1994 called level-wise,
join-based approach.
Another method was
developed by Zaki et al.
and what they got, called Eclat,
is based on vertical data format.
Then the third approach
essentially is pattern-based.
It's frequent pattern projection and
growth.
Pattern growth approach or FPgrowth,
developed by us in year 2000.
[MUSIC]

