[SOUND] We have learned support and
confidence,
these two measures are not sufficient
to describe association rule.
So the problem becomes,
what are additional interesting measures
good enough to describe the relationships?
So that's the reason we want to examine it
a little more like lift and chi-square,
whether they are good enough to describe
us additional interesting measures.
So lift has been popularly
used in statistics as well.
We look at the same table.
Okay?
For the same table we can think
B means playing basketball,
C means eating cereal, so
we have the exact same distribution.
Then for this conditions table,
we can use lift to compute it.
The lift is defined as this,
B and C are two item sets.
And for rule, B implies C, that confidence
if it's divided by C support, we get lift.
Or we can say if BC, these rules support
divided by B support times C support.
Okay?
So for this lift, the general rule
is if the lift is 1,
then these two items are independent.
If it is greater than 1,
they are positively correlated.
If it is less than 1,
they are negatively correlated.
For our example data set,
we were calculating lift of B and C,
and B and not C, we derived 0.89 and 1.33.
Okay?
Then from this data sets and
the rules, we probably can see, B and
C should be negatively correlated
because the lift is less than 1.
B and nought C are positively correlated
because the lift is greater than 1.
This actually fix our problem,
because we know, B and
C should be negatively correlated, B and
nought C should be positively correlated.
So this looks so very nice.
Let's look at another measure,
popularly used in statistics as,
as well, called chi-square.
In chi-square, the definition,
we need to calculate the expected value.
Okay, how to calculate the expected value?
If we can see, this 400 is a real value,
its observed value.
But expected value is just
based on the distribution.
For example, C and
not C the distribution is 700 over 250.
This is 3 to 1.
Among 600 stu, students, 3 to 1,
you will get 450 versus 150.
In that case we probably can see,
we still can use the popular,
the rules like if chi-square
is 0 they are independent.
If it is greater than 0,
they are correlated,
either positively or negatively.
So we need additional tests to,
to see whether they are positively or
negatively correlated.
Now for our example we can easily
calculate chi-square should be almost 76.
So, B and C should be correlated.
Further we'll consider they are negatively
correlated because the Expected value
is 450, the observed value is only 400,
it's a less.
So these things can solve
the problem as well.
But the problem becomes whether lift and
the chi-square are good in all the cases.
Let's examine some interesting case.
In this case, you probably can see this
not B, not C actually is quite big.
There are 100,000, okay?
These actually called null
transactions because they're
transactions contain neither B nor C.
And if we just look at B and
C relationship, we probably see B and
C should be negatively correlated, because
it's not easy to get B and C together.
B and not C is far bigger,
C and not B is also far bigger.
But, if we use lift,
we compute the lift of B and C,
we will get this 8.44 which
is far bigger than 1.
That's just B and C should be
strongly positively correlated.
This seems not right.
Even we try to use this same contingency
table, we add the expected value,
we do the computation,
we will find chi-square is bigger than 0.
In the meantime, the observed value
is far bigger than expected value.
So, we also should say B and
C are strongly positively correlated.
This seems to be wrong.
What's the problem?
Actually there are too
many null transactions.
That may make things distorted.
We need to fix it.
[MUSIC]

