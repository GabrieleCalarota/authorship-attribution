[MUSIC]
Now, we are going to discuss
another interesting problem,
Mining Compressed Patterns.
We know frequent pattern mining may
often generate many, many patterns but
in many of such patterns may
share some similarity, maybe very
scattered but, you know, not so meaningful
if you generate all those patterns.
Let's look at such an example,
suppose we finally get five pattern IDs,
so you perceive these five patterns,
are like P1 and
P2, they are very similar and
their supports are also very similar,
but P2 and P3,
they are similar in item sets, but
their supports are rather different,
can we compress them?
When we first examine closed patterns,
actually for
closed pattern,
there's nothing that you can compress.
The reason is closed patterns require
the supports are identical then you can
compress them.
But, none of them have identical support
counts, so nothing can be compressed?
What about max-pattern?
Of course we can use max-pattern like
P3 to represent all the patterns, but
on the other hand, you'll probably see P3,
this support is rather different
from all the others so
with P3, you may lose a lot of information
on the support of other patterns,
so the desired output actually is P2,
P3 and P4.
The reason people can see, is P1 and
P2, they share a similar item sets,
and also they share very
similar support counts,
so we may need a good measure to
see what things can be compressed.
The good measure could be
pattern distance measure.
We use this definition to
define the pattern business.
You probably can look at P1 and
P2 in the, when we look at this.
P1 and P2, their transaction,
intersection of their transaction ID.
What should be the count?
The number of transactions you can
intersect, actually a smaller one here
because every transaction containing
P2 must also containing P1, so
their support counts intersection should
be this number, 'kay, what about the unit?
The unit actually says all those
transactions, because we know all
the transactions P1, must also
containing the transaction of P2,
so their unit number should
be this number, okay?
In that case, we proceed these two numbers
very close to 1, then the distance,
1 minus this very close to one number
you'll get something very close to 0.
That means their pattern
distance is rather small.
Based on this we probably
can see we may be able to
define a delta-clustering or delta-cover.
That means if we can see the pattern, P,
the delta-cover of pattern P
is finding those patterns.
All the pattern can be expressed by this.
The distance is within delta.
Actually, you pretty see P2 is a good one,
because P2 essentially can cover
P1 because P1 just to have a little
less item sets, but their support is so
close to that extent we may say
they are within this delta-cover.
'Kay, so for delta-clustering,
we'll be able to cluster P1, P2 together,
using P2 to represent the pattern, so
that means if we do this delta-clustering,
then all the patterns in the cluster
can be represented by one pattern P.
So the problem becomes whether
we should mine all the patterns,
then compress them or we should directly
mine these compressed patterns.
Actually, there's a efficient method
which can directly mine those
compressed patterns.
I'm not going to get into the detail, but
you may refer to this interesting paper,
okay.
Then another interesting thinking
is Redundancy-Aware Top-k Patterns,
okay, that means, we want to get
a desired pattern, which is similar to
the compressed one is we want to get
high significance and low redundancy.
These kind of set-up patterns.
Okay, let's look at this a, b, c, d,
four different kind of compression.
Actually a is a set of original patterns.
Their clusters shows their
pattern distance and the,
the color the,
high color show it's more significant.
The lighter shows it's less significant,
'kay.
In that case you probably can see in this
bigger cluster there are three patterns.
They are quite significant.
If you just do the top-k pattern mining
that means you, you take the support
count or other significant measure,
you will only find these three patterns.
Suppose you want only find top three,
then all the remaining patterns like
here in the other cluster is
completely missing but if you say,
I just do the summarization,
try to find, you know, clusters, and
within each cluster, try to find
their centers, then you'll very well
find those less significant patterns,
so this may not be a good balance.
Actually, better balance is you
take care of both significance and
the redundancy simply says,
you look at this, this one.
There is something very significant, and
they are also in the cluster center,
you may want to show these patterns,
in the mean time suppose you can only
show three, you may show these
are significant and less redundant.
This one is significant and
also it represents this cluster,
so the problem becomes how to develop
efficient and effective methods,
finding such redundancy-aware
top-k patterns.
There's an interesting study which
uses Maximal Marginal Significance to
measure the combined
significance of pattern and
develop efficient method
to mine such patterns.
We are not going to get
into detail of this method,
interest in readers may read
the paper we pointed out.
Thank you.
[MUSIC]

