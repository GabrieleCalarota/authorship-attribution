In this last session,
we're going to compare the three
strategies we just did discussed.
We will do a little quantitative analysis.
The first interesting thing
is running efficiency.
We probably see,
if you look at these several methods,
we still summarize into
three different strategies.
Then because PDLDA, Turbo Topics, and
TNG will do more sophisticated analysis,
so their
computational, you know, time may take
longer, that one you probably can see.
Then LDA actually is very fast and
efficient compared to the others.
But LDA only considers single words,
unigrams.
So KERT and ToP-Mine,
the major difference is,
KERT first doing LDA,
then combining them into phrases.
But ToP-Mine, first generate
the phrases based on frequent
pattern mining and significant test,
then doing phrase LDA.
You're going to see, for running
time-wise, the last of three is fast but
comparatively, the ToP-Mine is
still generated very efficiently.
Thus, you may wonder ToP-Mine
actually take phrase LDA,
the sub part,
the second part of processing.
Why ToP-Mine can in many cases,
can be even slightly faster than LDA?
Just because ToP-Mine wants
you first generate phrases,
with the number of phrases usually
is less than number of words,
so you have less number of
units to be considered.
That's why may run a little
faster even than LDA.
Then we look at the results,
the quality of the results,
the first thing we want to see
is the coherence of topics.
That means which topic that generated the,
the phrases more coherent.
Then actually Top-Mine go to
the highest coherent Z score.
The Turbo Topic actually generated
also not bad and the KERT is not bad.
But the Top-Mine generated
the highest one.
Then PDLDA and TNG, the coherence
of the topics may not be as good.
Then we look at phrase intrusion.
What is phrase intrusion?
Phrase intrusion means you may
take phrases in one topic and
put it into another topic.
Then you see whether people can
recognize this one as intruder.
For example, suppose we have two topics,
one's topic A, another's topic B.
You take some phrases in topic A,
you throw them into topic B,
then you ask people to judge.
Which one likely, could be the intruder?
If you correctly recognize
those intruders,
simply says, these topic is very distinct,
a human can distinguish them.
It, that means the topic you generated
actually is pretty high quality.
So you probably can see,
we use a human to do the test.
The ToP-Mine have the highest value
average number of correct answers.
The Turbo Topic is not bad.
This is based on the ACL proceeding
on 20 conference, these two copra.
So what you can see here is the TNG and
PDLDA,
their average number of correct
answers may not be as high.
Then we look at the phrase quality,
that means whether they generate
the phrase, as in better quality.
Then we also measure the mean Z-score.
Then you see ToP-Mine, the phrase quality
is the highest then Turbo Topics.
Then TNG, but the KERT and the PDLDA,
their phrase quality may not be as high.
So, in summary, we, we study the three
strategies on topical phrase mining.
The first one is we do sophisticated
analysis, try to do the bag of words,
inference in the meantime,
try to generate the sequence of tokens.
It is integrated, but
it is a complex model.
The phrase quality and
topic inference really rely on each other.
That means whether you generate
better quality phrases,
you may generate better quality
inference or vice versa.
So it is slow and
it tends to be overfitting.
The Strategy 2 is first
do topic model inference.
Then try to combine three,
them into n-grams with each topic.
So the phrase quality really relies
on the topic label for unigrams.
That means if those two unigrams,
even they look like a phrase,
if they are,
even they carry different topic labels.
It's impossible to merge
them to generate phrases.
It can be fast, generally it may
generate high-quality topics and
phrases, but it may not be so stable.
The Strategy 3 is first,
we mine phrases using frequent patterns,
using significant test.
Then we impose the phrase on the RDA so
we do,
that means we do the prior bag-of-words,
topic inference.
We generate phrases first.
Okay?
Then measured the topic inference rely on
the correct segmentation of the documents.
But they are not sensitive because
using frequent pattern mining and
segmenting task generate phrases
in general, are in high quality.
Okay?
So, it can be fast.
You, you can generate good
quality topics and phrases.
Okay?
Then we list a bunch of papers we actually
lectured or referenced in this lecture.
If you want to go deeper,
you may like to dig in into those papers.
This is a pretty dynamic
research frontier.
You actually can see the interesting
applications of frequent pattern mining
[MUSIC]

