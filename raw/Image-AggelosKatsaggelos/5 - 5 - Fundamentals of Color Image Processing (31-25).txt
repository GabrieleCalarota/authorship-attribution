Welcome back there are too many reasons we
are considering color.
The first one is that color is a
powerful descriptor that can be used for
various tasks.
Such as segmentation, object detection,
tracking and identification.
The second one is that humans can
distinguish thousands of color shades
and intensities as compared to about only
two dozens shades of gray.
In this segment we first discuss the
characteristics of light.
Based on the absorption characteristics of
light, we define the colors
red green blue and the secondary colors of
cyan magenta and yellow.
We also discuss the primary colors of
pigments, which are cyan
magenta and yellow, and the secondary
colors of pigments, which are RGB.
We define the color distinguished
characteristics of brightness, hue and
saturation.
After that, we discuss color models, which
allow us
to specify colors in some standard and
generally accepted way.
We described the most commonly encountered
models of RBG, SMY, HSI, and YCbCr.
We also briefly addressed the independent
versus joint color procession approaches.
For the various aspects of our discussion,
we also showed some Explain the examples.
So let us proceed with this last exciting
and colorful segment of week four.
The use of color in image and
video processing is motivated by two
primary reasons.
The first one is that color is a powerful
descriptor.
Which can be used for various tasks
such as segmentation, object detection,
tracking, and identification.
You will see examples of these as we move
along.
The second reason is that humans can
distinguish thousands of color shades and
intensities As compared to about only two
dozen shades of grey or grey scale images.
For these two reasons color is an
important attribute in
image and video processing and we just
want to cover some of the basic
properties and basic ways to present color
In this segment.
Issac Newton in the mid 17th century
discovered that
when a beam of light passes through a
glass prism.
The light that comes out is not white but
consists of instead of a continues
spectrum of colors, ranging from violet
And the one end to red at the other end.
So, I showed in this figure that the color
spectrum may be divided into six broad
regions; violet, blue, green, yellow,
orange And red.
No color in the spectrum ends abruptly,
but
instead each color blends smoothly into
the next one.
The color you perceive of an object has to
do
with the nature of the light reflected by
the object.
If the object, for example, appears green.
Then the object absorbs the energy in all
regions of the visible part of the
electromagnetic spectrum except in this
range 495 to 570 nanometers.
In which the light is reflected by the
object.
Light can be characterized as achromatic,
without color.
In which case the only attribute of
achromatic
light is intensity or the amount of light.
Or it can be characterized as chromatic.
With color.
In this case, the characteristics are the
radiance, which is the
total amount of energy that flows from the
light source, and it's measured in watts.
It's also characterized by luminance.
Which is the perceived amount of energy,
and the unit is lumens.
So, for example, if energy is emitted in
the
far infrared region, it might have a lot
of
energy, a lot of radiance, but it is
hardly
perceived by the viewer, and therefore its
luminance is zero.
And it's also characterized by brightness.
This is hard to measure and it includes
the achromatic notion of
intensity and by and large brightness is
used to describe color sensation.
Cones In the eye are responsible for color
vision.
There about six to seven million cones.
It has been found experimentally that the
cones can be divided
into three principle sensing categories
which correspond roughly to the RGB.
Categories.
So, 65% of the cones are sensitive to red.
33% of the cones are sensitive to the
green light.
And the remaining 2% are sensitive To look
at this new category of light.
Although the blue cones are the most
sensitive ones.
So this figure shows the average
experimental curves that deal with
the absorption of light by the RGB cones
in the eye.
Due to these absorption characteristics of
the human eye.
Colors are seen as variable combinations
of the so called primary colors, the LGB.
For, the purpose of standardization, this
body CIE, which stands for.
Commission
International
de l'Eclairage
designated in 1931 the three primary
colors.
For the blue at 435.8
nanometers, for the green
546.1 nanometers and for the red 700
nanometers.
The
standard was set before the experimental
gaps that are shown
here became available and this is why
they're this discrepancy.
We see here that the absorption of the
blue peaks at 445.
While the designation by CIE was at 435.8
and so on and so forth.
So RGB are the primary colors, but if
we think of this standardized color at
these fixed
frequencies either this one or this ones
it doesn't
matter These fixed frequencies cannot
generate the visible colors.
The interpretation of primary colors is
correct if we allow
the wavelength also to vary as shown by
the gaps here.
The three primary colors we just
mentioned, RGB Can be added to produce
the secondary colors which are the cyan,
magenta, and yellow.
If we mix the three primary colors we'll
obtain white.
We'll also obtain white If we mix
a secondary color with its opposite
primary color.
So, magenta is the secondary color, and
the opposite primary color is green.
So, this is again the intersection between
magenta and green.
It's the white color.
So this is the additive model of the
colors.
And its used for example in color
television,
when we use CRT or a flat panel.
This is an example where we have separate
guns for RGB and its that combination.
That will allow the generation of more
possibility of colors.
The primary colors of pigment is defined
as one that subtracts or absorbs
the primary colors of light and reflector
transmit the other two, so.
For example, cyan equals 1 minus red,
we assume here that all the values are
normalized in the zero to 1 range.
So if we have a surface that is coated by
pure cyan, then this
surface It reflects light that does not
contain red so red is absorbed.
So the primary colors of pigments are the
magenta, cyan, yellow
and the secondary colors are red, green
and blue.
A proper combination of these three
pigment primaries,
generates black.
And black is also generated if I combine a
secondary such as green.
With its opposite primary, which is
magenta.
And this is referred also as the
subtractive model of color.
Here the distinguishing characteristics of
color.
The first one is brightness which we also
showed a couple of slides earlier.
As we said there it is hard to measure but
it's used to describe color sensation.
The second characteristic is hue.
It indicates the dominant wave length in
this mixtures
of light wave And the third one is
saturation.
It tells us about the relative purity of
the color or
the amount of white light that is mixed
with the hue.
The pure spectrum colors are fully
saturated Colors such as
pink, which is a combination of red and
white is
less saturated, and in general the degree
of saturation is
inversely proportional to the amount of
white light that is desending.
So if we add a little bit of white light
then it's.
Quite saturated you had a lot of light
that the grey separation is much less.
The amount of RGB to follow particular
color are called
the tristimulus values and are denoted by
capital X, Y, Z.
The color is then specified by it's
Trichomatic
coefficients in order by lower case x, y,
z.
We can obtain the trichromatic
coefficients according to these
relationships.
So little x is the proportion to big X
with respect to the sum of the tristimulus
values.
Really if we adopt the trichromatic
coefficients they add up to one.
So given a wavelength of light in the
visible spectrum.
The tristimulus values that are needed to
produce
the colors that corresponded to this
wavelength Can
be obtained direct either from curves or
from
table that can be combined from extensive
experimental results.
Another approach is to use the CIE
chromaticity diagram, shown here,
which shows that chemical composition as
function of x in the horizontal axis.
Which represents red and Y in the vertical
axis which represents green.
Clearly the value of Z which represents
blue is
can be found from This relationship is
often the relationship down here.
The point marked green here is about 62%
green,
25% red and the remaining Remaining 13%
blue.
The various spectrum
colors from the violet down here, at about
380 nanometers to red at 780.
Nanometers are located on the boundary of
this tongue shaped diagram here.
These are the pure colors in the spectrum
as we discussed earlier and any point
not of the boundary but within the diagram
represents a mixture of spectral colors.
The point of equal energy here
corresponds to equal fractions of the
three primary
colors represent the CIE, standard for
white light.
Any point of the boundaries of this
chromatic chart is fully saturated.
As the point leaves the boundary and
approaches this point of equal energy,
more white light is added to this point
and therefore it becomes less saturated.
And the saturation of this point of equal
energy is equal to zero.
The purpose of the color model which is
also called a color space or a
color system, is to facilitate the
specification of
colors in some standard and generally
accepted way.
So a color model specifies a coordinate
system and a subspace
within that system where each color is
represented by a single point.
The leading models in image and video
processing are the RGB, red green blue
model, which is suitable to describe color
monitors and video cameras.
The cyan magenta yellow, and cyan magenta
yellow and black.
CMYK for black which is suitable model for
color printing.
The HSI hue saturation intensity model,
which corresponds closely with the
way humans describe and interpret color,
and also the YUV and
YCbCr model Which is used primarily for
beta compression applications.
The actual model is based on the Cartesian
coordinate system.
The algebraic primary color are these
corners, red, green and blue.
The secondary colors are these other
corners, cyan.
And magenta, yellow, white is at this
corner and black at the origin.
The points of equal RGB extend from the
black point to
the white point so these are the grey
scale values of equal RGB.
Here is the 24-bit color cube the surface
of it.
2 to the 24 is equal to
16,777,216 different colors.
As already discussed Cyan magenta yellow
are the secondary
colors of light or the primary colors of
pigments.
So when for example a surface is coated
with cyan pigments and is illuminated with
white light, no red light is reflected
from the surface, and cyan is 1 minus.
Spread in this equation we assume all the
values
are normalized in the zero to one range,
right.
So cyan equals one minus red.
So in principle
equal amount sod CMY should produce black
but
in practice they produce a kind of muddy
looking black.
So because of that a fourth color has been
added the black color
we noted by K and this gives rise to the
CMYK color model.
The HSI model The couples intensity
component from the color carrying
information.
It's an ideal tool for developing image
processing algorithms based
on color descriptions that are natural and
intuitive to humans.
There non-linear expressions which allow
us to go from RGB to HSI and back.
It can be found in most text and image
processing, such as the one by Gonzales
and Woods.
Instead of using the equations here let's
try, let's
try to get the feel about the exercise
space.
In this figure we see the primary and
secondary colors.
We've seen this figure actually multiple
times already.
While this figure, we see the hue, the age
component of the first one.
The gray values in this figure correspond
to angles, so red,
for example, corresponds to 0 degrees
angle and therefore is black.
So here's the red and it corresponds
to angle zero degrees and it's in all
black.
In this figure we see the saturation
component of the original image here.
Clearly the primary colors are Fully
saturated shown here in white.
All the values here are critically mapped
in the zero to 55 range.
And finally here we see the I component,
the intensity values which are actually
these values one third of the sum of the
RGB value, yes.
So with a model like this one can
manipulate directly and independently the
H or S or I component and this way one can
change the individual colors.
This is a family of color models.
Where the luminance component Y is
separated from the chrominance components.
YUB is used by the PAL, NTSC and SECAM
color video standards.
So Y is again the luminous component.
Related to that is the Y IQ.
Y the luminous I the int phase and
Q the quadrature component coming from a
modulation scheme.
IQ are linearly related to UV, and
then YCBCr Y get the luminance and
these are the differential chromium
components.This is
combination out of ITU BT.601 and it is
scaled and offset version of YUV.
The linear relationships relating these
three color
models, and each one of them to the RGB
color model.
Here are the equations for the YCbcr BT
601 recommendation.
We see that the luminescence component is
60% due to the green channels.
Channel, 30% to the red and 10% to the B
and again these are the differential blue
and red channels.
Clearly since there is a linear
relationship between YCbCr
and RGB, I can solve for RGB in terms of
YCbCr.
These are the, the formula used by JPEG
conversion.
And, in general, the RGB values for an
eight bit image are in this
range, and the chrominous and luminous
components are force in this range.
So due to the fact again that luminance is
separated from chrominance very often
when processing an image that isn't
preserved
by this model we might carry the
processing.
In, with respect to the y component, while
not processing the
chrominus components, and just adding them
to the process y component.
For example, when we prefer motion
estimation, we
utilize the y component only, the
luminance component.
And the motion vectors that are found are
also utilized to motion compensate the
chrominus components.
We consider here, a color image, and chose
the composition
or representation utilizing the different
color spaces we just covered.
This is sun rise over lake Michigan here
in a cold winter.
This is just south of the north western
campus.
We see here the RGB components of the
color image.
There is a lot of red here where the sun
is rising.
So you see high intensity values.
The green channel comes very close to
representing the intensity
image or the gray scale version of the
color image.
We see here the cyan, magenta, yellow
components of the original color image.
These components are the negative, so the
RGB components
so for example cyan is equal to 1 minus
red.
So where the sun is rise, zing we get high
red
values and we get very low close to zero
cyan values.
We see here the HSI component of the
original color image.
So this is the intensity, it's the gray
scale
version you might say of the original
color image,
while the hue and situation are The the
color
elements or the color components of the
original image.
So we have this separation between
luminous intensity and commonness.
And here we show the luminous Y and the
differential color components CBNCr.
So this is again the grey scale image It
relates to the I
image of the previous slide and also to
the green of the RGB the composition.
This is a different way to separate
luminance and chrominance then the HSI
representation system.
The advantage you might say of YCBCR is
that there's a linear transformation
between RGB and YCBCR.
While the transformation from HSI to IGB
is a nonlinear one.
In processing color images and videos, the
first step is to choose the
appropriate color space is based on the
analysis and the discussion in this
segment.
The second decision is whether to process
each channel, this representation
independently or jointly.
Most of the work in the literature, it's
performed by processing is each channel
independently and
they call channel the RGB or YUV for
example planes or representation of the
color image.
And therefore there is no distinction you
might say between grayscale
image processing algorithm and the color
image processing algorithm.
In the sense again but when we deal with
color we apply the same algorithm
to use for the gray scale image three
times independently to each of the three
channels.
Alternatively one can utilize a multi
channel Now processing
so, in many cases gains are to be held
by capitalizing of the correlation and
complementary information conveyed
by the various color components of the
various channels.
So for example, in image compression, the
standard approach is
to find the motion by working with the
white component.
Out of the video in the YCbCr
re-composition.
Then the same motion is applied to the
chrominus components.
Work has been done and showed that one
can formulate a motion estimation problem
by working with
the three by one vector, where the RGB
for example, components from this three by
one vector.
And by enlarge, more accurate, motion
estimation can be found this way.
Another example and to touch a bit of that
when
we talk about restoration when we do
multi-channel processing again.
We try to capitalize on the between
channel correlation and the pose for,
for example the cross channel smoothness
as well as within channel smoothness.
We show here simple example where RGB and
HSI filtering is compared.
So this is a bled version of the
originally.
You showed earlier a 5 by 5 flat filter
was used in embedding
this image and each of the channels the RG
and B channels was filtered separately.
Here is the image you obtain when we
consider the HSI side of presentation and
only the I component Born in the
intensity component was filtered by this
same filter.
While the H and S component were unaltered
and
and just was were combined with the I
component.
This two images look indistinguishable and
we try to quantify that
by finding I think the difference between
the two, and this is the error, gray, is
equal to zero and it's almost identical,
the two images.
So this is simple example clearly which
demonstrates that if this
filter in a similar operation is what we
are interested in.
Then it would make sense to utilize the
HSI representation and feed it
one, the I channel instead of three
channels the RGB channels.
So, we have reached the end of week four.
During this week We learned some of the
basic
techniques for estimating the motion for
each pixel or
a group of pixels in a video frame, and
also ways to represent a color image in
video.
Some of the motion estimation techniques
are
more intuitive and easier to explain than
others.
So for example the block matching or
original matching technique
which is widely used if not exclusively
for video compression.
Might be the first idea that comes to
everybody's mind
if you spend a few minutes thinking about
the problem.
The fine implementation of details can
always be worked out
later The phase correlation or the
registration approach is are
rather intuitively clear and they are
based on a simple
property of the fully transformed that we
covered in week there.
The special temporal gradian method on the
other hand seem to stem from mathematical
manipulations Taking the [INAUDIBLE]
approximations, and are
not intuitively straight forward, at least
at first.
At the end, however, similar
considerations with the block matching
techniques are taking place, that is the
modeling assumption that
original pixels is experiencing the same
motion Since techniques are
also used widely, especially when a dense
motion field is required.
We also talked about primary and secondary
colors of light, and pigments.
And, we also discussed various models to
represent color.
We described the most commonly encountered
ones, that is LGB, CMY, HSI, and.
YUV, Y the VCR.
We know now that there are different
choices brought
in representing as well as processing in
color videos.
The material of this week is by in large,
not
as demanding as the material from weeks
two and three.
If however you do not feel 100% confident
about absolutely everything covered this
week, do not worry.
We can still use the final motion
estimation algorithm we derived in a
rather straight forward manner or perform
a
transformation from one color space to
another.
Clearly we'll be making use of motion
estimation in various parts of the course.
Especially when we cover video
compression.
Similarly, most data we process nowadays
are indeed in color.
Next week we'll cover an easily explained
and understand and fun
to play with topic in image and video
procession that of enhancement.
So, see you all next week.

