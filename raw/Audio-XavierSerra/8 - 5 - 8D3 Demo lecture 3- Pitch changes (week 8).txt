Welcome again to the course on audio
signal processing for music applications.
This week we're talking
about applications.
We're talking about how to use
the models that we have been studying,
throughout the course, for
the application of sound transformation.
So we aim at manipulating, sounds,
on changing different aspects of it.
In the first demonstration class,
we exemplified the idea of morphine
using the short time for the transfer.
In the last class we
talked about time scale.
How to change the direction of
the sound using the sonar model.
And in this class I want to talk about
pitch change how to change the frequencies
of a sound and
use the harmonic plus the classic model so
we're basically changing the pitch
information off harmonic sounds.
In order to use the harmonic model,
we need to,
understand a little bit, the sound.
So for example,
if we start with this saxophone sound.
Let's listen to this.
[MUSIC]
Okay, in order to define the,
the, especially the window size.
We need to know the ranges of fundamental
frequencies that are present here.
So a good way to do that is to,
look at the spectrogram of, of the sound.
And basically zoom in to
the first harmonic so that we see,
basically the fundamental frequency,
which is the first, line of this,
harmonic series, and kind of see which is
the lowest and highest volumes, in here.
So, it's better to use a bigger window
size so we see a more refined, line.
And with this, okay, we have a pretty
good, view of this line, and
clearly the lowest,
sound would be this note here or less,
so that's around, let me see,
let's say around 450 hertz, and
then the highest is this, note here
which is around 600 and something hertz.
Okay, so, this is a good information for
now, defining the parameters
of the harmonic, harmonic process
fundamentals, s o let's go to the,
the SMS tools, model UI and let's directly
to the harmonic stochastic model.
And we will open this same file, which
is this sax phrase short version of it.
Okay, now we have to
choose the parameters.
So the window black money is a good,
choice because it has a good
low level side lobes.
And now in order to
decide the window size,
well it's good to go to basically go to,
terminal, and
from we can just quickly do calculations,
so for
example we could just say okay the black
window has six beats in the main loop.
You multiply by 44,100, and
we said that the lowest frequency
was around 400 and something Hertz.
So let's you know, to be safe,
let's say okay, 400 Hertz.
So 400 and this is the window size
that's appropriate for a frequency
of 400 the lowest which is a meaningful
one the longest window that we'll need.
Okay so we put as window size
let's say 600 and 61 an odd size.
At 50 size and let's make a big one so
we have zero padding so
that's 2048 the threshold really
doesn't need to be that low,
but but let's leave ti so
we have a lot harmonics there.
The duration of essential tracks that's
fine, maximum number of harmonics.
The maximum number of
harmonics that there will be,
will be 44,100 divided by 400, okay?
That would be,
if it had all the harmonics, is the 110.
But of course,
this is the lowest we can see, and
this is really if we would have
harmonics all the way through.
So, 100 would be fine.
Then, we need to define the range
of the fundamental frequency so,
we can put the one we set, it was around
400, and the other was around 600 and
something, so,
to be safe let's say, 650, okay?
This is, nearest threshold to
identify the fundamental frequency.
Maybe, let's, I'll be a bit more flexible,
let's put seven, and, this deviation,
it's fine like this, and the stochastic
approximation for the residual.
We would need to be too, too wood,
we don't need to to get a compression, so
let's say it would have point 4 or
that should be okay.
Okay, let's, compute it now.
Okay, so this is the result.
We have the original signal, the analyze,
the harmonics plus the stochastic and
the synthesize.
Let's listen to the different components
of it, the sinusoidal component.
[MUSIC]
It clearly captures most of the sound.
Then let's listen to the stochastic.
[SOUND] Well, it's very soft,
but it's there, so,
it's it's a relevant component and
of course, the sound of it too.
[MUSIC]
Okay, so this is a good starting point,
to now run the transformation.
So let's go to let's quit this,
let's try to remember these parameters,
and now we will go to the other directory
where we have the transformations
interface and let's type hyphen and
the transformation GUI.
Okay, so this is the GUI for
the transformations, and
let's go directly to the HPS
model with the transformations,
and well is already by
default the six phases here.
So, let's use the parameters we've used,
if I remember was 661,
we did 50 of 2048.
The threshold was minus 100, saturation
was that, the number of harmonics 100.
This minimum was frequency was at 400 and
maximum was, 650.
At zero detection that zero
error fiscal was seven and
the [x] factor we put volume four.
Okay.
Now we can analyze.
And this will definitely do the same
thing that we did before, so
we can check that the analysis correct.
[MUSIC]
It's exactly the same sound
that we heard before.
So now we can start playing
around with the transformations.
And we have a 2 possibilities for
changing the frequency and
1 for changing the time so for
the time we're not interesting in changing
the time so let's say the time is 0, 0.
One means that, its not changing anything.
Okay, now in frequency scaling,
we have two frequency transformations.
Given that we are, in a harmonic sound,
we know what the harmonics are, and
that's a great advantage compared
with the sinusoidal model.
In fact.
These type of changes could be done
with the same sort of model, but,
of course, then,
we are restricted to some transformations.
And, for example, the frequency
stretching is not possible with the same
sort of model because we don't know
which corresponds to which harmonic.
Okay, let's just first maybe,
let's just use the scaling first.
So, let's just have here, again.
Without any transformation,
so if we put zero,
one, one, one, that means that there
is a frequency stretching of one,
which means no stretching at,
at the beginning and at the end.
And then okay, in the frequency scaling,
now let's start with by downloading or
sort of decreasing
the pitch of this sound.
For example point eight.
And [x] times zero.
We will have point eight and a time one
after we will also have point eight, okay?
A very, important,
parameter is this timbre preservation.
A timbre presentation, what it does,
it tries to preserve the shape
of the spectrum of the harmonic.
It a good one,
it preserves the heart the harmonic shape.
So, it should sound more natural
than if we put zero, In with zero,
we just transpose everything, and
so the magnitudes will be affected.
So let's apply it like this.
Okay, so
we have clearly transposed the harmonics,
down so now they're closer together.
So let's listen to the result.
[MUSIC]
So it sounds quite natural,
even though we have transpose,
mainly because of this tamper preservation
we have maintain quite a bit,
that is, this quality of the saxophone.
And then just to finish let's make some,
frequency stretching we can do stretching
is, is a kind of to convert the sound
into a new harmonic type of spectrum in
which we are adding an exponential factor
to the harmonic value of it let's say.
Think we have zero times zero one, and
say let's start with one and then at
the end let's stretch and also let's say
one point let's say one okay so we will
have a stretching factor at the end and
not at the beginning so progressively
the stretching will increase.
Let's see what that does.
Okay, so we see clearly here that
the fundamental has remained the same,
and the harmonics, while we still have
maintained the, the scaling factor,
so we are scaling everything down to
point eight, but the harmonics kept,
keep, getting apart from
each other more and more.
As, the time goes on, clearly,
the end, they are not equally spaced,
so that's an inharmonical spectrum,
let's listen to that.
[SOUND] Okay, so clearly the,
the low frequency is the same, but
as, as time progresses, the,
the sound, sounds more inharmonic and
is more metallic because the.
The harmonics have been stretched.
Of course we can do a lot of things,
so feel free to play around with
these parameters, and
of course with time scaling.
Time scaling is also very powerful, once
we have been able to analyze the sound,
with the harmonic plus stochastic model.
That's all I wanted to say, So
basically we have talked about
the idea of changing the pitch or
the frequencies of a sound.
At first we use Sonic Visualizer to to
understand the sound and then we the SMS
tools UI with the harmonic model to change
the pitch or the frequencies of a sound.
And we have been talking
about pitch change,
of course pitch change can be done with
the sinusoidal model, can be done with
the harmonic plus stochastic, or
the sinusoidal plus stochastic or
with quite a few of the models
we have been talking about.
And in Audacity also there is
some implementations for that.
So anyways, we just presented a little bit
of that, an example using the harmonic and
the potential for
these types of transformations, so
I hope you got an idea of that and, now
we'll have still another demonstration and
we'll be talking about the harmonic model.
But, in another,
type of transforming sounds which will be
a morphing of two sounds, interpolating
a representation of two sounds.
So, I hope to see you all next class.
Bye bye.

