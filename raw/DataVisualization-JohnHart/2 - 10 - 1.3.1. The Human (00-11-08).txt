[SOUND]
So
visualization is an interface
between the computer and the human.
And to understand visualization,
you really need to understand how a human
perceives what's being
displayed by the computer.
So what will we learn?
We'll learn, we may understand computers,
but we'll learn about how humans work,
specifically, how humans perceive and
process what's presented to them.
How can we use that knowledge to
create a more effective computer
interface for the human?
So I like giving this talk to computer
science students, because computer science
students are largely already
familiar with how a computer works.
But they really don't have
any idea how a human works.
And so we can use what's called
The Model Human Processor
to describe how a human works in
terms of how a computer works.
So here's a computer, this might be
a diagram of a computer that might be
a computer in a cellphone, for example.
You can have a CPU, some central
processing unit, and there'll be memory.
You'll have cache memory and then RAM.
The cache is sort of a short-term
memory that makes the RAM,
the slower RAM run faster for
the CPU, because the cache is faster.
You might have an output processor
that generates graphics or
causes the phone to vibrate or
do other things.
And there might be an input processor,
some media processor
that takes the video input from a camera
and the audio input from a microphone.
And so we can use the same design to
sort of understand how a human works.
And this is called
The Model Human Processor, and
it was invented by
Stuart Card back in 1981
as a way of describing how humans work
to people that work with computers.
And so with the Model Human Processor,
we don't have a CPU,
we have our cognitive processor.
And we don't have a media processor
accepting video input and audio input.
We have eyes and ears that generate
media in a visual image store and
auditory image store that are then
processed by a perceptual processor
before they're processed by
the cognitive process of the brain.
And we don't have cache and RAM, we have
a working memory and long-term memory.
And we don't have a graphics processor and
something that'll vibrate a phone.
We have a motor processor that controls
how our hands work and for example,
how our hands might draw a picture for us.
And in each case,
each of these processes, memories and
processors have certain decay and
cycle times.
Storage sizes that we can discuss
in the same way that we discussed
the storage size of random access memory
or the processing time of a processor.
So first we might look at video
processing, visual processing.
We have an eye.
And the eye takes 230
milliseconds to access,
meaning we need something from the eye,
we get it about 230 milliseconds later.
And that can vary between up to 70 and
to 700 milliseconds.
So we can get things as fast as
70 milliseconds from the eye.
And then we have a visual image store,
and the size is about 17.
And we're going to talk,
not necessarily in terms of bits,
bytes, or words, we're going to
talk about letters or chunks.
And we can store about 17 things
in our visual image stores, and
it depends what those things are.
And the visual image
store is very very brief.
It decays in about 200 milliseconds, and
this 200 milliseconds is our
persistence of the vision.
It's the fact that something
can be flashed to our eye, and
our eye remembers what it sees for
about two-tenths of a second.
And that's enough time for
the perceptual processor to catch it.
It's also enough time to do
certain processes, like reading.
And, so when we read, it may appear,
when you read the text on this slide,
that your eye is moving forward in a very
continuous fashion because it's how we're
processing the information.
And it may seem like we're processing
every letter at a time, but
that's not what's happening.
What happens is we have these saccades
in our eyes jerking from one location
to another.
And we do those very quickly, and
then our eye fixates on a single portion.
And we look at that portion and
the surrounding images on our retina.
And we don't perceive our saccades.
Our eye is jerking left and
right, and we don't see that.
Our perceptual system blanks that
out from our conscious selves.
In terms of reading, we can read
smaller fonts and larger fonts about
at the same rate, although larger fonts,
we probably feel they're easier to read.
We read them at the same rate,
and we still tend to read printed
pages faster than we read displays.
This text on the right shows that
you're not processing every letter, but
you're processing letters in chunks.
And you can still read this even though
it doesn't itself really make sense.
There's also audio processing.
And I haven't drawn the ear yet, but
you have an ear that sends signals
to an auditory image store.
And again, about five letters of
information, five things of information.
And when you hear something, you have
about a minute and a half to process it.
So if you're not paying attention to
something, if somebody's talking to you
and you're not paying attention,
and they say what did I just say?
If they said it in the last one and a half
seconds, then you got a pretty good chance
of being able to recover it
without even thinking about it.
And so, the way that the ear works,
there's an auditory canal
in your ear that focuses sounds,
that vibrates an eardrum.
That basically vibrates some mechanical
structures that then works its way around
a cochlea.
That's basically figuring out what
frequency composes the sound, and
stimulates the cilia,
that then send signals to the rest
of your perceptual system.
And the sound, there's pitch,
loudness, and timbre.
Pitch is the frequency where
in the cochlea it gets sensed.
Loudness is the amplitude of the waveform,
and then timbre is
the shape of the waveform.
And that can differ based, for example,
different instruments produce
different timbres of sound.
We can do stereo location of a source.
We have two ears, and we can do
some stereo location of a source.
But in general, it's not very accurate.
The more important thing is we
have a cocktail party effect.
That means that we can focus on
a particular conversation and
mentally filter out some of
the other noise that's going on.
And humans still do that much better
than computers ever have been able to.
And finally hand-eye coordination, and
this pathway's a little bit more involved.
We have an eye,
a visual image store that's helping
us process the imagery from the eye.
Then a perceptual processor that's
actually doing the processing on the data
in this visual image store.
That gets sent to the brain that
decides what to do with it, and
then the motor processor, the hand.
So we've got this hand-eye coordination
that goes through all these paths.
And you can start adding up the time,
230 milliseconds for the eye.
Another 100 milliseconds for
you to perceive what the eye is seeing.
Another 70 seconds for you to think about
the eye, and another 70 seconds for
your hand to respond to
instructions from your brain.
And so you can use that to figure out
how long it takes for you to react or
how long it for you to move the mouse.
If I have the mouse in some location,
and I want to move the mouse,
say to this figure's head.
I can figure out how long it's
going to take me to do that.
And this is based on several
properties of the human kinesthesis,
the fact that we know where are limbs are.
We know where our fingers
are bringing things to.
And also the fact that
larger movements are faster.
I can move the mouse quickly across
the screen and click as well.
I can move the mouse quickly across
the screen, but I do it less accurately.
And so we tend to, when we're finding a
target, like if I want to find the center
of the 0 in that 70 milliseconds,
I move quickly towards the 0.
But then I have to do a series
of finer and finer steps.
So we do large lunges followed
by finer and finer refinements.
And so that gives us a logarithmic
rate at which we find things.
And so if I need to move things farther
than the distance, D gets larger.
But if I need to get to a smaller object,
then the size matters as well.
So I need to divide by the size.
If I need to point to a larger thing,
it should take me less time.
So, it's one 1 over the size.
So, the distance / the size gives
me an indication I can point
to larger things farther away as fast as I
can point to smaller things closer to me.
And we take the logarithm,
because the number of steps I need
is based on this distance / size.
I'm taking shorter and shorter steps.
So this is a log base 2.
And then we have 240 milliseconds it
takes for each one of those lunges.
240 milliseconds is 70
milliseconds to move your hand.
It takes you a 100 milliseconds to be
able to see the result of your lunge, and
then another 70 milliseconds to decide
how to correct it with your next lunge.
So 70 milliseconds to move the hand,
100 milliseconds to see the result.
And then, another 70 milliseconds to
figure out what the next instruction
to your hand ought to be.
That's 240 milliseconds on average.
And then you need about 600 milliseconds,
six-tenths of a step, just to prepare
yourself to be able to do this exercise.
So this is a rough
approximation called Fitt's Law
that tells you how quickly it
should take you to move the mouse
to a certain region of the screen based
on where the mouse is to begin with.
So what did we learn?
We learned that the Model Human Processor
is a way of describing the human
to people that work with computers.
And it helps us now as we figure out
how to model the human when we're
presenting the human with various
data visualization presentations.
And that we deal with data in chunks
not necessarily bits, bytes, or words,
but chunks, and
they're very abstract chunks.
And we can use this model and all of its
terms in order to make predictions on
performance and also to provide insight
into how we can improve performance.
[MUSIC]

